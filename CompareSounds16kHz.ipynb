{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Audio Samples Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy import signal\n",
    "import essentia\n",
    "import essentia.standard as esstd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import cm, colors, LogNorm\n",
    "\n",
    "# %matplotlib notebook\n",
    "# %matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (15, 6) # set plot sizes to something larger than default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchaudio.set_audio_backend(\"sox_io\")\n",
    "sample_rate = 48000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dc_offset(pred, target):\n",
    "    pred_offset = pred.mean()\n",
    "    target_offset = target.mean()\n",
    "    dc_offset = pred_offset - target_offset\n",
    "\n",
    "    # Smallest quantization step for 16-bit audio\n",
    "    quantization_step_16bit = 1 / 32767.0\n",
    "\n",
    "    # Check if the absolute value of the DC offset is smaller or larger than the quantization step\n",
    "    if abs(dc_offset) < quantization_step_16bit:\n",
    "        print(\"The DC offset is smaller than the smallest quantization step for 16-bit audio.\")\n",
    "    else:\n",
    "        print(\"The DC offset is larger than the smallest quantization step for 16-bit audio.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_waveforms(o, t, sample_rate, start, end, title):    \n",
    "\n",
    "    o_zoom = o[start:end]\n",
    "    t_zoom = t[start:end]\n",
    "\n",
    "    # create time vector\n",
    "    time = range(start, end)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(time, o_zoom, alpha=0.8, label=\"Model\")\n",
    "    plt.plot(time, t_zoom, alpha=0.8, label=\"Target\")\n",
    "    plt.xlabel(\"Time (samples)\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"results/plots/{title}_waves.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import ScalarFormatter\n",
    "import numpy as np\n",
    "from scipy.signal import spectrogram, get_window\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def target_output_spectra(o, t, sample_rate, start, end, title):\n",
    "\n",
    "    o_zoom = o[start:end]\n",
    "    t_zoom = t[start:end]\n",
    "\n",
    "    N = int(len(o_zoom))         # Number of sample points\n",
    "    T = 1.0 / sample_rate        # sample spacing\n",
    "\n",
    "\n",
    "    fft_value = 2**14\n",
    "    overlap = T\n",
    "    ratio = fft_value // 4\n",
    "    seg = ratio\n",
    "    w = get_window('blackman', ratio)\n",
    "\n",
    "\n",
    "    freq_o, times_o, Sxx_o = spectrogram(\n",
    "        o_zoom, \n",
    "        fs=sample_rate,\n",
    "        window=w,\n",
    "        nfft=fft_value, \n",
    "        nperseg=seg,\n",
    "        noverlap=overlap,  \n",
    "        scaling='spectrum', \n",
    "        mode='magnitude'\n",
    "    )\n",
    "    freq_t, times_t, Sxx_t = spectrogram(\n",
    "        t_zoom, \n",
    "        fs=sample_rate, \n",
    "        nperseg=seg,\n",
    "        noverlap=overlap,  \n",
    "        scaling='spectrum', \n",
    "        mode='magnitude'\n",
    "    )\n",
    "\n",
    "    # Convert magnitude to dB\n",
    "    o_Sxx_dB = 10 * np.log10(Sxx_o + 1e-10)\n",
    "    t_Sxx_dB = 10 * np.log10(Sxx_t + 1e-10)\n",
    "\n",
    "    average_o = np.mean(o_Sxx_dB, axis=1)\n",
    "    average_t = np.mean(t_Sxx_dB, axis=1)\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(freq_o, average_o, alpha=1, label=\"Model\", linewidth=0.5)\n",
    "    plt.plot(freq_t, average_t, alpha=1, label=\"Target\", linewidth=0.5)\n",
    "    \n",
    "    plt.grid()\n",
    "    plt.xscale('log')  # Frequency should often be plotted on a log scale\n",
    "    plt.xlim([20, 10000])\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Average Magnitude (dB)')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Use ScalarFormatter to avoid scientific notation\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_major_formatter(ScalarFormatter())\n",
    "    ax.xaxis.get_major_formatter().set_scientific(False)\n",
    "    ax.xaxis.get_major_formatter().set_useOffset(False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_directory(directory_path, start, end):\n",
    "    \"\"\"\n",
    "    Walk through directory_path, and for each pair of out_{some_model_name}.wav and tgt_{same_model_name}.wav, \n",
    "    load them using torchaudio and call overlap_waveforms and two_spectrograms_difference functions.\n",
    "    \"\"\"\n",
    "    directory_path = Path(directory_path)\n",
    "    output_files = [f for f in directory_path.iterdir() if f.name.startswith(\"out_\") and f.suffix == \".wav\"]\n",
    "    \n",
    "    for out_file in output_files:\n",
    "        # Extract the model name and sample rate by splitting on '_'. \n",
    "        # This assumes the format is consistent with what's shown.\n",
    "        parts = out_file.stem.split(\"_\")\n",
    "        model_name = \"_\".join(parts[1:-1])  # Combine everything except 'out' and sample rate.\n",
    "        sample_rate_suffix = parts[-1]\n",
    "        \n",
    "        # Construct the expected name for the tgt file\n",
    "        tgt_file_name = f\"tgt_{model_name}_{sample_rate_suffix}.wav\"\n",
    "        tgt_file = directory_path / tgt_file_name\n",
    "        \n",
    "        if tgt_file.exists():\n",
    "            # Load the audio files using torchaudio\n",
    "            output, sample_rate = torchaudio.load(out_file)\n",
    "            target, _ = torchaudio.load(tgt_file)\n",
    "            \n",
    "            output = output.view(-1).numpy()\n",
    "            target = target.view(-1).numpy()\n",
    "\n",
    "            title = model_name + \"_\" + sample_rate_suffix\n",
    "            \n",
    "            # Call your functions\n",
    "            # overlap_waveforms(output, target, sample_rate, start, end, title)\n",
    "            # target_output_spectra(output, target, sample_rate, start, end, title)\n",
    "        else:\n",
    "            print(f\"Matching target file for {out_file} not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "SAMPLES_DIR = \"results/48k/audio/\"\n",
    "\n",
    "start_time = int(sample_rate * 1)\n",
    "end_time =  int(sample_rate * 3 + 1024)\n",
    "\n",
    "# process_directory(SAMPLES_DIR, start_time, end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \"results/48k/audio/out_LSTM-96_48k.wav\"\n",
    "loader = esstd.MonoLoader(filename=out_file)\n",
    "audio = loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = esstd.Windowing(type='hann')\n",
    "spectrum_f = esstd.Spectrum()\n",
    "logspec_f = esstd.LogSpectrum()\n",
    "\n",
    "def nth_octave_smoothing(spectrum, n: int = 3):\n",
    "    N = len(spectrum)\n",
    "    freq_bins = np.linspace(0, int(sample_rate/2), N)\n",
    "    y = np.zeros(shape=np.shape(spectrum), dtype = type(spectrum[0]))\n",
    "    M_1 = len(spectrum) - 1\n",
    "\n",
    "    for k in range(len(spectrum)):\n",
    "        a = int(np.round(k * 2 ** (-1 /(2 * n))))\n",
    "        b = int(np.round(k * 2 ** (1 /(2 * n))))\n",
    "\n",
    "        if a == b:\n",
    "            b += 1\n",
    "\n",
    "        if b > M_1:\n",
    "            b = M_1\n",
    "\n",
    "        y[k] = (1 / ((b-1) - a + 1)) * np.sum(spectrum[a:b])\n",
    "    return y, freq_bins\n",
    "\n",
    "frame = audio\n",
    "spec = spectrum_f(w(frame))\n",
    "\n",
    "\n",
    "log_f_spec, meanT, localT = logspec_f(spec)\n",
    "\n",
    "y, freq_bins = nth_octave_smoothing(log_f_spec, n=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import essentia.standard as esstd\n",
    "\n",
    "# Load the audio file\n",
    "loader = esstd.MonoLoader(filename='path_to_audio_file.wav')\n",
    "audio = loader()\n",
    "sample_rate = 48000  # adjust based on your file's sample rate\n",
    "\n",
    "def nth_octave_smoothing(spectrum, n: int = 3):\n",
    "    N = len(spectrum)\n",
    "    freq_bins = np.linspace(0, int(sample_rate/2), N)\n",
    "    y = np.zeros(shape=np.shape(spectrum), dtype = type(spectrum[0]))\n",
    "    M_1 = len(spectrum) - 1\n",
    "\n",
    "    for k in range(len(spectrum)):\n",
    "        a = int(np.round(k * 2 ** (-1 /(2 * n))))\n",
    "        b = int(np.round(k * 2 ** (1 /(2 * n))))\n",
    "\n",
    "        if a == b:\n",
    "            b += 1\n",
    "\n",
    "        if b > M_1:\n",
    "            b = M_1\n",
    "\n",
    "        y[k] = (1 / ((b-1) - a + 1)) * np.sum(spectrum[a:b])\n",
    "    return y, freq_bins\n",
    "\n",
    "w = esstd.Windowing(type='hann')\n",
    "spectrum_function = esstd.Spectrum()\n",
    "logspec = esstd.LogSpectrum()\n",
    "\n",
    "frame = audio[1*48000 : 2*48000+1024]\n",
    "spec = spectrum_function(w(frame))\n",
    "log_f_spec, meanT, localT = logspec(spec)\n",
    "\n",
    "y, freq_bins = nth_octave_smoothing(log_f_spec, n=3)\n",
    "\n",
    "plt.plot(freq_bins, y)\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.title('Smoothed Log Spectrum')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logNorm = esstd.UnaryOperator(type='log')\n",
    "sns.lineplot(logNorm(mfcc_bands))\n",
    "plt.title(\"Log-normalized mel band spectral energies of a frame:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the audio file\n",
    "\n",
    "audio = loader()\n",
    "\n",
    "# Compute MFCCs\n",
    "w = es.Windowing(type = 'hann')\n",
    "spectrum = es.Spectrum()  \n",
    "mfcc = es.MFCC(numberCoefficients=13)\n",
    "frame_sz = 1024\n",
    "hop_sz = 512\n",
    "mfccs = []\n",
    "\n",
    "\n",
    "mfccs = essentia.array(mfccs).T  # Transpose for plotting\n",
    "\n",
    "# Plot MFCCs\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(mfccs, aspect='auto', origin='lower', cmap='viridis')\n",
    "plt.ylabel('MFCC Coefficients')\n",
    "plt.xlabel('Frames')\n",
    "plt.title('MFCC')\n",
    "plt.colorbar(label='Amplitude')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
