Training with lr=0.01, batch_size=8, n_epochs=25
Initializing Training Process..

Torch version: 1.11.0 ------ Selected Device: cuda:0
Sample Rate: 16000 Hz ------  Crop Lenght:3200 samples

Found 4 files in ../plate-spring/spring
Using dry_train.h5 and wet_train.h5 for train split.
Parameters: 526.923 k
Receptive field: 14323 samples or 895.2 ms

Training Loop

Validation Loss Decreased(inf--->57.831155) Saving model ...
Epoch: 0, Learning Rate: 0.01
Epoch 1 		 Validation Loss: 57.831155, 		 Training Loss: 80189.623175Validation Loss Decreased(57.831155--->28.964974) Saving model ...
Epoch: 1, Learning Rate: 0.01
Epoch 2 		 Validation Loss: 28.964974, 		 Training Loss: 40.324092Validation Loss Decreased(28.964974--->9.028955) Saving model ...
Epoch: 2, Learning Rate: 0.01
Epoch 3 		 Validation Loss: 9.028955, 		 Training Loss: 15.328755Validation Loss Decreased(9.028955--->7.641009) Saving model ...
Epoch: 3, Learning Rate: 0.01
Epoch 4 		 Validation Loss: 7.641009, 		 Training Loss: 8.441035Epoch: 4, Learning Rate: 0.01
Epoch 5 		 Validation Loss: 7.684867, 		 Training Loss: 7.674302Validation Loss Decreased(7.641009--->6.810198) Saving model ...
Epoch: 5, Learning Rate: 0.01
Epoch 6 		 Validation Loss: 6.810198, 		 Training Loss: 8.431361Epoch: 6, Learning Rate: 0.01
Epoch 7 		 Validation Loss: 8.072810, 		 Training Loss: 6.865125Validation Loss Decreased(6.810198--->4.368264) Saving model ...
Epoch: 7, Learning Rate: 0.01
Epoch 8 		 Validation Loss: 4.368264, 		 Training Loss: 5.301184Validation Loss Decreased(4.368264--->4.187911) Saving model ...
Epoch: 8, Learning Rate: 0.01
Epoch 9 		 Validation Loss: 4.187911, 		 Training Loss: 4.784061Epoch: 9, Learning Rate: 0.01
Epoch 10 		 Validation Loss: 20.315129, 		 Training Loss: 6.047428Epoch: 10, Learning Rate: 0.01
Epoch 11 		 Validation Loss: 5.602730, 		 Training Loss: 10.662829Validation Loss Decreased(4.187911--->3.884235) Saving model ...
Epoch: 11, Learning Rate: 0.01
Epoch 12 		 Validation Loss: 3.884235, 		 Training Loss: 4.454360Epoch: 12, Learning Rate: 0.01
Epoch 13 		 Validation Loss: 4.782097, 		 Training Loss: 4.896824Validation Loss Decreased(3.884235--->3.680806) Saving model ...
Epoch: 13, Learning Rate: 0.01
Epoch 14 		 Validation Loss: 3.680806, 		 Training Loss: 3.940818Validation Loss Decreased(3.680806--->3.599127) Saving model ...
Epoch: 14, Learning Rate: 0.01
Epoch 15 		 Validation Loss: 3.599127, 		 Training Loss: 3.622622Validation Loss Decreased(3.599127--->3.531077) Saving model ...
Epoch: 15, Learning Rate: 0.01
Epoch 16 		 Validation Loss: 3.531077, 		 Training Loss: 3.624446Epoch: 16, Learning Rate: 0.01
Epoch 17 		 Validation Loss: 6.791672, 		 Training Loss: 14.106105Validation Loss Decreased(3.531077--->3.512854) Saving model ...
Epoch: 17, Learning Rate: 0.01
Epoch 18 		 Validation Loss: 3.512854, 		 Training Loss: 4.658668Validation Loss Decreased(3.512854--->3.313676) Saving model ...
Epoch: 18, Learning Rate: 0.01
Epoch 19 		 Validation Loss: 3.313676, 		 Training Loss: 3.672756Validation Loss Decreased(3.313676--->3.201209) Saving model ...
Epoch: 19, Learning Rate: 0.001
Epoch 20 		 Validation Loss: 3.201209, 		 Training Loss: 3.367595Validation Loss Decreased(3.201209--->3.114234) Saving model ...
Epoch: 20, Learning Rate: 0.001
Epoch 21 		 Validation Loss: 3.114234, 		 Training Loss: 3.119818Validation Loss Decreased(3.114234--->3.103894) Saving model ...
Epoch: 21, Learning Rate: 0.001
Epoch 22 		 Validation Loss: 3.103894, 		 Training Loss: 3.096018Validation Loss Decreased(3.103894--->3.094878) Saving model ...
Epoch: 22, Learning Rate: 0.0001
Epoch 23 		 Validation Loss: 3.094878, 		 Training Loss: 3.101444Validation Loss Decreased(3.094878--->3.087804) Saving model ...
Epoch: 23, Learning Rate: 0.0001
Epoch 24 		 Validation Loss: 3.087804, 		 Training Loss: 3.073788Epoch: 24, Learning Rate: 0.0001
Epoch 25 		 Validation Loss: 3.258793, 		 Training Loss: 3.104325Training Completed!
