Training with lr=0.001, batch_size=8, n_epochs=25
Initializing Training Process..

Torch version: 1.11.0 ------ Selected Device: cuda:0
Sample Rate: 16000 Hz ------  Crop Lenght:3200 samples

Found 4 files in ../plate-spring/spring
Using dry_train.h5 and wet_train.h5 for train split.
Parameters: 526.923 k
Receptive field: 14323 samples or 895.2 ms

Training Loop

Validation Loss Decreased(inf--->1.449322) Saving model ...
Epoch: 0, Learning Rate: 0.001
Epoch 1 		 Validation Loss: 1.449322, 		 Training Loss: 1.852347Validation Loss Decreased(1.449322--->1.280027) Saving model ...
Epoch: 1, Learning Rate: 0.001
Epoch 2 		 Validation Loss: 1.280027, 		 Training Loss: 1.326693Validation Loss Decreased(1.280027--->1.241018) Saving model ...
Epoch: 2, Learning Rate: 0.001
Epoch 3 		 Validation Loss: 1.241018, 		 Training Loss: 1.240160Epoch: 3, Learning Rate: 0.001
Epoch 4 		 Validation Loss: 1.243902, 		 Training Loss: 1.198866Validation Loss Decreased(1.241018--->1.204038) Saving model ...
Epoch: 4, Learning Rate: 0.001
Epoch 5 		 Validation Loss: 1.204038, 		 Training Loss: 1.159114Validation Loss Decreased(1.204038--->1.172147) Saving model ...
Epoch: 5, Learning Rate: 0.001
Epoch 6 		 Validation Loss: 1.172147, 		 Training Loss: 1.186376Validation Loss Decreased(1.172147--->1.132107) Saving model ...
Epoch: 6, Learning Rate: 0.001
Epoch 7 		 Validation Loss: 1.132107, 		 Training Loss: 1.152734Validation Loss Decreased(1.132107--->1.091599) Saving model ...
Epoch: 7, Learning Rate: 0.001
Epoch 8 		 Validation Loss: 1.091599, 		 Training Loss: 1.098795Epoch: 8, Learning Rate: 0.001
Epoch 9 		 Validation Loss: 1.134668, 		 Training Loss: 1.122640Validation Loss Decreased(1.091599--->1.087562) Saving model ...
Epoch: 9, Learning Rate: 0.001
Epoch 10 		 Validation Loss: 1.087562, 		 Training Loss: 1.083381Validation Loss Decreased(1.087562--->1.044683) Saving model ...
Epoch: 10, Learning Rate: 0.001
Epoch 11 		 Validation Loss: 1.044683, 		 Training Loss: 1.094431Validation Loss Decreased(1.044683--->1.039017) Saving model ...
Epoch: 11, Learning Rate: 0.001
Epoch 12 		 Validation Loss: 1.039017, 		 Training Loss: 1.038599Validation Loss Decreased(1.039017--->1.012942) Saving model ...
Epoch: 12, Learning Rate: 0.001
Epoch 13 		 Validation Loss: 1.012942, 		 Training Loss: 1.019604Epoch: 13, Learning Rate: 0.001
Epoch 14 		 Validation Loss: 1.288337, 		 Training Loss: 1.041846Validation Loss Decreased(1.012942--->1.010139) Saving model ...
Epoch: 14, Learning Rate: 0.001
Epoch 15 		 Validation Loss: 1.010139, 		 Training Loss: 1.084464Epoch: 15, Learning Rate: 0.001
Epoch 16 		 Validation Loss: 1.042601, 		 Training Loss: 1.034177Validation Loss Decreased(1.010139--->1.001461) Saving model ...
Epoch: 16, Learning Rate: 0.001
Epoch 17 		 Validation Loss: 1.001461, 		 Training Loss: 0.995972Validation Loss Decreased(1.001461--->0.972807) Saving model ...
Epoch: 17, Learning Rate: 0.001
Epoch 18 		 Validation Loss: 0.972807, 		 Training Loss: 0.998960Epoch: 18, Learning Rate: 0.001
Epoch 19 		 Validation Loss: 0.984255, 		 Training Loss: 1.008597Epoch: 19, Learning Rate: 0.0001
Epoch 20 		 Validation Loss: 1.091493, 		 Training Loss: 0.955475Validation Loss Decreased(0.972807--->0.915741) Saving model ...
Epoch: 20, Learning Rate: 0.0001
Epoch 21 		 Validation Loss: 0.915741, 		 Training Loss: 0.928326Validation Loss Decreased(0.915741--->0.908016) Saving model ...
Epoch: 21, Learning Rate: 0.0001
Epoch 22 		 Validation Loss: 0.908016, 		 Training Loss: 0.898562Validation Loss Decreased(0.908016--->0.907090) Saving model ...
Epoch: 22, Learning Rate: 1e-05
Epoch 23 		 Validation Loss: 0.907090, 		 Training Loss: 0.894174Validation Loss Decreased(0.907090--->0.904699) Saving model ...
Epoch: 23, Learning Rate: 1e-05
Epoch 24 		 Validation Loss: 0.904699, 		 Training Loss: 0.885450Validation Loss Decreased(0.904699--->0.899945) Saving model ...
Epoch: 24, Learning Rate: 1e-05
Epoch 25 		 Validation Loss: 0.899945, 		 Training Loss: 0.882744Training Completed!
