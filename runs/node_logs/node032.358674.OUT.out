Training with lr=0.001, batch_size=16, n_epochs=25
Initializing Training Process..

Torch version: 1.11.0 ------ Selected Device: cuda:0
Sample Rate: 16000 Hz ------  Crop Lenght:3200 samples

Found 4 files in ../plate-spring/spring
Using dry_train.h5 and wet_train.h5 for train split.
Parameters: 526.923 k
Receptive field: 14323 samples or 895.2 ms

Training Loop

Validation Loss Decreased(inf--->1.343287) Saving model ...
Epoch: 0, Learning Rate: 0.001
Epoch 1 		 Validation Loss: 1.343287, 		 Training Loss: 1.588861Validation Loss Decreased(1.343287--->1.268887) Saving model ...
Epoch: 1, Learning Rate: 0.001
Epoch 2 		 Validation Loss: 1.268887, 		 Training Loss: 1.325430Validation Loss Decreased(1.268887--->1.201874) Saving model ...
Epoch: 2, Learning Rate: 0.001
Epoch 3 		 Validation Loss: 1.201874, 		 Training Loss: 1.242191Epoch: 3, Learning Rate: 0.001
Epoch 4 		 Validation Loss: 1.235815, 		 Training Loss: 1.223885Validation Loss Decreased(1.201874--->1.158993) Saving model ...
Epoch: 4, Learning Rate: 0.001
Epoch 5 		 Validation Loss: 1.158993, 		 Training Loss: 1.194044Validation Loss Decreased(1.158993--->1.134597) Saving model ...
Epoch: 5, Learning Rate: 0.001
Epoch 6 		 Validation Loss: 1.134597, 		 Training Loss: 1.167656Epoch: 6, Learning Rate: 0.001
Epoch 7 		 Validation Loss: 1.141211, 		 Training Loss: 1.133973Validation Loss Decreased(1.134597--->1.104909) Saving model ...
Epoch: 7, Learning Rate: 0.001
Epoch 8 		 Validation Loss: 1.104909, 		 Training Loss: 1.100186Validation Loss Decreased(1.104909--->1.078025) Saving model ...
Epoch: 8, Learning Rate: 0.001
Epoch 9 		 Validation Loss: 1.078025, 		 Training Loss: 1.074525Validation Loss Decreased(1.078025--->1.034834) Saving model ...
Epoch: 9, Learning Rate: 0.001
Epoch 10 		 Validation Loss: 1.034834, 		 Training Loss: 1.081588Epoch: 10, Learning Rate: 0.001
Epoch 11 		 Validation Loss: 1.065544, 		 Training Loss: 1.024645Validation Loss Decreased(1.034834--->1.024433) Saving model ...
Epoch: 11, Learning Rate: 0.001
Epoch 12 		 Validation Loss: 1.024433, 		 Training Loss: 1.066822Validation Loss Decreased(1.024433--->1.007329) Saving model ...
Epoch: 12, Learning Rate: 0.001
Epoch 13 		 Validation Loss: 1.007329, 		 Training Loss: 1.038613Validation Loss Decreased(1.007329--->0.953288) Saving model ...
Epoch: 13, Learning Rate: 0.001
Epoch 14 		 Validation Loss: 0.953288, 		 Training Loss: 0.996761Validation Loss Decreased(0.953288--->0.944320) Saving model ...
Epoch: 14, Learning Rate: 0.001
Epoch 15 		 Validation Loss: 0.944320, 		 Training Loss: 0.996737Epoch: 15, Learning Rate: 0.001
Epoch 16 		 Validation Loss: 1.032014, 		 Training Loss: 0.987628Epoch: 16, Learning Rate: 0.001
Epoch 17 		 Validation Loss: 0.961334, 		 Training Loss: 0.981770Epoch: 17, Learning Rate: 0.001
Epoch 18 		 Validation Loss: 1.017435, 		 Training Loss: 0.962264Validation Loss Decreased(0.944320--->0.933589) Saving model ...
Epoch: 18, Learning Rate: 0.001
Epoch 19 		 Validation Loss: 0.933589, 		 Training Loss: 0.966638Epoch: 19, Learning Rate: 0.0001
Epoch 20 		 Validation Loss: 0.982707, 		 Training Loss: 0.967175Validation Loss Decreased(0.933589--->0.886710) Saving model ...
Epoch: 20, Learning Rate: 0.0001
Epoch 21 		 Validation Loss: 0.886710, 		 Training Loss: 0.915137Validation Loss Decreased(0.886710--->0.874106) Saving model ...
Epoch: 21, Learning Rate: 0.0001
Epoch 22 		 Validation Loss: 0.874106, 		 Training Loss: 0.888105Validation Loss Decreased(0.874106--->0.870870) Saving model ...
Epoch: 22, Learning Rate: 1e-05
Epoch 23 		 Validation Loss: 0.870870, 		 Training Loss: 0.880317Validation Loss Decreased(0.870870--->0.863620) Saving model ...
Epoch: 23, Learning Rate: 1e-05
Epoch 24 		 Validation Loss: 0.863620, 		 Training Loss: 0.873174Validation Loss Decreased(0.863620--->0.863186) Saving model ...
Epoch: 24, Learning Rate: 1e-05
Epoch 25 		 Validation Loss: 0.863186, 		 Training Loss: 0.871980Training Completed!
