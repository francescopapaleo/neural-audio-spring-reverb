Training with lr=0.001, batch_size=4, n_epochs=25
Initializing Training Process..

Torch version: 1.11.0 ------ Selected Device: cuda:0
Sample Rate: 16000 Hz ------  Crop Lenght:3200 samples

Found 4 files in ../plate-spring/spring
Using dry_train.h5 and wet_train.h5 for train split.
Parameters: 526.923 k
Receptive field: 14323 samples or 895.2 ms

Training Loop

Validation Loss Decreased(inf--->1.345930) Saving model ...
Epoch: 0, Learning Rate: 0.001
Epoch 1 		 Validation Loss: 1.345930, 		 Training Loss: 1.574753Epoch: 1, Learning Rate: 0.001
Epoch 2 		 Validation Loss: 1.349471, 		 Training Loss: 1.318424Epoch: 2, Learning Rate: 0.001
Epoch 3 		 Validation Loss: 1.695426, 		 Training Loss: 5.638599Epoch: 3, Learning Rate: 0.001
Epoch 4 		 Validation Loss: 1.374529, 		 Training Loss: 1.497180Validation Loss Decreased(1.345930--->1.301185) Saving model ...
Epoch: 4, Learning Rate: 0.001
Epoch 5 		 Validation Loss: 1.301185, 		 Training Loss: 1.343222Validation Loss Decreased(1.301185--->1.237329) Saving model ...
Epoch: 5, Learning Rate: 0.001
Epoch 6 		 Validation Loss: 1.237329, 		 Training Loss: 1.281323Validation Loss Decreased(1.237329--->1.170918) Saving model ...
Epoch: 6, Learning Rate: 0.001
Epoch 7 		 Validation Loss: 1.170918, 		 Training Loss: 1.219255Epoch: 7, Learning Rate: 0.001
Epoch 8 		 Validation Loss: 1.201938, 		 Training Loss: 1.326750Validation Loss Decreased(1.170918--->1.164511) Saving model ...
Epoch: 8, Learning Rate: 0.001
Epoch 9 		 Validation Loss: 1.164511, 		 Training Loss: 1.241916Validation Loss Decreased(1.164511--->1.152255) Saving model ...
Epoch: 9, Learning Rate: 0.001
Epoch 10 		 Validation Loss: 1.152255, 		 Training Loss: 1.185022Validation Loss Decreased(1.152255--->1.147986) Saving model ...
Epoch: 10, Learning Rate: 0.001
Epoch 11 		 Validation Loss: 1.147986, 		 Training Loss: 1.158034Validation Loss Decreased(1.147986--->1.135225) Saving model ...
Epoch: 11, Learning Rate: 0.001
Epoch 12 		 Validation Loss: 1.135225, 		 Training Loss: 1.158830Validation Loss Decreased(1.135225--->1.093140) Saving model ...
Epoch: 12, Learning Rate: 0.001
Epoch 13 		 Validation Loss: 1.093140, 		 Training Loss: 1.122583Validation Loss Decreased(1.093140--->1.085302) Saving model ...
Epoch: 13, Learning Rate: 0.001
Epoch 14 		 Validation Loss: 1.085302, 		 Training Loss: 1.098746Validation Loss Decreased(1.085302--->1.024213) Saving model ...
Epoch: 14, Learning Rate: 0.001
Epoch 15 		 Validation Loss: 1.024213, 		 Training Loss: 1.066426Epoch: 15, Learning Rate: 0.001
Epoch 16 		 Validation Loss: 1.029821, 		 Training Loss: 1.047718Validation Loss Decreased(1.024213--->1.019086) Saving model ...
Epoch: 16, Learning Rate: 0.001
Epoch 17 		 Validation Loss: 1.019086, 		 Training Loss: 1.046195Epoch: 17, Learning Rate: 0.001
Epoch 18 		 Validation Loss: 1.032856, 		 Training Loss: 1.029894Validation Loss Decreased(1.019086--->0.996195) Saving model ...
Epoch: 18, Learning Rate: 0.001
Epoch 19 		 Validation Loss: 0.996195, 		 Training Loss: 1.031489Validation Loss Decreased(0.996195--->0.995866) Saving model ...
Epoch: 19, Learning Rate: 0.0001
Epoch 20 		 Validation Loss: 0.995866, 		 Training Loss: 1.011151Validation Loss Decreased(0.995866--->0.955095) Saving model ...
Epoch: 20, Learning Rate: 0.0001
Epoch 21 		 Validation Loss: 0.955095, 		 Training Loss: 0.961079Validation Loss Decreased(0.955095--->0.954485) Saving model ...
Epoch: 21, Learning Rate: 0.0001
Epoch 22 		 Validation Loss: 0.954485, 		 Training Loss: 0.946883Validation Loss Decreased(0.954485--->0.942630) Saving model ...
Epoch: 22, Learning Rate: 1e-05
Epoch 23 		 Validation Loss: 0.942630, 		 Training Loss: 0.947102Validation Loss Decreased(0.942630--->0.936409) Saving model ...
Epoch: 23, Learning Rate: 1e-05
Epoch 24 		 Validation Loss: 0.936409, 		 Training Loss: 0.936450Validation Loss Decreased(0.936409--->0.934990) Saving model ...
Epoch: 24, Learning Rate: 1e-05
Epoch 25 		 Validation Loss: 0.934990, 		 Training Loss: 0.932020Training Completed!
