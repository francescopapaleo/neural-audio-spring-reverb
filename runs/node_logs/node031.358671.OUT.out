Training with lr=0.001, batch_size=8, n_epochs=25
Initializing Training Process..

Torch version: 1.11.0 ------ Selected Device: cuda:0
Sample Rate: 16000 Hz ------  Crop Lenght:3200 samples

Found 4 files in ../plate-spring/spring
Using dry_train.h5 and wet_train.h5 for train split.
Parameters: 526.923 k
Receptive field: 14323 samples or 895.2 ms

Training Loop

Validation Loss Decreased(inf--->1.495757) Saving model ...
Epoch: 0, Learning Rate: 0.001
Epoch 1 		 Validation Loss: 1.495757, 		 Training Loss: 1.620708Validation Loss Decreased(1.495757--->1.275954) Saving model ...
Epoch: 1, Learning Rate: 0.001
Epoch 2 		 Validation Loss: 1.275954, 		 Training Loss: 1.345583Validation Loss Decreased(1.275954--->1.272658) Saving model ...
Epoch: 2, Learning Rate: 0.001
Epoch 3 		 Validation Loss: 1.272658, 		 Training Loss: 1.263296Validation Loss Decreased(1.272658--->1.156065) Saving model ...
Epoch: 3, Learning Rate: 0.001
Epoch 4 		 Validation Loss: 1.156065, 		 Training Loss: 1.224985Validation Loss Decreased(1.156065--->1.126620) Saving model ...
Epoch: 4, Learning Rate: 0.001
Epoch 5 		 Validation Loss: 1.126620, 		 Training Loss: 1.155270Epoch: 5, Learning Rate: 0.001
Epoch 6 		 Validation Loss: 1.289154, 		 Training Loss: 1.192863Epoch: 6, Learning Rate: 0.001
Epoch 7 		 Validation Loss: 1.161280, 		 Training Loss: 1.143282Validation Loss Decreased(1.126620--->1.060641) Saving model ...
Epoch: 7, Learning Rate: 0.001
Epoch 8 		 Validation Loss: 1.060641, 		 Training Loss: 1.095678Validation Loss Decreased(1.060641--->1.037566) Saving model ...
Epoch: 8, Learning Rate: 0.001
Epoch 9 		 Validation Loss: 1.037566, 		 Training Loss: 1.071577Validation Loss Decreased(1.037566--->1.009222) Saving model ...
Epoch: 9, Learning Rate: 0.001
Epoch 10 		 Validation Loss: 1.009222, 		 Training Loss: 1.051814Epoch: 10, Learning Rate: 0.001
Epoch 11 		 Validation Loss: 1.011103, 		 Training Loss: 1.017257Epoch: 11, Learning Rate: 0.001
Epoch 12 		 Validation Loss: 1.055616, 		 Training Loss: 1.062538Epoch: 12, Learning Rate: 0.001
Epoch 13 		 Validation Loss: 1.188724, 		 Training Loss: 1.027763Validation Loss Decreased(1.009222--->0.965549) Saving model ...
Epoch: 13, Learning Rate: 0.001
Epoch 14 		 Validation Loss: 0.965549, 		 Training Loss: 1.011304Epoch: 14, Learning Rate: 0.001
Epoch 15 		 Validation Loss: 0.995533, 		 Training Loss: 1.011576Epoch: 15, Learning Rate: 0.001
Epoch 16 		 Validation Loss: 1.006060, 		 Training Loss: 0.983090Validation Loss Decreased(0.965549--->0.925504) Saving model ...
Epoch: 16, Learning Rate: 0.001
Epoch 17 		 Validation Loss: 0.925504, 		 Training Loss: 0.973577Epoch: 17, Learning Rate: 0.001
Epoch 18 		 Validation Loss: 0.953266, 		 Training Loss: 0.957117Epoch: 18, Learning Rate: 0.001
Epoch 19 		 Validation Loss: 0.979685, 		 Training Loss: 0.955003Epoch: 19, Learning Rate: 0.0001
Epoch 20 		 Validation Loss: 1.048448, 		 Training Loss: 1.061696Validation Loss Decreased(0.925504--->0.911891) Saving model ...
Epoch: 20, Learning Rate: 0.0001
Epoch 21 		 Validation Loss: 0.911891, 		 Training Loss: 0.936318Validation Loss Decreased(0.911891--->0.898780) Saving model ...
Epoch: 21, Learning Rate: 0.0001
Epoch 22 		 Validation Loss: 0.898780, 		 Training Loss: 0.905912Validation Loss Decreased(0.898780--->0.894151) Saving model ...
Epoch: 22, Learning Rate: 1e-05
Epoch 23 		 Validation Loss: 0.894151, 		 Training Loss: 0.895492Validation Loss Decreased(0.894151--->0.886219) Saving model ...
Epoch: 23, Learning Rate: 1e-05
Epoch 24 		 Validation Loss: 0.886219, 		 Training Loss: 0.884619Validation Loss Decreased(0.886219--->0.881666) Saving model ...
Epoch: 24, Learning Rate: 1e-05
Epoch 25 		 Validation Loss: 0.881666, 		 Training Loss: 0.881701Training Completed!
