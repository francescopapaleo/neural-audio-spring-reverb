Training with lr=0.1, batch_size=64, n_epochs=50
Initializing Training Process..

Torch version: 1.11.0 ------ Selected Device: cuda:0
Sample Rate: 16000 Hz ------  Crop Lenght:3200 samples

Found 4 files in ../plate-spring/spring
Using dry_train.h5 and wet_train.h5 for train split.
Parameters: 395.339 k
Receptive field: 3495251 samples or 218453.2 ms

Training Loop

Validation Loss Decreased(inf--->11255742122.666666) Saving model ...
Epoch 1 		 Validation Loss: 11255742122.666666, 		 Training Loss: 84926617187.334793Epoch 2 		 Validation Loss: 73841156096.000000, 		 Training Loss: 90477474450.285721Epoch 3 		 Validation Loss: 16276678997.333334, 		 Training Loss: 52091990308.571426Epoch 4 		 Validation Loss: 17064877056.000000, 		 Training Loss: 50583940973.714287Epoch 5 		 Validation Loss: 16759616512.000000, 		 Training Loss: 40923869074.285713Validation Loss Decreased(11255742122.666666--->5327859200.000000) Saving model ...
Epoch 6 		 Validation Loss: 5327859200.000000, 		 Training Loss: 9788986665.142857Validation Loss Decreased(5327859200.000000--->2673970773.333333) Saving model ...
Epoch 7 		 Validation Loss: 2673970773.333333, 		 Training Loss: 4133504416.000000Validation Loss Decreased(2673970773.333333--->313461141.333333) Saving model ...
Epoch 8 		 Validation Loss: 313461141.333333, 		 Training Loss: 898763499.428571Validation Loss Decreased(313461141.333333--->87670645.333333) Saving model ...
Epoch 9 		 Validation Loss: 87670645.333333, 		 Training Loss: 165379204.000000Validation Loss Decreased(87670645.333333--->48321814.666667) Saving model ...
Epoch 10 		 Validation Loss: 48321814.666667, 		 Training Loss: 70210661.428571Validation Loss Decreased(48321814.666667--->28326134.000000) Saving model ...
Epoch 11 		 Validation Loss: 28326134.000000, 		 Training Loss: 37536371.857143Validation Loss Decreased(28326134.000000--->21306058.000000) Saving model ...
Epoch 12 		 Validation Loss: 21306058.000000, 		 Training Loss: 24250542.142857Validation Loss Decreased(21306058.000000--->16566320.333333) Saving model ...
Epoch 13 		 Validation Loss: 16566320.333333, 		 Training Loss: 18296058.071429Validation Loss Decreased(16566320.333333--->14070680.000000) Saving model ...
Epoch 14 		 Validation Loss: 14070680.000000, 		 Training Loss: 14762791.357143Validation Loss Decreased(14070680.000000--->12364994.666667) Saving model ...
Epoch 15 		 Validation Loss: 12364994.666667, 		 Training Loss: 12248643.285714Validation Loss Decreased(12364994.666667--->10732780.666667) Saving model ...
Epoch 16 		 Validation Loss: 10732780.666667, 		 Training Loss: 10567827.500000Validation Loss Decreased(10732780.666667--->9621956.000000) Saving model ...
Epoch 17 		 Validation Loss: 9621956.000000, 		 Training Loss: 9449571.464286Validation Loss Decreased(9621956.000000--->8941942.333333) Saving model ...
Epoch 18 		 Validation Loss: 8941942.333333, 		 Training Loss: 8229988.607143Validation Loss Decreased(8941942.333333--->8041381.500000) Saving model ...
Epoch 19 		 Validation Loss: 8041381.500000, 		 Training Loss: 7390037.535714Validation Loss Decreased(8041381.500000--->7186450.833333) Saving model ...
Epoch 20 		 Validation Loss: 7186450.833333, 		 Training Loss: 6463025.392857Validation Loss Decreased(7186450.833333--->6568133.000000) Saving model ...
Epoch 21 		 Validation Loss: 6568133.000000, 		 Training Loss: 5965229.178571Validation Loss Decreased(6568133.000000--->6255108.333333) Saving model ...
Epoch 22 		 Validation Loss: 6255108.333333, 		 Training Loss: 5503379.642857Validation Loss Decreased(6255108.333333--->5787381.333333) Saving model ...
Epoch 23 		 Validation Loss: 5787381.333333, 		 Training Loss: 4979636.607143Validation Loss Decreased(5787381.333333--->5268529.583333) Saving model ...
Epoch 24 		 Validation Loss: 5268529.583333, 		 Training Loss: 4522095.785714Validation Loss Decreased(5268529.583333--->5220187.833333) Saving model ...
Epoch 25 		 Validation Loss: 5220187.833333, 		 Training Loss: 4193365.410714Epoch 26 		 Validation Loss: 9862403.666667, 		 Training Loss: 4761547.982143Epoch 27 		 Validation Loss: 5626420.750000, 		 Training Loss: 5946893.785714Validation Loss Decreased(5220187.833333--->5051158.500000) Saving model ...
Epoch 28 		 Validation Loss: 5051158.500000, 		 Training Loss: 5126574.214286Epoch 29 		 Validation Loss: 5372427.000000, 		 Training Loss: 3854747.892857Validation Loss Decreased(5051158.500000--->5020170.500000) Saving model ...
Epoch 30 		 Validation Loss: 5020170.500000, 		 Training Loss: 4303414.696429Epoch 31 		 Validation Loss: 6150795.666667, 		 Training Loss: 3775436.589286Epoch 32 		 Validation Loss: 6861640.333333, 		 Training Loss: 4244265.892857Epoch 33 		 Validation Loss: 5453701.333333, 		 Training Loss: 4200611.446429Validation Loss Decreased(5020170.500000--->3718370.500000) Saving model ...
Epoch 34 		 Validation Loss: 3718370.500000, 		 Training Loss: 3690282.767857Epoch 35 		 Validation Loss: 4655671.666667, 		 Training Loss: 2729192.508929Validation Loss Decreased(3718370.500000--->3603518.333333) Saving model ...
Epoch 36 		 Validation Loss: 3603518.333333, 		 Training Loss: 2769184.767857Epoch 37 		 Validation Loss: 3935709.166667, 		 Training Loss: 3880829.089286Validation Loss Decreased(3603518.333333--->2860066.125000) Saving model ...
Epoch 38 		 Validation Loss: 2860066.125000, 		 Training Loss: 2375505.910714Epoch 39 		 Validation Loss: 3195190.666667, 		 Training Loss: 2454220.491071Validation Loss Decreased(2860066.125000--->2801080.166667) Saving model ...
Epoch 40 		 Validation Loss: 2801080.166667, 		 Training Loss: 2367851.321429Validation Loss Decreased(2801080.166667--->2622897.875000) Saving model ...
Epoch 41 		 Validation Loss: 2622897.875000, 		 Training Loss: 1802925.241071Validation Loss Decreased(2622897.875000--->2533519.250000) Saving model ...
Epoch 42 		 Validation Loss: 2533519.250000, 		 Training Loss: 1747389.500000Validation Loss Decreased(2533519.250000--->2486671.500000) Saving model ...
Epoch 43 		 Validation Loss: 2486671.500000, 		 Training Loss: 1762997.410714Validation Loss Decreased(2486671.500000--->2464119.833333) Saving model ...
Epoch 44 		 Validation Loss: 2464119.833333, 		 Training Loss: 1701935.883929Validation Loss Decreased(2464119.833333--->2454784.250000) Saving model ...
Epoch 45 		 Validation Loss: 2454784.250000, 		 Training Loss: 1697356.794643Validation Loss Decreased(2454784.250000--->2436466.708333) Saving model ...
Epoch 46 		 Validation Loss: 2436466.708333, 		 Training Loss: 1693563.205357Epoch 47 		 Validation Loss: 2448923.208333, 		 Training Loss: 1674180.687500Validation Loss Decreased(2436466.708333--->2426496.750000) Saving model ...
Epoch 48 		 Validation Loss: 2426496.750000, 		 Training Loss: 1669837.169643Validation Loss Decreased(2426496.750000--->2424617.250000) Saving model ...
Epoch 49 		 Validation Loss: 2424617.250000, 		 Training Loss: 1644974.901786Validation Loss Decreased(2424617.250000--->2421292.833333) Saving model ...
Epoch 50 		 Validation Loss: 2421292.833333, 		 Training Loss: 1658145.848214Training Completed!
Training with lr=0.1, batch_size=64, n_epochs=100
Initializing Training Process..

Torch version: 1.11.0 ------ Selected Device: cuda:0
Sample Rate: 16000 Hz ------  Crop Lenght:3200 samples

Found 4 files in ../plate-spring/spring
Using dry_train.h5 and wet_train.h5 for train split.
Parameters: 395.339 k
Receptive field: 3495251 samples or 218453.2 ms

Training Loop

Validation Loss Decreased(inf--->86165228202.666672) Saving model ...
Epoch 1 		 Validation Loss: 86165228202.666672, 		 Training Loss: 14825292928.864735Epoch 2 		 Validation Loss: 569351733248.000000, 		 Training Loss: 198312888758.857147Epoch 3 		 Validation Loss: 234682122240.000000, 		 Training Loss: 532160647899.428589Epoch 4 		 Validation Loss: 115384227157.333328, 		 Training Loss: 292169516141.714294Validation Loss Decreased(86165228202.666672--->70634657109.333328) Saving model ...
Epoch 5 		 Validation Loss: 70634657109.333328, 		 Training Loss: 259274564461.714294Validation Loss Decreased(70634657109.333328--->28067564202.666668) Saving model ...
Epoch 6 		 Validation Loss: 28067564202.666668, 		 Training Loss: 22769486390.857143Validation Loss Decreased(28067564202.666668--->8649380522.666666) Saving model ...
Epoch 7 		 Validation Loss: 8649380522.666666, 		 Training Loss: 21330814427.428570Validation Loss Decreased(8649380522.666666--->3152392277.333333) Saving model ...
Epoch 8 		 Validation Loss: 3152392277.333333, 		 Training Loss: 7867099291.428572Validation Loss Decreased(3152392277.333333--->905275690.666667) Saving model ...
Epoch 9 		 Validation Loss: 905275690.666667, 		 Training Loss: 1793204653.714286Validation Loss Decreased(905275690.666667--->438605984.000000) Saving model ...
Epoch 10 		 Validation Loss: 438605984.000000, 		 Training Loss: 703772665.142857Validation Loss Decreased(438605984.000000--->328599957.333333) Saving model ...
Epoch 11 		 Validation Loss: 328599957.333333, 		 Training Loss: 389311506.285714Validation Loss Decreased(328599957.333333--->260072320.000000) Saving model ...
Epoch 12 		 Validation Loss: 260072320.000000, 		 Training Loss: 309284530.285714Validation Loss Decreased(260072320.000000--->212642512.000000) Saving model ...
Epoch 13 		 Validation Loss: 212642512.000000, 		 Training Loss: 244147966.857143Validation Loss Decreased(212642512.000000--->177728693.333333) Saving model ...
Epoch 14 		 Validation Loss: 177728693.333333, 		 Training Loss: 202676834.285714Validation Loss Decreased(177728693.333333--->150791738.666667) Saving model ...
Epoch 15 		 Validation Loss: 150791738.666667, 		 Training Loss: 167176781.142857Validation Loss Decreased(150791738.666667--->126586856.000000) Saving model ...
Epoch 16 		 Validation Loss: 126586856.000000, 		 Training Loss: 140255653.714286Validation Loss Decreased(126586856.000000--->103908701.333333) Saving model ...
Epoch 17 		 Validation Loss: 103908701.333333, 		 Training Loss: 116421241.714286Validation Loss Decreased(103908701.333333--->85746962.666667) Saving model ...
Epoch 18 		 Validation Loss: 85746962.666667, 		 Training Loss: 96975366.285714Validation Loss Decreased(85746962.666667--->74827848.000000) Saving model ...
Epoch 19 		 Validation Loss: 74827848.000000, 		 Training Loss: 81506014.285714Validation Loss Decreased(74827848.000000--->65997004.000000) Saving model ...
Epoch 20 		 Validation Loss: 65997004.000000, 		 Training Loss: 72328333.142857Validation Loss Decreased(65997004.000000--->59112681.333333) Saving model ...
Epoch 21 		 Validation Loss: 59112681.333333, 		 Training Loss: 63725721.142857Validation Loss Decreased(59112681.333333--->53215174.666667) Saving model ...
Epoch 22 		 Validation Loss: 53215174.666667, 		 Training Loss: 57667610.571429Validation Loss Decreased(53215174.666667--->48633210.666667) Saving model ...
Epoch 23 		 Validation Loss: 48633210.666667, 		 Training Loss: 51712184.000000Validation Loss Decreased(48633210.666667--->44413458.666667) Saving model ...
Epoch 24 		 Validation Loss: 44413458.666667, 		 Training Loss: 46371598.285714Validation Loss Decreased(44413458.666667--->40696713.333333) Saving model ...
Epoch 25 		 Validation Loss: 40696713.333333, 		 Training Loss: 43144190.857143Validation Loss Decreased(40696713.333333--->38232490.666667) Saving model ...
Epoch 26 		 Validation Loss: 38232490.666667, 		 Training Loss: 38952342.000000Validation Loss Decreased(38232490.666667--->35088883.333333) Saving model ...
Epoch 27 		 Validation Loss: 35088883.333333, 		 Training Loss: 35920298.571429Validation Loss Decreased(35088883.333333--->32543193.333333) Saving model ...
Epoch 28 		 Validation Loss: 32543193.333333, 		 Training Loss: 33087582.000000Validation Loss Decreased(32543193.333333--->30489164.666667) Saving model ...
Epoch 29 		 Validation Loss: 30489164.666667, 		 Training Loss: 30699283.142857Validation Loss Decreased(30489164.666667--->28693798.000000) Saving model ...
Epoch 30 		 Validation Loss: 28693798.000000, 		 Training Loss: 29754400.857143Validation Loss Decreased(28693798.000000--->28219272.666667) Saving model ...
Epoch 31 		 Validation Loss: 28219272.666667, 		 Training Loss: 27583385.714286Validation Loss Decreased(28219272.666667--->25671240.666667) Saving model ...
Epoch 32 		 Validation Loss: 25671240.666667, 		 Training Loss: 26532802.285714Validation Loss Decreased(25671240.666667--->25443409.333333) Saving model ...
Epoch 33 		 Validation Loss: 25443409.333333, 		 Training Loss: 27835671.857143Epoch 34 		 Validation Loss: 32175654.000000, 		 Training Loss: 30063815.571429Epoch 35 		 Validation Loss: 42133810.666667, 		 Training Loss: 51497979.857143Epoch 36 		 Validation Loss: 28297713.333333, 		 Training Loss: 34683034.285714Validation Loss Decreased(25443409.333333--->22282643.333333) Saving model ...
Epoch 37 		 Validation Loss: 22282643.333333, 		 Training Loss: 23800889.857143Validation Loss Decreased(22282643.333333--->20503095.333333) Saving model ...
Epoch 38 		 Validation Loss: 20503095.333333, 		 Training Loss: 21848271.714286Epoch 39 		 Validation Loss: 25310685.333333, 		 Training Loss: 21497597.000000Epoch 40 		 Validation Loss: 25599146.000000, 		 Training Loss: 20724432.357143Epoch 41 		 Validation Loss: 20749012.666667, 		 Training Loss: 18898146.642857Validation Loss Decreased(20503095.333333--->17355604.000000) Saving model ...
Epoch 42 		 Validation Loss: 17355604.000000, 		 Training Loss: 21359850.928571Epoch 43 		 Validation Loss: 23907482.666667, 		 Training Loss: 27273544.857143Epoch 44 		 Validation Loss: 17905540.333333, 		 Training Loss: 28248474.071429Epoch 45 		 Validation Loss: 17857220.000000, 		 Training Loss: 21700921.857143Epoch 46 		 Validation Loss: 26686278.666667, 		 Training Loss: 30938656.214286Epoch 47 		 Validation Loss: 19389692.666667, 		 Training Loss: 33926433.714286Validation Loss Decreased(17355604.000000--->16852811.000000) Saving model ...
Epoch 48 		 Validation Loss: 16852811.000000, 		 Training Loss: 20604136.428571Epoch 49 		 Validation Loss: 30529968.666667, 		 Training Loss: 22739321.571429Epoch 50 		 Validation Loss: 22995958.666667, 		 Training Loss: 21621403.857143Epoch 51 		 Validation Loss: 19953700.666667, 		 Training Loss: 20089798.142857Validation Loss Decreased(16852811.000000--->14686636.000000) Saving model ...
Epoch 52 		 Validation Loss: 14686636.000000, 		 Training Loss: 14957436.142857Epoch 53 		 Validation Loss: 15807965.333333, 		 Training Loss: 14690857.928571Epoch 54 		 Validation Loss: 15940418.000000, 		 Training Loss: 20247315.928571Epoch 55 		 Validation Loss: 23120203.333333, 		 Training Loss: 30445593.714286Epoch 56 		 Validation Loss: 18656558.000000, 		 Training Loss: 20589905.571429Epoch 57 		 Validation Loss: 26212409.333333, 		 Training Loss: 15001621.785714Epoch 58 		 Validation Loss: 18083778.000000, 		 Training Loss: 20412613.214286Validation Loss Decreased(14686636.000000--->13620631.333333) Saving model ...
Epoch 59 		 Validation Loss: 13620631.333333, 		 Training Loss: 23694973.000000Epoch 60 		 Validation Loss: 14546286.666667, 		 Training Loss: 16294573.714286Epoch 61 		 Validation Loss: 17718309.666667, 		 Training Loss: 14714143.071429Epoch 62 		 Validation Loss: 18482038.000000, 		 Training Loss: 16918140.571429Epoch 63 		 Validation Loss: 18233335.000000, 		 Training Loss: 15260504.214286Validation Loss Decreased(13620631.333333--->13394641.666667) Saving model ...
Epoch 64 		 Validation Loss: 13394641.666667, 		 Training Loss: 14358709.642857Validation Loss Decreased(13394641.666667--->11768935.000000) Saving model ...
Epoch 65 		 Validation Loss: 11768935.000000, 		 Training Loss: 14229759.714286Epoch 66 		 Validation Loss: 14717384.333333, 		 Training Loss: 13612994.714286Epoch 67 		 Validation Loss: 16508200.000000, 		 Training Loss: 13853491.428571Epoch 68 		 Validation Loss: 13279576.000000, 		 Training Loss: 15572985.500000Epoch 69 		 Validation Loss: 12130271.666667, 		 Training Loss: 10276051.500000Epoch 70 		 Validation Loss: 18532484.666667, 		 Training Loss: 12621601.678571Validation Loss Decreased(11768935.000000--->10612394.000000) Saving model ...
Epoch 71 		 Validation Loss: 10612394.000000, 		 Training Loss: 10848699.321429Validation Loss Decreased(10612394.000000--->9418422.500000) Saving model ...
Epoch 72 		 Validation Loss: 9418422.500000, 		 Training Loss: 8926826.642857Validation Loss Decreased(9418422.500000--->8488934.666667) Saving model ...
Epoch 73 		 Validation Loss: 8488934.666667, 		 Training Loss: 7746578.464286Epoch 74 		 Validation Loss: 9504177.666667, 		 Training Loss: 8008526.500000Validation Loss Decreased(8488934.666667--->7942428.000000) Saving model ...
Epoch 75 		 Validation Loss: 7942428.000000, 		 Training Loss: 9907126.142857Epoch 76 		 Validation Loss: 22212829.333333, 		 Training Loss: 10531317.821429Epoch 77 		 Validation Loss: 19220671.333333, 		 Training Loss: 24718052.678571Epoch 78 		 Validation Loss: 9394253.666667, 		 Training Loss: 12630885.571429Epoch 79 		 Validation Loss: 10037875.500000, 		 Training Loss: 11239339.785714Validation Loss Decreased(7942428.000000--->7744807.666667) Saving model ...
Epoch 80 		 Validation Loss: 7744807.666667, 		 Training Loss: 10112975.392857Validation Loss Decreased(7744807.666667--->7501589.000000) Saving model ...
Epoch 81 		 Validation Loss: 7501589.000000, 		 Training Loss: 6716673.500000Validation Loss Decreased(7501589.000000--->7409559.333333) Saving model ...
Epoch 82 		 Validation Loss: 7409559.333333, 		 Training Loss: 6424015.535714Validation Loss Decreased(7409559.333333--->7337926.666667) Saving model ...
Epoch 83 		 Validation Loss: 7337926.666667, 		 Training Loss: 6411050.321429Validation Loss Decreased(7337926.666667--->7283461.166667) Saving model ...
Epoch 84 		 Validation Loss: 7283461.166667, 		 Training Loss: 6299714.464286Validation Loss Decreased(7283461.166667--->7236474.833333) Saving model ...
Epoch 85 		 Validation Loss: 7236474.833333, 		 Training Loss: 6263771.107143Validation Loss Decreased(7236474.833333--->7193384.833333) Saving model ...
Epoch 86 		 Validation Loss: 7193384.833333, 		 Training Loss: 6291147.678571Validation Loss Decreased(7193384.833333--->7148343.500000) Saving model ...
Epoch 87 		 Validation Loss: 7148343.500000, 		 Training Loss: 6091777.571429Validation Loss Decreased(7148343.500000--->7108964.333333) Saving model ...
Epoch 88 		 Validation Loss: 7108964.333333, 		 Training Loss: 6034835.142857Validation Loss Decreased(7108964.333333--->7071708.166667) Saving model ...
Epoch 89 		 Validation Loss: 7071708.166667, 		 Training Loss: 5979358.142857Validation Loss Decreased(7071708.166667--->7036403.833333) Saving model ...
Epoch 90 		 Validation Loss: 7036403.833333, 		 Training Loss: 5932727.892857Validation Loss Decreased(7036403.833333--->7003668.333333) Saving model ...
Epoch 91 		 Validation Loss: 7003668.333333, 		 Training Loss: 5912369.642857Validation Loss Decreased(7003668.333333--->6967814.166667) Saving model ...
Epoch 92 		 Validation Loss: 6967814.166667, 		 Training Loss: 5832563.428571Validation Loss Decreased(6967814.166667--->6926458.166667) Saving model ...
Epoch 93 		 Validation Loss: 6926458.166667, 		 Training Loss: 5858977.142857Validation Loss Decreased(6926458.166667--->6891780.333333) Saving model ...
Epoch 94 		 Validation Loss: 6891780.333333, 		 Training Loss: 5849934.785714Validation Loss Decreased(6891780.333333--->6868083.666667) Saving model ...
Epoch 95 		 Validation Loss: 6868083.666667, 		 Training Loss: 5753998.428571Validation Loss Decreased(6868083.666667--->6857280.333333) Saving model ...
Epoch 96 		 Validation Loss: 6857280.333333, 		 Training Loss: 5791134.392857Validation Loss Decreased(6857280.333333--->6854550.500000) Saving model ...
Epoch 97 		 Validation Loss: 6854550.500000, 		 Training Loss: 5749053.785714Validation Loss Decreased(6854550.500000--->6850651.833333) Saving model ...
Epoch 98 		 Validation Loss: 6850651.833333, 		 Training Loss: 5741609.428571Validation Loss Decreased(6850651.833333--->6847789.000000) Saving model ...
Epoch 99 		 Validation Loss: 6847789.000000, 		 Training Loss: 5779224.785714Validation Loss Decreased(6847789.000000--->6843910.333333) Saving model ...
Epoch 100 		 Validation Loss: 6843910.333333, 		 Training Loss: 5752386.250000Training Completed!
Training with lr=0.1, batch_size=64, n_epochs=250
Initializing Training Process..

Torch version: 1.11.0 ------ Selected Device: cuda:0
Sample Rate: 16000 Hz ------  Crop Lenght:3200 samples

Found 4 files in ../plate-spring/spring
Using dry_train.h5 and wet_train.h5 for train split.
Parameters: 395.339 k
Receptive field: 3495251 samples or 218453.2 ms

Training Loop

Validation Loss Decreased(inf--->14487289856.000000) Saving model ...
Epoch 1 		 Validation Loss: 14487289856.000000, 		 Training Loss: 19767970609.334133Epoch 2 		 Validation Loss: 203477183146.666656, 		 Training Loss: 76426149522.285721Epoch 3 		 Validation Loss: 210437810858.666656, 		 Training Loss: 965425088219.428589Epoch 4 		 Validation Loss: 3049906765824.000000, 		 Training Loss: 2085492387840.000000Epoch 5 		 Validation Loss: 60277519985322.664062, 		 Training Loss: 17230564172946.285156Epoch 6 		 Validation Loss: 60677971159722.664062, 		 Training Loss: 32867057383131.429688Epoch 7 		 Validation Loss: 61222886746794.664062, 		 Training Loss: 123259764492580.578125Epoch 8 		 Validation Loss: 6412147097600.000000, 		 Training Loss: 73818901390482.281250Epoch 9 		 Validation Loss: 229200515913045.343750, 		 Training Loss: 60721228639670.859375Epoch 10 		 Validation Loss: 8491283130264235.000000, 		 Training Loss: 2602114964820553.000000Epoch 11 		 Validation Loss: 1292873605578752.000000, 		 Training Loss: 3763454637319314.500000Epoch 12 		 Validation Loss: 3639039443162453.500000, 		 Training Loss: 7025228733780553.000000Epoch 13 		 Validation Loss: 173860415952213.343750, 		 Training Loss: 1183785733923986.250000Epoch 14 		 Validation Loss: 816243524588885.375000, 		 Training Loss: 368453423576795.437500Epoch 15 		 Validation Loss: 174438077868714.656250, 		 Training Loss: 227668455999780.562500Epoch 16 		 Validation Loss: 44229699043328.000000, 		 Training Loss: 100463025174235.421875Epoch 17 		 Validation Loss: 29452790661120.000000, 		 Training Loss: 109434259748571.421875Epoch 18 		 Validation Loss: 7899052507136.000000, 		 Training Loss: 28635197379145.144531Epoch 19 		 Validation Loss: 3693297096021.333496, 		 Training Loss: 9052799799881.142578Epoch 20 		 Validation Loss: 1833503468202.666748, 		 Training Loss: 3058205861010.285645Epoch 21 		 Validation Loss: 1262711909034.666748, 		 Training Loss: 1510656231716.571533Epoch 22 		 Validation Loss: 880135897088.000000, 		 Training Loss: 1238794670665.142822Epoch 23 		 Validation Loss: 1363883720704.000000, 		 Training Loss: 1359751357586.285645Epoch 24 		 Validation Loss: 828259172352.000000, 		 Training Loss: 1248431397741.714355Epoch 25 		 Validation Loss: 686655755605.333374, 		 Training Loss: 1540259783826.285645Epoch 26 		 Validation Loss: 1146966463829.333252, 		 Training Loss: 1184462831616.000000Epoch 27 		 Validation Loss: 3261958018389.333496, 		 Training Loss: 3877063126454.856934Epoch 28 		 Validation Loss: 1763132003669.333252, 		 Training Loss: 2196661923254.857178Epoch 29 		 Validation Loss: 744134060714.666626, 		 Training Loss: 1236679955017.142822Epoch 30 		 Validation Loss: 762263983445.333374, 		 Training Loss: 812106369316.571411Epoch 31 		 Validation Loss: 663139472725.333374, 		 Training Loss: 688979872036.571411Epoch 32 		 Validation Loss: 473038127104.000000, 		 Training Loss: 592893984768.000000Epoch 33 		 Validation Loss: 402658754560.000000, 		 Training Loss: 503246967369.142883Epoch 34 		 Validation Loss: 395579927210.666687, 		 Training Loss: 490538383067.428589Epoch 35 		 Validation Loss: 347936653312.000000, 		 Training Loss: 512649929874.285706Epoch 36 		 Validation Loss: 383462670336.000000, 		 Training Loss: 424098482468.571411Epoch 37 		 Validation Loss: 315906108074.666687, 		 Training Loss: 418377395638.857117Epoch 38 		 Validation Loss: 293054294698.666687, 		 Training Loss: 397264409161.142883Epoch 39 		 Validation Loss: 395165117098.666687, 		 Training Loss: 375524030171.428589Epoch 40 		 Validation Loss: 264787476480.000000, 		 Training Loss: 417030698715.428589Epoch 41 		 Validation Loss: 373061429930.666687, 		 Training Loss: 448470801261.714294Epoch 42 		 Validation Loss: 331133386752.000000, 		 Training Loss: 372060183405.714294Epoch 43 		 Validation Loss: 1004031595861.333374, 		 Training Loss: 706862532900.571411Epoch 44 		 Validation Loss: 524653821952.000000, 		 Training Loss: 660446958153.142822Epoch 45 		 Validation Loss: 634093152938.666626, 		 Training Loss: 571978687634.285767Epoch 46 		 Validation Loss: 369675141120.000000, 		 Training Loss: 583260045312.000000Epoch 47 		 Validation Loss: 280856286549.333313, 		 Training Loss: 517486769883.428589Epoch 48 		 Validation Loss: 472199867050.666687, 		 Training Loss: 515783091346.285706Epoch 49 		 Validation Loss: 282306052096.000000, 		 Training Loss: 522628017590.857117Epoch 50 		 Validation Loss: 778820343125.333374, 		 Training Loss: 662593106505.142822Epoch 51 		 Validation Loss: 339078687402.666687, 		 Training Loss: 601109851574.857178Epoch 52 		 Validation Loss: 587211363669.333374, 		 Training Loss: 708484757211.428589Epoch 53 		 Validation Loss: 295036846080.000000, 		 Training Loss: 463446925312.000000Epoch 54 		 Validation Loss: 208993845248.000000, 		 Training Loss: 300496400969.142883Epoch 55 		 Validation Loss: 446338749781.333313, 		 Training Loss: 334072285476.571411Epoch 56 		 Validation Loss: 384048955392.000000, 		 Training Loss: 395132215296.000000Epoch 57 		 Validation Loss: 796028327253.333374, 		 Training Loss: 420687743268.571411Epoch 58 		 Validation Loss: 327453868032.000000, 		 Training Loss: 632865524004.571411Epoch 59 		 Validation Loss: 392303214592.000000, 		 Training Loss: 357983675538.285706Epoch 60 		 Validation Loss: 491178688512.000000, 		 Training Loss: 351695793590.857117Epoch 61 		 Validation Loss: 271702272682.666656, 		 Training Loss: 476288305444.571411Epoch 62 		 Validation Loss: 644101657941.333374, 		 Training Loss: 517897125888.000000Epoch 63 		 Validation Loss: 808152399872.000000, 		 Training Loss: 627767100562.285767Epoch 64 		 Validation Loss: 234610043562.666656, 		 Training Loss: 453619019190.857117Epoch 65 		 Validation Loss: 301957993813.333313, 		 Training Loss: 276245852745.142883Epoch 66 		 Validation Loss: 167822420650.666656, 		 Training Loss: 207937821549.714294Epoch 67 		 Validation Loss: 144025376085.333344, 		 Training Loss: 184682437485.714294Epoch 68 		 Validation Loss: 154964486826.666656, 		 Training Loss: 186530412836.571442Epoch 69 		 Validation Loss: 159077968554.666656, 		 Training Loss: 163290287542.857147Epoch 70 		 Validation Loss: 285380946602.666687, 		 Training Loss: 208631479149.714294Epoch 71 		 Validation Loss: 595143666346.666626, 		 Training Loss: 516703021348.571411Epoch 72 		 Validation Loss: 354388322986.666687, 		 Training Loss: 436497635035.428589Epoch 73 		 Validation Loss: 163642927786.666656, 		 Training Loss: 393540643108.571411Epoch 74 		 Validation Loss: 259810290346.666656, 		 Training Loss: 280303479076.571411Epoch 75 		 Validation Loss: 192944788821.333344, 		 Training Loss: 186582740406.857147Epoch 76 		 Validation Loss: 144099344384.000000, 		 Training Loss: 161789892900.571442Epoch 77 		 Validation Loss: 118026002432.000000, 		 Training Loss: 152856226084.571442Epoch 78 		 Validation Loss: 118105882624.000000, 		 Training Loss: 142940974518.857147Epoch 79 		 Validation Loss: 140811233962.666656, 		 Training Loss: 148495592886.857147Epoch 80 		 Validation Loss: 103881252864.000000, 		 Training Loss: 148670439424.000000Epoch 81 		 Validation Loss: 230211300010.666656, 		 Training Loss: 242656921307.428558Epoch 82 		 Validation Loss: 292023992320.000000, 		 Training Loss: 253926699593.142853Epoch 83 		 Validation Loss: 125654873429.333328, 		 Training Loss: 187892868827.428558Epoch 84 		 Validation Loss: 257273976149.333344, 		 Training Loss: 199780651593.142853Epoch 85 		 Validation Loss: 356121695573.333313, 		 Training Loss: 261946372681.142853Epoch 86 		 Validation Loss: 230687741269.333344, 		 Training Loss: 219243761078.857147Epoch 87 		 Validation Loss: 291675854165.333313, 		 Training Loss: 219831642404.571442Epoch 88 		 Validation Loss: 208921990485.333344, 		 Training Loss: 357713236553.142883Epoch 89 		 Validation Loss: 114139223381.333328, 		 Training Loss: 195154549613.714294Epoch 90 		 Validation Loss: 103776987818.666672, 		 Training Loss: 137061414034.285721Epoch 91 		 Validation Loss: 118587730602.666672, 		 Training Loss: 136094471899.428574Epoch 92 		 Validation Loss: 232440703658.666656, 		 Training Loss: 206205267382.857147Epoch 93 		 Validation Loss: 161846984704.000000, 		 Training Loss: 200269142308.571442Epoch 94 		 Validation Loss: 152298307584.000000, 		 Training Loss: 170675744182.857147Epoch 95 		 Validation Loss: 124734507690.666672, 		 Training Loss: 191305621504.000000Epoch 96 		 Validation Loss: 103029276672.000000, 		 Training Loss: 137481251693.714294Epoch 97 		 Validation Loss: 84534351189.333328, 		 Training Loss: 132710861092.571426Epoch 98 		 Validation Loss: 130389499904.000000, 		 Training Loss: 113375224393.142853Epoch 99 		 Validation Loss: 79282839552.000000, 		 Training Loss: 115924757357.714279Epoch 100 		 Validation Loss: 77757786794.666672, 		 Training Loss: 139657979026.285706Epoch 101 		 Validation Loss: 99966787584.000000, 		 Training Loss: 115926435547.428574Epoch 102 		 Validation Loss: 76059852800.000000, 		 Training Loss: 121662881206.857147Epoch 103 		 Validation Loss: 83003179008.000000, 		 Training Loss: 116972209883.428574Epoch 104 		 Validation Loss: 106827016874.666672, 		 Training Loss: 109155029577.142853Epoch 105 		 Validation Loss: 131469481301.333328, 		 Training Loss: 190880909019.428558Epoch 106 		 Validation Loss: 691712229376.000000, 		 Training Loss: 458740460982.857117Epoch 107 		 Validation Loss: 186407103146.666656, 		 Training Loss: 398025094875.428589Epoch 108 		 Validation Loss: 288566837248.000000, 		 Training Loss: 220072778020.571442Epoch 109 		 Validation Loss: 162871219541.333344, 		 Training Loss: 245283677915.428558Epoch 110 		 Validation Loss: 112104254122.666672, 		 Training Loss: 182192946029.714294Epoch 111 		 Validation Loss: 146618515456.000000, 		 Training Loss: 113596765330.285721Epoch 112 		 Validation Loss: 70292512768.000000, 		 Training Loss: 97482575286.857147Epoch 113 		 Validation Loss: 64796028928.000000, 		 Training Loss: 82033698816.000000Epoch 114 		 Validation Loss: 214194689365.333344, 		 Training Loss: 89732968448.000000Epoch 115 		 Validation Loss: 149958939989.333344, 		 Training Loss: 169748653787.428558Epoch 116 		 Validation Loss: 171284365312.000000, 		 Training Loss: 140700292242.285706Epoch 117 		 Validation Loss: 73037949610.666672, 		 Training Loss: 141938553417.142853Epoch 118 		 Validation Loss: 62173336917.333336, 		 Training Loss: 84427435739.428574Epoch 119 		 Validation Loss: 234858381312.000000, 		 Training Loss: 124146280155.428574Epoch 120 		 Validation Loss: 116504849066.666672, 		 Training Loss: 246364364214.857147Epoch 121 		 Validation Loss: 101960272554.666672, 		 Training Loss: 133793239040.000000Epoch 122 		 Validation Loss: 96296301909.333328, 		 Training Loss: 122126561572.571426Epoch 123 		 Validation Loss: 76103062869.333328, 		 Training Loss: 86868922368.000000Epoch 124 		 Validation Loss: 65875760469.333336, 		 Training Loss: 120142127981.714279Epoch 125 		 Validation Loss: 64861525333.333336, 		 Training Loss: 78858698459.428574Epoch 126 		 Validation Loss: 59010215936.000000, 		 Training Loss: 71488697490.285721Epoch 127 		 Validation Loss: 54963617792.000000, 		 Training Loss: 74360436443.428574Epoch 128 		 Validation Loss: 85228022442.666672, 		 Training Loss: 126725827730.285721Epoch 129 		 Validation Loss: 261729036970.666656, 		 Training Loss: 201980447012.571442Epoch 130 		 Validation Loss: 172008614570.666656, 		 Training Loss: 177254549211.428558Epoch 131 		 Validation Loss: 93378701994.666672, 		 Training Loss: 178181468745.142853Epoch 132 		 Validation Loss: 99510968320.000000, 		 Training Loss: 131838968393.142853Epoch 133 		 Validation Loss: 121052039850.666672, 		 Training Loss: 87948326619.428574Epoch 134 		 Validation Loss: 118931892906.666672, 		 Training Loss: 129395682450.285721Epoch 135 		 Validation Loss: 95737643008.000000, 		 Training Loss: 112900237897.142853Epoch 136 		 Validation Loss: 78925873152.000000, 		 Training Loss: 89684616630.857147Epoch 137 		 Validation Loss: 48494798165.333336, 		 Training Loss: 66761983707.428574Epoch 138 		 Validation Loss: 50543457621.333336, 		 Training Loss: 63893300077.714287Epoch 139 		 Validation Loss: 64212668416.000000, 		 Training Loss: 61245146258.285713Epoch 140 		 Validation Loss: 97440680618.666672, 		 Training Loss: 94866026203.428574Epoch 141 		 Validation Loss: 95598551040.000000, 		 Training Loss: 102108588617.142853Epoch 142 		 Validation Loss: 78828492117.333328, 		 Training Loss: 94946336182.857147Epoch 143 		 Validation Loss: 56074499413.333336, 		 Training Loss: 92247201499.428574Epoch 144 		 Validation Loss: 139776507904.000000, 		 Training Loss: 92161579885.714279Epoch 145 		 Validation Loss: 111594785450.666672, 		 Training Loss: 144980511890.285706Epoch 146 		 Validation Loss: 86180779349.333328, 		 Training Loss: 90504175323.428574Epoch 147 		 Validation Loss: 101854857898.666672, 		 Training Loss: 102918032822.857147Epoch 148 		 Validation Loss: 91089480362.666672, 		 Training Loss: 83749493613.714279Epoch 149 		 Validation Loss: 55531186858.666664, 		 Training Loss: 91614758326.857147Epoch 150 		 Validation Loss: 71816699904.000000, 		 Training Loss: 65610781257.142860Epoch 151 		 Validation Loss: 64468324352.000000, 		 Training Loss: 100966012928.000000Epoch 152 		 Validation Loss: 42604369237.333336, 		 Training Loss: 54840176054.857140Epoch 153 		 Validation Loss: 59069601109.333336, 		 Training Loss: 50222144658.285713Epoch 154 		 Validation Loss: 63348548949.333336, 		 Training Loss: 83021786843.428574Epoch 155 		 Validation Loss: 76005537109.333328, 		 Training Loss: 81740854710.857147Epoch 156 		 Validation Loss: 111587827712.000000, 		 Training Loss: 81225814893.714279Epoch 157 		 Validation Loss: 233386344448.000000, 		 Training Loss: 111332282953.142853Epoch 158 		 Validation Loss: 80310796288.000000, 		 Training Loss: 103689421970.285721Epoch 159 		 Validation Loss: 106940721834.666672, 		 Training Loss: 115043442688.000000Epoch 160 		 Validation Loss: 75780724053.333328, 		 Training Loss: 80827651803.428574Epoch 161 		 Validation Loss: 42287592789.333336, 		 Training Loss: 83002076013.714279Epoch 162 		 Validation Loss: 84130665813.333328, 		 Training Loss: 110074454016.000000Epoch 163 		 Validation Loss: 83898414421.333328, 		 Training Loss: 87457410194.285721Epoch 164 		 Validation Loss: 48576345429.333336, 		 Training Loss: 56656443392.000000Epoch 165 		 Validation Loss: 128559696554.666672, 		 Training Loss: 66159703478.857140Epoch 166 		 Validation Loss: 69116387328.000000, 		 Training Loss: 116962692534.857147Epoch 167 		 Validation Loss: 75392849237.333328, 		 Training Loss: 66816349330.285713Epoch 168 		 Validation Loss: 71961635498.666672, 		 Training Loss: 77069004800.000000Epoch 169 		 Validation Loss: 49173258240.000000, 		 Training Loss: 70608680667.428574Epoch 170 		 Validation Loss: 32531085312.000000, 		 Training Loss: 46628171483.428574Epoch 171 		 Validation Loss: 36553658368.000000, 		 Training Loss: 37862140489.142860Epoch 172 		 Validation Loss: 54586392576.000000, 		 Training Loss: 56248960438.857140Epoch 173 		 Validation Loss: 32926641493.333332, 		 Training Loss: 61871723812.571426Epoch 174 		 Validation Loss: 36847767552.000000, 		 Training Loss: 38524129865.142860Epoch 175 		 Validation Loss: 56423366656.000000, 		 Training Loss: 53951373458.285713Epoch 176 		 Validation Loss: 74520502272.000000, 		 Training Loss: 64969994532.571426Epoch 177 		 Validation Loss: 50629677056.000000, 		 Training Loss: 63919387794.285713Epoch 178 		 Validation Loss: 54378964309.333336, 		 Training Loss: 59577395492.571426Epoch 179 		 Validation Loss: 47464049322.666664, 		 Training Loss: 55994851035.428574Epoch 180 		 Validation Loss: 66765389824.000000, 		 Training Loss: 82998189787.428574Epoch 181 		 Validation Loss: 40511672320.000000, 		 Training Loss: 83799742756.571426Epoch 182 		 Validation Loss: 33833362090.666668, 		 Training Loss: 53359480685.714287Epoch 183 		 Validation Loss: 39854639786.666664, 		 Training Loss: 57707529947.428574Epoch 184 		 Validation Loss: 37793793365.333336, 		 Training Loss: 48254504082.285713Epoch 185 		 Validation Loss: 27207728469.333332, 		 Training Loss: 38369570377.142860Epoch 186 		 Validation Loss: 49702810965.333336, 		 Training Loss: 33666671030.857143Epoch 187 		 Validation Loss: 65498158421.333336, 		 Training Loss: 59309920109.714287Epoch 188 		 Validation Loss: 53993832448.000000, 		 Training Loss: 59263218541.714287Epoch 189 		 Validation Loss: 30768342357.333332, 		 Training Loss: 44987802185.142860Epoch 190 		 Validation Loss: 84557343402.666672, 		 Training Loss: 68152244955.428574Epoch 191 		 Validation Loss: 152136723114.666656, 		 Training Loss: 89631508187.428574Epoch 192 		 Validation Loss: 48645150037.333336, 		 Training Loss: 96192497664.000000Epoch 193 		 Validation Loss: 81454754474.666672, 		 Training Loss: 72316456228.571426Epoch 194 		 Validation Loss: 29641126570.666668, 		 Training Loss: 75605959680.000000Epoch 195 		 Validation Loss: 30298731861.333332, 		 Training Loss: 46335418953.142860Epoch 196 		 Validation Loss: 25688268800.000000, 		 Training Loss: 39470024265.142860Epoch 197 		 Validation Loss: 22401835008.000000, 		 Training Loss: 31553813065.142857Epoch 198 		 Validation Loss: 25137440768.000000, 		 Training Loss: 34289575497.142857Epoch 199 		 Validation Loss: 36518888789.333336, 		 Training Loss: 32704348891.428570Epoch 200 		 Validation Loss: 34852876288.000000, 		 Training Loss: 29558694765.714287Epoch 201 		 Validation Loss: 24749396650.666668, 		 Training Loss: 28217551286.857143Epoch 202 		 Validation Loss: 20696105642.666668, 		 Training Loss: 24223283200.000000Epoch 203 		 Validation Loss: 19461516629.333332, 		 Training Loss: 22600590336.000000Epoch 204 		 Validation Loss: 19331594922.666668, 		 Training Loss: 22074294125.714287Epoch 205 		 Validation Loss: 19218868906.666668, 		 Training Loss: 22059151067.428570Epoch 206 		 Validation Loss: 19089141077.333332, 		 Training Loss: 22236198692.571430Epoch 207 		 Validation Loss: 18991666517.333332, 		 Training Loss: 21830127177.142857Epoch 208 		 Validation Loss: 18893819904.000000, 		 Training Loss: 21814818962.285713Epoch 209 		 Validation Loss: 18806714368.000000, 		 Training Loss: 21482919350.857143Epoch 210 		 Validation Loss: 18763044864.000000, 		 Training Loss: 21760055296.000000Epoch 211 		 Validation Loss: 18699444224.000000, 		 Training Loss: 21516856685.714287Epoch 212 		 Validation Loss: 18540500992.000000, 		 Training Loss: 21443244251.428570Epoch 213 		 Validation Loss: 18436706304.000000, 		 Training Loss: 21205501805.714287Epoch 214 		 Validation Loss: 18353997141.333332, 		 Training Loss: 20953842980.571430Epoch 215 		 Validation Loss: 18278744746.666668, 		 Training Loss: 20670571666.285713Epoch 216 		 Validation Loss: 18200724138.666668, 		 Training Loss: 21269149184.000000Epoch 217 		 Validation Loss: 18115154602.666668, 		 Training Loss: 20651106157.714287Epoch 218 		 Validation Loss: 18045429077.333332, 		 Training Loss: 20549720868.571430Epoch 219 		 Validation Loss: 17993694549.333332, 		 Training Loss: 20690708772.571430Epoch 220 		 Validation Loss: 17882219861.333332, 		 Training Loss: 20485050221.714287Epoch 221 		 Validation Loss: 17914471765.333332, 		 Training Loss: 20457288704.000000Epoch 222 		 Validation Loss: 17874563754.666668, 		 Training Loss: 20876158976.000000Epoch 223 		 Validation Loss: 17817312597.333332, 		 Training Loss: 20257435282.285713Epoch 224 		 Validation Loss: 17752944640.000000, 		 Training Loss: 20554243437.714287Epoch 225 		 Validation Loss: 17599714645.333332, 		 Training Loss: 20126016512.000000Epoch 226 		 Validation Loss: 17505069738.666668, 		 Training Loss: 20529674971.428570Epoch 227 		 Validation Loss: 17412417536.000000, 		 Training Loss: 19988306797.714287Epoch 228 		 Validation Loss: 17377349290.666668, 		 Training Loss: 19940151808.000000Epoch 229 		 Validation Loss: 17296449877.333332, 		 Training Loss: 20319790299.428570Epoch 230 		 Validation Loss: 17227325098.666668, 		 Training Loss: 19683182518.857143Epoch 231 		 Validation Loss: 17170903381.333334, 		 Training Loss: 19677804763.428570Epoch 232 		 Validation Loss: 17106362368.000000, 		 Training Loss: 20068066377.142857Epoch 233 		 Validation Loss: 17039041194.666666, 		 Training Loss: 19978506093.714287Epoch 234 		 Validation Loss: 17241075029.333332, 		 Training Loss: 19994392210.285713Epoch 235 		 Validation Loss: 16924830720.000000, 		 Training Loss: 19948165193.142857Epoch 236 		 Validation Loss: 16945864021.333334, 		 Training Loss: 19810182217.142857Epoch 237 		 Validation Loss: 16787243690.666666, 		 Training Loss: 19233960813.714287Epoch 238 		 Validation Loss: 16787048789.333334, 		 Training Loss: 19429259995.428570Epoch 239 		 Validation Loss: 16777562453.333334, 		 Training Loss: 19400685275.428570Epoch 240 		 Validation Loss: 16771240277.333334, 		 Training Loss: 19058128457.142857Epoch 241 		 Validation Loss: 16770879488.000000, 		 Training Loss: 19628216027.428570Epoch 242 		 Validation Loss: 16760662357.333334, 		 Training Loss: 19424663917.714287Epoch 243 		 Validation Loss: 16754210474.666666, 		 Training Loss: 19074200941.714287Epoch 244 		 Validation Loss: 16746876586.666666, 		 Training Loss: 19481524516.571430Epoch 245 		 Validation Loss: 16743876266.666666, 		 Training Loss: 19289726098.285713Epoch 246 		 Validation Loss: 16737960960.000000, 		 Training Loss: 19305477485.714287Epoch 247 		 Validation Loss: 16735084544.000000, 		 Training Loss: 19109384996.571430Epoch 248 		 Validation Loss: 16723698346.666666, 		 Training Loss: 19061763510.857143Epoch 249 		 Validation Loss: 16722196138.666666, 		 Training Loss: 19135513014.857143Epoch 250 		 Validation Loss: 16710168234.666666, 		 Training Loss: 19055410395.428570Training Completed!
Training with lr=0.1, batch_size=128, n_epochs=50
Initializing Training Process..

Torch version: 1.11.0 ------ Selected Device: cuda:0
Sample Rate: 16000 Hz ------  Crop Lenght:3200 samples

Found 4 files in ../plate-spring/spring
Using dry_train.h5 and wet_train.h5 for train split.
Parameters: 395.339 k
Receptive field: 3495251 samples or 218453.2 ms

Training Loop

Validation Loss Decreased(inf--->720163136.000000) Saving model ...
Epoch 1 		 Validation Loss: 720163136.000000, 		 Training Loss: 3404672161.973096Epoch 2 		 Validation Loss: 76603129856.000000, 		 Training Loss: 14649334710.857143Epoch 3 		 Validation Loss: 821837496320.000000, 		 Training Loss: 75567156077.714279Epoch 4 		 Validation Loss: 150753427456.000000, 		 Training Loss: 183430948571.428558Epoch 5 		 Validation Loss: 143680700416.000000, 		 Training Loss: 1846472280356.571533Epoch 6 		 Validation Loss: 7846276628480.000000, 		 Training Loss: 4488447555291.428711Epoch 7 		 Validation Loss: 4846392967168.000000, 		 Training Loss: 2658275973997.714355Epoch 8 		 Validation Loss: 15495690452992.000000, 		 Training Loss: 6189808793307.428711Epoch 9 		 Validation Loss: 8243984728064.000000, 		 Training Loss: 48562094697910.859375Epoch 10 		 Validation Loss: 19465171369984.000000, 		 Training Loss: 8196206137929.142578Epoch 11 		 Validation Loss: 22848953384960.000000, 		 Training Loss: 15002017389421.714844Epoch 12 		 Validation Loss: 1133193461760.000000, 		 Training Loss: 9080295119725.714844Epoch 13 		 Validation Loss: 130513534976.000000, 		 Training Loss: 646016794624.000000Epoch 14 		 Validation Loss: 1212971614208.000000, 		 Training Loss: 335382485869.714294Epoch 15 		 Validation Loss: 110037721088.000000, 		 Training Loss: 630139760054.857178Epoch 16 		 Validation Loss: 96079495168.000000, 		 Training Loss: 100083063661.714279Epoch 17 		 Validation Loss: 82019745792.000000, 		 Training Loss: 85588285147.428574Epoch 18 		 Validation Loss: 53302071296.000000, 		 Training Loss: 58491456365.714287Epoch 19 		 Validation Loss: 122233552896.000000, 		 Training Loss: 80782826642.285721Epoch 20 		 Validation Loss: 51747143680.000000, 		 Training Loss: 87547511954.285721Epoch 21 		 Validation Loss: 33343844352.000000, 		 Training Loss: 40679656594.285713Epoch 22 		 Validation Loss: 13022105600.000000, 		 Training Loss: 22793957083.428570Epoch 23 		 Validation Loss: 12179166208.000000, 		 Training Loss: 14690274889.142857Epoch 24 		 Validation Loss: 9524879360.000000, 		 Training Loss: 10724464201.142857Epoch 25 		 Validation Loss: 8370609152.000000, 		 Training Loss: 7517764315.428572Epoch 26 		 Validation Loss: 12401415168.000000, 		 Training Loss: 7079689728.000000Epoch 27 		 Validation Loss: 7024152064.000000, 		 Training Loss: 12341965824.000000Epoch 28 		 Validation Loss: 11412902912.000000, 		 Training Loss: 9451740160.000000Epoch 29 		 Validation Loss: 8009618944.000000, 		 Training Loss: 10597290422.857143Epoch 30 		 Validation Loss: 3775445760.000000, 		 Training Loss: 6202023168.000000Epoch 31 		 Validation Loss: 3078827008.000000, 		 Training Loss: 4023224393.142857Epoch 32 		 Validation Loss: 2845584128.000000, 		 Training Loss: 3918555062.857143Epoch 33 		 Validation Loss: 2870020608.000000, 		 Training Loss: 3122073270.857143Epoch 34 		 Validation Loss: 2153214208.000000, 		 Training Loss: 3059682157.714286Epoch 35 		 Validation Loss: 1991871872.000000, 		 Training Loss: 2526241334.857143Epoch 36 		 Validation Loss: 1987750272.000000, 		 Training Loss: 2346218185.142857Epoch 37 		 Validation Loss: 2027895168.000000, 		 Training Loss: 2677369051.428571Epoch 38 		 Validation Loss: 2806901760.000000, 		 Training Loss: 2297629476.571429Epoch 39 		 Validation Loss: 2696040192.000000, 		 Training Loss: 2510513974.857143Epoch 40 		 Validation Loss: 3937118464.000000, 		 Training Loss: 2476739620.571429Epoch 41 		 Validation Loss: 2428703232.000000, 		 Training Loss: 3025360640.000000Epoch 42 		 Validation Loss: 1683542656.000000, 		 Training Loss: 2136151259.428571Epoch 43 		 Validation Loss: 1830315520.000000, 		 Training Loss: 1944460416.000000Epoch 44 		 Validation Loss: 1666985344.000000, 		 Training Loss: 1758722194.285714Epoch 45 		 Validation Loss: 1480685952.000000, 		 Training Loss: 1671401764.571429Epoch 46 		 Validation Loss: 1457308544.000000, 		 Training Loss: 1638462080.000000Epoch 47 		 Validation Loss: 1445906816.000000, 		 Training Loss: 1560002870.857143Epoch 48 		 Validation Loss: 1443819904.000000, 		 Training Loss: 1511900653.714286Epoch 49 		 Validation Loss: 1440991872.000000, 		 Training Loss: 1528239049.142857Epoch 50 		 Validation Loss: 1440218368.000000, 		 Training Loss: 1522399158.857143CUDA out of memory. Tried to allocate 1000.00 MiB (GPU 0; 14.76 GiB total capacity; 13.71 GiB already allocated; 109.75 MiB free; 13.75 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Error occurs, No graph saved
