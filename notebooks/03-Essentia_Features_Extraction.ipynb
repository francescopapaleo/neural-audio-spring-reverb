{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Audio Features with Essentia Streaming\n",
    "\n",
    "Essentia is an open-source C++ library for audio analysis and audio-based music information retrieval.\n",
    "Documentation: http://essentia.upf.edu/documentation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "import essentia\n",
    "import essentia.standard as esstd\n",
    "import essentia.streaming as esstr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from fnmatch import fnmatch\n",
    "from pathlib import Path\n",
    "\n",
    "from src.data.egfxset import load_egfxset\n",
    "from src.data.springset import load_springset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('../data/raw/')\n",
    "MODELS_DIR = Path('../models/')\n",
    "RESULTS_DIR = Path('../results/')\n",
    "PLOTS_DIR = Path('../results/plots/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_basic_features_essentia(data, sample_rate):\n",
    "    \"\"\"\"\"\"\n",
    "\n",
    "    features = {}\n",
    "\n",
    "    pool = essentia.Pool()\n",
    "\n",
    "    # Instantiate the algorithms\n",
    "    # loader = esstr.MonoLoader(filename=file, sampleRate=sample_rate)\n",
    "    loader = esstr.VectorInput(data)\n",
    "    fcut = esstr.FrameCutter(frameSize=2048, hopSize=1024)\n",
    "    w = esstr.Windowing(type='hann')\n",
    "    spec = esstr.Spectrum(size=2048)\n",
    "    \n",
    "    gain = esstr.ReplayGain(sampleRate=sample_rate)\n",
    "    leq = esstr.Leq()\n",
    "    loudness = esstr.Loudness()\n",
    "\n",
    "    zero_crossing_rate = esstr.ZeroCrossingRate()\n",
    "    \n",
    "    centroid = esstr.SpectralCentroidTime(sampleRate=sample_rate)\n",
    "    pitch = esstr.PitchYin(sampleRate=sample_rate)\n",
    "\n",
    "    # Connect the algorithms\n",
    "    loader.data >> fcut.signal\n",
    "    fcut.frame >> centroid.array\n",
    "    fcut.frame >> loudness.signal\n",
    "\n",
    "    fcut.frame >> zero_crossing_rate.signal\n",
    "    \n",
    "    fcut.frame >> pitch.signal\n",
    "   \n",
    "    loader.data >> gain.signal\n",
    "    loader.data >> leq.signal\n",
    "    \n",
    "    # Create a pool and output algorithms\n",
    "    gain.replayGain >> (pool, 'gain')\n",
    "    leq.leq >> (pool, 'leq')\n",
    "    loudness.loudness >> (pool, 'loudness')\n",
    "    \n",
    "    zero_crossing_rate.zeroCrossingRate >> (pool, 'zcr')\n",
    "    \n",
    "    centroid.centroid >> (pool, 'centroid')\n",
    "\n",
    "    pitch.pitch >> (pool, 'pitch')\n",
    "    pitch.pitchConfidence >> (pool, 'confidence')\n",
    "\n",
    "    # Run the network\n",
    "    essentia.run(loader)\n",
    "\n",
    "    aggrpool = esstd.PoolAggregator(defaultStats = [\"mean\"])(pool)    \n",
    "    descriptors = aggrpool.descriptorNames()\n",
    "    \n",
    "    # for feature in ['gain', 'leq', 'loudness.mean', 'centroid.mean', 'pitch.mean', 'confidence.mean']:\n",
    "    #     features[feature].append(np.array(aggrpool[feature]).flatten()[0])\n",
    "    for feature in ['gain', 'leq', 'loudness.mean', 'zcr.mean', 'centroid.mean', 'pitch.mean', 'confidence.mean']:\n",
    "        value = np.array(aggrpool[feature]).flatten()[0]\n",
    "        if feature not in features:\n",
    "            features[feature] = []\n",
    "            features[feature].append(value)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Larger set of features\n",
    "\n",
    "\n",
    "to get help:\n",
    "```python\n",
    "help(esstr.SNR())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on StreamingAlgo in module essentia.streaming object:\n",
      "\n",
      "class StreamingAlgo(Algorithm)\n",
      " |  StreamingAlgo(**kwargs)\n",
      " |  \n",
      " |  LowLevelSpectralExtractor\n",
      " |  \n",
      " |  \n",
      " |  Inputs:\n",
      " |  \n",
      " |    [real] signal - the input audio signal\n",
      " |  \n",
      " |  \n",
      " |  Outputs:\n",
      " |  \n",
      " |    [vector_real] barkbands - spectral energy at each bark band. See BarkBands alogithm\n",
      " |           [real] barkbands_kurtosis - kurtosis from bark bands. See DistributionShape algorithm documentation\n",
      " |           [real] barkbands_skewness - skewness from bark bands. See DistributionShape algorithm documentation\n",
      " |           [real] barkbands_spread - spread from barkbands. See DistributionShape algorithm documentation\n",
      " |           [real] hfc - See HFC algorithm documentation\n",
      " |    [vector_real] mfcc - See MFCC algorithm documentation\n",
      " |           [real] pitch - See PitchYinFFT algorithm documentation\n",
      " |           [real] pitch_instantaneous_confidence - See PitchYinFFT algorithm documentation\n",
      " |           [real] pitch_salience - See PitchSalience algorithm documentation\n",
      " |           [real] silence_rate_20dB - See SilenceRate algorithm documentation\n",
      " |           [real] silence_rate_30dB - See SilenceRate algorithm documentation\n",
      " |           [real] silence_rate_60dB - See SilenceRate algorithm documentation\n",
      " |           [real] spectral_complexity - See Spectral algorithm documentation\n",
      " |           [real] spectral_crest - See Crest algorithm documentation\n",
      " |           [real] spectral_decrease - See Decrease algorithm documentation\n",
      " |           [real] spectral_energy - See Energy algorithm documentation\n",
      " |           [real] spectral_energyband_low - Energy in band (20,150] Hz. See EnergyBand algorithm documentation\n",
      " |           [real] spectral_energyband_middle_low - Energy in band (150,800] Hz.See EnergyBand algorithm documentation\n",
      " |           [real] spectral_energyband_middle_high - Energy in band (800,4000] Hz. See EnergyBand algorithm documentation\n",
      " |           [real] spectral_energyband_high - Energy in band (4000,20000] Hz. See EnergyBand algorithm documentation\n",
      " |           [real] spectral_flatness_db - See flatnessDB algorithm documentation\n",
      " |           [real] spectral_flux - See Flux algorithm documentation\n",
      " |           [real] spectral_rms - See RMS algorithm documentation\n",
      " |           [real] spectral_rolloff - See RollOff algorithm documentation\n",
      " |           [real] spectral_strongpeak - See StrongPeak algorithm documentation\n",
      " |           [real] zerocrossingrate - See ZeroCrossingRate algorithm documentation\n",
      " |           [real] inharmonicity - See Inharmonicity algorithm documentation\n",
      " |    [vector_real] tristimulus - See Tristimulus algorithm documentation\n",
      " |           [real] oddtoevenharmonicenergyratio - See OddToEvenHarmonicEnergyRatio algorithm documentation\n",
      " |  \n",
      " |  \n",
      " |  Parameters:\n",
      " |  \n",
      " |    frameSize:\n",
      " |      integer ∈ (0,inf) (default = 2048)\n",
      " |      the frame size for computing low level features\n",
      " |  \n",
      " |    hopSize:\n",
      " |      integer ∈ (0,inf) (default = 1024)\n",
      " |      the hop size for computing low level features\n",
      " |  \n",
      " |    sampleRate:\n",
      " |      real ∈ (0,inf) (default = 44100)\n",
      " |      the audio sampling rate\n",
      " |  \n",
      " |  \n",
      " |  Description:\n",
      " |  \n",
      " |    This algorithm extracts all low-level spectral features, which do not require\n",
      " |    an equal-loudness filter for their computation, from an audio signal\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      StreamingAlgo\n",
      " |      Algorithm\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, **kwargs)\n",
      " |  \n",
      " |  configure(self, **kwargs)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __struct__ = {'category': 'Extractors', 'description': 'This algorithm...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Algorithm:\n",
      " |  \n",
      " |  __configure__(...)\n",
      " |      Configures the algorithm.\n",
      " |  \n",
      " |  getDoc(...)\n",
      " |      Returns the doc string for the algorithm\n",
      " |  \n",
      " |  getInputType(...)\n",
      " |      returns a string representation of input type specified by a given name\n",
      " |  \n",
      " |  getOutputType(...)\n",
      " |      returns a string representation of input type specified by a given name\n",
      " |  \n",
      " |  getStruct(...)\n",
      " |      Returns the doc struct for the algorithm\n",
      " |  \n",
      " |  hasInput(...)\n",
      " |      Returns true if algorithm contains given sink name.\n",
      " |  \n",
      " |  hasOutput(...)\n",
      " |      Returns true if algorithm contains given source name.\n",
      " |  \n",
      " |  inputNames(...)\n",
      " |      Returns a list of the sink names of the algorithm.\n",
      " |  \n",
      " |  name(...)\n",
      " |      Returns the name of the algorithm.\n",
      " |  \n",
      " |  outputNames(...)\n",
      " |      Returns a list of the source names of the algorithm.\n",
      " |  \n",
      " |  paramType(...)\n",
      " |      Returns the type of the parameter given by its name\n",
      " |  \n",
      " |  paramValue(...)\n",
      " |      Returns the value of the parameter or None if not yet configured\n",
      " |  \n",
      " |  parameterNames(...)\n",
      " |      Returns the names of the parameters for this algorithm.\n",
      " |  \n",
      " |  push(...)\n",
      " |      acquires 1 token for the given source name.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from Algorithm:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# help(esstr.SNR())\n",
    "print(help(esstr.LowLevelSpectralExtractor()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_more_features_essentia(data, sample_rate):\n",
    "    \"\"\"Extract various audio features using Essentia's streaming mode.\"\"\"\n",
    "    \n",
    "    frame_size = 1024\n",
    "    # noise_threshold = -90\n",
    "\n",
    "    features = {}\n",
    "    pool = essentia.Pool()\n",
    "\n",
    "    # Instantiate the algorithms\n",
    "    loader = esstr.VectorInput(data)\n",
    "    fcut = esstr.FrameCutter(frameSize=frame_size, hopSize=512)\n",
    "    w = esstr.Windowing()\n",
    "    spec = esstr.Spectrum(size=frame_size)\n",
    "\n",
    "    gain = esstr.ReplayGain(sampleRate=sample_rate)\n",
    "    leq = esstr.Leq()\n",
    "    loudness = esstr.Loudness()\n",
    "    zero_crossing_rate = esstr.ZeroCrossingRate()\n",
    "    centroid = esstr.SpectralCentroidTime(sampleRate=sample_rate)\n",
    "    pitch = esstr.PitchYin(sampleRate=sample_rate, frameSize=frame_size)\n",
    "    \n",
    "    # New features' algorithms\n",
    "    flatness = esstr.FlatnessDB()\n",
    "    hfc = esstr.HFC(sampleRate=sample_rate)\n",
    "    # snr = esstr.SNR(sampleRate=sample_rate, frameSize=frame_size, noiseThreshold=noise_threshold)\n",
    "\n",
    "    # Connect the algorithms\n",
    "    loader.data >> fcut.signal\n",
    "    loader.data >> gain.signal\n",
    "    loader.data >> leq.signal\n",
    "\n",
    "    fcut.frame >> centroid.array\n",
    "    fcut.frame >> loudness.signal\n",
    "    fcut.frame >> zero_crossing_rate.signal\n",
    "    fcut.frame >> pitch.signal\n",
    "    # fcut.frame >> snr.frame\n",
    "    \n",
    "    fcut.frame >> w.frame\n",
    "    w.frame >> spec.frame\n",
    "\n",
    "    spec.spectrum >> flatness.array\n",
    "    spec.spectrum >> hfc.spectrum\n",
    "    \n",
    "    # Add the features to the pool\n",
    "    gain.replayGain >> (pool, 'gain')\n",
    "    leq.leq >> (pool, 'leq')\n",
    "    loudness.loudness >> (pool, 'loudness')\n",
    "    zero_crossing_rate.zeroCrossingRate >> (pool, 'zcr')\n",
    "    centroid.centroid >> (pool, 'centroid')\n",
    "    pitch.pitch >> (pool, 'pitch')\n",
    "    pitch.pitchConfidence >> (pool, 'confidence')\n",
    "\n",
    "    # snr.instantSNR >> None\n",
    "    # snr.averagedSNR >> None\n",
    "    # snr.spectralSNR >> (pool, 'spectralSNR')\n",
    "    \n",
    "    flatness.flatnessDB >> (pool, 'flatness')\n",
    "    hfc.hfc >> (pool, 'hfc')\n",
    "    \n",
    "    # Run the network\n",
    "    essentia.run(loader)\n",
    "\n",
    "    aggrpool = esstd.PoolAggregator(defaultStats = [\"mean\"])(pool)    \n",
    "\n",
    "    # Extract features\n",
    "    for feature in ['gain', 'leq', 'loudness.mean', 'zcr.mean', 'pitch.mean', 'confidence.mean', 'flatness.mean', 'hfc.mean']:\n",
    "        value = np.array(aggrpool[feature]).flatten()[0]\n",
    "        \n",
    "        # Remove the .mean suffix for storage\n",
    "        feature_name = feature.replace('.mean', '')\n",
    "\n",
    "        if feature_name not in features:\n",
    "            features[feature_name] = []\n",
    "        features[feature_name].append(value)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EGFxSet\n",
    "\n",
    "This may take long time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 48000\n",
    "train_loader, valid_loader, test_loader = load_egfxset(datadir=DATA_DIR, batch_size=1, train_ratio=0.50, valid_ratio=0.25, test_ratio=0.25, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EGFxSet: train set\n",
    "\n",
    "data_x = []\n",
    "data_y = []\n",
    "\n",
    "for idx, (input, target) in enumerate(train_loader):\n",
    "    # Convert tensor to numpy and ensure dtype and shape\n",
    "    input_np = input.numpy().squeeze().astype(np.float32)\n",
    "    target_np = target.numpy().squeeze().astype(np.float32)\n",
    "\n",
    "    # Extract features from the dry signal\n",
    "    x_features = extract_more_features_essentia(input_np, sample_rate)\n",
    "    y_features = extract_more_features_essentia(target_np, sample_rate)\n",
    "\n",
    "    x_features = {f'{key}': value for key, value in x_features.items()}\n",
    "    y_features = {f'{key}': value for key, value in y_features.items()}\n",
    "    \n",
    "    data_x.append({'idx': idx, **x_features})\n",
    "    data_y.append({'idx': idx, **y_features})\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_x = pd.DataFrame(data_x)\n",
    "df_y = pd.DataFrame(data_y)\n",
    "\n",
    "# Save DataFrame as a .json file\n",
    "df_x.to_json(os.path.join(RESULTS_DIR, 'egfxset_x_train.json'), orient='records', lines=True)\n",
    "df_y.to_json(os.path.join(RESULTS_DIR, 'egfxset_y_train.json'), orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EGFxSet: validation set\n",
    "\n",
    "data_x = []\n",
    "data_y = []\n",
    "\n",
    "for idx, (input, target) in enumerate(valid_loader):\n",
    "    # Convert tensor to numpy and ensure dtype and shape\n",
    "    input_np = input.numpy().squeeze().astype(np.float32)\n",
    "    target_np = target.numpy().squeeze().astype(np.float32)\n",
    "\n",
    "    # Extract features from the dry signal\n",
    "    x_features = extract_more_features_essentia(input_np, sample_rate)\n",
    "    y_features = extract_more_features_essentia(target_np, sample_rate)\n",
    "\n",
    "    x_features = {f'{key}': value for key, value in x_features.items()}\n",
    "    y_features = {f'{key}': value for key, value in y_features.items()}\n",
    "    \n",
    "    data_x.append({'idx': idx, **x_features})\n",
    "    data_y.append({'idx': idx, **y_features})\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_x = pd.DataFrame(data_x)\n",
    "df_y = pd.DataFrame(data_y)\n",
    "\n",
    "# Save DataFrame as a .json file\n",
    "df_x.to_json(os.path.join(RESULTS_DIR, 'egfxset_x_valid.json'), orient='records', lines=True)\n",
    "df_y.to_json(os.path.join(RESULTS_DIR, 'egfxset_y_valid.json'), orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EGFxSet: test set\n",
    "\n",
    "data_x = []\n",
    "data_y = []\n",
    "\n",
    "for idx, (input, target) in enumerate(test_loader):\n",
    "    # Convert tensor to numpy and ensure dtype and shape\n",
    "    input_np = input.numpy().squeeze().astype(np.float32)\n",
    "    target_np = target.numpy().squeeze().astype(np.float32)\n",
    "\n",
    "    # Extract features from the dry signal\n",
    "    x_features = extract_more_features_essentia(input_np, sample_rate)\n",
    "    y_features = extract_more_features_essentia(target_np, sample_rate)\n",
    "\n",
    "    x_features = {f'{key}': value for key, value in x_features.items()}\n",
    "    y_features = {f'{key}': value for key, value in y_features.items()}\n",
    "    \n",
    "    data_x.append({'idx': idx, **x_features})\n",
    "    data_y.append({'idx': idx, **y_features})\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_x = pd.DataFrame(data_x)\n",
    "df_y = pd.DataFrame(data_y)\n",
    "\n",
    "# Save DataFrame as a .json file\n",
    "df_x.to_json(os.path.join(RESULTS_DIR, 'egfxset_x_test.json'), orient='records', lines=True)\n",
    "df_y.to_json(os.path.join(RESULTS_DIR, 'egfxset_y_test.json'), orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SpringSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 files in ../data/raw/spring\n",
      "Using dry_train.h5 and wet_train.h5 for train split.\n",
      "Found 4 files in ../data/raw/spring\n",
      "Using dry_val_test.h5 and wet_val_test.h5 for test split.\n"
     ]
    }
   ],
   "source": [
    "sample_rate = 16000\n",
    "\n",
    "train_loader, valid_loader, test_loader = load_springset(datadir=DATA_DIR, batch_size=1, train_ratio=0.70, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SpringSet: train set\n",
    "\n",
    "data_x = []\n",
    "data_y = []\n",
    "\n",
    "for idx, (input, target) in enumerate(train_loader):\n",
    "    # Convert tensor to numpy and ensure dtype and shape\n",
    "    input_np = input.numpy().squeeze().astype(np.float32)\n",
    "    target_np = target.numpy().squeeze().astype(np.float32)\n",
    "\n",
    "    # Extract features from the dry signal\n",
    "    x_features = extract_more_features_essentia(input_np, sample_rate)\n",
    "    y_features = extract_more_features_essentia(target_np, sample_rate)\n",
    "\n",
    "    x_features = {f'{key}': value for key, value in x_features.items()}\n",
    "    y_features = {f'{key}': value for key, value in y_features.items()}\n",
    "    \n",
    "    data_x.append({'idx': idx, **x_features})\n",
    "    data_y.append({'idx': idx, **y_features})\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_x = pd.DataFrame(data_x)\n",
    "df_y = pd.DataFrame(data_y)\n",
    "\n",
    "# Save DataFrame as a .json file\n",
    "df_x.to_json(os.path.join(RESULTS_DIR, 'springset_x_train.json'), orient='records', lines=True)\n",
    "df_y.to_json(os.path.join(RESULTS_DIR, 'springset_y_train.json'), orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SpringSet: validation set\n",
    "\n",
    "data_x = []\n",
    "data_y = []\n",
    "\n",
    "for idx, (input, target) in enumerate(valid_loader):\n",
    "    # Convert tensor to numpy and ensure dtype and shape\n",
    "    input_np = input.numpy().squeeze().astype(np.float32)\n",
    "    target_np = target.numpy().squeeze().astype(np.float32)\n",
    "\n",
    "    # Extract features from the dry signal\n",
    "    x_features = extract_more_features_essentia(input_np, sample_rate)\n",
    "    y_features = extract_more_features_essentia(target_np, sample_rate)\n",
    "\n",
    "    x_features = {f'{key}': value for key, value in x_features.items()}\n",
    "    y_features = {f'{key}': value for key, value in y_features.items()}\n",
    "    \n",
    "    data_x.append({'idx': idx, **x_features})\n",
    "    data_y.append({'idx': idx, **y_features})\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_x = pd.DataFrame(data_x)\n",
    "df_y = pd.DataFrame(data_y)\n",
    "\n",
    "# Save DataFrame as a .json file\n",
    "df_x.to_json(os.path.join(RESULTS_DIR, 'springset_x_valid.json'), orient='records', lines=True)\n",
    "df_y.to_json(os.path.join(RESULTS_DIR, 'springset_y_valid.json'), orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SpringSet: test set\n",
    "\n",
    "data_x = []\n",
    "data_y = []\n",
    "\n",
    "for idx, (input, target) in enumerate(test_loader):\n",
    "    # Convert tensor to numpy and ensure dtype and shape\n",
    "    input_np = input.numpy().squeeze().astype(np.float32)\n",
    "    target_np = target.numpy().squeeze().astype(np.float32)\n",
    "\n",
    "    # Extract features from the dry signal\n",
    "    x_features = extract_more_features_essentia(input_np, sample_rate)\n",
    "    y_features = extract_more_features_essentia(target_np, sample_rate)\n",
    "\n",
    "    x_features = {f'{key}': value for key, value in x_features.items()}\n",
    "    y_features = {f'{key}': value for key, value in y_features.items()}\n",
    "    \n",
    "    data_x.append({'idx': idx, **x_features})\n",
    "    data_y.append({'idx': idx, **y_features})\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_x = pd.DataFrame(data_x)\n",
    "df_y = pd.DataFrame(data_y)\n",
    "\n",
    "# Save DataFrame as a .json file\n",
    "df_x.to_json(os.path.join(RESULTS_DIR, 'springset_x_test.json'), orient='records', lines=True)\n",
    "df_y.to_json(os.path.join(RESULTS_DIR, 'springset_y_test.json'), orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
