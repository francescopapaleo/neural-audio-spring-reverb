#-----------------------------------------------------------------------#
                     Initializing training process
-------------------------------------------------------------------------

Torch version: 1.11.0 ------ Selected Device: cuda:0
Sample Rate: 16000 Hz ------  Crop Lenght: 3200 samples
-------------------------------------------------------------------------
Model: TCN
Parameters: 247.688 k
Receptive field: 54611 samples or 3413.2 ms
-------------------------------------------------------------------------
Adjusting learning rate of group 0 to 1.0000e-02.
Epoch: 1 / 2500Epoch 1 		 Training Loss: 558.1150581666401
Validation step:0Validation step:1Validation step:2Epoch 1 		 Validation Loss: 288.6855010986328
Validation Loss Decreased(inf--->288.685501) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-02.
Epoch: 2 / 2500Epoch 2 		 Training Loss: 77.65514700753349
Validation step:0Validation step:1Validation step:2Epoch 2 		 Validation Loss: 17.392030239105225
Validation Loss Decreased(288.685501--->17.392030) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-02.
Epoch: 3 / 2500Epoch 3 		 Training Loss: 7.975000108991351
Validation step:0Validation step:1Validation step:2Epoch 3 		 Validation Loss: 13.635266304016113
Validation Loss Decreased(17.392030--->13.635266) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-02.
Epoch: 4 / 2500Epoch 4 		 Training Loss: 5.667036294937134
Validation step:0Validation step:1Validation step:2Epoch 4 		 Validation Loss: 9.615236759185791
Validation Loss Decreased(13.635266--->9.615237) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-02.
Epoch: 5 / 2500Epoch 5 		 Training Loss: 3.227947320256914
Validation step:0Validation step:1Validation step:2Epoch 5 		 Validation Loss: 8.558799266815186
Validation Loss Decreased(9.615237--->8.558799) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-02.
Epoch: 6 / 2500Epoch 6 		 Training Loss: 2.7121479340962003
Validation step:0Validation step:1Validation step:2Epoch 6 		 Validation Loss: 6.7973198890686035
Validation Loss Decreased(8.558799--->6.797320) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-02.
Epoch: 7 / 2500Epoch 7 		 Training Loss: 2.2046257938657488
Validation step:0Validation step:1Validation step:2Epoch 7 		 Validation Loss: 6.448554277420044
Validation Loss Decreased(6.797320--->6.448554) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-02.
Epoch: 8 / 2500Epoch 8 		 Training Loss: 1.9688533885138375
Validation step:0Validation step:1Validation step:2Epoch 8 		 Validation Loss: 5.758179426193237
Validation Loss Decreased(6.448554--->5.758179) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-02.
Epoch: 9 / 2500Epoch 9 		 Training Loss: 1.8086307219096593
Validation step:0Validation step:1Validation step:2Epoch 9 		 Validation Loss: 5.38164222240448
Validation Loss Decreased(5.758179--->5.381642) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-02.
Epoch: 10 / 2500Epoch 10 		 Training Loss: 1.7798759511538915
Validation step:0Validation step:1Validation step:2Epoch 10 		 Validation Loss: 5.304032802581787
Validation Loss Decreased(5.381642--->5.304033) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-03.
Epoch: 11 / 2500Epoch 11 		 Training Loss: 1.7034428800855363
Validation step:0Validation step:1Validation step:2Epoch 11 		 Validation Loss: 4.964667081832886
Validation Loss Decreased(5.304033--->4.964667) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-03.
Epoch: 12 / 2500Epoch 12 		 Training Loss: 1.604676536151341
Validation step:0Validation step:1Validation step:2Epoch 12 		 Validation Loss: 4.767251133918762
Validation Loss Decreased(4.964667--->4.767251) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-03.
Epoch: 13 / 2500Epoch 13 		 Training Loss: 1.5682295986584254
Validation step:0Validation step:1Validation step:2Epoch 13 		 Validation Loss: 4.695606708526611
Validation Loss Decreased(4.767251--->4.695607) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-03.
Epoch: 14 / 2500Epoch 14 		 Training Loss: 1.5454424960272652
Validation step:0Validation step:1Validation step:2Epoch 14 		 Validation Loss: 4.65951943397522
Validation Loss Decreased(4.695607--->4.659519) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-03.
Epoch: 15 / 2500Epoch 15 		 Training Loss: 1.5309487751552038
Validation step:0Validation step:1Validation step:2Epoch 15 		 Validation Loss: 4.617916941642761
Validation Loss Decreased(4.659519--->4.617917) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-03.
Epoch: 16 / 2500Epoch 16 		 Training Loss: 1.51981520652771
Validation step:0Validation step:1Validation step:2Epoch 16 		 Validation Loss: 4.591012716293335
Validation Loss Decreased(4.617917--->4.591013) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-03.
Epoch: 17 / 2500Epoch 17 		 Training Loss: 1.5089644534247262
Validation step:0Validation step:1Validation step:2Epoch 17 		 Validation Loss: 4.566814303398132
Validation Loss Decreased(4.591013--->4.566814) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-03.
Epoch: 18 / 2500Epoch 18 		 Training Loss: 1.5006714718682426
Validation step:0Validation step:1Validation step:2Epoch 18 		 Validation Loss: 4.538281559944153
Validation Loss Decreased(4.566814--->4.538282) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-03.
Epoch: 19 / 2500Epoch 19 		 Training Loss: 1.496573567390442
Validation step:0Validation step:1Validation step:2Epoch 19 		 Validation Loss: 4.522050261497498
Validation Loss Decreased(4.538282--->4.522050) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-03.
Epoch: 20 / 2500Epoch 20 		 Training Loss: 1.4881543346813746
Validation step:0Validation step:1Validation step:2Epoch 20 		 Validation Loss: 4.496829271316528
Validation Loss Decreased(4.522050--->4.496829) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-04.
Epoch: 21 / 2500Epoch 21 		 Training Loss: 1.481019411768232
Validation step:0Validation step:1Validation step:2Epoch 21 		 Validation Loss: 4.4934223890304565
Validation Loss Decreased(4.496829--->4.493422) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-04.
Epoch: 22 / 2500Epoch 22 		 Training Loss: 1.4801996094839913
Validation step:0Validation step:1Validation step:2Epoch 22 		 Validation Loss: 4.490068078041077
Validation Loss Decreased(4.493422--->4.490068) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-04.
Epoch: 23 / 2500Epoch 23 		 Training Loss: 1.4786458952086312
Validation step:0Validation step:1Validation step:2Epoch 23 		 Validation Loss: 4.487728118896484
Validation Loss Decreased(4.490068--->4.487728) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-04.
Epoch: 24 / 2500Epoch 24 		 Training Loss: 1.47788781779153
Validation step:0Validation step:1Validation step:2Epoch 24 		 Validation Loss: 4.484645128250122
Validation Loss Decreased(4.487728--->4.484645) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-04.
Epoch: 25 / 2500Epoch 25 		 Training Loss: 1.4771068692207336
Validation step:0Validation step:1Validation step:2Epoch 25 		 Validation Loss: 4.484427213668823
Validation Loss Decreased(4.484645--->4.484427) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-04.
Epoch: 26 / 2500Epoch 26 		 Training Loss: 1.47520683492933
Validation step:0Validation step:1Validation step:2Epoch 26 		 Validation Loss: 4.480708837509155
Validation Loss Decreased(4.484427--->4.480709) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-04.
Epoch: 27 / 2500Epoch 27 		 Training Loss: 1.4772294504301888
Validation step:0Validation step:1Validation step:2Epoch 27 		 Validation Loss: 4.479154706001282
Validation Loss Decreased(4.480709--->4.479155) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-04.
Epoch: 28 / 2500Epoch 28 		 Training Loss: 1.4744737148284912
Validation step:0Validation step:1Validation step:2Epoch 28 		 Validation Loss: 4.477297902107239
Validation Loss Decreased(4.479155--->4.477298) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-04.
Epoch: 29 / 2500Epoch 29 		 Training Loss: 1.4732199226106917
Validation step:0Validation step:1Validation step:2Epoch 29 		 Validation Loss: 4.473430514335632
Validation Loss Decreased(4.477298--->4.473431) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-04.
Epoch: 30 / 2500Epoch 30 		 Training Loss: 1.4710616043635778
Validation step:0Validation step:1Validation step:2Epoch 30 		 Validation Loss: 4.4711339473724365
Validation Loss Decreased(4.473431--->4.471134) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-05.
Epoch: 31 / 2500Epoch 31 		 Training Loss: 1.4727845106806075
Validation step:0Validation step:1Validation step:2Epoch 31 		 Validation Loss: 4.470937013626099
Validation Loss Decreased(4.471134--->4.470937) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-05.
Epoch: 32 / 2500Epoch 32 		 Training Loss: 1.4724000607218062
Validation step:0Validation step:1Validation step:2Epoch 32 		 Validation Loss: 4.470603942871094
Validation Loss Decreased(4.470937--->4.470604) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-05.
Epoch: 33 / 2500Epoch 33 		 Training Loss: 1.4711399674415588
Validation step:0Validation step:1Validation step:2Epoch 33 		 Validation Loss: 4.4705445766448975
Validation Loss Decreased(4.470604--->4.470545) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-05.
Epoch: 34 / 2500Epoch 34 		 Training Loss: 1.4730891585350037
Validation step:0Validation step:1Validation step:2Epoch 34 		 Validation Loss: 4.470420837402344
Validation Loss Decreased(4.470545--->4.470421) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-05.
Epoch: 35 / 2500Epoch 35 		 Training Loss: 1.470741604055677
Validation step:0Validation step:1Validation step:2Epoch 35 		 Validation Loss: 4.46994686126709
Validation Loss Decreased(4.470421--->4.469947) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-05.
Epoch: 36 / 2500Epoch 36 		 Training Loss: 1.4722404309681483
Validation step:0Validation step:1Validation step:2Epoch 36 		 Validation Loss: 4.4698638916015625
Validation Loss Decreased(4.469947--->4.469864) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-05.
Epoch: 37 / 2500Epoch 37 		 Training Loss: 1.4729076623916626
Validation step:0Validation step:1Validation step:2Epoch 37 		 Validation Loss: 4.469481110572815
Validation Loss Decreased(4.469864--->4.469481) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-05.
Epoch: 38 / 2500Epoch 38 		 Training Loss: 1.4725987826074873
Validation step:0Validation step:1Validation step:2Epoch 38 		 Validation Loss: 4.469460844993591
Validation Loss Decreased(4.469481--->4.469461) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-05.
Epoch: 39 / 2500Epoch 39 		 Training Loss: 1.4708722233772278
Validation step:0Validation step:1Validation step:2Epoch 39 		 Validation Loss: 4.468933343887329
Validation Loss Decreased(4.469461--->4.468933) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-05.
Epoch: 40 / 2500Epoch 40 		 Training Loss: 1.470381702695574
Validation step:0Validation step:1Validation step:2Epoch 40 		 Validation Loss: 4.468746542930603
Validation Loss Decreased(4.468933--->4.468747) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-06.
Epoch: 41 / 2500Epoch 41 		 Training Loss: 1.4711182798658098
Validation step:0Validation step:1Validation step:2Epoch 41 		 Validation Loss: 4.468666076660156
Validation Loss Decreased(4.468747--->4.468666) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-06.
Epoch: 42 / 2500Epoch 42 		 Training Loss: 1.471100083419255
Validation step:0Validation step:1Validation step:2Epoch 42 		 Validation Loss: 4.468628287315369
Validation Loss Decreased(4.468666--->4.468628) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-06.
Epoch: 43 / 2500Epoch 43 		 Training Loss: 1.4715561015265328
Validation step:0Validation step:1Validation step:2Epoch 43 		 Validation Loss: 4.468591094017029
Validation Loss Decreased(4.468628--->4.468591) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-06.
Epoch: 44 / 2500Epoch 44 		 Training Loss: 1.469642094203404
Validation step:0Validation step:1Validation step:2Epoch 44 		 Validation Loss: 4.468539834022522
Validation Loss Decreased(4.468591--->4.468540) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-06.
Epoch: 45 / 2500Epoch 45 		 Training Loss: 1.4720876216888428
Validation step:0Validation step:1Validation step:2Epoch 45 		 Validation Loss: 4.468505859375
Validation Loss Decreased(4.468540--->4.468506) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-06.
Epoch: 46 / 2500Epoch 46 		 Training Loss: 1.4713040590286255
Validation step:0Validation step:1Validation step:2Epoch 46 		 Validation Loss: 4.468474984169006
Validation Loss Decreased(4.468506--->4.468475) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-06.
Epoch: 47 / 2500Epoch 47 		 Training Loss: 1.4708535841533117
Validation step:0Validation step:1Validation step:2Epoch 47 		 Validation Loss: 4.468430042266846
Validation Loss Decreased(4.468475--->4.468430) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-06.
Epoch: 48 / 2500Epoch 48 		 Training Loss: 1.4713824391365051
Validation step:0Validation step:1Validation step:2Epoch 48 		 Validation Loss: 4.468410849571228
Validation Loss Decreased(4.468430--->4.468411) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-06.
Epoch: 49 / 2500Epoch 49 		 Training Loss: 1.4704870326178414
Validation step:0Validation step:1Validation step:2Epoch 49 		 Validation Loss: 4.468394041061401
Validation Loss Decreased(4.468411--->4.468394) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-06.
Epoch: 50 / 2500Epoch 50 		 Training Loss: 1.4718776941299438
Validation step:0Validation step:1Validation step:2Epoch 50 		 Validation Loss: 4.468349933624268
Validation Loss Decreased(4.468394--->4.468350) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 51 / 2500Epoch 51 		 Training Loss: 1.4718753014292036
Validation step:0Validation step:1Validation step:2Epoch 51 		 Validation Loss: 4.468350529670715
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 52 / 2500Epoch 52 		 Training Loss: 1.471776851585933
Validation step:0Validation step:1Validation step:2Epoch 52 		 Validation Loss: 4.468348503112793
Validation Loss Decreased(4.468350--->4.468349) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 53 / 2500Epoch 53 		 Training Loss: 1.4690352507999964
Validation step:0Validation step:1Validation step:2Epoch 53 		 Validation Loss: 4.468348145484924
Validation Loss Decreased(4.468349--->4.468348) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 54 / 2500Epoch 54 		 Training Loss: 1.4717569095747811
Validation step:0Validation step:1Validation step:2Epoch 54 		 Validation Loss: 4.468348383903503
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 55 / 2500Epoch 55 		 Training Loss: 1.4724341971533639
Validation step:0Validation step:1Validation step:2Epoch 55 		 Validation Loss: 4.468347787857056
Validation Loss Decreased(4.468348--->4.468348) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 56 / 2500Epoch 56 		 Training Loss: 1.472375409943717
Validation step:0Validation step:1Validation step:2Epoch 56 		 Validation Loss: 4.468346357345581
Validation Loss Decreased(4.468348--->4.468346) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 57 / 2500Epoch 57 		 Training Loss: 1.469211723123278
Validation step:0Validation step:1Validation step:2Epoch 57 		 Validation Loss: 4.468343257904053
Validation Loss Decreased(4.468346--->4.468343) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 58 / 2500Epoch 58 		 Training Loss: 1.471458102975573
Validation step:0Validation step:1Validation step:2Epoch 58 		 Validation Loss: 4.468342185020447
Validation Loss Decreased(4.468343--->4.468342) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 59 / 2500Epoch 59 		 Training Loss: 1.4713296805109297
Validation step:0Validation step:1Validation step:2Epoch 59 		 Validation Loss: 4.468344211578369
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 60 / 2500Epoch 60 		 Training Loss: 1.4697690095220293
Validation step:0Validation step:1Validation step:2Epoch 60 		 Validation Loss: 4.468337774276733
Validation Loss Decreased(4.468342--->4.468338) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 61 / 2500Epoch 61 		 Training Loss: 1.4695130160876684
Validation step:0Validation step:1Validation step:2Epoch 61 		 Validation Loss: 4.4683369398117065
Validation Loss Decreased(4.468338--->4.468337) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 62 / 2500Epoch 62 		 Training Loss: 1.470268726348877
Validation step:0Validation step:1Validation step:2Epoch 62 		 Validation Loss: 4.46833610534668
Validation Loss Decreased(4.468337--->4.468336) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 63 / 2500Epoch 63 		 Training Loss: 1.4709628820419312
Validation step:0Validation step:1Validation step:2Epoch 63 		 Validation Loss: 4.468336343765259
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 64 / 2500Epoch 64 		 Training Loss: 1.4707025630133492
Validation step:0Validation step:1Validation step:2Epoch 64 		 Validation Loss: 4.468333721160889
Validation Loss Decreased(4.468336--->4.468334) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 65 / 2500Epoch 65 		 Training Loss: 1.471418057169233
Validation step:0Validation step:1Validation step:2Epoch 65 		 Validation Loss: 4.468329906463623
Validation Loss Decreased(4.468334--->4.468330) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 66 / 2500Epoch 66 		 Training Loss: 1.4721469283103943
Validation step:0Validation step:1Validation step:2Epoch 66 		 Validation Loss: 4.468330383300781
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 67 / 2500Epoch 67 		 Training Loss: 1.4716140116964067
Validation step:0Validation step:1Validation step:2Epoch 67 		 Validation Loss: 4.468327283859253
Validation Loss Decreased(4.468330--->4.468327) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 68 / 2500Epoch 68 		 Training Loss: 1.4705026830945696
Validation step:0Validation step:1Validation step:2Epoch 68 		 Validation Loss: 4.468323469161987
Validation Loss Decreased(4.468327--->4.468323) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 69 / 2500Epoch 69 		 Training Loss: 1.4706674899373735
Validation step:0Validation step:1Validation step:2Epoch 69 		 Validation Loss: 4.4683191776275635
Validation Loss Decreased(4.468323--->4.468319) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 70 / 2500Epoch 70 		 Training Loss: 1.4717819094657898
Validation step:0Validation step:1Validation step:2Epoch 70 		 Validation Loss: 4.468313694000244
Validation Loss Decreased(4.468319--->4.468314) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 71 / 2500Epoch 71 		 Training Loss: 1.4698083230427332
Validation step:0Validation step:1Validation step:2Epoch 71 		 Validation Loss: 4.468312978744507
Validation Loss Decreased(4.468314--->4.468313) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 72 / 2500Epoch 72 		 Training Loss: 1.4720669559070043
Validation step:0Validation step:1Validation step:2Epoch 72 		 Validation Loss: 4.468308806419373
Validation Loss Decreased(4.468313--->4.468309) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 73 / 2500Epoch 73 		 Training Loss: 1.4708363158362252
Validation step:0Validation step:1Validation step:2Epoch 73 		 Validation Loss: 4.4683085680007935
Validation Loss Decreased(4.468309--->4.468309) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 74 / 2500Epoch 74 		 Training Loss: 1.4716055393218994
Validation step:0Validation step:1Validation step:2Epoch 74 		 Validation Loss: 4.468306660652161
Validation Loss Decreased(4.468309--->4.468307) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 75 / 2500Epoch 75 		 Training Loss: 1.4708593487739563
Validation step:0Validation step:1Validation step:2Epoch 75 		 Validation Loss: 4.468306303024292
Validation Loss Decreased(4.468307--->4.468306) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 76 / 2500Epoch 76 		 Training Loss: 1.4721887452261788
Validation step:0Validation step:1Validation step:2Epoch 76 		 Validation Loss: 4.468303680419922
Validation Loss Decreased(4.468306--->4.468304) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 77 / 2500Epoch 77 		 Training Loss: 1.4713873948369707
Validation step:0Validation step:1Validation step:2Epoch 77 		 Validation Loss: 4.468300819396973
Validation Loss Decreased(4.468304--->4.468301) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 78 / 2500Epoch 78 		 Training Loss: 1.4719978485788618
Validation step:0Validation step:1Validation step:2Epoch 78 		 Validation Loss: 4.468299508094788
Validation Loss Decreased(4.468301--->4.468300) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 79 / 2500Epoch 79 		 Training Loss: 1.4717663015638078
Validation step:0Validation step:1Validation step:2Epoch 79 		 Validation Loss: 4.468294024467468
Validation Loss Decreased(4.468300--->4.468294) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 80 / 2500Epoch 80 		 Training Loss: 1.4702756915773665
Validation step:0Validation step:1Validation step:2Epoch 80 		 Validation Loss: 4.468288779258728
Validation Loss Decreased(4.468294--->4.468289) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 81 / 2500Epoch 81 		 Training Loss: 1.472389851297651
Validation step:0Validation step:1Validation step:2Epoch 81 		 Validation Loss: 4.468286633491516
Validation Loss Decreased(4.468289--->4.468287) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 82 / 2500Epoch 82 		 Training Loss: 1.470853226525443
Validation step:0Validation step:1Validation step:2Epoch 82 		 Validation Loss: 4.468286871910095
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 83 / 2500Epoch 83 		 Training Loss: 1.4710458857672555
Validation step:0Validation step:1Validation step:2Epoch 83 		 Validation Loss: 4.4682852029800415
Validation Loss Decreased(4.468287--->4.468285) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 84 / 2500Epoch 84 		 Training Loss: 1.4716071741921561
Validation step:0Validation step:1Validation step:2Epoch 84 		 Validation Loss: 4.468284010887146
Validation Loss Decreased(4.468285--->4.468284) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 85 / 2500Epoch 85 		 Training Loss: 1.4709935784339905
Validation step:0Validation step:1Validation step:2Epoch 85 		 Validation Loss: 4.468278408050537
Validation Loss Decreased(4.468284--->4.468278) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 86 / 2500Epoch 86 		 Training Loss: 1.4717007194246565
Validation step:0Validation step:1Validation step:2Epoch 86 		 Validation Loss: 4.468275308609009
Validation Loss Decreased(4.468278--->4.468275) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 87 / 2500Epoch 87 		 Training Loss: 1.4720622386251176
Validation step:0Validation step:1Validation step:2Epoch 87 		 Validation Loss: 4.468271970748901
Validation Loss Decreased(4.468275--->4.468272) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 88 / 2500Epoch 88 		 Training Loss: 1.4711058820996965
Validation step:0Validation step:1Validation step:2Epoch 88 		 Validation Loss: 4.468272805213928
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 89 / 2500Epoch 89 		 Training Loss: 1.4706339240074158
Validation step:0Validation step:1Validation step:2Epoch 89 		 Validation Loss: 4.468265652656555
Validation Loss Decreased(4.468272--->4.468266) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 90 / 2500Epoch 90 		 Training Loss: 1.4714836307934351
Validation step:0Validation step:1Validation step:2Epoch 90 		 Validation Loss: 4.468264579772949
Validation Loss Decreased(4.468266--->4.468265) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 91 / 2500Epoch 91 		 Training Loss: 1.471345032964434
Validation step:0Validation step:1Validation step:2Epoch 91 		 Validation Loss: 4.468261480331421
Validation Loss Decreased(4.468265--->4.468261) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 92 / 2500Epoch 92 		 Training Loss: 1.4707590767315455
Validation step:0Validation step:1Validation step:2Epoch 92 		 Validation Loss: 4.468254566192627
Validation Loss Decreased(4.468261--->4.468255) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 93 / 2500Epoch 93 		 Training Loss: 1.4714885098593575
Validation step:0Validation step:1Validation step:2Epoch 93 		 Validation Loss: 4.468249559402466
Validation Loss Decreased(4.468255--->4.468250) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 94 / 2500Epoch 94 		 Training Loss: 1.4713078056062971
Validation step:0Validation step:1Validation step:2Epoch 94 		 Validation Loss: 4.468249797821045
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 95 / 2500Epoch 95 		 Training Loss: 1.4721990312848772
Validation step:0Validation step:1Validation step:2Epoch 95 		 Validation Loss: 4.468247413635254
Validation Loss Decreased(4.468250--->4.468247) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 96 / 2500Epoch 96 		 Training Loss: 1.4701652441705977
Validation step:0Validation step:1Validation step:2Epoch 96 		 Validation Loss: 4.468243718147278
Validation Loss Decreased(4.468247--->4.468244) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 97 / 2500Epoch 97 		 Training Loss: 1.4721166576657976
Validation step:0Validation step:1Validation step:2Epoch 97 		 Validation Loss: 4.468236088752747
Validation Loss Decreased(4.468244--->4.468236) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 98 / 2500Epoch 98 		 Training Loss: 1.4708951030458723
Validation step:0Validation step:1Validation step:2Epoch 98 		 Validation Loss: 4.468233585357666
Validation Loss Decreased(4.468236--->4.468234) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 99 / 2500Epoch 99 		 Training Loss: 1.4716044323784965
Validation step:0Validation step:1Validation step:2Epoch 99 		 Validation Loss: 4.468233823776245
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 100 / 2500Epoch 100 		 Training Loss: 1.4707131470952715
Validation step:0Validation step:1Validation step:2Epoch 100 		 Validation Loss: 4.468226194381714
Validation Loss Decreased(4.468234--->4.468226) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 101 / 2500Epoch 101 		 Training Loss: 1.470633898462568
Validation step:0Validation step:1Validation step:2Epoch 101 		 Validation Loss: 4.468221664428711
Validation Loss Decreased(4.468226--->4.468222) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 102 / 2500Epoch 102 		 Training Loss: 1.4703603216579981
Validation step:0Validation step:1Validation step:2Epoch 102 		 Validation Loss: 4.468214750289917
Validation Loss Decreased(4.468222--->4.468215) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 103 / 2500Epoch 103 		 Training Loss: 1.470416750226702
Validation step:0Validation step:1Validation step:2Epoch 103 		 Validation Loss: 4.468220114707947
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 104 / 2500Epoch 104 		 Training Loss: 1.4703930105481828
Validation step:0Validation step:1Validation step:2Epoch 104 		 Validation Loss: 4.468210935592651
Validation Loss Decreased(4.468215--->4.468211) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 105 / 2500Epoch 105 		 Training Loss: 1.470965129988534
Validation step:0Validation step:1Validation step:2Epoch 105 		 Validation Loss: 4.468207836151123
Validation Loss Decreased(4.468211--->4.468208) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 106 / 2500Epoch 106 		 Training Loss: 1.4695813741002763
Validation step:0Validation step:1Validation step:2Epoch 106 		 Validation Loss: 4.468206405639648
Validation Loss Decreased(4.468208--->4.468206) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 107 / 2500Epoch 107 		 Training Loss: 1.4713702712740218
Validation step:0Validation step:1Validation step:2Epoch 107 		 Validation Loss: 4.468204379081726
Validation Loss Decreased(4.468206--->4.468204) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 108 / 2500Epoch 108 		 Training Loss: 1.4697498508862086
Validation step:0Validation step:1Validation step:2Epoch 108 		 Validation Loss: 4.468195557594299
Validation Loss Decreased(4.468204--->4.468196) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 109 / 2500Epoch 109 		 Training Loss: 1.4717978749956404
Validation step:0Validation step:1Validation step:2Epoch 109 		 Validation Loss: 4.4681947231292725
Validation Loss Decreased(4.468196--->4.468195) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 110 / 2500Epoch 110 		 Training Loss: 1.4720025403159005
Validation step:0Validation step:1Validation step:2Epoch 110 		 Validation Loss: 4.468190550804138
Validation Loss Decreased(4.468195--->4.468191) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 111 / 2500Epoch 111 		 Training Loss: 1.4707344429833549
Validation step:0Validation step:1Validation step:2Epoch 111 		 Validation Loss: 4.468185544013977
Validation Loss Decreased(4.468191--->4.468186) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 112 / 2500Epoch 112 		 Training Loss: 1.4717969724110194
Validation step:0Validation step:1Validation step:2Epoch 112 		 Validation Loss: 4.4681830406188965
Validation Loss Decreased(4.468186--->4.468183) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 113 / 2500Epoch 113 		 Training Loss: 1.4721330830029078
Validation step:0Validation step:1Validation step:2Epoch 113 		 Validation Loss: 4.46817684173584
Validation Loss Decreased(4.468183--->4.468177) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 114 / 2500Epoch 114 		 Training Loss: 1.470762278352465
Validation step:0Validation step:1Validation step:2Epoch 114 		 Validation Loss: 4.4681761264801025
Validation Loss Decreased(4.468177--->4.468176) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 115 / 2500Epoch 115 		 Training Loss: 1.471856917653765
Validation step:0Validation step:1Validation step:2Epoch 115 		 Validation Loss: 4.468170881271362
Validation Loss Decreased(4.468176--->4.468171) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 116 / 2500Epoch 116 		 Training Loss: 1.4706188355173384
Validation step:0Validation step:1Validation step:2Epoch 116 		 Validation Loss: 4.468164682388306
Validation Loss Decreased(4.468171--->4.468165) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 117 / 2500Epoch 117 		 Training Loss: 1.4711550218718392
Validation step:0Validation step:1Validation step:2Epoch 117 		 Validation Loss: 4.468161582946777
Validation Loss Decreased(4.468165--->4.468162) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 118 / 2500Epoch 118 		 Training Loss: 1.4701296261378698
Validation step:0Validation step:1Validation step:2Epoch 118 		 Validation Loss: 4.468154191970825
Validation Loss Decreased(4.468162--->4.468154) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 119 / 2500Epoch 119 		 Training Loss: 1.4702849643571037
Validation step:0Validation step:1Validation step:2Epoch 119 		 Validation Loss: 4.46815299987793
Validation Loss Decreased(4.468154--->4.468153) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 120 / 2500Epoch 120 		 Training Loss: 1.4706719347408839
Validation step:0Validation step:1Validation step:2Epoch 120 		 Validation Loss: 4.468147873878479
Validation Loss Decreased(4.468153--->4.468148) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 121 / 2500Epoch 121 		 Training Loss: 1.471111842564174
Validation step:0Validation step:1Validation step:2Epoch 121 		 Validation Loss: 4.468143463134766
Validation Loss Decreased(4.468148--->4.468143) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 122 / 2500Epoch 122 		 Training Loss: 1.4712512152535575
Validation step:0Validation step:1Validation step:2Epoch 122 		 Validation Loss: 4.4681360721588135
Validation Loss Decreased(4.468143--->4.468136) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 123 / 2500Epoch 123 		 Training Loss: 1.470891330923353
Validation step:0Validation step:1Validation step:2Epoch 123 		 Validation Loss: 4.468134045600891
Validation Loss Decreased(4.468136--->4.468134) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 124 / 2500Epoch 124 		 Training Loss: 1.471937792641776
Validation step:0Validation step:1Validation step:2Epoch 124 		 Validation Loss: 4.468127727508545
Validation Loss Decreased(4.468134--->4.468128) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 125 / 2500Epoch 125 		 Training Loss: 1.4708393727030074
Validation step:0Validation step:1Validation step:2Epoch 125 		 Validation Loss: 4.468124508857727
Validation Loss Decreased(4.468128--->4.468125) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 126 / 2500Epoch 126 		 Training Loss: 1.4702390006610326
Validation step:0Validation step:1Validation step:2Epoch 126 		 Validation Loss: 4.468119382858276
Validation Loss Decreased(4.468125--->4.468119) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 127 / 2500Epoch 127 		 Training Loss: 1.4717863372394018
Validation step:0Validation step:1Validation step:2Epoch 127 		 Validation Loss: 4.468114137649536
Validation Loss Decreased(4.468119--->4.468114) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 128 / 2500Epoch 128 		 Training Loss: 1.4695674691881453
Validation step:0Validation step:1Validation step:2Epoch 128 		 Validation Loss: 4.468109369277954
Validation Loss Decreased(4.468114--->4.468109) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 129 / 2500Epoch 129 		 Training Loss: 1.4722726855959212
Validation step:0Validation step:1Validation step:2Epoch 129 		 Validation Loss: 4.468104720115662
Validation Loss Decreased(4.468109--->4.468105) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 130 / 2500Epoch 130 		 Training Loss: 1.470107112612043
Validation step:0Validation step:1Validation step:2Epoch 130 		 Validation Loss: 4.46809709072113
Validation Loss Decreased(4.468105--->4.468097) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 131 / 2500Epoch 131 		 Training Loss: 1.4712239078113012
Validation step:0Validation step:1Validation step:2Epoch 131 		 Validation Loss: 4.468094706535339
Validation Loss Decreased(4.468097--->4.468095) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 132 / 2500Epoch 132 		 Training Loss: 1.4713391746793474
Validation step:0Validation step:1Validation step:2Epoch 132 		 Validation Loss: 4.4680867195129395
Validation Loss Decreased(4.468095--->4.468087) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 133 / 2500Epoch 133 		 Training Loss: 1.4697619250842504
Validation step:0Validation step:1Validation step:2Epoch 133 		 Validation Loss: 4.468082070350647
Validation Loss Decreased(4.468087--->4.468082) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 134 / 2500Epoch 134 		 Training Loss: 1.4703184366226196
Validation step:0Validation step:1Validation step:2Epoch 134 		 Validation Loss: 4.468080520629883
Validation Loss Decreased(4.468082--->4.468081) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 135 / 2500Epoch 135 		 Training Loss: 1.4707303387778146
Validation step:0Validation step:1Validation step:2Epoch 135 		 Validation Loss: 4.468073010444641
Validation Loss Decreased(4.468081--->4.468073) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 136 / 2500Epoch 136 		 Training Loss: 1.469897244657789
Validation step:0Validation step:1Validation step:2Epoch 136 		 Validation Loss: 4.46806526184082
Validation Loss Decreased(4.468073--->4.468065) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 137 / 2500Epoch 137 		 Training Loss: 1.4710953150476729
Validation step:0Validation step:1Validation step:2Epoch 137 		 Validation Loss: 4.468067526817322
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 138 / 2500Epoch 138 		 Training Loss: 1.4705259118761336
Validation step:0Validation step:1Validation step:2Epoch 138 		 Validation Loss: 4.4680564403533936
Validation Loss Decreased(4.468065--->4.468056) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 139 / 2500Epoch 139 		 Training Loss: 1.4718113711902074
Validation step:0Validation step:1Validation step:2Epoch 139 		 Validation Loss: 4.468051552772522
Validation Loss Decreased(4.468056--->4.468052) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 140 / 2500Epoch 140 		 Training Loss: 1.4702468769890922
Validation step:0Validation step:1Validation step:2Epoch 140 		 Validation Loss: 4.468048572540283
Validation Loss Decreased(4.468052--->4.468049) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 141 / 2500Epoch 141 		 Training Loss: 1.4721674493380956
Validation step:0Validation step:1Validation step:2Epoch 141 		 Validation Loss: 4.468039512634277
Validation Loss Decreased(4.468049--->4.468040) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 142 / 2500Epoch 142 		 Training Loss: 1.4696647354534693
Validation step:0Validation step:1Validation step:2Epoch 142 		 Validation Loss: 4.468034148216248
Validation Loss Decreased(4.468040--->4.468034) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 143 / 2500Epoch 143 		 Training Loss: 1.4717769367354256
Validation step:0Validation step:1Validation step:2Epoch 143 		 Validation Loss: 4.468025803565979
Validation Loss Decreased(4.468034--->4.468026) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 144 / 2500Epoch 144 		 Training Loss: 1.4708102345466614
Validation step:0Validation step:1Validation step:2Epoch 144 		 Validation Loss: 4.468020796775818
Validation Loss Decreased(4.468026--->4.468021) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 145 / 2500Epoch 145 		 Training Loss: 1.4712209871837072
Validation step:0Validation step:1Validation step:2Epoch 145 		 Validation Loss: 4.468019247055054
Validation Loss Decreased(4.468021--->4.468019) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 146 / 2500Epoch 146 		 Training Loss: 1.4704529302460807
Validation step:0Validation step:1Validation step:2Epoch 146 		 Validation Loss: 4.468014597892761
Validation Loss Decreased(4.468019--->4.468015) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 147 / 2500Epoch 147 		 Training Loss: 1.4713057620184762
Validation step:0Validation step:1Validation step:2Epoch 147 		 Validation Loss: 4.467999219894409
Validation Loss Decreased(4.468015--->4.467999) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 148 / 2500Epoch 148 		 Training Loss: 1.4707512174333846
Validation step:0Validation step:1Validation step:2Epoch 148 		 Validation Loss: 4.467994928359985
Validation Loss Decreased(4.467999--->4.467995) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 149 / 2500Epoch 149 		 Training Loss: 1.472084334918431
Validation step:0Validation step:1Validation step:2Epoch 149 		 Validation Loss: 4.4679930210113525
Validation Loss Decreased(4.467995--->4.467993) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 150 / 2500Epoch 150 		 Training Loss: 1.47195280449731
Validation step:0Validation step:1Validation step:2Epoch 150 		 Validation Loss: 4.467991352081299
Validation Loss Decreased(4.467993--->4.467991) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 151 / 2500Epoch 151 		 Training Loss: 1.4708076800618852
Validation step:0Validation step:1Validation step:2Epoch 151 		 Validation Loss: 4.467986822128296
Validation Loss Decreased(4.467991--->4.467987) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 152 / 2500Epoch 152 		 Training Loss: 1.4708019835608346
Validation step:0Validation step:1Validation step:2Epoch 152 		 Validation Loss: 4.467973232269287
Validation Loss Decreased(4.467987--->4.467973) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 153 / 2500Epoch 153 		 Training Loss: 1.4712983540126257
Validation step:0Validation step:1Validation step:2Epoch 153 		 Validation Loss: 4.467972040176392
Validation Loss Decreased(4.467973--->4.467972) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 154 / 2500Epoch 154 		 Training Loss: 1.4711632984025138
Validation step:0Validation step:1Validation step:2Epoch 154 		 Validation Loss: 4.467960715293884
Validation Loss Decreased(4.467972--->4.467961) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 155 / 2500Epoch 155 		 Training Loss: 1.4723929251943315
Validation step:0Validation step:1Validation step:2Epoch 155 		 Validation Loss: 4.467953681945801
Validation Loss Decreased(4.467961--->4.467954) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 156 / 2500Epoch 156 		 Training Loss: 1.4712529863630022
Validation step:0Validation step:1Validation step:2Epoch 156 		 Validation Loss: 4.467949151992798
Validation Loss Decreased(4.467954--->4.467949) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 157 / 2500Epoch 157 		 Training Loss: 1.4713937044143677
Validation step:0Validation step:1Validation step:2Epoch 157 		 Validation Loss: 4.467943549156189
Validation Loss Decreased(4.467949--->4.467944) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 158 / 2500Epoch 158 		 Training Loss: 1.471317206110273
Validation step:0Validation step:1Validation step:2Epoch 158 		 Validation Loss: 4.467934846878052
Validation Loss Decreased(4.467944--->4.467935) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 159 / 2500Epoch 159 		 Training Loss: 1.470058194228581
Validation step:0Validation step:1Validation step:2Epoch 159 		 Validation Loss: 4.467929244041443
Validation Loss Decreased(4.467935--->4.467929) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 160 / 2500Epoch 160 		 Training Loss: 1.4700800010136195
Validation step:0Validation step:1Validation step:2Epoch 160 		 Validation Loss: 4.467920303344727
Validation Loss Decreased(4.467929--->4.467920) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 161 / 2500Epoch 161 		 Training Loss: 1.4704499585287911
Validation step:0Validation step:1Validation step:2Epoch 161 		 Validation Loss: 4.467916369438171
Validation Loss Decreased(4.467920--->4.467916) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 162 / 2500Epoch 162 		 Training Loss: 1.4711541618619646
Validation step:0Validation step:1Validation step:2Epoch 162 		 Validation Loss: 4.46790874004364
Validation Loss Decreased(4.467916--->4.467909) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 163 / 2500Epoch 163 		 Training Loss: 1.471311696938106
Validation step:0Validation step:1Validation step:2Epoch 163 		 Validation Loss: 4.467904567718506
Validation Loss Decreased(4.467909--->4.467905) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 164 / 2500Epoch 164 		 Training Loss: 1.4711819802011763
Validation step:0Validation step:1Validation step:2Epoch 164 		 Validation Loss: 4.4678932428359985
Validation Loss Decreased(4.467905--->4.467893) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 165 / 2500Epoch 165 		 Training Loss: 1.4708323308399744
Validation step:0Validation step:1Validation step:2Epoch 165 		 Validation Loss: 4.46788763999939
Validation Loss Decreased(4.467893--->4.467888) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 166 / 2500Epoch 166 		 Training Loss: 1.4688799977302551
Validation step:0Validation step:1Validation step:2Epoch 166 		 Validation Loss: 4.467880725860596
Validation Loss Decreased(4.467888--->4.467881) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 167 / 2500Epoch 167 		 Training Loss: 1.47065703357969
Validation step:0Validation step:1Validation step:2Epoch 167 		 Validation Loss: 4.467867016792297
Validation Loss Decreased(4.467881--->4.467867) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 168 / 2500Epoch 168 		 Training Loss: 1.471573259149279
Validation step:0Validation step:1Validation step:2Epoch 168 		 Validation Loss: 4.467866539955139
Validation Loss Decreased(4.467867--->4.467867) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 169 / 2500Epoch 169 		 Training Loss: 1.4704094273703439
Validation step:0Validation step:1Validation step:2Epoch 169 		 Validation Loss: 4.46785831451416
Validation Loss Decreased(4.467867--->4.467858) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 170 / 2500Epoch 170 		 Training Loss: 1.4692242571285792
Validation step:0Validation step:1Validation step:2Epoch 170 		 Validation Loss: 4.467851638793945
Validation Loss Decreased(4.467858--->4.467852) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 171 / 2500Epoch 171 		 Training Loss: 1.4718796610832214
Validation step:0Validation step:1Validation step:2Epoch 171 		 Validation Loss: 4.467849493026733
Validation Loss Decreased(4.467852--->4.467849) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 172 / 2500Epoch 172 		 Training Loss: 1.4700603485107422
Validation step:0Validation step:1Validation step:2Epoch 172 		 Validation Loss: 4.467835903167725
Validation Loss Decreased(4.467849--->4.467836) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 173 / 2500Epoch 173 		 Training Loss: 1.4715272869382585
Validation step:0Validation step:1Validation step:2Epoch 173 		 Validation Loss: 4.467830419540405
Validation Loss Decreased(4.467836--->4.467830) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 174 / 2500Epoch 174 		 Training Loss: 1.471246830054692
Validation step:0Validation step:1Validation step:2Epoch 174 		 Validation Loss: 4.467823028564453
Validation Loss Decreased(4.467830--->4.467823) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 175 / 2500Epoch 175 		 Training Loss: 1.4714170013155257
Validation step:0Validation step:1Validation step:2Epoch 175 		 Validation Loss: 4.46780788898468
Validation Loss Decreased(4.467823--->4.467808) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 176 / 2500Epoch 176 		 Training Loss: 1.471272315297808
Validation step:0Validation step:1Validation step:2Epoch 176 		 Validation Loss: 4.467797517776489
Validation Loss Decreased(4.467808--->4.467798) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 177 / 2500Epoch 177 		 Training Loss: 1.4706416385514396
Validation step:0Validation step:1Validation step:2Epoch 177 		 Validation Loss: 4.467795729637146
Validation Loss Decreased(4.467798--->4.467796) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 178 / 2500Epoch 178 		 Training Loss: 1.470723467213767
Validation step:0Validation step:1Validation step:2Epoch 178 		 Validation Loss: 4.467789053916931
Validation Loss Decreased(4.467796--->4.467789) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 179 / 2500Epoch 179 		 Training Loss: 1.471369641167777
Validation step:0Validation step:1Validation step:2Epoch 179 		 Validation Loss: 4.467775344848633
Validation Loss Decreased(4.467789--->4.467775) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 180 / 2500Epoch 180 		 Training Loss: 1.4710216862814767
Validation step:0Validation step:1Validation step:2Epoch 180 		 Validation Loss: 4.467770457267761
Validation Loss Decreased(4.467775--->4.467770) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 181 / 2500Epoch 181 		 Training Loss: 1.4699873583657401
Validation step:0Validation step:1Validation step:2Epoch 181 		 Validation Loss: 4.467763543128967
Validation Loss Decreased(4.467770--->4.467764) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 182 / 2500Epoch 182 		 Training Loss: 1.471512564590999
Validation step:0Validation step:1Validation step:2Epoch 182 		 Validation Loss: 4.467752814292908
Validation Loss Decreased(4.467764--->4.467753) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 183 / 2500Epoch 183 		 Training Loss: 1.470938273838588
Validation step:0Validation step:1Validation step:2Epoch 183 		 Validation Loss: 4.467742562294006
Validation Loss Decreased(4.467753--->4.467743) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 184 / 2500Epoch 184 		 Training Loss: 1.4705655404499598
Validation step:0Validation step:1Validation step:2Epoch 184 		 Validation Loss: 4.467734456062317
Validation Loss Decreased(4.467743--->4.467734) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 185 / 2500Epoch 185 		 Training Loss: 1.4703367352485657
Validation step:0Validation step:1Validation step:2Epoch 185 		 Validation Loss: 4.467730283737183
Validation Loss Decreased(4.467734--->4.467730) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 186 / 2500Epoch 186 		 Training Loss: 1.47146509374891
Validation step:0Validation step:1Validation step:2Epoch 186 		 Validation Loss: 4.467717885971069
Validation Loss Decreased(4.467730--->4.467718) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 187 / 2500Epoch 187 		 Training Loss: 1.472064163003649
Validation step:0Validation step:1Validation step:2Epoch 187 		 Validation Loss: 4.467708945274353
Validation Loss Decreased(4.467718--->4.467709) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 188 / 2500Epoch 188 		 Training Loss: 1.4715720415115356
Validation step:0Validation step:1Validation step:2Epoch 188 		 Validation Loss: 4.467691779136658
Validation Loss Decreased(4.467709--->4.467692) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 189 / 2500Epoch 189 		 Training Loss: 1.4709283709526062
Validation step:0Validation step:1Validation step:2Epoch 189 		 Validation Loss: 4.4676902294158936
Validation Loss Decreased(4.467692--->4.467690) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 190 / 2500Epoch 190 		 Training Loss: 1.4703244481767928
Validation step:0Validation step:1Validation step:2Epoch 190 		 Validation Loss: 4.467684984207153
Validation Loss Decreased(4.467690--->4.467685) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 191 / 2500Epoch 191 		 Training Loss: 1.471081623009273
Validation step:0Validation step:1Validation step:2Epoch 191 		 Validation Loss: 4.467676997184753
Validation Loss Decreased(4.467685--->4.467677) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 192 / 2500Epoch 192 		 Training Loss: 1.47091201373509
Validation step:0Validation step:1Validation step:2Epoch 192 		 Validation Loss: 4.467665314674377
Validation Loss Decreased(4.467677--->4.467665) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 193 / 2500Epoch 193 		 Training Loss: 1.4716944353921073
Validation step:0Validation step:1Validation step:2Epoch 193 		 Validation Loss: 4.467660188674927
Validation Loss Decreased(4.467665--->4.467660) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 194 / 2500Epoch 194 		 Training Loss: 1.4701424751962935
Validation step:0Validation step:1Validation step:2Epoch 194 		 Validation Loss: 4.467642664909363
Validation Loss Decreased(4.467660--->4.467643) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 195 / 2500Epoch 195 		 Training Loss: 1.4709785069738115
Validation step:0Validation step:1Validation step:2Epoch 195 		 Validation Loss: 4.467634558677673
Validation Loss Decreased(4.467643--->4.467635) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 196 / 2500Epoch 196 		 Training Loss: 1.4701941864831107
Validation step:0Validation step:1Validation step:2Epoch 196 		 Validation Loss: 4.467628121376038
Validation Loss Decreased(4.467635--->4.467628) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 197 / 2500Epoch 197 		 Training Loss: 1.471018101487841
Validation step:0Validation step:1Validation step:2Epoch 197 		 Validation Loss: 4.467613935470581
Validation Loss Decreased(4.467628--->4.467614) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 198 / 2500Epoch 198 		 Training Loss: 1.470545334475381
Validation step:0Validation step:1Validation step:2Epoch 198 		 Validation Loss: 4.467610239982605
Validation Loss Decreased(4.467614--->4.467610) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 199 / 2500Epoch 199 		 Training Loss: 1.4695985657828194
Validation step:0Validation step:1Validation step:2Epoch 199 		 Validation Loss: 4.467597484588623
Validation Loss Decreased(4.467610--->4.467597) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 200 / 2500Epoch 200 		 Training Loss: 1.470363199710846
Validation step:0Validation step:1Validation step:2Epoch 200 		 Validation Loss: 4.467586040496826
Validation Loss Decreased(4.467597--->4.467586) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 201 / 2500Epoch 201 		 Training Loss: 1.4712570309638977
Validation step:0Validation step:1Validation step:2Epoch 201 		 Validation Loss: 4.467578291893005
Validation Loss Decreased(4.467586--->4.467578) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 202 / 2500Epoch 202 		 Training Loss: 1.470130741596222
Validation step:0Validation step:1Validation step:2Epoch 202 		 Validation Loss: 4.467567563056946
Validation Loss Decreased(4.467578--->4.467568) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 203 / 2500Epoch 203 		 Training Loss: 1.4701775738171168
Validation step:0Validation step:1Validation step:2Epoch 203 		 Validation Loss: 4.467560648918152
Validation Loss Decreased(4.467568--->4.467561) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 204 / 2500Epoch 204 		 Training Loss: 1.4691440548215593
Validation step:0Validation step:1Validation step:2Epoch 204 		 Validation Loss: 4.46754789352417
Validation Loss Decreased(4.467561--->4.467548) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 205 / 2500Epoch 205 		 Training Loss: 1.4704228809901647
Validation step:0Validation step:1Validation step:2Epoch 205 		 Validation Loss: 4.4675421714782715
Validation Loss Decreased(4.467548--->4.467542) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 206 / 2500Epoch 206 		 Training Loss: 1.4725983398301261
Validation step:0Validation step:1Validation step:2Epoch 206 		 Validation Loss: 4.467529654502869
Validation Loss Decreased(4.467542--->4.467530) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 207 / 2500Epoch 207 		 Training Loss: 1.4705404213496618
Validation step:0Validation step:1Validation step:2Epoch 207 		 Validation Loss: 4.467521905899048
Validation Loss Decreased(4.467530--->4.467522) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 208 / 2500Epoch 208 		 Training Loss: 1.4715284534863062
Validation step:0Validation step:1Validation step:2Epoch 208 		 Validation Loss: 4.46751070022583
Validation Loss Decreased(4.467522--->4.467511) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 209 / 2500Epoch 209 		 Training Loss: 1.4703647238867623
Validation step:0Validation step:1Validation step:2Epoch 209 		 Validation Loss: 4.467500805854797
Validation Loss Decreased(4.467511--->4.467501) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 210 / 2500Epoch 210 		 Training Loss: 1.4701400739806039
Validation step:0Validation step:1Validation step:2Epoch 210 		 Validation Loss: 4.4674906730651855
Validation Loss Decreased(4.467501--->4.467491) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 211 / 2500Epoch 211 		 Training Loss: 1.469638935157231
Validation step:0Validation step:1Validation step:2Epoch 211 		 Validation Loss: 4.467482566833496
Validation Loss Decreased(4.467491--->4.467483) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 212 / 2500Epoch 212 		 Training Loss: 1.4712836146354675
Validation step:0Validation step:1Validation step:2Epoch 212 		 Validation Loss: 4.467471361160278
Validation Loss Decreased(4.467483--->4.467471) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 213 / 2500Epoch 213 		 Training Loss: 1.4700341394969396
Validation step:0Validation step:1Validation step:2Epoch 213 		 Validation Loss: 4.467456340789795
Validation Loss Decreased(4.467471--->4.467456) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 214 / 2500Epoch 214 		 Training Loss: 1.4715765884944372
Validation step:0Validation step:1Validation step:2Epoch 214 		 Validation Loss: 4.46744978427887
Validation Loss Decreased(4.467456--->4.467450) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 215 / 2500Epoch 215 		 Training Loss: 1.470202922821045
Validation step:0Validation step:1Validation step:2Epoch 215 		 Validation Loss: 4.467439889907837
Validation Loss Decreased(4.467450--->4.467440) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 216 / 2500Epoch 216 		 Training Loss: 1.470941194466182
Validation step:0Validation step:1Validation step:2Epoch 216 		 Validation Loss: 4.467420816421509
Validation Loss Decreased(4.467440--->4.467421) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 217 / 2500Epoch 217 		 Training Loss: 1.4705701896122523
Validation step:0Validation step:1Validation step:2Epoch 217 		 Validation Loss: 4.467412829399109
Validation Loss Decreased(4.467421--->4.467413) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 218 / 2500Epoch 218 		 Training Loss: 1.471236492906298
Validation step:0Validation step:1Validation step:2Epoch 218 		 Validation Loss: 4.467392444610596
Validation Loss Decreased(4.467413--->4.467392) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 219 / 2500Epoch 219 		 Training Loss: 1.4698806745665414
Validation step:0Validation step:1Validation step:2Epoch 219 		 Validation Loss: 4.467386841773987
Validation Loss Decreased(4.467392--->4.467387) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 220 / 2500Epoch 220 		 Training Loss: 1.4709097572735377
Validation step:0Validation step:1Validation step:2Epoch 220 		 Validation Loss: 4.4673752784729
Validation Loss Decreased(4.467387--->4.467375) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 221 / 2500Epoch 221 		 Training Loss: 1.4697907396725245
Validation step:0Validation step:1Validation step:2Epoch 221 		 Validation Loss: 4.467358589172363
Validation Loss Decreased(4.467375--->4.467359) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 222 / 2500Epoch 222 		 Training Loss: 1.4708996670586723
Validation step:0Validation step:1Validation step:2Epoch 222 		 Validation Loss: 4.467347621917725
Validation Loss Decreased(4.467359--->4.467348) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 223 / 2500Epoch 223 		 Training Loss: 1.4708076800618852
Validation step:0Validation step:1Validation step:2Epoch 223 		 Validation Loss: 4.467331767082214
Validation Loss Decreased(4.467348--->4.467332) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 224 / 2500Epoch 224 		 Training Loss: 1.4705874153545924
Validation step:0Validation step:1Validation step:2Epoch 224 		 Validation Loss: 4.46732223033905
Validation Loss Decreased(4.467332--->4.467322) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 225 / 2500Epoch 225 		 Training Loss: 1.471661048276084
Validation step:0Validation step:1Validation step:2Epoch 225 		 Validation Loss: 4.467302680015564
Validation Loss Decreased(4.467322--->4.467303) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 226 / 2500Epoch 226 		 Training Loss: 1.4710559504372733
Validation step:0Validation step:1Validation step:2Epoch 226 		 Validation Loss: 4.467297554016113
Validation Loss Decreased(4.467303--->4.467298) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 227 / 2500Epoch 227 		 Training Loss: 1.4699981723512923
Validation step:0Validation step:1Validation step:2Epoch 227 		 Validation Loss: 4.467283129692078
Validation Loss Decreased(4.467298--->4.467283) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 228 / 2500Epoch 228 		 Training Loss: 1.4711496915136064
Validation step:0Validation step:1Validation step:2Epoch 228 		 Validation Loss: 4.467264533042908
Validation Loss Decreased(4.467283--->4.467265) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 229 / 2500Epoch 229 		 Training Loss: 1.4714325410979134
Validation step:0Validation step:1Validation step:2Epoch 229 		 Validation Loss: 4.467263460159302
Validation Loss Decreased(4.467265--->4.467263) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 230 / 2500Epoch 230 		 Training Loss: 1.4697452613285609
Validation step:0Validation step:1Validation step:2Epoch 230 		 Validation Loss: 4.467243790626526
Validation Loss Decreased(4.467263--->4.467244) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 231 / 2500Epoch 231 		 Training Loss: 1.4710513693945748
Validation step:0Validation step:1Validation step:2Epoch 231 		 Validation Loss: 4.4672359228134155
Validation Loss Decreased(4.467244--->4.467236) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 232 / 2500Epoch 232 		 Training Loss: 1.4692326613834925
Validation step:0Validation step:1Validation step:2Epoch 232 		 Validation Loss: 4.467220306396484
Validation Loss Decreased(4.467236--->4.467220) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 233 / 2500Epoch 233 		 Training Loss: 1.4708312068666731
Validation step:0Validation step:1Validation step:2Epoch 233 		 Validation Loss: 4.467204928398132
Validation Loss Decreased(4.467220--->4.467205) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 234 / 2500Epoch 234 		 Training Loss: 1.471319590296064
Validation step:0Validation step:1Validation step:2Epoch 234 		 Validation Loss: 4.467207551002502
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 235 / 2500Epoch 235 		 Training Loss: 1.4707021032060896
Validation step:0Validation step:1Validation step:2Epoch 235 		 Validation Loss: 4.467184543609619
Validation Loss Decreased(4.467205--->4.467185) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 236 / 2500Epoch 236 		 Training Loss: 1.4710533022880554
Validation step:0Validation step:1Validation step:2Epoch 236 		 Validation Loss: 4.467170238494873
Validation Loss Decreased(4.467185--->4.467170) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 237 / 2500Epoch 237 		 Training Loss: 1.4686695848192488
Validation step:0Validation step:1Validation step:2Epoch 237 		 Validation Loss: 4.467149138450623
Validation Loss Decreased(4.467170--->4.467149) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 238 / 2500Epoch 238 		 Training Loss: 1.470529590334211
Validation step:0Validation step:1Validation step:2Epoch 238 		 Validation Loss: 4.4671361446380615
Validation Loss Decreased(4.467149--->4.467136) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 239 / 2500Epoch 239 		 Training Loss: 1.470636521066938
Validation step:0Validation step:1Validation step:2Epoch 239 		 Validation Loss: 4.467123866081238
Validation Loss Decreased(4.467136--->4.467124) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 240 / 2500Epoch 240 		 Training Loss: 1.471485504082271
Validation step:0Validation step:1Validation step:2Epoch 240 		 Validation Loss: 4.467113494873047
Validation Loss Decreased(4.467124--->4.467113) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 241 / 2500Epoch 241 		 Training Loss: 1.4706823825836182
Validation step:0Validation step:1Validation step:2Epoch 241 		 Validation Loss: 4.467090010643005
Validation Loss Decreased(4.467113--->4.467090) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 242 / 2500Epoch 242 		 Training Loss: 1.47099426814488
Validation step:0Validation step:1Validation step:2Epoch 242 		 Validation Loss: 4.467087149620056
Validation Loss Decreased(4.467090--->4.467087) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 243 / 2500Epoch 243 		 Training Loss: 1.4709264295441764
Validation step:0Validation step:1Validation step:2Epoch 243 		 Validation Loss: 4.467073321342468
Validation Loss Decreased(4.467087--->4.467073) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 244 / 2500Epoch 244 		 Training Loss: 1.4713843294552393
Validation step:0Validation step:1Validation step:2Epoch 244 		 Validation Loss: 4.46706223487854
Validation Loss Decreased(4.467073--->4.467062) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 245 / 2500Epoch 245 		 Training Loss: 1.470620061670031
Validation step:0Validation step:1Validation step:2Epoch 245 		 Validation Loss: 4.467045903205872
Validation Loss Decreased(4.467062--->4.467046) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 246 / 2500Epoch 246 		 Training Loss: 1.4709565469196864
Validation step:0Validation step:1Validation step:2Epoch 246 		 Validation Loss: 4.4670250415802
Validation Loss Decreased(4.467046--->4.467025) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 247 / 2500Epoch 247 		 Training Loss: 1.4708249739238195
Validation step:0Validation step:1Validation step:2Epoch 247 		 Validation Loss: 4.467012286186218
Validation Loss Decreased(4.467025--->4.467012) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 248 / 2500Epoch 248 		 Training Loss: 1.4704399960381644
Validation step:0Validation step:1Validation step:2Epoch 248 		 Validation Loss: 4.466998934745789
Validation Loss Decreased(4.467012--->4.466999) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 249 / 2500Epoch 249 		 Training Loss: 1.4708071265901839
Validation step:0Validation step:1Validation step:2Epoch 249 		 Validation Loss: 4.466984272003174
Validation Loss Decreased(4.466999--->4.466984) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 250 / 2500Epoch 250 		 Training Loss: 1.470146758215768
Validation step:0Validation step:1Validation step:2Epoch 250 		 Validation Loss: 4.466964602470398
Validation Loss Decreased(4.466984--->4.466965) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 251 / 2500Epoch 251 		 Training Loss: 1.4700935738427299
Validation step:0Validation step:1Validation step:2Epoch 251 		 Validation Loss: 4.466960072517395
Validation Loss Decreased(4.466965--->4.466960) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 252 / 2500Epoch 252 		 Training Loss: 1.470144816807338
Validation step:0Validation step:1Validation step:2Epoch 252 		 Validation Loss: 4.466942191123962
Validation Loss Decreased(4.466960--->4.466942) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 253 / 2500Epoch 253 		 Training Loss: 1.4696004220417567
Validation step:0Validation step:1Validation step:2Epoch 253 		 Validation Loss: 4.466931462287903
Validation Loss Decreased(4.466942--->4.466931) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 254 / 2500Epoch 254 		 Training Loss: 1.4695018018995012
Validation step:0Validation step:1Validation step:2Epoch 254 		 Validation Loss: 4.46691370010376
Validation Loss Decreased(4.466931--->4.466914) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 255 / 2500Epoch 255 		 Training Loss: 1.4711845091411047
Validation step:0Validation step:1Validation step:2Epoch 255 		 Validation Loss: 4.466897368431091
Validation Loss Decreased(4.466914--->4.466897) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 256 / 2500Epoch 256 		 Training Loss: 1.4718612687928336
Validation step:0Validation step:1Validation step:2Epoch 256 		 Validation Loss: 4.466880798339844
Validation Loss Decreased(4.466897--->4.466881) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 257 / 2500Epoch 257 		 Training Loss: 1.4710879411016191
Validation step:0Validation step:1Validation step:2Epoch 257 		 Validation Loss: 4.466863036155701
Validation Loss Decreased(4.466881--->4.466863) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 258 / 2500Epoch 258 		 Training Loss: 1.4704604659761702
Validation step:0Validation step:1Validation step:2Epoch 258 		 Validation Loss: 4.466846346855164
Validation Loss Decreased(4.466863--->4.466846) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 259 / 2500Epoch 259 		 Training Loss: 1.4709110515458244
Validation step:0Validation step:1Validation step:2Epoch 259 		 Validation Loss: 4.466827988624573
Validation Loss Decreased(4.466846--->4.466828) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 260 / 2500Epoch 260 		 Training Loss: 1.4708683746201652
Validation step:0Validation step:1Validation step:2Epoch 260 		 Validation Loss: 4.4668048620224
Validation Loss Decreased(4.466828--->4.466805) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 261 / 2500Epoch 261 		 Training Loss: 1.4706826210021973
Validation step:0Validation step:1Validation step:2Epoch 261 		 Validation Loss: 4.4667885303497314
Validation Loss Decreased(4.466805--->4.466789) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 262 / 2500Epoch 262 		 Training Loss: 1.4706613676888602
Validation step:0Validation step:1Validation step:2Epoch 262 		 Validation Loss: 4.466777205467224
Validation Loss Decreased(4.466789--->4.466777) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 263 / 2500Epoch 263 		 Training Loss: 1.4706907612936837
Validation step:0Validation step:1Validation step:2Epoch 263 		 Validation Loss: 4.466758966445923
Validation Loss Decreased(4.466777--->4.466759) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 264 / 2500Epoch 264 		 Training Loss: 1.4709458436284746
Validation step:0Validation step:1Validation step:2Epoch 264 		 Validation Loss: 4.466736435890198
Validation Loss Decreased(4.466759--->4.466736) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 265 / 2500Epoch 265 		 Training Loss: 1.4700455069541931
Validation step:0Validation step:1Validation step:2Epoch 265 		 Validation Loss: 4.466720342636108
Validation Loss Decreased(4.466736--->4.466720) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 266 / 2500Epoch 266 		 Training Loss: 1.4700256841523307
Validation step:0Validation step:1Validation step:2Epoch 266 		 Validation Loss: 4.466711044311523
Validation Loss Decreased(4.466720--->4.466711) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 267 / 2500Epoch 267 		 Training Loss: 1.4710706216948373
Validation step:0Validation step:1Validation step:2Epoch 267 		 Validation Loss: 4.466707468032837
Validation Loss Decreased(4.466711--->4.466707) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 268 / 2500Epoch 268 		 Training Loss: 1.4715905785560608
Validation step:0Validation step:1Validation step:2Epoch 268 		 Validation Loss: 4.466695427894592
Validation Loss Decreased(4.466707--->4.466695) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 269 / 2500Epoch 269 		 Training Loss: 1.46880327803748
Validation step:0Validation step:1Validation step:2Epoch 269 		 Validation Loss: 4.466656565666199
Validation Loss Decreased(4.466695--->4.466657) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 270 / 2500Epoch 270 		 Training Loss: 1.4708351407732283
Validation step:0Validation step:1Validation step:2Epoch 270 		 Validation Loss: 4.46664297580719
Validation Loss Decreased(4.466657--->4.466643) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 271 / 2500Epoch 271 		 Training Loss: 1.4695056251117162
Validation step:0Validation step:1Validation step:2Epoch 271 		 Validation Loss: 4.466634750366211
Validation Loss Decreased(4.466643--->4.466635) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 272 / 2500Epoch 272 		 Training Loss: 1.470492856843131
Validation step:0Validation step:1Validation step:2Epoch 272 		 Validation Loss: 4.466616272926331
Validation Loss Decreased(4.466635--->4.466616) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 273 / 2500Epoch 273 		 Training Loss: 1.4708313686507088
Validation step:0Validation step:1Validation step:2Epoch 273 		 Validation Loss: 4.4665961265563965
Validation Loss Decreased(4.466616--->4.466596) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 274 / 2500Epoch 274 		 Training Loss: 1.4713717954499381
Validation step:0Validation step:1Validation step:2Epoch 274 		 Validation Loss: 4.466580748558044
Validation Loss Decreased(4.466596--->4.466581) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 275 / 2500Epoch 275 		 Training Loss: 1.4686667578560966
Validation step:0Validation step:1Validation step:2Epoch 275 		 Validation Loss: 4.466559529304504
Validation Loss Decreased(4.466581--->4.466560) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 276 / 2500Epoch 276 		 Training Loss: 1.4692411422729492
Validation step:0Validation step:1Validation step:2Epoch 276 		 Validation Loss: 4.4665433168411255
Validation Loss Decreased(4.466560--->4.466543) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 277 / 2500Epoch 277 		 Training Loss: 1.470403824533735
Validation step:0Validation step:1Validation step:2Epoch 277 		 Validation Loss: 4.4665234088897705
Validation Loss Decreased(4.466543--->4.466523) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 278 / 2500Epoch 278 		 Training Loss: 1.470413659300123
Validation step:0Validation step:1Validation step:2Epoch 278 		 Validation Loss: 4.46649968624115
Validation Loss Decreased(4.466523--->4.466500) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 279 / 2500Epoch 279 		 Training Loss: 1.4704494220869881
Validation step:0Validation step:1Validation step:2Epoch 279 		 Validation Loss: 4.466479778289795
Validation Loss Decreased(4.466500--->4.466480) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 280 / 2500Epoch 280 		 Training Loss: 1.4712508405957903
Validation step:0Validation step:1Validation step:2Epoch 280 		 Validation Loss: 4.466467380523682
Validation Loss Decreased(4.466480--->4.466467) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 281 / 2500Epoch 281 		 Training Loss: 1.4704116923468453
Validation step:0Validation step:1Validation step:2Epoch 281 		 Validation Loss: 4.466442227363586
Validation Loss Decreased(4.466467--->4.466442) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 282 / 2500Epoch 282 		 Training Loss: 1.4708592891693115
Validation step:0Validation step:1Validation step:2Epoch 282 		 Validation Loss: 4.466420292854309
Validation Loss Decreased(4.466442--->4.466420) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 283 / 2500Epoch 283 		 Training Loss: 1.4710398060934884
Validation step:0Validation step:1Validation step:2Epoch 283 		 Validation Loss: 4.466405868530273
Validation Loss Decreased(4.466420--->4.466406) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 284 / 2500Epoch 284 		 Training Loss: 1.469417895589556
Validation step:0Validation step:1Validation step:2Epoch 284 		 Validation Loss: 4.466379284858704
Validation Loss Decreased(4.466406--->4.466379) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 285 / 2500Epoch 285 		 Training Loss: 1.4704110963003976
Validation step:0Validation step:1Validation step:2Epoch 285 		 Validation Loss: 4.466362118721008
Validation Loss Decreased(4.466379--->4.466362) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 286 / 2500Epoch 286 		 Training Loss: 1.4710234233311243
Validation step:0Validation step:1Validation step:2Epoch 286 		 Validation Loss: 4.466341614723206
Validation Loss Decreased(4.466362--->4.466342) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 287 / 2500Epoch 287 		 Training Loss: 1.4705359084265572
Validation step:0Validation step:1Validation step:2Epoch 287 		 Validation Loss: 4.466315507888794
Validation Loss Decreased(4.466342--->4.466316) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 288 / 2500Epoch 288 		 Training Loss: 1.4714387995856149
Validation step:0Validation step:1Validation step:2Epoch 288 		 Validation Loss: 4.466298937797546
Validation Loss Decreased(4.466316--->4.466299) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 289 / 2500Epoch 289 		 Training Loss: 1.4705723524093628
Validation step:0Validation step:1Validation step:2Epoch 289 		 Validation Loss: 4.466273069381714
Validation Loss Decreased(4.466299--->4.466273) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 290 / 2500Epoch 290 		 Training Loss: 1.4710124135017395
Validation step:0Validation step:1Validation step:2Epoch 290 		 Validation Loss: 4.466259121894836
Validation Loss Decreased(4.466273--->4.466259) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 291 / 2500Epoch 291 		 Training Loss: 1.4697850602013725
Validation step:0Validation step:1Validation step:2Epoch 291 		 Validation Loss: 4.4662452936172485
Validation Loss Decreased(4.466259--->4.466245) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 292 / 2500Epoch 292 		 Training Loss: 1.4708686470985413
Validation step:0Validation step:1Validation step:2Epoch 292 		 Validation Loss: 4.466226577758789
Validation Loss Decreased(4.466245--->4.466227) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 293 / 2500Epoch 293 		 Training Loss: 1.4701497214181083
Validation step:0Validation step:1Validation step:2Epoch 293 		 Validation Loss: 4.46621036529541
Validation Loss Decreased(4.466227--->4.466210) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 294 / 2500Epoch 294 		 Training Loss: 1.4719421522957938
Validation step:0Validation step:1Validation step:2Epoch 294 		 Validation Loss: 4.466187596321106
Validation Loss Decreased(4.466210--->4.466188) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 295 / 2500Epoch 295 		 Training Loss: 1.4710958770343237
Validation step:0Validation step:1Validation step:2Epoch 295 		 Validation Loss: 4.466173052787781
Validation Loss Decreased(4.466188--->4.466173) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 296 / 2500Epoch 296 		 Training Loss: 1.4695123263767786
Validation step:0Validation step:1Validation step:2Epoch 296 		 Validation Loss: 4.466171503067017
Validation Loss Decreased(4.466173--->4.466172) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 297 / 2500Epoch 297 		 Training Loss: 1.4716287851333618
Validation step:0Validation step:1Validation step:2Epoch 297 		 Validation Loss: 4.466130375862122
Validation Loss Decreased(4.466172--->4.466130) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 298 / 2500Epoch 298 		 Training Loss: 1.470352556024279
Validation step:0Validation step:1Validation step:2Epoch 298 		 Validation Loss: 4.466108322143555
Validation Loss Decreased(4.466130--->4.466108) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 299 / 2500Epoch 299 		 Training Loss: 1.4702686411993844
Validation step:0Validation step:1Validation step:2Epoch 299 		 Validation Loss: 4.466085910797119
Validation Loss Decreased(4.466108--->4.466086) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 300 / 2500Epoch 300 		 Training Loss: 1.4714469824518477
Validation step:0Validation step:1Validation step:2Epoch 300 		 Validation Loss: 4.466067433357239
Validation Loss Decreased(4.466086--->4.466067) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 301 / 2500Epoch 301 		 Training Loss: 1.4705045052937098
Validation step:0Validation step:1Validation step:2Epoch 301 		 Validation Loss: 4.466044306755066
Validation Loss Decreased(4.466067--->4.466044) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 302 / 2500Epoch 302 		 Training Loss: 1.4707029887608118
Validation step:0Validation step:1Validation step:2Epoch 302 		 Validation Loss: 4.466021180152893
Validation Loss Decreased(4.466044--->4.466021) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 303 / 2500Epoch 303 		 Training Loss: 1.469874952520643
Validation step:0Validation step:1Validation step:2Epoch 303 		 Validation Loss: 4.466000318527222
Validation Loss Decreased(4.466021--->4.466000) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 304 / 2500Epoch 304 		 Training Loss: 1.4702410697937012
Validation step:0Validation step:1Validation step:2Epoch 304 		 Validation Loss: 4.4659950733184814
Validation Loss Decreased(4.466000--->4.465995) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 305 / 2500Epoch 305 		 Training Loss: 1.4712735244206019
Validation step:0Validation step:1Validation step:2Epoch 305 		 Validation Loss: 4.465969681739807
Validation Loss Decreased(4.465995--->4.465970) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 306 / 2500Epoch 306 		 Training Loss: 1.4710513693945748
Validation step:0Validation step:1Validation step:2Epoch 306 		 Validation Loss: 4.465930223464966
Validation Loss Decreased(4.465970--->4.465930) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 307 / 2500Epoch 307 		 Training Loss: 1.4712920018604823
Validation step:0Validation step:1Validation step:2Epoch 307 		 Validation Loss: 4.4659082889556885
Validation Loss Decreased(4.465930--->4.465908) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 308 / 2500Epoch 308 		 Training Loss: 1.4697336724826269
Validation step:0Validation step:1Validation step:2Epoch 308 		 Validation Loss: 4.4659013748168945
Validation Loss Decreased(4.465908--->4.465901) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 309 / 2500Epoch 309 		 Training Loss: 1.4704845717975072
Validation step:0Validation step:1Validation step:2Epoch 309 		 Validation Loss: 4.465873599052429
Validation Loss Decreased(4.465901--->4.465874) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 310 / 2500Epoch 310 		 Training Loss: 1.4698201077325004
Validation step:0Validation step:1Validation step:2Epoch 310 		 Validation Loss: 4.465843200683594
Validation Loss Decreased(4.465874--->4.465843) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 311 / 2500Epoch 311 		 Training Loss: 1.4701018503734045
Validation step:0Validation step:1Validation step:2Epoch 311 		 Validation Loss: 4.465827226638794
Validation Loss Decreased(4.465843--->4.465827) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 312 / 2500Epoch 312 		 Training Loss: 1.4693139791488647
Validation step:0Validation step:1Validation step:2Epoch 312 		 Validation Loss: 4.465791344642639
Validation Loss Decreased(4.465827--->4.465791) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 313 / 2500Epoch 313 		 Training Loss: 1.4708723851612635
Validation step:0Validation step:1Validation step:2Epoch 313 		 Validation Loss: 4.465766072273254
Validation Loss Decreased(4.465791--->4.465766) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 314 / 2500Epoch 314 		 Training Loss: 1.4693387065614973
Validation step:0Validation step:1Validation step:2Epoch 314 		 Validation Loss: 4.465747594833374
Validation Loss Decreased(4.465766--->4.465748) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 315 / 2500Epoch 315 		 Training Loss: 1.470570138522557
Validation step:0Validation step:1Validation step:2Epoch 315 		 Validation Loss: 4.465728044509888
Validation Loss Decreased(4.465748--->4.465728) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 316 / 2500Epoch 316 		 Training Loss: 1.470936621938433
Validation step:0Validation step:1Validation step:2Epoch 316 		 Validation Loss: 4.4656935930252075
Validation Loss Decreased(4.465728--->4.465694) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 317 / 2500Epoch 317 		 Training Loss: 1.4702550428254264
Validation step:0Validation step:1Validation step:2Epoch 317 		 Validation Loss: 4.4656760692596436
Validation Loss Decreased(4.465694--->4.465676) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 318 / 2500Epoch 318 		 Training Loss: 1.471597399030413
Validation step:0Validation step:1Validation step:2Epoch 318 		 Validation Loss: 4.465652823448181
Validation Loss Decreased(4.465676--->4.465653) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 319 / 2500Epoch 319 		 Training Loss: 1.4703141025134496
Validation step:0Validation step:1Validation step:2Epoch 319 		 Validation Loss: 4.465628981590271
Validation Loss Decreased(4.465653--->4.465629) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 320 / 2500Epoch 320 		 Training Loss: 1.4716225096157618
Validation step:0Validation step:1Validation step:2Epoch 320 		 Validation Loss: 4.465601086616516
Validation Loss Decreased(4.465629--->4.465601) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 321 / 2500Epoch 321 		 Training Loss: 1.4714126586914062
Validation step:0Validation step:1Validation step:2Epoch 321 		 Validation Loss: 4.4655760526657104
Validation Loss Decreased(4.465601--->4.465576) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 322 / 2500Epoch 322 		 Training Loss: 1.4699219294956751
Validation step:0Validation step:1Validation step:2Epoch 322 		 Validation Loss: 4.4655526876449585
Validation Loss Decreased(4.465576--->4.465553) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 323 / 2500Epoch 323 		 Training Loss: 1.4710799285343714
Validation step:0Validation step:1Validation step:2Epoch 323 		 Validation Loss: 4.465535759925842
Validation Loss Decreased(4.465553--->4.465536) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 324 / 2500Epoch 324 		 Training Loss: 1.4703350833484106
Validation step:0Validation step:1Validation step:2Epoch 324 		 Validation Loss: 4.465505838394165
Validation Loss Decreased(4.465536--->4.465506) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 325 / 2500Epoch 325 		 Training Loss: 1.4693173255239214
Validation step:0Validation step:1Validation step:2Epoch 325 		 Validation Loss: 4.465472102165222
Validation Loss Decreased(4.465506--->4.465472) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 326 / 2500Epoch 326 		 Training Loss: 1.4702461447034563
Validation step:0Validation step:1Validation step:2Epoch 326 		 Validation Loss: 4.465455174446106
Validation Loss Decreased(4.465472--->4.465455) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 327 / 2500Epoch 327 		 Training Loss: 1.4693497249058314
Validation step:0Validation step:1Validation step:2Epoch 327 		 Validation Loss: 4.465438961982727
Validation Loss Decreased(4.465455--->4.465439) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 328 / 2500Epoch 328 		 Training Loss: 1.4702320439474923
Validation step:0Validation step:1Validation step:2Epoch 328 		 Validation Loss: 4.465416431427002
Validation Loss Decreased(4.465439--->4.465416) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 329 / 2500Epoch 329 		 Training Loss: 1.4686101249286108
Validation step:0Validation step:1Validation step:2Epoch 329 		 Validation Loss: 4.465384364128113
Validation Loss Decreased(4.465416--->4.465384) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 330 / 2500Epoch 330 		 Training Loss: 1.468889253480094
Validation step:0Validation step:1Validation step:2Epoch 330 		 Validation Loss: 4.465339660644531
Validation Loss Decreased(4.465384--->4.465340) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 331 / 2500Epoch 331 		 Training Loss: 1.469366763319288
Validation step:0Validation step:1Validation step:2Epoch 331 		 Validation Loss: 4.4653050899505615
Validation Loss Decreased(4.465340--->4.465305) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 332 / 2500Epoch 332 		 Training Loss: 1.4676761371748788
Validation step:0Validation step:1Validation step:2Epoch 332 		 Validation Loss: 4.465279936790466
Validation Loss Decreased(4.465305--->4.465280) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 333 / 2500Epoch 333 		 Training Loss: 1.4705795560564314
Validation step:0Validation step:1Validation step:2Epoch 333 		 Validation Loss: 4.465270638465881
Validation Loss Decreased(4.465280--->4.465271) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 334 / 2500Epoch 334 		 Training Loss: 1.4707976409367152
Validation step:0Validation step:1Validation step:2Epoch 334 		 Validation Loss: 4.465234756469727
Validation Loss Decreased(4.465271--->4.465235) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 335 / 2500Epoch 335 		 Training Loss: 1.4714363302503313
Validation step:0Validation step:1Validation step:2Epoch 335 		 Validation Loss: 4.465198278427124
Validation Loss Decreased(4.465235--->4.465198) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 336 / 2500Epoch 336 		 Training Loss: 1.4689945152827673
Validation step:0Validation step:1Validation step:2Epoch 336 		 Validation Loss: 4.465168118476868
Validation Loss Decreased(4.465198--->4.465168) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 337 / 2500Epoch 337 		 Training Loss: 1.4703750780650549
Validation step:0Validation step:1Validation step:2Epoch 337 		 Validation Loss: 4.4651408195495605
Validation Loss Decreased(4.465168--->4.465141) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 338 / 2500Epoch 338 		 Training Loss: 1.4696918981415885
Validation step:0Validation step:1Validation step:2Epoch 338 		 Validation Loss: 4.465116500854492
Validation Loss Decreased(4.465141--->4.465117) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 339 / 2500Epoch 339 		 Training Loss: 1.4698354005813599
Validation step:0Validation step:1Validation step:2Epoch 339 		 Validation Loss: 4.4650750160217285
Validation Loss Decreased(4.465117--->4.465075) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 340 / 2500Epoch 340 		 Training Loss: 1.4703485454831804
Validation step:0Validation step:1Validation step:2Epoch 340 		 Validation Loss: 4.4650479555130005
Validation Loss Decreased(4.465075--->4.465048) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 341 / 2500Epoch 341 		 Training Loss: 1.4705692614827837
Validation step:0Validation step:1Validation step:2Epoch 341 		 Validation Loss: 4.465029358863831
Validation Loss Decreased(4.465048--->4.465029) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 342 / 2500Epoch 342 		 Training Loss: 1.4705155406679427
Validation step:0Validation step:1Validation step:2Epoch 342 		 Validation Loss: 4.465021014213562
Validation Loss Decreased(4.465029--->4.465021) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 343 / 2500Epoch 343 		 Training Loss: 1.4702890855925423
Validation step:0Validation step:1Validation step:2Epoch 343 		 Validation Loss: 4.464987874031067
Validation Loss Decreased(4.465021--->4.464988) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 344 / 2500Epoch 344 		 Training Loss: 1.470764764717647
Validation step:0Validation step:1Validation step:2Epoch 344 		 Validation Loss: 4.464944243431091
Validation Loss Decreased(4.464988--->4.464944) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 345 / 2500Epoch 345 		 Training Loss: 1.4705156598772322
Validation step:0Validation step:1Validation step:2Epoch 345 		 Validation Loss: 4.464925765991211
Validation Loss Decreased(4.464944--->4.464926) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 346 / 2500Epoch 346 		 Training Loss: 1.4701925345829554
Validation step:0Validation step:1Validation step:2Epoch 346 		 Validation Loss: 4.464901447296143
Validation Loss Decreased(4.464926--->4.464901) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 347 / 2500Epoch 347 		 Training Loss: 1.469201215675899
Validation step:0Validation step:1Validation step:2Epoch 347 		 Validation Loss: 4.464866280555725
Validation Loss Decreased(4.464901--->4.464866) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 348 / 2500Epoch 348 		 Training Loss: 1.4713762402534485
Validation step:0Validation step:1Validation step:2Epoch 348 		 Validation Loss: 4.464829921722412
Validation Loss Decreased(4.464866--->4.464830) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 349 / 2500Epoch 349 		 Training Loss: 1.4711416534015112
Validation step:0Validation step:1Validation step:2Epoch 349 		 Validation Loss: 4.46479856967926
Validation Loss Decreased(4.464830--->4.464799) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 350 / 2500Epoch 350 		 Training Loss: 1.4685780576297216
Validation step:0Validation step:1Validation step:2Epoch 350 		 Validation Loss: 4.464778542518616
Validation Loss Decreased(4.464799--->4.464779) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 351 / 2500Epoch 351 		 Training Loss: 1.4693117908069067
Validation step:0Validation step:1Validation step:2Epoch 351 		 Validation Loss: 4.46474027633667
Validation Loss Decreased(4.464779--->4.464740) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 352 / 2500Epoch 352 		 Training Loss: 1.4696468796048845
Validation step:0Validation step:1Validation step:2Epoch 352 		 Validation Loss: 4.464724898338318
Validation Loss Decreased(4.464740--->4.464725) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 353 / 2500Epoch 353 		 Training Loss: 1.4697585531643458
Validation step:0Validation step:1Validation step:2Epoch 353 		 Validation Loss: 4.464718699455261
Validation Loss Decreased(4.464725--->4.464719) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 354 / 2500Epoch 354 		 Training Loss: 1.468351491859981
Validation step:0Validation step:1Validation step:2Epoch 354 		 Validation Loss: 4.464655876159668
Validation Loss Decreased(4.464719--->4.464656) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 355 / 2500Epoch 355 		 Training Loss: 1.4686652081353324
Validation step:0Validation step:1Validation step:2Epoch 355 		 Validation Loss: 4.464619994163513
Validation Loss Decreased(4.464656--->4.464620) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 356 / 2500Epoch 356 		 Training Loss: 1.4696919236864363
Validation step:0Validation step:1Validation step:2Epoch 356 		 Validation Loss: 4.464608073234558
Validation Loss Decreased(4.464620--->4.464608) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 357 / 2500Epoch 357 		 Training Loss: 1.4683119314057487
Validation step:0Validation step:1Validation step:2Epoch 357 		 Validation Loss: 4.464553236961365
Validation Loss Decreased(4.464608--->4.464553) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 358 / 2500Epoch 358 		 Training Loss: 1.4693812813077654
Validation step:0Validation step:1Validation step:2Epoch 358 		 Validation Loss: 4.464517593383789
Validation Loss Decreased(4.464553--->4.464518) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 359 / 2500Epoch 359 		 Training Loss: 1.4690345099994115
Validation step:0Validation step:1Validation step:2Epoch 359 		 Validation Loss: 4.464489579200745
Validation Loss Decreased(4.464518--->4.464490) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 360 / 2500Epoch 360 		 Training Loss: 1.4686895864350455
Validation step:0Validation step:1Validation step:2Epoch 360 		 Validation Loss: 4.464449048042297
Validation Loss Decreased(4.464490--->4.464449) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 361 / 2500Epoch 361 		 Training Loss: 1.4703829543931144
Validation step:0Validation step:1Validation step:2Epoch 361 		 Validation Loss: 4.4644105434417725
Validation Loss Decreased(4.464449--->4.464411) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 362 / 2500Epoch 362 		 Training Loss: 1.4702332190104894
Validation step:0Validation step:1Validation step:2Epoch 362 		 Validation Loss: 4.464375257492065
Validation Loss Decreased(4.464411--->4.464375) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 363 / 2500Epoch 363 		 Training Loss: 1.469251079218728
Validation step:0Validation step:1Validation step:2Epoch 363 		 Validation Loss: 4.464349746704102
Validation Loss Decreased(4.464375--->4.464350) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 364 / 2500Epoch 364 		 Training Loss: 1.4707450866699219
Validation step:0Validation step:1Validation step:2Epoch 364 		 Validation Loss: 4.4643179178237915
Validation Loss Decreased(4.464350--->4.464318) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 365 / 2500Epoch 365 		 Training Loss: 1.469358810356685
Validation step:0Validation step:1Validation step:2Epoch 365 		 Validation Loss: 4.46430516242981
Validation Loss Decreased(4.464318--->4.464305) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 366 / 2500Epoch 366 		 Training Loss: 1.4707272137914384
Validation step:0Validation step:1Validation step:2Epoch 366 		 Validation Loss: 4.464256644248962
Validation Loss Decreased(4.464305--->4.464257) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 367 / 2500Epoch 367 		 Training Loss: 1.4702700802258082
Validation step:0Validation step:1Validation step:2Epoch 367 		 Validation Loss: 4.464228868484497
Validation Loss Decreased(4.464257--->4.464229) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 368 / 2500Epoch 368 		 Training Loss: 1.4698786054338728
Validation step:0Validation step:1Validation step:2Epoch 368 		 Validation Loss: 4.464194655418396
Validation Loss Decreased(4.464229--->4.464195) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 369 / 2500Epoch 369 		 Training Loss: 1.4703826223100935
Validation step:0Validation step:1Validation step:2Epoch 369 		 Validation Loss: 4.464164972305298
Validation Loss Decreased(4.464195--->4.464165) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 370 / 2500Epoch 370 		 Training Loss: 1.4691157000405448
Validation step:0Validation step:1Validation step:2Epoch 370 		 Validation Loss: 4.464131712913513
Validation Loss Decreased(4.464165--->4.464132) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 371 / 2500Epoch 371 		 Training Loss: 1.4689029199736459
Validation step:0Validation step:1Validation step:2Epoch 371 		 Validation Loss: 4.464095115661621
Validation Loss Decreased(4.464132--->4.464095) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 372 / 2500Epoch 372 		 Training Loss: 1.4681407042912074
Validation step:0Validation step:1Validation step:2Epoch 372 		 Validation Loss: 4.46403968334198
Validation Loss Decreased(4.464095--->4.464040) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 373 / 2500Epoch 373 		 Training Loss: 1.4694964034216744
Validation step:0Validation step:1Validation step:2Epoch 373 		 Validation Loss: 4.464011192321777
Validation Loss Decreased(4.464040--->4.464011) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 374 / 2500Epoch 374 		 Training Loss: 1.4705256138529097
Validation step:0Validation step:1Validation step:2Epoch 374 		 Validation Loss: 4.4639739990234375
Validation Loss Decreased(4.464011--->4.463974) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 375 / 2500Epoch 375 		 Training Loss: 1.470022167478289
Validation step:0Validation step:1Validation step:2Epoch 375 		 Validation Loss: 4.463956594467163
Validation Loss Decreased(4.463974--->4.463957) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 376 / 2500Epoch 376 		 Training Loss: 1.4688728622027807
Validation step:0Validation step:1Validation step:2Epoch 376 		 Validation Loss: 4.463931083679199
Validation Loss Decreased(4.463957--->4.463931) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 377 / 2500Epoch 377 		 Training Loss: 1.4702855007989066
Validation step:0Validation step:1Validation step:2Epoch 377 		 Validation Loss: 4.463893532752991
Validation Loss Decreased(4.463931--->4.463894) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 378 / 2500Epoch 378 		 Training Loss: 1.4700847097805567
Validation step:0Validation step:1Validation step:2Epoch 378 		 Validation Loss: 4.463856101036072
Validation Loss Decreased(4.463894--->4.463856) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 379 / 2500Epoch 379 		 Training Loss: 1.4672261731965202
Validation step:0Validation step:1Validation step:2Epoch 379 		 Validation Loss: 4.463806867599487
Validation Loss Decreased(4.463856--->4.463807) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 380 / 2500Epoch 380 		 Training Loss: 1.4700073174067907
Validation step:0Validation step:1Validation step:2Epoch 380 		 Validation Loss: 4.463783502578735
Validation Loss Decreased(4.463807--->4.463784) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 381 / 2500Epoch 381 		 Training Loss: 1.4697097539901733
Validation step:0Validation step:1Validation step:2Epoch 381 		 Validation Loss: 4.463726997375488
Validation Loss Decreased(4.463784--->4.463727) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 382 / 2500Epoch 382 		 Training Loss: 1.4696726543562753
Validation step:0Validation step:1Validation step:2Epoch 382 		 Validation Loss: 4.463703036308289
Validation Loss Decreased(4.463727--->4.463703) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 383 / 2500Epoch 383 		 Training Loss: 1.4701590027127946
Validation step:0Validation step:1Validation step:2Epoch 383 		 Validation Loss: 4.463683724403381
Validation Loss Decreased(4.463703--->4.463684) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 384 / 2500Epoch 384 		 Training Loss: 1.469300193446023
Validation step:0Validation step:1Validation step:2Epoch 384 		 Validation Loss: 4.463638782501221
Validation Loss Decreased(4.463684--->4.463639) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 385 / 2500Epoch 385 		 Training Loss: 1.469378846032279
Validation step:0Validation step:1Validation step:2Epoch 385 		 Validation Loss: 4.463599324226379
Validation Loss Decreased(4.463639--->4.463599) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 386 / 2500Epoch 386 		 Training Loss: 1.470355476651873
Validation step:0Validation step:1Validation step:2Epoch 386 		 Validation Loss: 4.463558554649353
Validation Loss Decreased(4.463599--->4.463559) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 387 / 2500Epoch 387 		 Training Loss: 1.4692006707191467
Validation step:0Validation step:1Validation step:2Epoch 387 		 Validation Loss: 4.4635089635849
Validation Loss Decreased(4.463559--->4.463509) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 388 / 2500Epoch 388 		 Training Loss: 1.4698528902871268
Validation step:0Validation step:1Validation step:2Epoch 388 		 Validation Loss: 4.463489651679993
Validation Loss Decreased(4.463509--->4.463490) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 389 / 2500Epoch 389 		 Training Loss: 1.47023378099714
Validation step:0Validation step:1Validation step:2Epoch 389 		 Validation Loss: 4.463448524475098
Validation Loss Decreased(4.463490--->4.463449) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 390 / 2500Epoch 390 		 Training Loss: 1.4702998655182975
Validation step:0Validation step:1Validation step:2Epoch 390 		 Validation Loss: 4.463399887084961
Validation Loss Decreased(4.463449--->4.463400) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 391 / 2500Epoch 391 		 Training Loss: 1.4703813706125533
Validation step:0Validation step:1Validation step:2Epoch 391 		 Validation Loss: 4.463355898857117
Validation Loss Decreased(4.463400--->4.463356) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 392 / 2500Epoch 392 		 Training Loss: 1.469968012401036
Validation step:0Validation step:1Validation step:2Epoch 392 		 Validation Loss: 4.463315844535828
Validation Loss Decreased(4.463356--->4.463316) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 393 / 2500Epoch 393 		 Training Loss: 1.4685192363602775
Validation step:0Validation step:1Validation step:2Epoch 393 		 Validation Loss: 4.46327805519104
Validation Loss Decreased(4.463316--->4.463278) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 394 / 2500Epoch 394 		 Training Loss: 1.4693940537316459
Validation step:0Validation step:1Validation step:2Epoch 394 		 Validation Loss: 4.463244199752808
Validation Loss Decreased(4.463278--->4.463244) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 395 / 2500Epoch 395 		 Training Loss: 1.4674780879701887
Validation step:0Validation step:1Validation step:2Epoch 395 		 Validation Loss: 4.4632076025009155
Validation Loss Decreased(4.463244--->4.463208) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 396 / 2500Epoch 396 		 Training Loss: 1.4689864260809762
Validation step:0Validation step:1Validation step:2Epoch 396 		 Validation Loss: 4.463169693946838
Validation Loss Decreased(4.463208--->4.463170) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 397 / 2500Epoch 397 		 Training Loss: 1.4673315371785844
Validation step:0Validation step:1Validation step:2Epoch 397 		 Validation Loss: 4.463123679161072
Validation Loss Decreased(4.463170--->4.463124) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 398 / 2500Epoch 398 		 Training Loss: 1.4699386273111616
Validation step:0Validation step:1Validation step:2Epoch 398 		 Validation Loss: 4.463102340698242
Validation Loss Decreased(4.463124--->4.463102) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 399 / 2500Epoch 399 		 Training Loss: 1.4687736460140772
Validation step:0Validation step:1Validation step:2Epoch 399 		 Validation Loss: 4.4630773067474365
Validation Loss Decreased(4.463102--->4.463077) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 400 / 2500Epoch 400 		 Training Loss: 1.4667473435401917
Validation step:0Validation step:1Validation step:2Epoch 400 		 Validation Loss: 4.463035345077515
Validation Loss Decreased(4.463077--->4.463035) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 401 / 2500Epoch 401 		 Training Loss: 1.4699329052652632
Validation step:0Validation step:1Validation step:2Epoch 401 		 Validation Loss: 4.4630125761032104
Validation Loss Decreased(4.463035--->4.463013) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 402 / 2500Epoch 402 		 Training Loss: 1.4687711426189967
Validation step:0Validation step:1Validation step:2Epoch 402 		 Validation Loss: 4.4629576206207275
Validation Loss Decreased(4.463013--->4.462958) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 403 / 2500Epoch 403 		 Training Loss: 1.4702531354767936
Validation step:0Validation step:1Validation step:2Epoch 403 		 Validation Loss: 4.462900638580322
Validation Loss Decreased(4.462958--->4.462901) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 404 / 2500Epoch 404 		 Training Loss: 1.4701203618730818
Validation step:0Validation step:1Validation step:2Epoch 404 		 Validation Loss: 4.462856292724609
Validation Loss Decreased(4.462901--->4.462856) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 405 / 2500Epoch 405 		 Training Loss: 1.4690946170261927
Validation step:0Validation step:1Validation step:2Epoch 405 		 Validation Loss: 4.462819337844849
Validation Loss Decreased(4.462856--->4.462819) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 406 / 2500Epoch 406 		 Training Loss: 1.4693319371768407
Validation step:0Validation step:1Validation step:2Epoch 406 		 Validation Loss: 4.462806940078735
Validation Loss Decreased(4.462819--->4.462807) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 407 / 2500Epoch 407 		 Training Loss: 1.469805325780596
Validation step:0Validation step:1Validation step:2Epoch 407 		 Validation Loss: 4.462768077850342
Validation Loss Decreased(4.462807--->4.462768) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 408 / 2500Epoch 408 		 Training Loss: 1.4704321537699019
Validation step:0Validation step:1Validation step:2Epoch 408 		 Validation Loss: 4.462715268135071
Validation Loss Decreased(4.462768--->4.462715) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 409 / 2500Epoch 409 		 Training Loss: 1.4700034345899309
Validation step:0Validation step:1Validation step:2Epoch 409 		 Validation Loss: 4.462643265724182
Validation Loss Decreased(4.462715--->4.462643) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 410 / 2500Epoch 410 		 Training Loss: 1.4684036714690072
Validation step:0Validation step:1Validation step:2Epoch 410 		 Validation Loss: 4.462579607963562
Validation Loss Decreased(4.462643--->4.462580) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 411 / 2500Epoch 411 		 Training Loss: 1.4692610927990504
Validation step:0Validation step:1Validation step:2Epoch 411 		 Validation Loss: 4.462531208992004
Validation Loss Decreased(4.462580--->4.462531) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 412 / 2500Epoch 412 		 Training Loss: 1.4694403409957886
Validation step:0Validation step:1Validation step:2Epoch 412 		 Validation Loss: 4.46247923374176
Validation Loss Decreased(4.462531--->4.462479) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 413 / 2500Epoch 413 		 Training Loss: 1.469314660344805
Validation step:0Validation step:1Validation step:2Epoch 413 		 Validation Loss: 4.462446093559265
Validation Loss Decreased(4.462479--->4.462446) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 414 / 2500Epoch 414 		 Training Loss: 1.4696960619517736
Validation step:0Validation step:1Validation step:2Epoch 414 		 Validation Loss: 4.46240508556366
Validation Loss Decreased(4.462446--->4.462405) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 415 / 2500Epoch 415 		 Training Loss: 1.469249699796949
Validation step:0Validation step:1Validation step:2Epoch 415 		 Validation Loss: 4.462359666824341
Validation Loss Decreased(4.462405--->4.462360) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 416 / 2500Epoch 416 		 Training Loss: 1.4695995109421867
Validation step:0Validation step:1Validation step:2Epoch 416 		 Validation Loss: 4.4623154401779175
Validation Loss Decreased(4.462360--->4.462315) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 417 / 2500Epoch 417 		 Training Loss: 1.4680675949369157
Validation step:0Validation step:1Validation step:2Epoch 417 		 Validation Loss: 4.4622802734375
Validation Loss Decreased(4.462315--->4.462280) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 418 / 2500Epoch 418 		 Training Loss: 1.4680938635553633
Validation step:0Validation step:1Validation step:2Epoch 418 		 Validation Loss: 4.462224364280701
Validation Loss Decreased(4.462280--->4.462224) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 419 / 2500Epoch 419 		 Training Loss: 1.4684888635362898
Validation step:0Validation step:1Validation step:2Epoch 419 		 Validation Loss: 4.462185621261597
Validation Loss Decreased(4.462224--->4.462186) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 420 / 2500Epoch 420 		 Training Loss: 1.4674272622380937
Validation step:0Validation step:1Validation step:2Epoch 420 		 Validation Loss: 4.462143540382385
Validation Loss Decreased(4.462186--->4.462144) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 421 / 2500Epoch 421 		 Training Loss: 1.4690400787762232
Validation step:0Validation step:1Validation step:2Epoch 421 		 Validation Loss: 4.462109923362732
Validation Loss Decreased(4.462144--->4.462110) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 422 / 2500Epoch 422 		 Training Loss: 1.4678067309515817
Validation step:0Validation step:1Validation step:2Epoch 422 		 Validation Loss: 4.462058663368225
Validation Loss Decreased(4.462110--->4.462059) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 423 / 2500Epoch 423 		 Training Loss: 1.4689286862100874
Validation step:0Validation step:1Validation step:2Epoch 423 		 Validation Loss: 4.462012410163879
Validation Loss Decreased(4.462059--->4.462012) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 424 / 2500Epoch 424 		 Training Loss: 1.4695998685700553
Validation step:0Validation step:1Validation step:2Epoch 424 		 Validation Loss: 4.461947441101074
Validation Loss Decreased(4.462012--->4.461947) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 425 / 2500Epoch 425 		 Training Loss: 1.4695656384740556
Validation step:0Validation step:1Validation step:2Epoch 425 		 Validation Loss: 4.461905837059021
Validation Loss Decreased(4.461947--->4.461906) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 426 / 2500Epoch 426 		 Training Loss: 1.469047520841871
Validation step:0Validation step:1Validation step:2Epoch 426 		 Validation Loss: 4.461868524551392
Validation Loss Decreased(4.461906--->4.461869) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 427 / 2500Epoch 427 		 Training Loss: 1.4700502582958765
Validation step:0Validation step:1Validation step:2Epoch 427 		 Validation Loss: 4.461835265159607
Validation Loss Decreased(4.461869--->4.461835) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 428 / 2500Epoch 428 		 Training Loss: 1.4692057796886988
Validation step:0Validation step:1Validation step:2Epoch 428 		 Validation Loss: 4.461805939674377
Validation Loss Decreased(4.461835--->4.461806) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 429 / 2500Epoch 429 		 Training Loss: 1.4674816727638245
Validation step:0Validation step:1Validation step:2Epoch 429 		 Validation Loss: 4.461741805076599
Validation Loss Decreased(4.461806--->4.461742) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 430 / 2500Epoch 430 		 Training Loss: 1.469905640397753
Validation step:0Validation step:1Validation step:2Epoch 430 		 Validation Loss: 4.461696147918701
Validation Loss Decreased(4.461742--->4.461696) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 431 / 2500Epoch 431 		 Training Loss: 1.4684103301593237
Validation step:0Validation step:1Validation step:2Epoch 431 		 Validation Loss: 4.461653709411621
Validation Loss Decreased(4.461696--->4.461654) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 432 / 2500Epoch 432 		 Training Loss: 1.466173427445548
Validation step:0Validation step:1Validation step:2Epoch 432 		 Validation Loss: 4.461600422859192
Validation Loss Decreased(4.461654--->4.461600) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 433 / 2500Epoch 433 		 Training Loss: 1.4693598747253418
Validation step:0Validation step:1Validation step:2Epoch 433 		 Validation Loss: 4.461552262306213
Validation Loss Decreased(4.461600--->4.461552) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 434 / 2500Epoch 434 		 Training Loss: 1.4670159561293465
Validation step:0Validation step:1Validation step:2Epoch 434 		 Validation Loss: 4.4615113735198975
Validation Loss Decreased(4.461552--->4.461511) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 435 / 2500Epoch 435 		 Training Loss: 1.4698052832058497
Validation step:0Validation step:1Validation step:2Epoch 435 		 Validation Loss: 4.4614577293396
Validation Loss Decreased(4.461511--->4.461458) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 436 / 2500Epoch 436 		 Training Loss: 1.4693414398602076
Validation step:0Validation step:1Validation step:2Epoch 436 		 Validation Loss: 4.461403489112854
Validation Loss Decreased(4.461458--->4.461403) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 437 / 2500Epoch 437 		 Training Loss: 1.4690311125346593
Validation step:0Validation step:1Validation step:2Epoch 437 		 Validation Loss: 4.461364984512329
Validation Loss Decreased(4.461403--->4.461365) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 438 / 2500Epoch 438 		 Training Loss: 1.4687564628464835
Validation step:0Validation step:1Validation step:2Epoch 438 		 Validation Loss: 4.461315035820007
Validation Loss Decreased(4.461365--->4.461315) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 439 / 2500Epoch 439 		 Training Loss: 1.4688674637249537
Validation step:0Validation step:1Validation step:2Epoch 439 		 Validation Loss: 4.461290240287781
Validation Loss Decreased(4.461315--->4.461290) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 440 / 2500Epoch 440 		 Training Loss: 1.4700589690889632
Validation step:0Validation step:1Validation step:2Epoch 440 		 Validation Loss: 4.461225152015686
Validation Loss Decreased(4.461290--->4.461225) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 441 / 2500Epoch 441 		 Training Loss: 1.468458047934941
Validation step:0Validation step:1Validation step:2Epoch 441 		 Validation Loss: 4.46115243434906
Validation Loss Decreased(4.461225--->4.461152) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 442 / 2500Epoch 442 		 Training Loss: 1.4679886783872331
Validation step:0Validation step:1Validation step:2Epoch 442 		 Validation Loss: 4.4611382484436035
Validation Loss Decreased(4.461152--->4.461138) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 443 / 2500Epoch 443 		 Training Loss: 1.4699749605996268
Validation step:0Validation step:1Validation step:2Epoch 443 		 Validation Loss: 4.461055159568787
Validation Loss Decreased(4.461138--->4.461055) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 444 / 2500Epoch 444 		 Training Loss: 1.4693062135151453
Validation step:0Validation step:1Validation step:2Epoch 444 		 Validation Loss: 4.461009502410889
Validation Loss Decreased(4.461055--->4.461010) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 445 / 2500Epoch 445 		 Training Loss: 1.4674931168556213
Validation step:0Validation step:1Validation step:2Epoch 445 		 Validation Loss: 4.4609534740448
Validation Loss Decreased(4.461010--->4.460953) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 446 / 2500Epoch 446 		 Training Loss: 1.4693280799048287
Validation step:0Validation step:1Validation step:2Epoch 446 		 Validation Loss: 4.4608941078186035
Validation Loss Decreased(4.460953--->4.460894) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 447 / 2500Epoch 447 		 Training Loss: 1.4695412942341395
Validation step:0Validation step:1Validation step:2Epoch 447 		 Validation Loss: 4.460827827453613
Validation Loss Decreased(4.460894--->4.460828) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 448 / 2500Epoch 448 		 Training Loss: 1.4696023208754403
Validation step:0Validation step:1Validation step:2Epoch 448 		 Validation Loss: 4.460785746574402
Validation Loss Decreased(4.460828--->4.460786) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 449 / 2500Epoch 449 		 Training Loss: 1.4679112774985177
Validation step:0Validation step:1Validation step:2Epoch 449 		 Validation Loss: 4.460731387138367
Validation Loss Decreased(4.460786--->4.460731) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 450 / 2500Epoch 450 		 Training Loss: 1.4689426336969649
Validation step:0Validation step:1Validation step:2Epoch 450 		 Validation Loss: 4.460675239562988
Validation Loss Decreased(4.460731--->4.460675) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 451 / 2500Epoch 451 		 Training Loss: 1.4692752616746085
Validation step:0Validation step:1Validation step:2Epoch 451 		 Validation Loss: 4.460617661476135
Validation Loss Decreased(4.460675--->4.460618) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 452 / 2500Epoch 452 		 Training Loss: 1.4693146177700587
Validation step:0Validation step:1Validation step:2Epoch 452 		 Validation Loss: 4.460574150085449
Validation Loss Decreased(4.460618--->4.460574) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 453 / 2500Epoch 453 		 Training Loss: 1.4676485402243478
Validation step:0Validation step:1Validation step:2Epoch 453 		 Validation Loss: 4.460517883300781
Validation Loss Decreased(4.460574--->4.460518) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 454 / 2500Epoch 454 		 Training Loss: 1.4683075717517309
Validation step:0Validation step:1Validation step:2Epoch 454 		 Validation Loss: 4.460483908653259
Validation Loss Decreased(4.460518--->4.460484) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 455 / 2500Epoch 455 		 Training Loss: 1.4687736289841788
Validation step:0Validation step:1Validation step:2Epoch 455 		 Validation Loss: 4.46041464805603
Validation Loss Decreased(4.460484--->4.460415) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 456 / 2500Epoch 456 		 Training Loss: 1.4669580374445235
Validation step:0Validation step:1Validation step:2Epoch 456 		 Validation Loss: 4.460351943969727
Validation Loss Decreased(4.460415--->4.460352) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 457 / 2500Epoch 457 		 Training Loss: 1.4666535684040614
Validation step:0Validation step:1Validation step:2Epoch 457 		 Validation Loss: 4.460322380065918
Validation Loss Decreased(4.460352--->4.460322) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 458 / 2500Epoch 458 		 Training Loss: 1.4686885135514396
Validation step:0Validation step:1Validation step:2Epoch 458 		 Validation Loss: 4.460261225700378
Validation Loss Decreased(4.460322--->4.460261) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 459 / 2500Epoch 459 		 Training Loss: 1.469085761478969
Validation step:0Validation step:1Validation step:2Epoch 459 		 Validation Loss: 4.460233449935913
Validation Loss Decreased(4.460261--->4.460233) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 460 / 2500Epoch 460 		 Training Loss: 1.4696865592684065
Validation step:0Validation step:1Validation step:2Epoch 460 		 Validation Loss: 4.460157632827759
Validation Loss Decreased(4.460233--->4.460158) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 461 / 2500Epoch 461 		 Training Loss: 1.469116015093667
Validation step:0Validation step:1Validation step:2Epoch 461 		 Validation Loss: 4.460070848464966
Validation Loss Decreased(4.460158--->4.460071) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 462 / 2500Epoch 462 		 Training Loss: 1.468773135117122
Validation step:0Validation step:1Validation step:2Epoch 462 		 Validation Loss: 4.4600032567977905
Validation Loss Decreased(4.460071--->4.460003) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 463 / 2500Epoch 463 		 Training Loss: 1.467420790876661
Validation step:0Validation step:1Validation step:2Epoch 463 		 Validation Loss: 4.459984302520752
Validation Loss Decreased(4.460003--->4.459984) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 464 / 2500Epoch 464 		 Training Loss: 1.4685537815093994
Validation step:0Validation step:1Validation step:2Epoch 464 		 Validation Loss: 4.459925413131714
Validation Loss Decreased(4.459984--->4.459925) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 465 / 2500Epoch 465 		 Training Loss: 1.469213102545057
Validation step:0Validation step:1Validation step:2Epoch 465 		 Validation Loss: 4.459872484207153
Validation Loss Decreased(4.459925--->4.459872) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 466 / 2500Epoch 466 		 Training Loss: 1.4665885652814592
Validation step:0Validation step:1Validation step:2Epoch 466 		 Validation Loss: 4.459788203239441
Validation Loss Decreased(4.459872--->4.459788) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 467 / 2500Epoch 467 		 Training Loss: 1.4691738486289978
Validation step:0Validation step:1Validation step:2Epoch 467 		 Validation Loss: 4.459761261940002
Validation Loss Decreased(4.459788--->4.459761) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 468 / 2500Epoch 468 		 Training Loss: 1.4688804064478194
Validation step:0Validation step:1Validation step:2Epoch 468 		 Validation Loss: 4.459702253341675
Validation Loss Decreased(4.459761--->4.459702) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 469 / 2500Epoch 469 		 Training Loss: 1.469046677861895
Validation step:0Validation step:1Validation step:2Epoch 469 		 Validation Loss: 4.459617972373962
Validation Loss Decreased(4.459702--->4.459618) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 470 / 2500Epoch 470 		 Training Loss: 1.467999015535627
Validation step:0Validation step:1Validation step:2Epoch 470 		 Validation Loss: 4.459556221961975
Validation Loss Decreased(4.459618--->4.459556) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 471 / 2500Epoch 471 		 Training Loss: 1.4683672104563033
Validation step:0Validation step:1Validation step:2Epoch 471 		 Validation Loss: 4.4594972133636475
Validation Loss Decreased(4.459556--->4.459497) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 472 / 2500Epoch 472 		 Training Loss: 1.4671574831008911
Validation step:0Validation step:1Validation step:2Epoch 472 		 Validation Loss: 4.459436416625977
Validation Loss Decreased(4.459497--->4.459436) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 473 / 2500Epoch 473 		 Training Loss: 1.4680640016283308
Validation step:0Validation step:1Validation step:2Epoch 473 		 Validation Loss: 4.459363698959351
Validation Loss Decreased(4.459436--->4.459364) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 474 / 2500Epoch 474 		 Training Loss: 1.468805262020656
Validation step:0Validation step:1Validation step:2Epoch 474 		 Validation Loss: 4.459347367286682
Validation Loss Decreased(4.459364--->4.459347) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 475 / 2500Epoch 475 		 Training Loss: 1.466666272708348
Validation step:0Validation step:1Validation step:2Epoch 475 		 Validation Loss: 4.459292531013489
Validation Loss Decreased(4.459347--->4.459293) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 476 / 2500Epoch 476 		 Training Loss: 1.4685376031058175
Validation step:0Validation step:1Validation step:2Epoch 476 		 Validation Loss: 4.45919132232666
Validation Loss Decreased(4.459293--->4.459191) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 477 / 2500Epoch 477 		 Training Loss: 1.46707364491054
Validation step:0Validation step:1Validation step:2Epoch 477 		 Validation Loss: 4.459135413169861
Validation Loss Decreased(4.459191--->4.459135) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 478 / 2500Epoch 478 		 Training Loss: 1.4679684383528573
Validation step:0Validation step:1Validation step:2Epoch 478 		 Validation Loss: 4.4590984582901
Validation Loss Decreased(4.459135--->4.459098) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 479 / 2500Epoch 479 		 Training Loss: 1.4678322757993425
Validation step:0Validation step:1Validation step:2Epoch 479 		 Validation Loss: 4.459027171134949
Validation Loss Decreased(4.459098--->4.459027) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 480 / 2500Epoch 480 		 Training Loss: 1.4674581374440874
Validation step:0Validation step:1Validation step:2Epoch 480 		 Validation Loss: 4.458953380584717
Validation Loss Decreased(4.459027--->4.458953) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 481 / 2500Epoch 481 		 Training Loss: 1.467608162334987
Validation step:0Validation step:1Validation step:2Epoch 481 		 Validation Loss: 4.458896040916443
Validation Loss Decreased(4.458953--->4.458896) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 482 / 2500Epoch 482 		 Training Loss: 1.468813955783844
Validation step:0Validation step:1Validation step:2Epoch 482 		 Validation Loss: 4.458856105804443
Validation Loss Decreased(4.458896--->4.458856) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 483 / 2500Epoch 483 		 Training Loss: 1.466260586466108
Validation step:0Validation step:1Validation step:2Epoch 483 		 Validation Loss: 4.4587754011154175
Validation Loss Decreased(4.458856--->4.458775) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 484 / 2500Epoch 484 		 Training Loss: 1.4689514211245946
Validation step:0Validation step:1Validation step:2Epoch 484 		 Validation Loss: 4.458721995353699
Validation Loss Decreased(4.458775--->4.458722) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 485 / 2500Epoch 485 		 Training Loss: 1.4686550327709742
Validation step:0Validation step:1Validation step:2Epoch 485 		 Validation Loss: 4.458635568618774
Validation Loss Decreased(4.458722--->4.458636) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 486 / 2500Epoch 486 		 Training Loss: 1.466751081602914
Validation step:0Validation step:1Validation step:2Epoch 486 		 Validation Loss: 4.458600997924805
Validation Loss Decreased(4.458636--->4.458601) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 487 / 2500Epoch 487 		 Training Loss: 1.4680869494165694
Validation step:0Validation step:1Validation step:2Epoch 487 		 Validation Loss: 4.458504796028137
Validation Loss Decreased(4.458601--->4.458505) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 488 / 2500Epoch 488 		 Training Loss: 1.4681454130581446
Validation step:0Validation step:1Validation step:2Epoch 488 		 Validation Loss: 4.458453297615051
Validation Loss Decreased(4.458505--->4.458453) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 489 / 2500Epoch 489 		 Training Loss: 1.4668191415922982
Validation step:0Validation step:1Validation step:2Epoch 489 		 Validation Loss: 4.458389639854431
Validation Loss Decreased(4.458453--->4.458390) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 490 / 2500Epoch 490 		 Training Loss: 1.46725880248206
Validation step:0Validation step:1Validation step:2Epoch 490 		 Validation Loss: 4.458334445953369
Validation Loss Decreased(4.458390--->4.458334) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 491 / 2500Epoch 491 		 Training Loss: 1.4676145655768258
Validation step:0Validation step:1Validation step:2Epoch 491 		 Validation Loss: 4.4582250118255615
Validation Loss Decreased(4.458334--->4.458225) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 492 / 2500Epoch 492 		 Training Loss: 1.4678806407111031
Validation step:0Validation step:1Validation step:2Epoch 492 		 Validation Loss: 4.458167552947998
Validation Loss Decreased(4.458225--->4.458168) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 493 / 2500Epoch 493 		 Training Loss: 1.4666293263435364
Validation step:0Validation step:1Validation step:2Epoch 493 		 Validation Loss: 4.458127737045288
Validation Loss Decreased(4.458168--->4.458128) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 494 / 2500Epoch 494 		 Training Loss: 1.4682940585272652
Validation step:0Validation step:1Validation step:2Epoch 494 		 Validation Loss: 4.4580711126327515
Validation Loss Decreased(4.458128--->4.458071) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 495 / 2500Epoch 495 		 Training Loss: 1.4672202808516366
Validation step:0Validation step:1Validation step:2Epoch 495 		 Validation Loss: 4.458014130592346
Validation Loss Decreased(4.458071--->4.458014) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 496 / 2500Epoch 496 		 Training Loss: 1.4665390508515495
Validation step:0Validation step:1Validation step:2Epoch 496 		 Validation Loss: 4.457952976226807
Validation Loss Decreased(4.458014--->4.457953) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 497 / 2500Epoch 497 		 Training Loss: 1.4691498535020011
Validation step:0Validation step:1Validation step:2Epoch 497 		 Validation Loss: 4.457882285118103
Validation Loss Decreased(4.457953--->4.457882) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 498 / 2500Epoch 498 		 Training Loss: 1.4667577402932304
Validation step:0Validation step:1Validation step:2Epoch 498 		 Validation Loss: 4.457784414291382
Validation Loss Decreased(4.457882--->4.457784) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 499 / 2500Epoch 499 		 Training Loss: 1.4665269766535078
Validation step:0Validation step:1Validation step:2Epoch 499 		 Validation Loss: 4.457713961601257
Validation Loss Decreased(4.457784--->4.457714) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 500 / 2500Epoch 500 		 Training Loss: 1.4666647911071777
Validation step:0Validation step:1Validation step:2Epoch 500 		 Validation Loss: 4.457662343978882
Validation Loss Decreased(4.457714--->4.457662) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 501 / 2500Epoch 501 		 Training Loss: 1.468126050063542
Validation step:0Validation step:1Validation step:2Epoch 501 		 Validation Loss: 4.457592844963074
Validation Loss Decreased(4.457662--->4.457593) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 502 / 2500Epoch 502 		 Training Loss: 1.4681412066732134
Validation step:0Validation step:1Validation step:2Epoch 502 		 Validation Loss: 4.457524061203003
Validation Loss Decreased(4.457593--->4.457524) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 503 / 2500Epoch 503 		 Training Loss: 1.4680078881127494
Validation step:0Validation step:1Validation step:2Epoch 503 		 Validation Loss: 4.457458019256592
Validation Loss Decreased(4.457524--->4.457458) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 504 / 2500Epoch 504 		 Training Loss: 1.4657459684780665
Validation step:0Validation step:1Validation step:2Epoch 504 		 Validation Loss: 4.457376837730408
Validation Loss Decreased(4.457458--->4.457377) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 505 / 2500Epoch 505 		 Training Loss: 1.467890202999115
Validation step:0Validation step:1Validation step:2Epoch 505 		 Validation Loss: 4.457387804985046
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 506 / 2500Epoch 506 		 Training Loss: 1.4667647736413139
Validation step:0Validation step:1Validation step:2Epoch 506 		 Validation Loss: 4.45731508731842
Validation Loss Decreased(4.457377--->4.457315) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 507 / 2500Epoch 507 		 Training Loss: 1.4683571457862854
Validation step:0Validation step:1Validation step:2Epoch 507 		 Validation Loss: 4.4572107791900635
Validation Loss Decreased(4.457315--->4.457211) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 508 / 2500Epoch 508 		 Training Loss: 1.4674225194113595
Validation step:0Validation step:1Validation step:2Epoch 508 		 Validation Loss: 4.457109451293945
Validation Loss Decreased(4.457211--->4.457109) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 509 / 2500Epoch 509 		 Training Loss: 1.4653495805604118
Validation step:0Validation step:1Validation step:2Epoch 509 		 Validation Loss: 4.457056164741516
Validation Loss Decreased(4.457109--->4.457056) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 510 / 2500Epoch 510 		 Training Loss: 1.466174500329154
Validation step:0Validation step:1Validation step:2Epoch 510 		 Validation Loss: 4.456977725028992
Validation Loss Decreased(4.457056--->4.456978) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 511 / 2500Epoch 511 		 Training Loss: 1.466439630304064
Validation step:0Validation step:1Validation step:2Epoch 511 		 Validation Loss: 4.456897020339966
Validation Loss Decreased(4.456978--->4.456897) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 512 / 2500Epoch 512 		 Training Loss: 1.4673726643834795
Validation step:0Validation step:1Validation step:2Epoch 512 		 Validation Loss: 4.456822633743286
Validation Loss Decreased(4.456897--->4.456823) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 513 / 2500Epoch 513 		 Training Loss: 1.4667149697031294
Validation step:0Validation step:1Validation step:2Epoch 513 		 Validation Loss: 4.456742763519287
Validation Loss Decreased(4.456823--->4.456743) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 514 / 2500Epoch 514 		 Training Loss: 1.4668473090444292
Validation step:0Validation step:1Validation step:2Epoch 514 		 Validation Loss: 4.456676363945007
Validation Loss Decreased(4.456743--->4.456676) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 515 / 2500Epoch 515 		 Training Loss: 1.4671370727675301
Validation step:0Validation step:1Validation step:2Epoch 515 		 Validation Loss: 4.456603527069092
Validation Loss Decreased(4.456676--->4.456604) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 516 / 2500Epoch 516 		 Training Loss: 1.4663018158503942
Validation step:0Validation step:1Validation step:2Epoch 516 		 Validation Loss: 4.456539750099182
Validation Loss Decreased(4.456604--->4.456540) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 517 / 2500Epoch 517 		 Training Loss: 1.4659595830099923
Validation step:0Validation step:1Validation step:2Epoch 517 		 Validation Loss: 4.456417560577393
Validation Loss Decreased(4.456540--->4.456418) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 518 / 2500Epoch 518 		 Training Loss: 1.4650185108184814
Validation step:0Validation step:1Validation step:2Epoch 518 		 Validation Loss: 4.456372380256653
Validation Loss Decreased(4.456418--->4.456372) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 519 / 2500Epoch 519 		 Training Loss: 1.4682764496122087
Validation step:0Validation step:1Validation step:2Epoch 519 		 Validation Loss: 4.456312298774719
Validation Loss Decreased(4.456372--->4.456312) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 520 / 2500Epoch 520 		 Training Loss: 1.467176914215088
Validation step:0Validation step:1Validation step:2Epoch 520 		 Validation Loss: 4.456233024597168
Validation Loss Decreased(4.456312--->4.456233) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 521 / 2500Epoch 521 		 Training Loss: 1.465638858931405
Validation step:0Validation step:1Validation step:2Epoch 521 		 Validation Loss: 4.45615553855896
Validation Loss Decreased(4.456233--->4.456156) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 522 / 2500Epoch 522 		 Training Loss: 1.4662849732807703
Validation step:0Validation step:1Validation step:2Epoch 522 		 Validation Loss: 4.456066608428955
Validation Loss Decreased(4.456156--->4.456067) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 523 / 2500Epoch 523 		 Training Loss: 1.466597659247262
Validation step:0Validation step:1Validation step:2Epoch 523 		 Validation Loss: 4.456036925315857
Validation Loss Decreased(4.456067--->4.456037) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 524 / 2500Epoch 524 		 Training Loss: 1.4667503067425318
Validation step:0Validation step:1Validation step:2Epoch 524 		 Validation Loss: 4.455970287322998
Validation Loss Decreased(4.456037--->4.455970) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 525 / 2500Epoch 525 		 Training Loss: 1.4656959516661507
Validation step:0Validation step:1Validation step:2Epoch 525 		 Validation Loss: 4.455885887145996
Validation Loss Decreased(4.455970--->4.455886) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 526 / 2500Epoch 526 		 Training Loss: 1.4666647485324316
Validation step:0Validation step:1Validation step:2Epoch 526 		 Validation Loss: 4.4558093547821045
Validation Loss Decreased(4.455886--->4.455809) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 527 / 2500Epoch 527 		 Training Loss: 1.4660589098930359
Validation step:0Validation step:1Validation step:2Epoch 527 		 Validation Loss: 4.45574676990509
Validation Loss Decreased(4.455809--->4.455747) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 528 / 2500Epoch 528 		 Training Loss: 1.466373188155038
Validation step:0Validation step:1Validation step:2Epoch 528 		 Validation Loss: 4.455649256706238
Validation Loss Decreased(4.455747--->4.455649) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 529 / 2500Epoch 529 		 Training Loss: 1.4647386925561088
Validation step:0Validation step:1Validation step:2Epoch 529 		 Validation Loss: 4.455578684806824
Validation Loss Decreased(4.455649--->4.455579) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 530 / 2500Epoch 530 		 Training Loss: 1.4659755315099443
Validation step:0Validation step:1Validation step:2Epoch 530 		 Validation Loss: 4.45551609992981
Validation Loss Decreased(4.455579--->4.455516) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 531 / 2500Epoch 531 		 Training Loss: 1.466270557471684
Validation step:0Validation step:1Validation step:2Epoch 531 		 Validation Loss: 4.455442190170288
Validation Loss Decreased(4.455516--->4.455442) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 532 / 2500Epoch 532 		 Training Loss: 1.4673544594219752
Validation step:0Validation step:1Validation step:2Epoch 532 		 Validation Loss: 4.4553704261779785
Validation Loss Decreased(4.455442--->4.455370) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 533 / 2500Epoch 533 		 Training Loss: 1.4666929926191057
Validation step:0Validation step:1Validation step:2Epoch 533 		 Validation Loss: 4.455248236656189
Validation Loss Decreased(4.455370--->4.455248) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 534 / 2500Epoch 534 		 Training Loss: 1.4665873561586653
Validation step:0Validation step:1Validation step:2Epoch 534 		 Validation Loss: 4.455196976661682
Validation Loss Decreased(4.455248--->4.455197) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 535 / 2500Epoch 535 		 Training Loss: 1.4672995379992895
Validation step:0Validation step:1Validation step:2Epoch 535 		 Validation Loss: 4.4551109075546265
Validation Loss Decreased(4.455197--->4.455111) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 536 / 2500Epoch 536 		 Training Loss: 1.4653335469109672
Validation step:0Validation step:1Validation step:2Epoch 536 		 Validation Loss: 4.455036401748657
Validation Loss Decreased(4.455111--->4.455036) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 537 / 2500Epoch 537 		 Training Loss: 1.4665265679359436
Validation step:0Validation step:1Validation step:2Epoch 537 		 Validation Loss: 4.454966902732849
Validation Loss Decreased(4.455036--->4.454967) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 538 / 2500Epoch 538 		 Training Loss: 1.4669538566044398
Validation step:0Validation step:1Validation step:2Epoch 538 		 Validation Loss: 4.454890727996826
Validation Loss Decreased(4.454967--->4.454891) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 539 / 2500Epoch 539 		 Training Loss: 1.466460747378213
Validation step:0Validation step:1Validation step:2Epoch 539 		 Validation Loss: 4.4547823667526245
Validation Loss Decreased(4.454891--->4.454782) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 540 / 2500Epoch 540 		 Training Loss: 1.4667749745505196
Validation step:0Validation step:1Validation step:2Epoch 540 		 Validation Loss: 4.454743266105652
Validation Loss Decreased(4.454782--->4.454743) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 541 / 2500Epoch 541 		 Training Loss: 1.4659226451601302
Validation step:0Validation step:1Validation step:2Epoch 541 		 Validation Loss: 4.454633951187134
Validation Loss Decreased(4.454743--->4.454634) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 542 / 2500Epoch 542 		 Training Loss: 1.4667027592658997
Validation step:0Validation step:1Validation step:2Epoch 542 		 Validation Loss: 4.454545974731445
Validation Loss Decreased(4.454634--->4.454546) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 543 / 2500Epoch 543 		 Training Loss: 1.4657124451228551
Validation step:0Validation step:1Validation step:2Epoch 543 		 Validation Loss: 4.454461693763733
Validation Loss Decreased(4.454546--->4.454462) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 544 / 2500Epoch 544 		 Training Loss: 1.4656988552638464
Validation step:0Validation step:1Validation step:2Epoch 544 		 Validation Loss: 4.454380512237549
Validation Loss Decreased(4.454462--->4.454381) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 545 / 2500Epoch 545 		 Training Loss: 1.4663581677845545
Validation step:0Validation step:1Validation step:2Epoch 545 		 Validation Loss: 4.4543235301971436
Validation Loss Decreased(4.454381--->4.454324) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 546 / 2500Epoch 546 		 Training Loss: 1.4666448746408736
Validation step:0Validation step:1Validation step:2Epoch 546 		 Validation Loss: 4.454255700111389
Validation Loss Decreased(4.454324--->4.454256) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 547 / 2500Epoch 547 		 Training Loss: 1.4657698358808244
Validation step:0Validation step:1Validation step:2Epoch 547 		 Validation Loss: 4.4542152881622314
Validation Loss Decreased(4.454256--->4.454215) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 548 / 2500Epoch 548 		 Training Loss: 1.466314673423767
Validation step:0Validation step:1Validation step:2Epoch 548 		 Validation Loss: 4.454107165336609
Validation Loss Decreased(4.454215--->4.454107) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 549 / 2500Epoch 549 		 Training Loss: 1.4655583841460091
Validation step:0Validation step:1Validation step:2Epoch 549 		 Validation Loss: 4.453990936279297
Validation Loss Decreased(4.454107--->4.453991) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 550 / 2500Epoch 550 		 Training Loss: 1.4663289104189192
Validation step:0Validation step:1Validation step:2Epoch 550 		 Validation Loss: 4.453883528709412
Validation Loss Decreased(4.453991--->4.453884) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 551 / 2500Epoch 551 		 Training Loss: 1.4650729554040092
Validation step:0Validation step:1Validation step:2Epoch 551 		 Validation Loss: 4.453870892524719
Validation Loss Decreased(4.453884--->4.453871) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 552 / 2500Epoch 552 		 Training Loss: 1.4656781724521093
Validation step:0Validation step:1Validation step:2Epoch 552 		 Validation Loss: 4.453763127326965
Validation Loss Decreased(4.453871--->4.453763) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 553 / 2500Epoch 553 		 Training Loss: 1.466852034841265
Validation step:0Validation step:1Validation step:2Epoch 553 		 Validation Loss: 4.453706741333008
Validation Loss Decreased(4.453763--->4.453707) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 554 / 2500Epoch 554 		 Training Loss: 1.466498613357544
Validation step:0Validation step:1Validation step:2Epoch 554 		 Validation Loss: 4.453612685203552
Validation Loss Decreased(4.453707--->4.453613) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 555 / 2500Epoch 555 		 Training Loss: 1.4645879438945226
Validation step:0Validation step:1Validation step:2Epoch 555 		 Validation Loss: 4.453494906425476
Validation Loss Decreased(4.453613--->4.453495) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 556 / 2500Epoch 556 		 Training Loss: 1.4666365810803004
Validation step:0Validation step:1Validation step:2Epoch 556 		 Validation Loss: 4.453428387641907
Validation Loss Decreased(4.453495--->4.453428) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 557 / 2500Epoch 557 		 Training Loss: 1.4662884218352181
Validation step:0Validation step:1Validation step:2Epoch 557 		 Validation Loss: 4.453367590904236
Validation Loss Decreased(4.453428--->4.453368) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 558 / 2500Epoch 558 		 Training Loss: 1.4666121516908919
Validation step:0Validation step:1Validation step:2Epoch 558 		 Validation Loss: 4.4532729387283325
Validation Loss Decreased(4.453368--->4.453273) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 559 / 2500Epoch 559 		 Training Loss: 1.4652623619352068
Validation step:0Validation step:1Validation step:2Epoch 559 		 Validation Loss: 4.4531776905059814
Validation Loss Decreased(4.453273--->4.453178) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 560 / 2500Epoch 560 		 Training Loss: 1.4663761598723275
Validation step:0Validation step:1Validation step:2Epoch 560 		 Validation Loss: 4.453099370002747
Validation Loss Decreased(4.453178--->4.453099) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 561 / 2500Epoch 561 		 Training Loss: 1.465459712914058
Validation step:0Validation step:1Validation step:2Epoch 561 		 Validation Loss: 4.453029274940491
Validation Loss Decreased(4.453099--->4.453029) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 562 / 2500Epoch 562 		 Training Loss: 1.4642732313701086
Validation step:0Validation step:1Validation step:2Epoch 562 		 Validation Loss: 4.452917098999023
Validation Loss Decreased(4.453029--->4.452917) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 563 / 2500Epoch 563 		 Training Loss: 1.4661489129066467
Validation step:0Validation step:1Validation step:2Epoch 563 		 Validation Loss: 4.452883005142212
Validation Loss Decreased(4.452917--->4.452883) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 564 / 2500Epoch 564 		 Training Loss: 1.4650897809437342
Validation step:0Validation step:1Validation step:2Epoch 564 		 Validation Loss: 4.452798128128052
Validation Loss Decreased(4.452883--->4.452798) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 565 / 2500Epoch 565 		 Training Loss: 1.4651025022779192
Validation step:0Validation step:1Validation step:2Epoch 565 		 Validation Loss: 4.452674984931946
Validation Loss Decreased(4.452798--->4.452675) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 566 / 2500Epoch 566 		 Training Loss: 1.466127370085035
Validation step:0Validation step:1Validation step:2Epoch 566 		 Validation Loss: 4.4525837898254395
Validation Loss Decreased(4.452675--->4.452584) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 567 / 2500Epoch 567 		 Training Loss: 1.4654509680611747
Validation step:0Validation step:1Validation step:2Epoch 567 		 Validation Loss: 4.452462196350098
Validation Loss Decreased(4.452584--->4.452462) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 568 / 2500Epoch 568 		 Training Loss: 1.4648664082799638
Validation step:0Validation step:1Validation step:2Epoch 568 		 Validation Loss: 4.452351450920105
Validation Loss Decreased(4.452462--->4.452351) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 569 / 2500Epoch 569 		 Training Loss: 1.4646381480353219
Validation step:0Validation step:1Validation step:2Epoch 569 		 Validation Loss: 4.45223069190979
Validation Loss Decreased(4.452351--->4.452231) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 570 / 2500Epoch 570 		 Training Loss: 1.4663550342832292
Validation step:0Validation step:1Validation step:2Epoch 570 		 Validation Loss: 4.452168107032776
Validation Loss Decreased(4.452231--->4.452168) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 571 / 2500Epoch 571 		 Training Loss: 1.4652323467390878
Validation step:0Validation step:1Validation step:2Epoch 571 		 Validation Loss: 4.452089190483093
Validation Loss Decreased(4.452168--->4.452089) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 572 / 2500Epoch 572 		 Training Loss: 1.4644224728856767
Validation step:0Validation step:1Validation step:2Epoch 572 		 Validation Loss: 4.452048420906067
Validation Loss Decreased(4.452089--->4.452048) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 573 / 2500Epoch 573 		 Training Loss: 1.466412135532924
Validation step:0Validation step:1Validation step:2Epoch 573 		 Validation Loss: 4.451919198036194
Validation Loss Decreased(4.452048--->4.451919) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 574 / 2500Epoch 574 		 Training Loss: 1.4647167410169328
Validation step:0Validation step:1Validation step:2Epoch 574 		 Validation Loss: 4.451868176460266
Validation Loss Decreased(4.451919--->4.451868) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 575 / 2500Epoch 575 		 Training Loss: 1.4658881170409066
Validation step:0Validation step:1Validation step:2Epoch 575 		 Validation Loss: 4.451751351356506
Validation Loss Decreased(4.451868--->4.451751) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 576 / 2500Epoch 576 		 Training Loss: 1.4661936504500253
Validation step:0Validation step:1Validation step:2Epoch 576 		 Validation Loss: 4.451671719551086
Validation Loss Decreased(4.451751--->4.451672) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 577 / 2500Epoch 577 		 Training Loss: 1.465505804334368
Validation step:0Validation step:1Validation step:2Epoch 577 		 Validation Loss: 4.451665639877319
Validation Loss Decreased(4.451672--->4.451666) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 578 / 2500Epoch 578 		 Training Loss: 1.4651810697146825
Validation step:0Validation step:1Validation step:2Epoch 578 		 Validation Loss: 4.4514851570129395
Validation Loss Decreased(4.451666--->4.451485) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 579 / 2500Epoch 579 		 Training Loss: 1.4666091884885515
Validation step:0Validation step:1Validation step:2Epoch 579 		 Validation Loss: 4.451387405395508
Validation Loss Decreased(4.451485--->4.451387) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 580 / 2500Epoch 580 		 Training Loss: 1.463360173361642
Validation step:0Validation step:1Validation step:2Epoch 580 		 Validation Loss: 4.451351046562195
Validation Loss Decreased(4.451387--->4.451351) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 581 / 2500Epoch 581 		 Training Loss: 1.4664311749594552
Validation step:0Validation step:1Validation step:2Epoch 581 		 Validation Loss: 4.451197385787964
Validation Loss Decreased(4.451351--->4.451197) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 582 / 2500Epoch 582 		 Training Loss: 1.4640087570462907
Validation step:0Validation step:1Validation step:2Epoch 582 		 Validation Loss: 4.451084494590759
Validation Loss Decreased(4.451197--->4.451084) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 583 / 2500Epoch 583 		 Training Loss: 1.4640368478638786
Validation step:0Validation step:1Validation step:2Epoch 583 		 Validation Loss: 4.451014161109924
Validation Loss Decreased(4.451084--->4.451014) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 584 / 2500Epoch 584 		 Training Loss: 1.4664502058710371
Validation step:0Validation step:1Validation step:2Epoch 584 		 Validation Loss: 4.45095694065094
Validation Loss Decreased(4.451014--->4.450957) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 585 / 2500Epoch 585 		 Training Loss: 1.463949475969587
Validation step:0Validation step:1Validation step:2Epoch 585 		 Validation Loss: 4.450917482376099
Validation Loss Decreased(4.450957--->4.450917) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 586 / 2500Epoch 586 		 Training Loss: 1.4654776539121355
Validation step:0Validation step:1Validation step:2Epoch 586 		 Validation Loss: 4.450782418251038
Validation Loss Decreased(4.450917--->4.450782) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 587 / 2500Epoch 587 		 Training Loss: 1.4647190400532313
Validation step:0Validation step:1Validation step:2Epoch 587 		 Validation Loss: 4.4506916999816895
Validation Loss Decreased(4.450782--->4.450692) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 588 / 2500Epoch 588 		 Training Loss: 1.4661111065319605
Validation step:0Validation step:1Validation step:2Epoch 588 		 Validation Loss: 4.45058536529541
Validation Loss Decreased(4.450692--->4.450585) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 589 / 2500Epoch 589 		 Training Loss: 1.4634393538747514
Validation step:0Validation step:1Validation step:2Epoch 589 		 Validation Loss: 4.450463891029358
Validation Loss Decreased(4.450585--->4.450464) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 590 / 2500Epoch 590 		 Training Loss: 1.4661110213824682
Validation step:0Validation step:1Validation step:2Epoch 590 		 Validation Loss: 4.450389862060547
Validation Loss Decreased(4.450464--->4.450390) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 591 / 2500Epoch 591 		 Training Loss: 1.4660763485091073
Validation step:0Validation step:1Validation step:2Epoch 591 		 Validation Loss: 4.450350403785706
Validation Loss Decreased(4.450390--->4.450350) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 592 / 2500Epoch 592 		 Training Loss: 1.4648798108100891
Validation step:0Validation step:1Validation step:2Epoch 592 		 Validation Loss: 4.450293660163879
Validation Loss Decreased(4.450350--->4.450294) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 593 / 2500Epoch 593 		 Training Loss: 1.4641933270863123
Validation step:0Validation step:1Validation step:2Epoch 593 		 Validation Loss: 4.450134515762329
Validation Loss Decreased(4.450294--->4.450135) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 594 / 2500Epoch 594 		 Training Loss: 1.4646555525915963
Validation step:0Validation step:1Validation step:2Epoch 594 		 Validation Loss: 4.450077533721924
Validation Loss Decreased(4.450135--->4.450078) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 595 / 2500Epoch 595 		 Training Loss: 1.4659125549452645
Validation step:0Validation step:1Validation step:2Epoch 595 		 Validation Loss: 4.449991941452026
Validation Loss Decreased(4.450078--->4.449992) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 596 / 2500Epoch 596 		 Training Loss: 1.464907467365265
Validation step:0Validation step:1Validation step:2Epoch 596 		 Validation Loss: 4.449817180633545
Validation Loss Decreased(4.449992--->4.449817) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 597 / 2500Epoch 597 		 Training Loss: 1.4649608816419328
Validation step:0Validation step:1Validation step:2Epoch 597 		 Validation Loss: 4.449751615524292
Validation Loss Decreased(4.449817--->4.449752) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 598 / 2500Epoch 598 		 Training Loss: 1.46449932881764
Validation step:0Validation step:1Validation step:2Epoch 598 		 Validation Loss: 4.449616312980652
Validation Loss Decreased(4.449752--->4.449616) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 599 / 2500Epoch 599 		 Training Loss: 1.4643290894372123
Validation step:0Validation step:1Validation step:2Epoch 599 		 Validation Loss: 4.4494487047195435
Validation Loss Decreased(4.449616--->4.449449) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 600 / 2500Epoch 600 		 Training Loss: 1.465117165020534
Validation step:0Validation step:1Validation step:2Epoch 600 		 Validation Loss: 4.449381589889526
Validation Loss Decreased(4.449449--->4.449382) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 601 / 2500Epoch 601 		 Training Loss: 1.4647457684789384
Validation step:0Validation step:1Validation step:2Epoch 601 		 Validation Loss: 4.449266195297241
Validation Loss Decreased(4.449382--->4.449266) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 602 / 2500Epoch 602 		 Training Loss: 1.4622998152460371
Validation step:0Validation step:1Validation step:2Epoch 602 		 Validation Loss: 4.449169158935547
Validation Loss Decreased(4.449266--->4.449169) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 603 / 2500Epoch 603 		 Training Loss: 1.4636994089399065
Validation step:0Validation step:1Validation step:2Epoch 603 		 Validation Loss: 4.44911527633667
Validation Loss Decreased(4.449169--->4.449115) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 604 / 2500Epoch 604 		 Training Loss: 1.4639710869107927
Validation step:0Validation step:1Validation step:2Epoch 604 		 Validation Loss: 4.448989152908325
Validation Loss Decreased(4.449115--->4.448989) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 605 / 2500Epoch 605 		 Training Loss: 1.4647609761783056
Validation step:0Validation step:1Validation step:2Epoch 605 		 Validation Loss: 4.448910117149353
Validation Loss Decreased(4.448989--->4.448910) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 606 / 2500Epoch 606 		 Training Loss: 1.4653014540672302
Validation step:0Validation step:1Validation step:2Epoch 606 		 Validation Loss: 4.448828816413879
Validation Loss Decreased(4.448910--->4.448829) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 607 / 2500Epoch 607 		 Training Loss: 1.4649678042956762
Validation step:0Validation step:1Validation step:2Epoch 607 		 Validation Loss: 4.448763012886047
Validation Loss Decreased(4.448829--->4.448763) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 608 / 2500Epoch 608 		 Training Loss: 1.4643792254584176
Validation step:0Validation step:1Validation step:2Epoch 608 		 Validation Loss: 4.448607325553894
Validation Loss Decreased(4.448763--->4.448607) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 609 / 2500Epoch 609 		 Training Loss: 1.4624186498778207
Validation step:0Validation step:1Validation step:2Epoch 609 		 Validation Loss: 4.448497533798218
Validation Loss Decreased(4.448607--->4.448498) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 610 / 2500Epoch 610 		 Training Loss: 1.4632733634540014
Validation step:0Validation step:1Validation step:2Epoch 610 		 Validation Loss: 4.448453068733215
Validation Loss Decreased(4.448498--->4.448453) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 611 / 2500Epoch 611 		 Training Loss: 1.465973973274231
Validation step:0Validation step:1Validation step:2Epoch 611 		 Validation Loss: 4.4483911991119385
Validation Loss Decreased(4.448453--->4.448391) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 612 / 2500Epoch 612 		 Training Loss: 1.464408380644662
Validation step:0Validation step:1Validation step:2Epoch 612 		 Validation Loss: 4.448264122009277
Validation Loss Decreased(4.448391--->4.448264) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 613 / 2500Epoch 613 		 Training Loss: 1.4644217150551933
Validation step:0Validation step:1Validation step:2Epoch 613 		 Validation Loss: 4.448155522346497
Validation Loss Decreased(4.448264--->4.448156) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 614 / 2500Epoch 614 		 Training Loss: 1.4639293721743993
Validation step:0Validation step:1Validation step:2Epoch 614 		 Validation Loss: 4.448052525520325
Validation Loss Decreased(4.448156--->4.448053) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 615 / 2500Epoch 615 		 Training Loss: 1.4624533653259277
Validation step:0Validation step:1Validation step:2Epoch 615 		 Validation Loss: 4.4479745626449585
Validation Loss Decreased(4.448053--->4.447975) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 616 / 2500Epoch 616 		 Training Loss: 1.4633527483258928
Validation step:0Validation step:1Validation step:2Epoch 616 		 Validation Loss: 4.4478442668914795
Validation Loss Decreased(4.447975--->4.447844) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 617 / 2500Epoch 617 		 Training Loss: 1.4636293479374476
Validation step:0Validation step:1Validation step:2Epoch 617 		 Validation Loss: 4.447697639465332
Validation Loss Decreased(4.447844--->4.447698) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 618 / 2500Epoch 618 		 Training Loss: 1.4638320888791765
Validation step:0Validation step:1Validation step:2Epoch 618 		 Validation Loss: 4.4476189613342285
Validation Loss Decreased(4.447698--->4.447619) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 619 / 2500Epoch 619 		 Training Loss: 1.4635701264653886
Validation step:0Validation step:1Validation step:2Epoch 619 		 Validation Loss: 4.4475014209747314
Validation Loss Decreased(4.447619--->4.447501) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 620 / 2500Epoch 620 		 Training Loss: 1.4630216700690133
Validation step:0Validation step:1Validation step:2Epoch 620 		 Validation Loss: 4.447392225265503
Validation Loss Decreased(4.447501--->4.447392) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 621 / 2500Epoch 621 		 Training Loss: 1.464563991342272
Validation step:0Validation step:1Validation step:2Epoch 621 		 Validation Loss: 4.447334408760071
Validation Loss Decreased(4.447392--->4.447334) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 622 / 2500Epoch 622 		 Training Loss: 1.463571514402117
Validation step:0Validation step:1Validation step:2Epoch 622 		 Validation Loss: 4.447237610816956
Validation Loss Decreased(4.447334--->4.447238) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 623 / 2500Epoch 623 		 Training Loss: 1.4646291903087072
Validation step:0Validation step:1Validation step:2Epoch 623 		 Validation Loss: 4.4470953941345215
Validation Loss Decreased(4.447238--->4.447095) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 624 / 2500Epoch 624 		 Training Loss: 1.463896666254316
Validation step:0Validation step:1Validation step:2Epoch 624 		 Validation Loss: 4.447003602981567
Validation Loss Decreased(4.447095--->4.447004) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 625 / 2500Epoch 625 		 Training Loss: 1.4634901625769479
Validation step:0Validation step:1Validation step:2Epoch 625 		 Validation Loss: 4.446868062019348
Validation Loss Decreased(4.447004--->4.446868) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 626 / 2500Epoch 626 		 Training Loss: 1.4638971601213728
Validation step:0Validation step:1Validation step:2Epoch 626 		 Validation Loss: 4.446808338165283
Validation Loss Decreased(4.446868--->4.446808) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 627 / 2500Epoch 627 		 Training Loss: 1.4639981133597237
Validation step:0Validation step:1Validation step:2Epoch 627 		 Validation Loss: 4.446627378463745
Validation Loss Decreased(4.446808--->4.446627) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 628 / 2500Epoch 628 		 Training Loss: 1.4626287392207555
Validation step:0Validation step:1Validation step:2Epoch 628 		 Validation Loss: 4.446645140647888
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 629 / 2500Epoch 629 		 Training Loss: 1.4638428773198808
Validation step:0Validation step:1Validation step:2Epoch 629 		 Validation Loss: 4.446489453315735
Validation Loss Decreased(4.446627--->4.446489) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 630 / 2500Epoch 630 		 Training Loss: 1.4638511964253016
Validation step:0Validation step:1Validation step:2Epoch 630 		 Validation Loss: 4.446371674537659
Validation Loss Decreased(4.446489--->4.446372) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 631 / 2500Epoch 631 		 Training Loss: 1.4637360657964433
Validation step:0Validation step:1Validation step:2Epoch 631 		 Validation Loss: 4.4462385177612305
Validation Loss Decreased(4.446372--->4.446239) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 632 / 2500Epoch 632 		 Training Loss: 1.4634713189942496
Validation step:0Validation step:1Validation step:2Epoch 632 		 Validation Loss: 4.446143627166748
Validation Loss Decreased(4.446239--->4.446144) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 633 / 2500Epoch 633 		 Training Loss: 1.4642020293644495
Validation step:0Validation step:1Validation step:2Epoch 633 		 Validation Loss: 4.445994853973389
Validation Loss Decreased(4.446144--->4.445995) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 634 / 2500Epoch 634 		 Training Loss: 1.4645543609346663
Validation step:0Validation step:1Validation step:2Epoch 634 		 Validation Loss: 4.445767641067505
Validation Loss Decreased(4.445995--->4.445768) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 635 / 2500Epoch 635 		 Training Loss: 1.4636667115347726
Validation step:0Validation step:1Validation step:2Epoch 635 		 Validation Loss: 4.445722579956055
Validation Loss Decreased(4.445768--->4.445723) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 636 / 2500Epoch 636 		 Training Loss: 1.463110591684069
Validation step:0Validation step:1Validation step:2Epoch 636 		 Validation Loss: 4.445588946342468
Validation Loss Decreased(4.445723--->4.445589) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 637 / 2500Epoch 637 		 Training Loss: 1.4629616056169783
Validation step:0Validation step:1Validation step:2Epoch 637 		 Validation Loss: 4.44551420211792
Validation Loss Decreased(4.445589--->4.445514) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 638 / 2500Epoch 638 		 Training Loss: 1.4640985131263733
Validation step:0Validation step:1Validation step:2Epoch 638 		 Validation Loss: 4.445392966270447
Validation Loss Decreased(4.445514--->4.445393) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 639 / 2500Epoch 639 		 Training Loss: 1.462462169783456
Validation step:0Validation step:1Validation step:2Epoch 639 		 Validation Loss: 4.445211291313171
Validation Loss Decreased(4.445393--->4.445211) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 640 / 2500Epoch 640 		 Training Loss: 1.4620437281472343
Validation step:0Validation step:1Validation step:2Epoch 640 		 Validation Loss: 4.445125937461853
Validation Loss Decreased(4.445211--->4.445126) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 641 / 2500Epoch 641 		 Training Loss: 1.4620265109198434
Validation step:0Validation step:1Validation step:2Epoch 641 		 Validation Loss: 4.445051193237305
Validation Loss Decreased(4.445126--->4.445051) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 642 / 2500Epoch 642 		 Training Loss: 1.462801558630807
Validation step:0Validation step:1Validation step:2Epoch 642 		 Validation Loss: 4.444948196411133
Validation Loss Decreased(4.445051--->4.444948) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 643 / 2500Epoch 643 		 Training Loss: 1.4635509167398726
Validation step:0Validation step:1Validation step:2Epoch 643 		 Validation Loss: 4.44484007358551
Validation Loss Decreased(4.444948--->4.444840) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 644 / 2500Epoch 644 		 Training Loss: 1.4618919066020422
Validation step:0Validation step:1Validation step:2Epoch 644 		 Validation Loss: 4.444823741912842
Validation Loss Decreased(4.444840--->4.444824) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 645 / 2500Epoch 645 		 Training Loss: 1.4638852647372655
Validation step:0Validation step:1Validation step:2Epoch 645 		 Validation Loss: 4.444634437561035
Validation Loss Decreased(4.444824--->4.444634) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 646 / 2500Epoch 646 		 Training Loss: 1.4640145216669356
Validation step:0Validation step:1Validation step:2Epoch 646 		 Validation Loss: 4.444504261016846
Validation Loss Decreased(4.444634--->4.444504) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 647 / 2500Epoch 647 		 Training Loss: 1.4626704880169459
Validation step:0Validation step:1Validation step:2Epoch 647 		 Validation Loss: 4.444379210472107
Validation Loss Decreased(4.444504--->4.444379) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 648 / 2500Epoch 648 		 Training Loss: 1.4631170119558061
Validation step:0Validation step:1Validation step:2Epoch 648 		 Validation Loss: 4.444310426712036
Validation Loss Decreased(4.444379--->4.444310) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 649 / 2500Epoch 649 		 Training Loss: 1.4616622243608748
Validation step:0Validation step:1Validation step:2Epoch 649 		 Validation Loss: 4.444178223609924
Validation Loss Decreased(4.444310--->4.444178) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 650 / 2500Epoch 650 		 Training Loss: 1.4632033961159843
Validation step:0Validation step:1Validation step:2Epoch 650 		 Validation Loss: 4.443992972373962
Validation Loss Decreased(4.444178--->4.443993) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 651 / 2500Epoch 651 		 Training Loss: 1.4631571003368922
Validation step:0Validation step:1Validation step:2Epoch 651 		 Validation Loss: 4.443922162055969
Validation Loss Decreased(4.443993--->4.443922) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 652 / 2500Epoch 652 		 Training Loss: 1.4630777069500513
Validation step:0Validation step:1Validation step:2Epoch 652 		 Validation Loss: 4.443798065185547
Validation Loss Decreased(4.443922--->4.443798) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 653 / 2500Epoch 653 		 Training Loss: 1.4614421214376176
Validation step:0Validation step:1Validation step:2Epoch 653 		 Validation Loss: 4.443717122077942
Validation Loss Decreased(4.443798--->4.443717) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 654 / 2500Epoch 654 		 Training Loss: 1.461990773677826
Validation step:0Validation step:1Validation step:2Epoch 654 		 Validation Loss: 4.443552732467651
Validation Loss Decreased(4.443717--->4.443553) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 655 / 2500Epoch 655 		 Training Loss: 1.461753053324563
Validation step:0Validation step:1Validation step:2Epoch 655 		 Validation Loss: 4.443476557731628
Validation Loss Decreased(4.443553--->4.443477) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 656 / 2500Epoch 656 		 Training Loss: 1.4624213491167342
Validation step:0Validation step:1Validation step:2Epoch 656 		 Validation Loss: 4.443405270576477
Validation Loss Decreased(4.443477--->4.443405) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 657 / 2500Epoch 657 		 Training Loss: 1.4620953457696098
Validation step:0Validation step:1Validation step:2Epoch 657 		 Validation Loss: 4.443300127983093
Validation Loss Decreased(4.443405--->4.443300) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 658 / 2500Epoch 658 		 Training Loss: 1.4632405383246285
Validation step:0Validation step:1Validation step:2Epoch 658 		 Validation Loss: 4.443171739578247
Validation Loss Decreased(4.443300--->4.443172) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 659 / 2500Epoch 659 		 Training Loss: 1.4614942073822021
Validation step:0Validation step:1Validation step:2Epoch 659 		 Validation Loss: 4.443117618560791
Validation Loss Decreased(4.443172--->4.443118) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 660 / 2500Epoch 660 		 Training Loss: 1.4617212670189994
Validation step:0Validation step:1Validation step:2Epoch 660 		 Validation Loss: 4.443053603172302
Validation Loss Decreased(4.443118--->4.443054) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 661 / 2500Epoch 661 		 Training Loss: 1.4630513872419084
Validation step:0Validation step:1Validation step:2Epoch 661 		 Validation Loss: 4.442862272262573
Validation Loss Decreased(4.443054--->4.442862) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 662 / 2500Epoch 662 		 Training Loss: 1.4623992868832179
Validation step:0Validation step:1Validation step:2Epoch 662 		 Validation Loss: 4.442750334739685
Validation Loss Decreased(4.442862--->4.442750) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 663 / 2500Epoch 663 		 Training Loss: 1.461150893143245
Validation step:0Validation step:1Validation step:2Epoch 663 		 Validation Loss: 4.442695379257202
Validation Loss Decreased(4.442750--->4.442695) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 664 / 2500Epoch 664 		 Training Loss: 1.4623504281044006
Validation step:0Validation step:1Validation step:2Epoch 664 		 Validation Loss: 4.442600131034851
Validation Loss Decreased(4.442695--->4.442600) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 665 / 2500Epoch 665 		 Training Loss: 1.4630380017416817
Validation step:0Validation step:1Validation step:2Epoch 665 		 Validation Loss: 4.4424132108688354
Validation Loss Decreased(4.442600--->4.442413) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 666 / 2500Epoch 666 		 Training Loss: 1.4607101763997759
Validation step:0Validation step:1Validation step:2Epoch 666 		 Validation Loss: 4.4422807693481445
Validation Loss Decreased(4.442413--->4.442281) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 667 / 2500Epoch 667 		 Training Loss: 1.4602946894509452
Validation step:0Validation step:1Validation step:2Epoch 667 		 Validation Loss: 4.442195892333984
Validation Loss Decreased(4.442281--->4.442196) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 668 / 2500Epoch 668 		 Training Loss: 1.46283563545772
Validation step:0Validation step:1Validation step:2Epoch 668 		 Validation Loss: 4.442059516906738
Validation Loss Decreased(4.442196--->4.442060) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 669 / 2500Epoch 669 		 Training Loss: 1.4622510075569153
Validation step:0Validation step:1Validation step:2Epoch 669 		 Validation Loss: 4.441921710968018
Validation Loss Decreased(4.442060--->4.441922) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 670 / 2500Epoch 670 		 Training Loss: 1.4620483773095267
Validation step:0Validation step:1Validation step:2Epoch 670 		 Validation Loss: 4.441827654838562
Validation Loss Decreased(4.441922--->4.441828) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 671 / 2500Epoch 671 		 Training Loss: 1.4622594714164734
Validation step:0Validation step:1Validation step:2Epoch 671 		 Validation Loss: 4.441707968711853
Validation Loss Decreased(4.441828--->4.441708) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 672 / 2500Epoch 672 		 Training Loss: 1.462109455040523
Validation step:0Validation step:1Validation step:2Epoch 672 		 Validation Loss: 4.4415857791900635
Validation Loss Decreased(4.441708--->4.441586) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 673 / 2500Epoch 673 		 Training Loss: 1.462346179144723
Validation step:0Validation step:1Validation step:2Epoch 673 		 Validation Loss: 4.441431999206543
Validation Loss Decreased(4.441586--->4.441432) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 674 / 2500Epoch 674 		 Training Loss: 1.4625149369239807
Validation step:0Validation step:1Validation step:2Epoch 674 		 Validation Loss: 4.441335082054138
Validation Loss Decreased(4.441432--->4.441335) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 675 / 2500Epoch 675 		 Training Loss: 1.4617751921926225
Validation step:0Validation step:1Validation step:2Epoch 675 		 Validation Loss: 4.44118595123291
Validation Loss Decreased(4.441335--->4.441186) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 676 / 2500Epoch 676 		 Training Loss: 1.4602509651865279
Validation step:0Validation step:1Validation step:2Epoch 676 		 Validation Loss: 4.441072225570679
Validation Loss Decreased(4.441186--->4.441072) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 677 / 2500Epoch 677 		 Training Loss: 1.4631712521825517
Validation step:0Validation step:1Validation step:2Epoch 677 		 Validation Loss: 4.440973997116089
Validation Loss Decreased(4.441072--->4.440974) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 678 / 2500Epoch 678 		 Training Loss: 1.4620937619890486
Validation step:0Validation step:1Validation step:2Epoch 678 		 Validation Loss: 4.440833330154419
Validation Loss Decreased(4.440974--->4.440833) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 679 / 2500Epoch 679 		 Training Loss: 1.4593306609562464
Validation step:0Validation step:1Validation step:2Epoch 679 		 Validation Loss: 4.440699815750122
Validation Loss Decreased(4.440833--->4.440700) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 680 / 2500Epoch 680 		 Training Loss: 1.460536071232387
Validation step:0Validation step:1Validation step:2Epoch 680 		 Validation Loss: 4.440579056739807
Validation Loss Decreased(4.440700--->4.440579) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 681 / 2500Epoch 681 		 Training Loss: 1.4626899787357874
Validation step:0Validation step:1Validation step:2Epoch 681 		 Validation Loss: 4.440501093864441
Validation Loss Decreased(4.440579--->4.440501) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 682 / 2500Epoch 682 		 Training Loss: 1.4623201319149561
Validation step:0Validation step:1Validation step:2Epoch 682 		 Validation Loss: 4.44026505947113
Validation Loss Decreased(4.440501--->4.440265) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 683 / 2500Epoch 683 		 Training Loss: 1.4622566955430167
Validation step:0Validation step:1Validation step:2Epoch 683 		 Validation Loss: 4.440181612968445
Validation Loss Decreased(4.440265--->4.440182) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 684 / 2500Epoch 684 		 Training Loss: 1.4618329576083593
Validation step:0Validation step:1Validation step:2Epoch 684 		 Validation Loss: 4.4400599002838135
Validation Loss Decreased(4.440182--->4.440060) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 685 / 2500Epoch 685 		 Training Loss: 1.4609093836375646
Validation step:0Validation step:1Validation step:2Epoch 685 		 Validation Loss: 4.439932346343994
Validation Loss Decreased(4.440060--->4.439932) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 686 / 2500Epoch 686 		 Training Loss: 1.4609917742865426
Validation step:0Validation step:1Validation step:2Epoch 686 		 Validation Loss: 4.439832448959351
Validation Loss Decreased(4.439932--->4.439832) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 687 / 2500Epoch 687 		 Training Loss: 1.461986482143402
Validation step:0Validation step:1Validation step:2Epoch 687 		 Validation Loss: 4.439709782600403
Validation Loss Decreased(4.439832--->4.439710) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 688 / 2500Epoch 688 		 Training Loss: 1.461367198399135
Validation step:0Validation step:1Validation step:2Epoch 688 		 Validation Loss: 4.439637541770935
Validation Loss Decreased(4.439710--->4.439638) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 689 / 2500Epoch 689 		 Training Loss: 1.461191543510982
Validation step:0Validation step:1Validation step:2Epoch 689 		 Validation Loss: 4.43949818611145
Validation Loss Decreased(4.439638--->4.439498) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 690 / 2500Epoch 690 		 Training Loss: 1.4606554678508215
Validation step:0Validation step:1Validation step:2Epoch 690 		 Validation Loss: 4.4393579959869385
Validation Loss Decreased(4.439498--->4.439358) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 691 / 2500Epoch 691 		 Training Loss: 1.4590014219284058
Validation step:0Validation step:1Validation step:2Epoch 691 		 Validation Loss: 4.43920636177063
Validation Loss Decreased(4.439358--->4.439206) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 692 / 2500Epoch 692 		 Training Loss: 1.4618092349597387
Validation step:0Validation step:1Validation step:2Epoch 692 		 Validation Loss: 4.439105868339539
Validation Loss Decreased(4.439206--->4.439106) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 693 / 2500Epoch 693 		 Training Loss: 1.4598850778170995
Validation step:0Validation step:1Validation step:2Epoch 693 		 Validation Loss: 4.439033031463623
Validation Loss Decreased(4.439106--->4.439033) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 694 / 2500Epoch 694 		 Training Loss: 1.4606355684144157
Validation step:0Validation step:1Validation step:2Epoch 694 		 Validation Loss: 4.438878774642944
Validation Loss Decreased(4.439033--->4.438879) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 695 / 2500Epoch 695 		 Training Loss: 1.459289244243077
Validation step:0Validation step:1Validation step:2Epoch 695 		 Validation Loss: 4.438742399215698
Validation Loss Decreased(4.438879--->4.438742) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 696 / 2500Epoch 696 		 Training Loss: 1.4599445717675346
Validation step:0Validation step:1Validation step:2Epoch 696 		 Validation Loss: 4.438587427139282
Validation Loss Decreased(4.438742--->4.438587) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 697 / 2500Epoch 697 		 Training Loss: 1.4600003446851457
Validation step:0Validation step:1Validation step:2Epoch 697 		 Validation Loss: 4.438466429710388
Validation Loss Decreased(4.438587--->4.438466) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 698 / 2500Epoch 698 		 Training Loss: 1.461711551461901
Validation step:0Validation step:1Validation step:2Epoch 698 		 Validation Loss: 4.438346028327942
Validation Loss Decreased(4.438466--->4.438346) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 699 / 2500Epoch 699 		 Training Loss: 1.4606287223952157
Validation step:0Validation step:1Validation step:2Epoch 699 		 Validation Loss: 4.4382253885269165
Validation Loss Decreased(4.438346--->4.438225) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 700 / 2500Epoch 700 		 Training Loss: 1.4614574483462743
Validation step:0Validation step:1Validation step:2Epoch 700 		 Validation Loss: 4.438081741333008
Validation Loss Decreased(4.438225--->4.438082) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 701 / 2500Epoch 701 		 Training Loss: 1.4604970472199577
Validation step:0Validation step:1Validation step:2Epoch 701 		 Validation Loss: 4.437985301017761
Validation Loss Decreased(4.438082--->4.437985) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 702 / 2500Epoch 702 		 Training Loss: 1.4599674599511283
Validation step:0Validation step:1Validation step:2Epoch 702 		 Validation Loss: 4.437841892242432
Validation Loss Decreased(4.437985--->4.437842) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 703 / 2500Epoch 703 		 Training Loss: 1.4586801188332694
Validation step:0Validation step:1Validation step:2Epoch 703 		 Validation Loss: 4.437759757041931
Validation Loss Decreased(4.437842--->4.437760) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 704 / 2500Epoch 704 		 Training Loss: 1.4598700319017683
Validation step:0Validation step:1Validation step:2Epoch 704 		 Validation Loss: 4.437653660774231
Validation Loss Decreased(4.437760--->4.437654) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 705 / 2500Epoch 705 		 Training Loss: 1.4607514313289098
Validation step:0Validation step:1Validation step:2Epoch 705 		 Validation Loss: 4.437441825866699
Validation Loss Decreased(4.437654--->4.437442) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 706 / 2500Epoch 706 		 Training Loss: 1.4592506034033639
Validation step:0Validation step:1Validation step:2Epoch 706 		 Validation Loss: 4.437334656715393
Validation Loss Decreased(4.437442--->4.437335) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 707 / 2500Epoch 707 		 Training Loss: 1.460648545197078
Validation step:0Validation step:1Validation step:2Epoch 707 		 Validation Loss: 4.437211751937866
Validation Loss Decreased(4.437335--->4.437212) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 708 / 2500Epoch 708 		 Training Loss: 1.4596531391143799
Validation step:0Validation step:1Validation step:2Epoch 708 		 Validation Loss: 4.437079310417175
Validation Loss Decreased(4.437212--->4.437079) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 709 / 2500Epoch 709 		 Training Loss: 1.45986727305821
Validation step:0Validation step:1Validation step:2Epoch 709 		 Validation Loss: 4.436928153038025
Validation Loss Decreased(4.437079--->4.436928) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 710 / 2500Epoch 710 		 Training Loss: 1.4592485768454415
Validation step:0Validation step:1Validation step:2Epoch 710 		 Validation Loss: 4.436737060546875
Validation Loss Decreased(4.436928--->4.436737) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 711 / 2500Epoch 711 		 Training Loss: 1.4598143100738525
Validation step:0Validation step:1Validation step:2Epoch 711 		 Validation Loss: 4.436642169952393
Validation Loss Decreased(4.436737--->4.436642) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 712 / 2500Epoch 712 		 Training Loss: 1.4566450885363988
Validation step:0Validation step:1Validation step:2Epoch 712 		 Validation Loss: 4.4364787340164185
Validation Loss Decreased(4.436642--->4.436479) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 713 / 2500Epoch 713 		 Training Loss: 1.4604624680110387
Validation step:0Validation step:1Validation step:2Epoch 713 		 Validation Loss: 4.436418771743774
Validation Loss Decreased(4.436479--->4.436419) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 714 / 2500Epoch 714 		 Training Loss: 1.4593609826905387
Validation step:0Validation step:1Validation step:2Epoch 714 		 Validation Loss: 4.436253309249878
Validation Loss Decreased(4.436419--->4.436253) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 715 / 2500Epoch 715 		 Training Loss: 1.4605629273823328
Validation step:0Validation step:1Validation step:2Epoch 715 		 Validation Loss: 4.436180591583252
Validation Loss Decreased(4.436253--->4.436181) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 716 / 2500Epoch 716 		 Training Loss: 1.4596433128629411
Validation step:0Validation step:1Validation step:2Epoch 716 		 Validation Loss: 4.436063051223755
Validation Loss Decreased(4.436181--->4.436063) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 717 / 2500Epoch 717 		 Training Loss: 1.4594348583902632
Validation step:0Validation step:1Validation step:2Epoch 717 		 Validation Loss: 4.435951232910156
Validation Loss Decreased(4.436063--->4.435951) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 718 / 2500Epoch 718 		 Training Loss: 1.459277297769274
Validation step:0Validation step:1Validation step:2Epoch 718 		 Validation Loss: 4.435827851295471
Validation Loss Decreased(4.435951--->4.435828) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 719 / 2500Epoch 719 		 Training Loss: 1.4591906070709229
Validation step:0Validation step:1Validation step:2Epoch 719 		 Validation Loss: 4.435711026191711
Validation Loss Decreased(4.435828--->4.435711) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 720 / 2500Epoch 720 		 Training Loss: 1.4600763320922852
Validation step:0Validation step:1Validation step:2Epoch 720 		 Validation Loss: 4.43551766872406
Validation Loss Decreased(4.435711--->4.435518) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 721 / 2500Epoch 721 		 Training Loss: 1.4593462688582284
Validation step:0Validation step:1Validation step:2Epoch 721 		 Validation Loss: 4.435389399528503
Validation Loss Decreased(4.435518--->4.435389) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 722 / 2500Epoch 722 		 Training Loss: 1.4591546484402247
Validation step:0Validation step:1Validation step:2Epoch 722 		 Validation Loss: 4.435258507728577
Validation Loss Decreased(4.435389--->4.435259) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 723 / 2500Epoch 723 		 Training Loss: 1.4589178221566337
Validation step:0Validation step:1Validation step:2Epoch 723 		 Validation Loss: 4.435136675834656
Validation Loss Decreased(4.435259--->4.435137) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 724 / 2500Epoch 724 		 Training Loss: 1.458811240536826
Validation step:0Validation step:1Validation step:2Epoch 724 		 Validation Loss: 4.434985518455505
Validation Loss Decreased(4.435137--->4.434986) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 725 / 2500Epoch 725 		 Training Loss: 1.458153145653861
Validation step:0Validation step:1Validation step:2Epoch 725 		 Validation Loss: 4.434829115867615
Validation Loss Decreased(4.434986--->4.434829) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 726 / 2500Epoch 726 		 Training Loss: 1.4601953029632568
Validation step:0Validation step:1Validation step:2Epoch 726 		 Validation Loss: 4.434658765792847
Validation Loss Decreased(4.434829--->4.434659) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 727 / 2500Epoch 727 		 Training Loss: 1.460103988647461
Validation step:0Validation step:1Validation step:2Epoch 727 		 Validation Loss: 4.434545040130615
Validation Loss Decreased(4.434659--->4.434545) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 728 / 2500Epoch 728 		 Training Loss: 1.4597335457801819
Validation step:0Validation step:1Validation step:2Epoch 728 		 Validation Loss: 4.43437385559082
Validation Loss Decreased(4.434545--->4.434374) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 729 / 2500Epoch 729 		 Training Loss: 1.4586252910750253
Validation step:0Validation step:1Validation step:2Epoch 729 		 Validation Loss: 4.434235453605652
Validation Loss Decreased(4.434374--->4.434235) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 730 / 2500Epoch 730 		 Training Loss: 1.458668155329568
Validation step:0Validation step:1Validation step:2Epoch 730 		 Validation Loss: 4.43411910533905
Validation Loss Decreased(4.434235--->4.434119) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 731 / 2500Epoch 731 		 Training Loss: 1.4590634192739214
Validation step:0Validation step:1Validation step:2Epoch 731 		 Validation Loss: 4.434000253677368
Validation Loss Decreased(4.434119--->4.434000) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 732 / 2500Epoch 732 		 Training Loss: 1.4569536277226038
Validation step:0Validation step:1Validation step:2Epoch 732 		 Validation Loss: 4.433858752250671
Validation Loss Decreased(4.434000--->4.433859) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 733 / 2500Epoch 733 		 Training Loss: 1.458840651171548
Validation step:0Validation step:1Validation step:2Epoch 733 		 Validation Loss: 4.433718919754028
Validation Loss Decreased(4.433859--->4.433719) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 734 / 2500Epoch 734 		 Training Loss: 1.4589800153459822
Validation step:0Validation step:1Validation step:2Epoch 734 		 Validation Loss: 4.433580279350281
Validation Loss Decreased(4.433719--->4.433580) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 735 / 2500Epoch 735 		 Training Loss: 1.4588767290115356
Validation step:0Validation step:1Validation step:2Epoch 735 		 Validation Loss: 4.4334776401519775
Validation Loss Decreased(4.433580--->4.433478) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 736 / 2500Epoch 736 		 Training Loss: 1.458024833883558
Validation step:0Validation step:1Validation step:2Epoch 736 		 Validation Loss: 4.433305025100708
Validation Loss Decreased(4.433478--->4.433305) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 737 / 2500Epoch 737 		 Training Loss: 1.4585937006132943
Validation step:0Validation step:1Validation step:2Epoch 737 		 Validation Loss: 4.433197021484375
Validation Loss Decreased(4.433305--->4.433197) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 738 / 2500Epoch 738 		 Training Loss: 1.4588950872421265
Validation step:0Validation step:1Validation step:2Epoch 738 		 Validation Loss: 4.433075189590454
Validation Loss Decreased(4.433197--->4.433075) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 739 / 2500Epoch 739 		 Training Loss: 1.459069013595581
Validation step:0Validation step:1Validation step:2Epoch 739 		 Validation Loss: 4.432909965515137
Validation Loss Decreased(4.433075--->4.432910) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 740 / 2500Epoch 740 		 Training Loss: 1.4596682446343558
Validation step:0Validation step:1Validation step:2Epoch 740 		 Validation Loss: 4.432754158973694
Validation Loss Decreased(4.432910--->4.432754) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 741 / 2500Epoch 741 		 Training Loss: 1.459074718611581
Validation step:0Validation step:1Validation step:2Epoch 741 		 Validation Loss: 4.432685852050781
Validation Loss Decreased(4.432754--->4.432686) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 742 / 2500Epoch 742 		 Training Loss: 1.4582142404147558
Validation step:0Validation step:1Validation step:2Epoch 742 		 Validation Loss: 4.432605862617493
Validation Loss Decreased(4.432686--->4.432606) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 743 / 2500Epoch 743 		 Training Loss: 1.45905624968665
Validation step:0Validation step:1Validation step:2Epoch 743 		 Validation Loss: 4.432466506958008
Validation Loss Decreased(4.432606--->4.432467) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 744 / 2500Epoch 744 		 Training Loss: 1.4591944984027319
Validation step:0Validation step:1Validation step:2Epoch 744 		 Validation Loss: 4.432299017906189
Validation Loss Decreased(4.432467--->4.432299) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 745 / 2500Epoch 745 		 Training Loss: 1.4587470378194536
Validation step:0Validation step:1Validation step:2Epoch 745 		 Validation Loss: 4.432123303413391
Validation Loss Decreased(4.432299--->4.432123) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 746 / 2500Epoch 746 		 Training Loss: 1.4582272512572152
Validation step:0Validation step:1Validation step:2Epoch 746 		 Validation Loss: 4.431962013244629
Validation Loss Decreased(4.432123--->4.431962) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 747 / 2500Epoch 747 		 Training Loss: 1.458537518978119
Validation step:0Validation step:1Validation step:2Epoch 747 		 Validation Loss: 4.4317708015441895
Validation Loss Decreased(4.431962--->4.431771) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 748 / 2500Epoch 748 		 Training Loss: 1.458895776953016
Validation step:0Validation step:1Validation step:2Epoch 748 		 Validation Loss: 4.431663274765015
Validation Loss Decreased(4.431771--->4.431663) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 749 / 2500Epoch 749 		 Training Loss: 1.4583527190344674
Validation step:0Validation step:1Validation step:2Epoch 749 		 Validation Loss: 4.431531548500061
Validation Loss Decreased(4.431663--->4.431532) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 750 / 2500Epoch 750 		 Training Loss: 1.4581874694143022
Validation step:0Validation step:1Validation step:2Epoch 750 		 Validation Loss: 4.43136727809906
Validation Loss Decreased(4.431532--->4.431367) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 751 / 2500Epoch 751 		 Training Loss: 1.4574518374034338
Validation step:0Validation step:1Validation step:2Epoch 751 		 Validation Loss: 4.431227684020996
Validation Loss Decreased(4.431367--->4.431228) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 752 / 2500Epoch 752 		 Training Loss: 1.4579177498817444
Validation step:0Validation step:1Validation step:2Epoch 752 		 Validation Loss: 4.431093811988831
Validation Loss Decreased(4.431228--->4.431094) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 753 / 2500Epoch 753 		 Training Loss: 1.4587808081081934
Validation step:0Validation step:1Validation step:2Epoch 753 		 Validation Loss: 4.430982708930969
Validation Loss Decreased(4.431094--->4.430983) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 754 / 2500Epoch 754 		 Training Loss: 1.4588628837040492
Validation step:0Validation step:1Validation step:2Epoch 754 		 Validation Loss: 4.430821061134338
Validation Loss Decreased(4.430983--->4.430821) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 755 / 2500Epoch 755 		 Training Loss: 1.4574525015694755
Validation step:0Validation step:1Validation step:2Epoch 755 		 Validation Loss: 4.430751323699951
Validation Loss Decreased(4.430821--->4.430751) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 756 / 2500Epoch 756 		 Training Loss: 1.4572599359921046
Validation step:0Validation step:1Validation step:2Epoch 756 		 Validation Loss: 4.430544853210449
Validation Loss Decreased(4.430751--->4.430545) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 757 / 2500Epoch 757 		 Training Loss: 1.4546834911618913
Validation step:0Validation step:1Validation step:2Epoch 757 		 Validation Loss: 4.4304046630859375
Validation Loss Decreased(4.430545--->4.430405) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 758 / 2500Epoch 758 		 Training Loss: 1.4540745445660181
Validation step:0Validation step:1Validation step:2Epoch 758 		 Validation Loss: 4.430293560028076
Validation Loss Decreased(4.430405--->4.430294) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 759 / 2500Epoch 759 		 Training Loss: 1.4587760482515608
Validation step:0Validation step:1Validation step:2Epoch 759 		 Validation Loss: 4.430160760879517
Validation Loss Decreased(4.430294--->4.430161) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 760 / 2500Epoch 760 		 Training Loss: 1.4583099314144679
Validation step:0Validation step:1Validation step:2Epoch 760 		 Validation Loss: 4.430066347122192
Validation Loss Decreased(4.430161--->4.430066) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 761 / 2500Epoch 761 		 Training Loss: 1.4573146445410592
Validation step:0Validation step:1Validation step:2Epoch 761 		 Validation Loss: 4.429912447929382
Validation Loss Decreased(4.430066--->4.429912) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 762 / 2500Epoch 762 		 Training Loss: 1.455998718738556
Validation step:0Validation step:1Validation step:2Epoch 762 		 Validation Loss: 4.429818391799927
Validation Loss Decreased(4.429912--->4.429818) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 763 / 2500Epoch 763 		 Training Loss: 1.4573365790503365
Validation step:0Validation step:1Validation step:2Epoch 763 		 Validation Loss: 4.429705739021301
Validation Loss Decreased(4.429818--->4.429706) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 764 / 2500Epoch 764 		 Training Loss: 1.4578621302332198
Validation step:0Validation step:1Validation step:2Epoch 764 		 Validation Loss: 4.429593801498413
Validation Loss Decreased(4.429706--->4.429594) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 765 / 2500Epoch 765 		 Training Loss: 1.457501334803445
Validation step:0Validation step:1Validation step:2Epoch 765 		 Validation Loss: 4.429370760917664
Validation Loss Decreased(4.429594--->4.429371) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 766 / 2500Epoch 766 		 Training Loss: 1.4574802432741438
Validation step:0Validation step:1Validation step:2Epoch 766 		 Validation Loss: 4.429267764091492
Validation Loss Decreased(4.429371--->4.429268) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 767 / 2500Epoch 767 		 Training Loss: 1.4565702336175101
Validation step:0Validation step:1Validation step:2Epoch 767 		 Validation Loss: 4.429203271865845
Validation Loss Decreased(4.429268--->4.429203) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 768 / 2500Epoch 768 		 Training Loss: 1.4575172833033971
Validation step:0Validation step:1Validation step:2Epoch 768 		 Validation Loss: 4.429111957550049
Validation Loss Decreased(4.429203--->4.429112) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 769 / 2500Epoch 769 		 Training Loss: 1.4559793642589025
Validation step:0Validation step:1Validation step:2Epoch 769 		 Validation Loss: 4.428828835487366
Validation Loss Decreased(4.429112--->4.428829) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 770 / 2500Epoch 770 		 Training Loss: 1.4560054966381617
Validation step:0Validation step:1Validation step:2Epoch 770 		 Validation Loss: 4.4286580085754395
Validation Loss Decreased(4.428829--->4.428658) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 771 / 2500Epoch 771 		 Training Loss: 1.4556663376944405
Validation step:0Validation step:1Validation step:2Epoch 771 		 Validation Loss: 4.428497672080994
Validation Loss Decreased(4.428658--->4.428498) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 772 / 2500Epoch 772 		 Training Loss: 1.4579400760786874
Validation step:0Validation step:1Validation step:2Epoch 772 		 Validation Loss: 4.428327918052673
Validation Loss Decreased(4.428498--->4.428328) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 773 / 2500Epoch 773 		 Training Loss: 1.4546208807400294
Validation step:0Validation step:1Validation step:2Epoch 773 		 Validation Loss: 4.428285360336304
Validation Loss Decreased(4.428328--->4.428285) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 774 / 2500Epoch 774 		 Training Loss: 1.4573149936539787
Validation step:0Validation step:1Validation step:2Epoch 774 		 Validation Loss: 4.428329944610596
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 775 / 2500Epoch 775 		 Training Loss: 1.455883034637996
Validation step:0Validation step:1Validation step:2Epoch 775 		 Validation Loss: 4.428087115287781
Validation Loss Decreased(4.428285--->4.428087) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 776 / 2500Epoch 776 		 Training Loss: 1.4570911186082023
Validation step:0Validation step:1Validation step:2Epoch 776 		 Validation Loss: 4.427927494049072
Validation Loss Decreased(4.428087--->4.427927) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 777 / 2500Epoch 777 		 Training Loss: 1.456777879170009
Validation step:0Validation step:1Validation step:2Epoch 777 		 Validation Loss: 4.427832245826721
Validation Loss Decreased(4.427927--->4.427832) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 778 / 2500Epoch 778 		 Training Loss: 1.4576671293803625
Validation step:0Validation step:1Validation step:2Epoch 778 		 Validation Loss: 4.427563905715942
Validation Loss Decreased(4.427832--->4.427564) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 779 / 2500Epoch 779 		 Training Loss: 1.4564362338611059
Validation step:0Validation step:1Validation step:2Epoch 779 		 Validation Loss: 4.427428245544434
Validation Loss Decreased(4.427564--->4.427428) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 780 / 2500Epoch 780 		 Training Loss: 1.4563762886183602
Validation step:0Validation step:1Validation step:2Epoch 780 		 Validation Loss: 4.427425503730774
Validation Loss Decreased(4.427428--->4.427426) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 781 / 2500Epoch 781 		 Training Loss: 1.4542518939290727
Validation step:0Validation step:1Validation step:2Epoch 781 		 Validation Loss: 4.427143335342407
Validation Loss Decreased(4.427426--->4.427143) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 782 / 2500Epoch 782 		 Training Loss: 1.4568462201527186
Validation step:0Validation step:1Validation step:2Epoch 782 		 Validation Loss: 4.4269702434539795
Validation Loss Decreased(4.427143--->4.426970) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 783 / 2500Epoch 783 		 Training Loss: 1.4573754242488317
Validation step:0Validation step:1Validation step:2Epoch 783 		 Validation Loss: 4.426891088485718
Validation Loss Decreased(4.426970--->4.426891) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 784 / 2500Epoch 784 		 Training Loss: 1.4564102973256792
Validation step:0Validation step:1Validation step:2Epoch 784 		 Validation Loss: 4.426746487617493
Validation Loss Decreased(4.426891--->4.426746) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 785 / 2500Epoch 785 		 Training Loss: 1.4557302849633353
Validation step:0Validation step:1Validation step:2Epoch 785 		 Validation Loss: 4.426454067230225
Validation Loss Decreased(4.426746--->4.426454) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 786 / 2500Epoch 786 		 Training Loss: 1.4575263772692
Validation step:0Validation step:1Validation step:2Epoch 786 		 Validation Loss: 4.426290392875671
Validation Loss Decreased(4.426454--->4.426290) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 787 / 2500Epoch 787 		 Training Loss: 1.4564457024846758
Validation step:0Validation step:1Validation step:2Epoch 787 		 Validation Loss: 4.426209092140198
Validation Loss Decreased(4.426290--->4.426209) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 788 / 2500Epoch 788 		 Training Loss: 1.4562831350735255
Validation step:0Validation step:1Validation step:2Epoch 788 		 Validation Loss: 4.4262659549713135
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 789 / 2500Epoch 789 		 Training Loss: 1.456811010837555
Validation step:0Validation step:1Validation step:2Epoch 789 		 Validation Loss: 4.426090240478516
Validation Loss Decreased(4.426209--->4.426090) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 790 / 2500Epoch 790 		 Training Loss: 1.456207811832428
Validation step:0Validation step:1Validation step:2Epoch 790 		 Validation Loss: 4.425784230232239
Validation Loss Decreased(4.426090--->4.425784) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 791 / 2500Epoch 791 		 Training Loss: 1.4562011446271623
Validation step:0Validation step:1Validation step:2Epoch 791 		 Validation Loss: 4.425750374794006
Validation Loss Decreased(4.425784--->4.425750) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 792 / 2500Epoch 792 		 Training Loss: 1.4569662639072962
Validation step:0Validation step:1Validation step:2Epoch 792 		 Validation Loss: 4.425574421882629
Validation Loss Decreased(4.425750--->4.425574) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 793 / 2500Epoch 793 		 Training Loss: 1.453347989491054
Validation step:0Validation step:1Validation step:2Epoch 793 		 Validation Loss: 4.425448536872864
Validation Loss Decreased(4.425574--->4.425449) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 794 / 2500Epoch 794 		 Training Loss: 1.4544470310211182
Validation step:0Validation step:1Validation step:2Epoch 794 		 Validation Loss: 4.425325512886047
Validation Loss Decreased(4.425449--->4.425326) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 795 / 2500Epoch 795 		 Training Loss: 1.4556454845837183
Validation step:0Validation step:1Validation step:2Epoch 795 		 Validation Loss: 4.42509126663208
Validation Loss Decreased(4.425326--->4.425091) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 796 / 2500Epoch 796 		 Training Loss: 1.456113108566829
Validation step:0Validation step:1Validation step:2Epoch 796 		 Validation Loss: 4.424919486045837
Validation Loss Decreased(4.425091--->4.424919) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 797 / 2500Epoch 797 		 Training Loss: 1.4545018332345145
Validation step:0Validation step:1Validation step:2Epoch 797 		 Validation Loss: 4.424920678138733
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 798 / 2500Epoch 798 		 Training Loss: 1.4540244766644068
Validation step:0Validation step:1Validation step:2Epoch 798 		 Validation Loss: 4.424741268157959
Validation Loss Decreased(4.424919--->4.424741) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 799 / 2500Epoch 799 		 Training Loss: 1.4561149222510201
Validation step:0Validation step:1Validation step:2Epoch 799 		 Validation Loss: 4.424416780471802
Validation Loss Decreased(4.424741--->4.424417) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 800 / 2500Epoch 800 		 Training Loss: 1.4553011315209525
Validation step:0Validation step:1Validation step:2Epoch 800 		 Validation Loss: 4.4242271184921265
Validation Loss Decreased(4.424417--->4.424227) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 801 / 2500Epoch 801 		 Training Loss: 1.4543954474585397
Validation step:0Validation step:1Validation step:2Epoch 801 		 Validation Loss: 4.424229145050049
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 802 / 2500Epoch 802 		 Training Loss: 1.4545236825942993
Validation step:0Validation step:1Validation step:2Epoch 802 		 Validation Loss: 4.42428982257843
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 803 / 2500Epoch 803 		 Training Loss: 1.4552039759499686
Validation step:0Validation step:1Validation step:2Epoch 803 		 Validation Loss: 4.424147367477417
Validation Loss Decreased(4.424227--->4.424147) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 804 / 2500Epoch 804 		 Training Loss: 1.4532410587583269
Validation step:0Validation step:1Validation step:2Epoch 804 		 Validation Loss: 4.423846364021301
Validation Loss Decreased(4.424147--->4.423846) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 805 / 2500Epoch 805 		 Training Loss: 1.4546308772904533
Validation step:0Validation step:1Validation step:2Epoch 805 		 Validation Loss: 4.42355489730835
Validation Loss Decreased(4.423846--->4.423555) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 806 / 2500Epoch 806 		 Training Loss: 1.4559680904660905
Validation step:0Validation step:1Validation step:2Epoch 806 		 Validation Loss: 4.423528432846069
Validation Loss Decreased(4.423555--->4.423528) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 807 / 2500Epoch 807 		 Training Loss: 1.452757477760315
Validation step:0Validation step:1Validation step:2Epoch 807 		 Validation Loss: 4.423438787460327
Validation Loss Decreased(4.423528--->4.423439) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 808 / 2500Epoch 808 		 Training Loss: 1.456232258251735
Validation step:0Validation step:1Validation step:2Epoch 808 		 Validation Loss: 4.423232913017273
Validation Loss Decreased(4.423439--->4.423233) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 809 / 2500Epoch 809 		 Training Loss: 1.4524951662336076
Validation step:0Validation step:1Validation step:2Epoch 809 		 Validation Loss: 4.423110365867615
Validation Loss Decreased(4.423233--->4.423110) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 810 / 2500Epoch 810 		 Training Loss: 1.4560831870351518
Validation step:0Validation step:1Validation step:2Epoch 810 		 Validation Loss: 4.422764420509338
Validation Loss Decreased(4.423110--->4.422764) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 811 / 2500Epoch 811 		 Training Loss: 1.4557762571743555
Validation step:0Validation step:1Validation step:2Epoch 811 		 Validation Loss: 4.422600626945496
Validation Loss Decreased(4.422764--->4.422601) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 812 / 2500Epoch 812 		 Training Loss: 1.4555784123284476
Validation step:0Validation step:1Validation step:2Epoch 812 		 Validation Loss: 4.422891855239868
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 813 / 2500Epoch 813 		 Training Loss: 1.4532360093934196
Validation step:0Validation step:1Validation step:2Epoch 813 		 Validation Loss: 4.422701478004456
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 814 / 2500Epoch 814 		 Training Loss: 1.4552186727523804
Validation step:0Validation step:1Validation step:2Epoch 814 		 Validation Loss: 4.422279119491577
Validation Loss Decreased(4.422601--->4.422279) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 815 / 2500Epoch 815 		 Training Loss: 1.453445383480617
Validation step:0Validation step:1Validation step:2Epoch 815 		 Validation Loss: 4.422070860862732
Validation Loss Decreased(4.422279--->4.422071) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 816 / 2500Epoch 816 		 Training Loss: 1.4546877912112646
Validation step:0Validation step:1Validation step:2Epoch 816 		 Validation Loss: 4.421996593475342
Validation Loss Decreased(4.422071--->4.421997) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 817 / 2500Epoch 817 		 Training Loss: 1.4539244260106767
Validation step:0Validation step:1Validation step:2Epoch 817 		 Validation Loss: 4.421790599822998
Validation Loss Decreased(4.421997--->4.421791) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 818 / 2500Epoch 818 		 Training Loss: 1.4544159940310888
Validation step:0Validation step:1Validation step:2Epoch 818 		 Validation Loss: 4.421790957450867
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 819 / 2500Epoch 819 		 Training Loss: 1.454610058239528
Validation step:0Validation step:1Validation step:2Epoch 819 		 Validation Loss: 4.421566009521484
Validation Loss Decreased(4.421791--->4.421566) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 820 / 2500Epoch 820 		 Training Loss: 1.4544774208750044
Validation step:0Validation step:1Validation step:2Epoch 820 		 Validation Loss: 4.421391248703003
Validation Loss Decreased(4.421566--->4.421391) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 821 / 2500Epoch 821 		 Training Loss: 1.4536713446889604
Validation step:0Validation step:1Validation step:2Epoch 821 		 Validation Loss: 4.42122745513916
Validation Loss Decreased(4.421391--->4.421227) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 822 / 2500Epoch 822 		 Training Loss: 1.4545848965644836
Validation step:0Validation step:1Validation step:2Epoch 822 		 Validation Loss: 4.421102404594421
Validation Loss Decreased(4.421227--->4.421102) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 823 / 2500Epoch 823 		 Training Loss: 1.4536870462553841
Validation step:0Validation step:1Validation step:2Epoch 823 		 Validation Loss: 4.420975208282471
Validation Loss Decreased(4.421102--->4.420975) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 824 / 2500Epoch 824 		 Training Loss: 1.454714570726667
Validation step:0Validation step:1Validation step:2Epoch 824 		 Validation Loss: 4.4207398891448975
Validation Loss Decreased(4.420975--->4.420740) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 825 / 2500Epoch 825 		 Training Loss: 1.4540998935699463
Validation step:0Validation step:1Validation step:2Epoch 825 		 Validation Loss: 4.420796275138855
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 826 / 2500Epoch 826 		 Training Loss: 1.4534936802727836
Validation step:0Validation step:1Validation step:2Epoch 826 		 Validation Loss: 4.42079758644104
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 827 / 2500Epoch 827 		 Training Loss: 1.453293604510171
Validation step:0Validation step:1Validation step:2Epoch 827 		 Validation Loss: 4.420478105545044
Validation Loss Decreased(4.420740--->4.420478) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 828 / 2500Epoch 828 		 Training Loss: 1.4543564575059074
Validation step:0Validation step:1Validation step:2Epoch 828 		 Validation Loss: 4.420117616653442
Validation Loss Decreased(4.420478--->4.420118) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 829 / 2500Epoch 829 		 Training Loss: 1.4536999889782496
Validation step:0Validation step:1Validation step:2Epoch 829 		 Validation Loss: 4.420168876647949
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 830 / 2500Epoch 830 		 Training Loss: 1.4552395173481532
Validation step:0Validation step:1Validation step:2Epoch 830 		 Validation Loss: 4.419873118400574
Validation Loss Decreased(4.420118--->4.419873) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 831 / 2500Epoch 831 		 Training Loss: 1.4536489333425249
Validation step:0Validation step:1Validation step:2Epoch 831 		 Validation Loss: 4.41969621181488
Validation Loss Decreased(4.419873--->4.419696) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 832 / 2500Epoch 832 		 Training Loss: 1.453487413270133
Validation step:0Validation step:1Validation step:2Epoch 832 		 Validation Loss: 4.419584274291992
Validation Loss Decreased(4.419696--->4.419584) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 833 / 2500Epoch 833 		 Training Loss: 1.4547316517148698
Validation step:0Validation step:1Validation step:2Epoch 833 		 Validation Loss: 4.419464826583862
Validation Loss Decreased(4.419584--->4.419465) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 834 / 2500Epoch 834 		 Training Loss: 1.4540026358195715
Validation step:0Validation step:1Validation step:2Epoch 834 		 Validation Loss: 4.4192633628845215
Validation Loss Decreased(4.419465--->4.419263) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 835 / 2500Epoch 835 		 Training Loss: 1.4536747932434082
Validation step:0Validation step:1Validation step:2Epoch 835 		 Validation Loss: 4.419106960296631
Validation Loss Decreased(4.419263--->4.419107) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 836 / 2500Epoch 836 		 Training Loss: 1.454034081527165
Validation step:0Validation step:1Validation step:2Epoch 836 		 Validation Loss: 4.418917655944824
Validation Loss Decreased(4.419107--->4.418918) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 837 / 2500Epoch 837 		 Training Loss: 1.4539742469787598
Validation step:0Validation step:1Validation step:2Epoch 837 		 Validation Loss: 4.418876647949219
Validation Loss Decreased(4.418918--->4.418877) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 838 / 2500Epoch 838 		 Training Loss: 1.4542319093431746
Validation step:0Validation step:1Validation step:2Epoch 838 		 Validation Loss: 4.4188315868377686
Validation Loss Decreased(4.418877--->4.418832) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 839 / 2500Epoch 839 		 Training Loss: 1.4521889090538025
Validation step:0Validation step:1Validation step:2Epoch 839 		 Validation Loss: 4.418579697608948
Validation Loss Decreased(4.418832--->4.418580) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 840 / 2500Epoch 840 		 Training Loss: 1.452598546232496
Validation step:0Validation step:1Validation step:2Epoch 840 		 Validation Loss: 4.418313384056091
Validation Loss Decreased(4.418580--->4.418313) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 841 / 2500Epoch 841 		 Training Loss: 1.4524617024830409
Validation step:0Validation step:1Validation step:2Epoch 841 		 Validation Loss: 4.418299317359924
Validation Loss Decreased(4.418313--->4.418299) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 842 / 2500Epoch 842 		 Training Loss: 1.4529559441975184
Validation step:0Validation step:1Validation step:2Epoch 842 		 Validation Loss: 4.41812002658844
Validation Loss Decreased(4.418299--->4.418120) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 843 / 2500Epoch 843 		 Training Loss: 1.4524437018803187
Validation step:0Validation step:1Validation step:2Epoch 843 		 Validation Loss: 4.417926549911499
Validation Loss Decreased(4.418120--->4.417927) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 844 / 2500Epoch 844 		 Training Loss: 1.4515272378921509
Validation step:0Validation step:1Validation step:2Epoch 844 		 Validation Loss: 4.417770504951477
Validation Loss Decreased(4.417927--->4.417771) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 845 / 2500Epoch 845 		 Training Loss: 1.4533583777291434
Validation step:0Validation step:1Validation step:2Epoch 845 		 Validation Loss: 4.417670369148254
Validation Loss Decreased(4.417771--->4.417670) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 846 / 2500Epoch 846 		 Training Loss: 1.4542496800422668
Validation step:0Validation step:1Validation step:2Epoch 846 		 Validation Loss: 4.417405605316162
Validation Loss Decreased(4.417670--->4.417406) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 847 / 2500Epoch 847 		 Training Loss: 1.453404358455113
Validation step:0Validation step:1Validation step:2Epoch 847 		 Validation Loss: 4.417375326156616
Validation Loss Decreased(4.417406--->4.417375) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 848 / 2500Epoch 848 		 Training Loss: 1.4536938922745841
Validation step:0Validation step:1Validation step:2Epoch 848 		 Validation Loss: 4.417210817337036
Validation Loss Decreased(4.417375--->4.417211) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 849 / 2500Epoch 849 		 Training Loss: 1.452705672809056
Validation step:0Validation step:1Validation step:2Epoch 849 		 Validation Loss: 4.417155623435974
Validation Loss Decreased(4.417211--->4.417156) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 850 / 2500Epoch 850 		 Training Loss: 1.4528001206261771
Validation step:0Validation step:1Validation step:2Epoch 850 		 Validation Loss: 4.41700804233551
Validation Loss Decreased(4.417156--->4.417008) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 851 / 2500Epoch 851 		 Training Loss: 1.4538371137210302
Validation step:0Validation step:1Validation step:2Epoch 851 		 Validation Loss: 4.4168620109558105
Validation Loss Decreased(4.417008--->4.416862) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 852 / 2500Epoch 852 		 Training Loss: 1.451942699296134
Validation step:0Validation step:1Validation step:2Epoch 852 		 Validation Loss: 4.41666853427887
Validation Loss Decreased(4.416862--->4.416669) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 853 / 2500Epoch 853 		 Training Loss: 1.4528168780463082
Validation step:0Validation step:1Validation step:2Epoch 853 		 Validation Loss: 4.4164674282073975
Validation Loss Decreased(4.416669--->4.416467) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 854 / 2500Epoch 854 		 Training Loss: 1.4537004487855094
Validation step:0Validation step:1Validation step:2Epoch 854 		 Validation Loss: 4.416427135467529
Validation Loss Decreased(4.416467--->4.416427) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 855 / 2500Epoch 855 		 Training Loss: 1.4533958179610116
Validation step:0Validation step:1Validation step:2Epoch 855 		 Validation Loss: 4.416083931922913
Validation Loss Decreased(4.416427--->4.416084) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 856 / 2500Epoch 856 		 Training Loss: 1.45291040624891
Validation step:0Validation step:1Validation step:2Epoch 856 		 Validation Loss: 4.415865898132324
Validation Loss Decreased(4.416084--->4.415866) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 857 / 2500Epoch 857 		 Training Loss: 1.4522656883512224
Validation step:0Validation step:1Validation step:2Epoch 857 		 Validation Loss: 4.415730834007263
Validation Loss Decreased(4.415866--->4.415731) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 858 / 2500Epoch 858 		 Training Loss: 1.4524298225130354
Validation step:0Validation step:1Validation step:2Epoch 858 		 Validation Loss: 4.41560435295105
Validation Loss Decreased(4.415731--->4.415604) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 859 / 2500Epoch 859 		 Training Loss: 1.4526831337383814
Validation step:0Validation step:1Validation step:2Epoch 859 		 Validation Loss: 4.415560007095337
Validation Loss Decreased(4.415604--->4.415560) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 860 / 2500Epoch 860 		 Training Loss: 1.452085256576538
Validation step:0Validation step:1Validation step:2Epoch 860 		 Validation Loss: 4.415349245071411
Validation Loss Decreased(4.415560--->4.415349) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 861 / 2500Epoch 861 		 Training Loss: 1.4529719267572676
Validation step:0Validation step:1Validation step:2Epoch 861 		 Validation Loss: 4.415304064750671
Validation Loss Decreased(4.415349--->4.415304) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 862 / 2500Epoch 862 		 Training Loss: 1.452291761125837
Validation step:0Validation step:1Validation step:2Epoch 862 		 Validation Loss: 4.415072441101074
Validation Loss Decreased(4.415304--->4.415072) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 863 / 2500Epoch 863 		 Training Loss: 1.4521829230444772
Validation step:0Validation step:1Validation step:2Epoch 863 		 Validation Loss: 4.414946675300598
Validation Loss Decreased(4.415072--->4.414947) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 864 / 2500Epoch 864 		 Training Loss: 1.4524529320853097
Validation step:0Validation step:1Validation step:2Epoch 864 		 Validation Loss: 4.4147785902023315
Validation Loss Decreased(4.414947--->4.414779) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 865 / 2500Epoch 865 		 Training Loss: 1.4516643030302865
Validation step:0Validation step:1Validation step:2Epoch 865 		 Validation Loss: 4.414760708808899
Validation Loss Decreased(4.414779--->4.414761) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 866 / 2500Epoch 866 		 Training Loss: 1.451542820249285
Validation step:0Validation step:1Validation step:2Epoch 866 		 Validation Loss: 4.41463577747345
Validation Loss Decreased(4.414761--->4.414636) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 867 / 2500Epoch 867 		 Training Loss: 1.4517971873283386
Validation step:0Validation step:1Validation step:2Epoch 867 		 Validation Loss: 4.414454221725464
Validation Loss Decreased(4.414636--->4.414454) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 868 / 2500Epoch 868 		 Training Loss: 1.4498187899589539
Validation step:0Validation step:1Validation step:2Epoch 868 		 Validation Loss: 4.41409432888031
Validation Loss Decreased(4.414454--->4.414094) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 869 / 2500Epoch 869 		 Training Loss: 1.45186471087592
Validation step:0Validation step:1Validation step:2Epoch 869 		 Validation Loss: 4.413973093032837
Validation Loss Decreased(4.414094--->4.413973) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 870 / 2500Epoch 870 		 Training Loss: 1.4519744259970528
Validation step:0Validation step:1Validation step:2Epoch 870 		 Validation Loss: 4.413931369781494
Validation Loss Decreased(4.413973--->4.413931) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 871 / 2500Epoch 871 		 Training Loss: 1.452181611742292
Validation step:0Validation step:1Validation step:2Epoch 871 		 Validation Loss: 4.4136141538619995
Validation Loss Decreased(4.413931--->4.413614) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 872 / 2500Epoch 872 		 Training Loss: 1.4486764413969857
Validation step:0Validation step:1Validation step:2Epoch 872 		 Validation Loss: 4.413407802581787
Validation Loss Decreased(4.413614--->4.413408) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 873 / 2500Epoch 873 		 Training Loss: 1.452423972742898
Validation step:0Validation step:1Validation step:2Epoch 873 		 Validation Loss: 4.4133617877960205
Validation Loss Decreased(4.413408--->4.413362) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 874 / 2500Epoch 874 		 Training Loss: 1.451304282460894
Validation step:0Validation step:1Validation step:2Epoch 874 		 Validation Loss: 4.4132431745529175
Validation Loss Decreased(4.413362--->4.413243) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 875 / 2500Epoch 875 		 Training Loss: 1.4499744432313102
Validation step:0Validation step:1Validation step:2Epoch 875 		 Validation Loss: 4.4130799770355225
Validation Loss Decreased(4.413243--->4.413080) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 876 / 2500Epoch 876 		 Training Loss: 1.4524629626955305
Validation step:0Validation step:1Validation step:2Epoch 876 		 Validation Loss: 4.412876605987549
Validation Loss Decreased(4.413080--->4.412877) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 877 / 2500Epoch 877 		 Training Loss: 1.4524394358907426
Validation step:0Validation step:1Validation step:2Epoch 877 		 Validation Loss: 4.4126869440078735
Validation Loss Decreased(4.412877--->4.412687) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 878 / 2500Epoch 878 		 Training Loss: 1.451498074190957
Validation step:0Validation step:1Validation step:2Epoch 878 		 Validation Loss: 4.412622094154358
Validation Loss Decreased(4.412687--->4.412622) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 879 / 2500Epoch 879 		 Training Loss: 1.4508644001824516
Validation step:0Validation step:1Validation step:2Epoch 879 		 Validation Loss: 4.412358522415161
Validation Loss Decreased(4.412622--->4.412359) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 880 / 2500Epoch 880 		 Training Loss: 1.4500535385949271
Validation step:0Validation step:1Validation step:2Epoch 880 		 Validation Loss: 4.412228345870972
Validation Loss Decreased(4.412359--->4.412228) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 881 / 2500Epoch 881 		 Training Loss: 1.4494517956461226
Validation step:0Validation step:1Validation step:2Epoch 881 		 Validation Loss: 4.412250876426697
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 882 / 2500Epoch 882 		 Training Loss: 1.4509458797318595
Validation step:0Validation step:1Validation step:2Epoch 882 		 Validation Loss: 4.412076950073242
Validation Loss Decreased(4.412228--->4.412077) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 883 / 2500Epoch 883 		 Training Loss: 1.450057762009757
Validation step:0Validation step:1Validation step:2Epoch 883 		 Validation Loss: 4.411888837814331
Validation Loss Decreased(4.412077--->4.411889) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 884 / 2500Epoch 884 		 Training Loss: 1.4507816008159093
Validation step:0Validation step:1Validation step:2Epoch 884 		 Validation Loss: 4.4116644859313965
Validation Loss Decreased(4.411889--->4.411664) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 885 / 2500Epoch 885 		 Training Loss: 1.4521583148411341
Validation step:0Validation step:1Validation step:2Epoch 885 		 Validation Loss: 4.411613583564758
Validation Loss Decreased(4.411664--->4.411614) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 886 / 2500Epoch 886 		 Training Loss: 1.45074143580028
Validation step:0Validation step:1Validation step:2Epoch 886 		 Validation Loss: 4.411473274230957
Validation Loss Decreased(4.411614--->4.411473) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 887 / 2500Epoch 887 		 Training Loss: 1.450667781489236
Validation step:0Validation step:1Validation step:2Epoch 887 		 Validation Loss: 4.411247611045837
Validation Loss Decreased(4.411473--->4.411248) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 888 / 2500Epoch 888 		 Training Loss: 1.4499607001032149
Validation step:0Validation step:1Validation step:2Epoch 888 		 Validation Loss: 4.411011219024658
Validation Loss Decreased(4.411248--->4.411011) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 889 / 2500Epoch 889 		 Training Loss: 1.4517775007656641
Validation step:0Validation step:1Validation step:2Epoch 889 		 Validation Loss: 4.410986065864563
Validation Loss Decreased(4.411011--->4.410986) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 890 / 2500Epoch 890 		 Training Loss: 1.450562289782933
Validation step:0Validation step:1Validation step:2Epoch 890 		 Validation Loss: 4.410876393318176
Validation Loss Decreased(4.410986--->4.410876) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 891 / 2500Epoch 891 		 Training Loss: 1.4507178579057967
Validation step:0Validation step:1Validation step:2Epoch 891 		 Validation Loss: 4.410632371902466
Validation Loss Decreased(4.410876--->4.410632) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 892 / 2500Epoch 892 		 Training Loss: 1.45038127047675
Validation step:0Validation step:1Validation step:2Epoch 892 		 Validation Loss: 4.410376191139221
Validation Loss Decreased(4.410632--->4.410376) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 893 / 2500Epoch 893 		 Training Loss: 1.4512592468942915
Validation step:0Validation step:1Validation step:2Epoch 893 		 Validation Loss: 4.4102500677108765
Validation Loss Decreased(4.410376--->4.410250) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 894 / 2500Epoch 894 		 Training Loss: 1.4511036106518336
Validation step:0Validation step:1Validation step:2Epoch 894 		 Validation Loss: 4.410135746002197
Validation Loss Decreased(4.410250--->4.410136) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 895 / 2500Epoch 895 		 Training Loss: 1.4502433282988412
Validation step:0Validation step:1Validation step:2Epoch 895 		 Validation Loss: 4.409986972808838
Validation Loss Decreased(4.410136--->4.409987) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 896 / 2500Epoch 896 		 Training Loss: 1.4501850945608956
Validation step:0Validation step:1Validation step:2Epoch 896 		 Validation Loss: 4.409899592399597
Validation Loss Decreased(4.409987--->4.409900) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 897 / 2500Epoch 897 		 Training Loss: 1.4514155898775374
Validation step:0Validation step:1Validation step:2Epoch 897 		 Validation Loss: 4.409639954566956
Validation Loss Decreased(4.409900--->4.409640) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 898 / 2500Epoch 898 		 Training Loss: 1.4473162037985665
Validation step:0Validation step:1Validation step:2Epoch 898 		 Validation Loss: 4.409608960151672
Validation Loss Decreased(4.409640--->4.409609) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 899 / 2500Epoch 899 		 Training Loss: 1.4503518002373832
Validation step:0Validation step:1Validation step:2Epoch 899 		 Validation Loss: 4.409402966499329
Validation Loss Decreased(4.409609--->4.409403) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 900 / 2500Epoch 900 		 Training Loss: 1.4511435287339347
Validation step:0Validation step:1Validation step:2Epoch 900 		 Validation Loss: 4.409199357032776
Validation Loss Decreased(4.409403--->4.409199) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 901 / 2500Epoch 901 		 Training Loss: 1.4499780791146415
Validation step:0Validation step:1Validation step:2Epoch 901 		 Validation Loss: 4.408994674682617
Validation Loss Decreased(4.409199--->4.408995) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 902 / 2500Epoch 902 		 Training Loss: 1.4495744790349687
Validation step:0Validation step:1Validation step:2Epoch 902 		 Validation Loss: 4.408828139305115
Validation Loss Decreased(4.408995--->4.408828) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 903 / 2500Epoch 903 		 Training Loss: 1.4497601304735457
Validation step:0Validation step:1Validation step:2Epoch 903 		 Validation Loss: 4.4087324142456055
Validation Loss Decreased(4.408828--->4.408732) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 904 / 2500Epoch 904 		 Training Loss: 1.4495200514793396
Validation step:0Validation step:1Validation step:2Epoch 904 		 Validation Loss: 4.408528089523315
Validation Loss Decreased(4.408732--->4.408528) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 905 / 2500Epoch 905 		 Training Loss: 1.4496178456715174
Validation step:0Validation step:1Validation step:2Epoch 905 		 Validation Loss: 4.408382773399353
Validation Loss Decreased(4.408528--->4.408383) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 906 / 2500Epoch 906 		 Training Loss: 1.45053859267916
Validation step:0Validation step:1Validation step:2Epoch 906 		 Validation Loss: 4.408275604248047
Validation Loss Decreased(4.408383--->4.408276) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 907 / 2500Epoch 907 		 Training Loss: 1.4496389201709203
Validation step:0Validation step:1Validation step:2Epoch 907 		 Validation Loss: 4.408110857009888
Validation Loss Decreased(4.408276--->4.408111) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 908 / 2500Epoch 908 		 Training Loss: 1.451839804649353
Validation step:0Validation step:1Validation step:2Epoch 908 		 Validation Loss: 4.407955169677734
Validation Loss Decreased(4.408111--->4.407955) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 909 / 2500Epoch 909 		 Training Loss: 1.4495118856430054
Validation step:0Validation step:1Validation step:2Epoch 909 		 Validation Loss: 4.407743692398071
Validation Loss Decreased(4.407955--->4.407744) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 910 / 2500Epoch 910 		 Training Loss: 1.4490115557398116
Validation step:0Validation step:1Validation step:2Epoch 910 		 Validation Loss: 4.407581210136414
Validation Loss Decreased(4.407744--->4.407581) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 911 / 2500Epoch 911 		 Training Loss: 1.4479386380740575
Validation step:0Validation step:1Validation step:2Epoch 911 		 Validation Loss: 4.407336354255676
Validation Loss Decreased(4.407581--->4.407336) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 912 / 2500Epoch 912 		 Training Loss: 1.4490464329719543
Validation step:0Validation step:1Validation step:2Epoch 912 		 Validation Loss: 4.407273888587952
Validation Loss Decreased(4.407336--->4.407274) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 913 / 2500Epoch 913 		 Training Loss: 1.4492208531924657
Validation step:0Validation step:1Validation step:2Epoch 913 		 Validation Loss: 4.407275915145874
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 914 / 2500Epoch 914 		 Training Loss: 1.448648452758789
Validation step:0Validation step:1Validation step:2Epoch 914 		 Validation Loss: 4.407060861587524
Validation Loss Decreased(4.407274--->4.407061) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 915 / 2500Epoch 915 		 Training Loss: 1.4481383221490043
Validation step:0Validation step:1Validation step:2Epoch 915 		 Validation Loss: 4.4068604707717896
Validation Loss Decreased(4.407061--->4.406860) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 916 / 2500Epoch 916 		 Training Loss: 1.4497475368635995
Validation step:0Validation step:1Validation step:2Epoch 916 		 Validation Loss: 4.4066349267959595
Validation Loss Decreased(4.406860--->4.406635) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 917 / 2500Epoch 917 		 Training Loss: 1.448883822986058
Validation step:0Validation step:1Validation step:2Epoch 917 		 Validation Loss: 4.406437516212463
Validation Loss Decreased(4.406635--->4.406438) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 918 / 2500Epoch 918 		 Training Loss: 1.4489901321274894
Validation step:0Validation step:1Validation step:2Epoch 918 		 Validation Loss: 4.406365990638733
Validation Loss Decreased(4.406438--->4.406366) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 919 / 2500Epoch 919 		 Training Loss: 1.4482463342802865
Validation step:0Validation step:1Validation step:2Epoch 919 		 Validation Loss: 4.40622353553772
Validation Loss Decreased(4.406366--->4.406224) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 920 / 2500Epoch 920 		 Training Loss: 1.4498779007366724
Validation step:0Validation step:1Validation step:2Epoch 920 		 Validation Loss: 4.406043648719788
Validation Loss Decreased(4.406224--->4.406044) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 921 / 2500Epoch 921 		 Training Loss: 1.4478695562907629
Validation step:0Validation step:1Validation step:2Epoch 921 		 Validation Loss: 4.405878901481628
Validation Loss Decreased(4.406044--->4.405879) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 922 / 2500Epoch 922 		 Training Loss: 1.4488790886742728
Validation step:0Validation step:1Validation step:2Epoch 922 		 Validation Loss: 4.40564227104187
Validation Loss Decreased(4.405879--->4.405642) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 923 / 2500Epoch 923 		 Training Loss: 1.449632397719792
Validation step:0Validation step:1Validation step:2Epoch 923 		 Validation Loss: 4.405640482902527
Validation Loss Decreased(4.405642--->4.405640) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 924 / 2500Epoch 924 		 Training Loss: 1.448808763708387
Validation step:0Validation step:1Validation step:2Epoch 924 		 Validation Loss: 4.405433773994446
Validation Loss Decreased(4.405640--->4.405434) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 925 / 2500Epoch 925 		 Training Loss: 1.4468608754021781
Validation step:0Validation step:1Validation step:2Epoch 925 		 Validation Loss: 4.405198574066162
Validation Loss Decreased(4.405434--->4.405199) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 926 / 2500Epoch 926 		 Training Loss: 1.4486851862498693
Validation step:0Validation step:1Validation step:2Epoch 926 		 Validation Loss: 4.405205607414246
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 927 / 2500Epoch 927 		 Training Loss: 1.4487723878451757
Validation step:0Validation step:1Validation step:2Epoch 927 		 Validation Loss: 4.405078411102295
Validation Loss Decreased(4.405199--->4.405078) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 928 / 2500Epoch 928 		 Training Loss: 1.4465867025511605
Validation step:0Validation step:1Validation step:2Epoch 928 		 Validation Loss: 4.404805660247803
Validation Loss Decreased(4.405078--->4.404806) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 929 / 2500Epoch 929 		 Training Loss: 1.4475019659314836
Validation step:0Validation step:1Validation step:2Epoch 929 		 Validation Loss: 4.404626727104187
Validation Loss Decreased(4.404806--->4.404627) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 930 / 2500Epoch 930 		 Training Loss: 1.4476924879210336
Validation step:0Validation step:1Validation step:2Epoch 930 		 Validation Loss: 4.404443860054016
Validation Loss Decreased(4.404627--->4.404444) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 931 / 2500Epoch 931 		 Training Loss: 1.447517727102552
Validation step:0Validation step:1Validation step:2Epoch 931 		 Validation Loss: 4.40429413318634
Validation Loss Decreased(4.404444--->4.404294) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 932 / 2500Epoch 932 		 Training Loss: 1.4454405818666731
Validation step:0Validation step:1Validation step:2Epoch 932 		 Validation Loss: 4.404176354408264
Validation Loss Decreased(4.404294--->4.404176) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 933 / 2500Epoch 933 		 Training Loss: 1.4485120943614416
Validation step:0Validation step:1Validation step:2Epoch 933 		 Validation Loss: 4.4041138887405396
Validation Loss Decreased(4.404176--->4.404114) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 934 / 2500Epoch 934 		 Training Loss: 1.4486142992973328
Validation step:0Validation step:1Validation step:2Epoch 934 		 Validation Loss: 4.403873443603516
Validation Loss Decreased(4.404114--->4.403873) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 935 / 2500Epoch 935 		 Training Loss: 1.4461273806435722
Validation step:0Validation step:1Validation step:2Epoch 935 		 Validation Loss: 4.403676509857178
Validation Loss Decreased(4.403873--->4.403677) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 936 / 2500Epoch 936 		 Training Loss: 1.4460693172046117
Validation step:0Validation step:1Validation step:2Epoch 936 		 Validation Loss: 4.40361487865448
Validation Loss Decreased(4.403677--->4.403615) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 937 / 2500Epoch 937 		 Training Loss: 1.4483528307506017
Validation step:0Validation step:1Validation step:2Epoch 937 		 Validation Loss: 4.403512001037598
Validation Loss Decreased(4.403615--->4.403512) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 938 / 2500Epoch 938 		 Training Loss: 1.4485152534076147
Validation step:0Validation step:1Validation step:2Epoch 938 		 Validation Loss: 4.403288722038269
Validation Loss Decreased(4.403512--->4.403289) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 939 / 2500Epoch 939 		 Training Loss: 1.447740375995636
Validation step:0Validation step:1Validation step:2Epoch 939 		 Validation Loss: 4.4030492305755615
Validation Loss Decreased(4.403289--->4.403049) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 940 / 2500Epoch 940 		 Training Loss: 1.447407330785479
Validation step:0Validation step:1Validation step:2Epoch 940 		 Validation Loss: 4.402861833572388
Validation Loss Decreased(4.403049--->4.402862) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 941 / 2500Epoch 941 		 Training Loss: 1.4473966360092163
Validation step:0Validation step:1Validation step:2Epoch 941 		 Validation Loss: 4.402780771255493
Validation Loss Decreased(4.402862--->4.402781) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 942 / 2500Epoch 942 		 Training Loss: 1.4490577152797155
Validation step:0Validation step:1Validation step:2Epoch 942 		 Validation Loss: 4.402587652206421
Validation Loss Decreased(4.402781--->4.402588) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 943 / 2500Epoch 943 		 Training Loss: 1.4471170050757272
Validation step:0Validation step:1Validation step:2Epoch 943 		 Validation Loss: 4.402411699295044
Validation Loss Decreased(4.402588--->4.402412) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 944 / 2500Epoch 944 		 Training Loss: 1.4478774241038732
Validation step:0Validation step:1Validation step:2Epoch 944 		 Validation Loss: 4.402191519737244
Validation Loss Decreased(4.402412--->4.402192) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 945 / 2500Epoch 945 		 Training Loss: 1.4483323863574438
Validation step:0Validation step:1Validation step:2Epoch 945 		 Validation Loss: 4.4020689725875854
Validation Loss Decreased(4.402192--->4.402069) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 946 / 2500Epoch 946 		 Training Loss: 1.446477668625968
Validation step:0Validation step:1Validation step:2Epoch 946 		 Validation Loss: 4.401977300643921
Validation Loss Decreased(4.402069--->4.401977) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 947 / 2500Epoch 947 		 Training Loss: 1.4465749263763428
Validation step:0Validation step:1Validation step:2Epoch 947 		 Validation Loss: 4.401922941207886
Validation Loss Decreased(4.401977--->4.401923) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 948 / 2500Epoch 948 		 Training Loss: 1.4473072716167994
Validation step:0Validation step:1Validation step:2Epoch 948 		 Validation Loss: 4.401750206947327
Validation Loss Decreased(4.401923--->4.401750) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 949 / 2500Epoch 949 		 Training Loss: 1.448057234287262
Validation step:0Validation step:1Validation step:2Epoch 949 		 Validation Loss: 4.401652812957764
Validation Loss Decreased(4.401750--->4.401653) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 950 / 2500Epoch 950 		 Training Loss: 1.4475149341991969
Validation step:0Validation step:1Validation step:2Epoch 950 		 Validation Loss: 4.401394367218018
Validation Loss Decreased(4.401653--->4.401394) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 951 / 2500Epoch 951 		 Training Loss: 1.4459725958960397
Validation step:0Validation step:1Validation step:2Epoch 951 		 Validation Loss: 4.4013062715530396
Validation Loss Decreased(4.401394--->4.401306) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 952 / 2500Epoch 952 		 Training Loss: 1.4468575716018677
Validation step:0Validation step:1Validation step:2Epoch 952 		 Validation Loss: 4.4011470079422
Validation Loss Decreased(4.401306--->4.401147) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 953 / 2500Epoch 953 		 Training Loss: 1.4477257898875646
Validation step:0Validation step:1Validation step:2Epoch 953 		 Validation Loss: 4.400955438613892
Validation Loss Decreased(4.401147--->4.400955) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 954 / 2500Epoch 954 		 Training Loss: 1.4466081517083305
Validation step:0Validation step:1Validation step:2Epoch 954 		 Validation Loss: 4.400732398033142
Validation Loss Decreased(4.400955--->4.400732) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 955 / 2500Epoch 955 		 Training Loss: 1.444974149976458
Validation step:0Validation step:1Validation step:2Epoch 955 		 Validation Loss: 4.400581240653992
Validation Loss Decreased(4.400732--->4.400581) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 956 / 2500Epoch 956 		 Training Loss: 1.4474206737109594
Validation step:0Validation step:1Validation step:2Epoch 956 		 Validation Loss: 4.400570631027222
Validation Loss Decreased(4.400581--->4.400571) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 957 / 2500Epoch 957 		 Training Loss: 1.447139663355691
Validation step:0Validation step:1Validation step:2Epoch 957 		 Validation Loss: 4.400422096252441
Validation Loss Decreased(4.400571--->4.400422) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 958 / 2500Epoch 958 		 Training Loss: 1.447565725871495
Validation step:0Validation step:1Validation step:2Epoch 958 		 Validation Loss: 4.40024209022522
Validation Loss Decreased(4.400422--->4.400242) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 959 / 2500Epoch 959 		 Training Loss: 1.4465438553265162
Validation step:0Validation step:1Validation step:2Epoch 959 		 Validation Loss: 4.400069832801819
Validation Loss Decreased(4.400242--->4.400070) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 960 / 2500Epoch 960 		 Training Loss: 1.4461349504334586
Validation step:0Validation step:1Validation step:2Epoch 960 		 Validation Loss: 4.399884104728699
Validation Loss Decreased(4.400070--->4.399884) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 961 / 2500Epoch 961 		 Training Loss: 1.4474069476127625
Validation step:0Validation step:1Validation step:2Epoch 961 		 Validation Loss: 4.399730563163757
Validation Loss Decreased(4.399884--->4.399731) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 962 / 2500Epoch 962 		 Training Loss: 1.4477201444762093
Validation step:0Validation step:1Validation step:2Epoch 962 		 Validation Loss: 4.399622082710266
Validation Loss Decreased(4.399731--->4.399622) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 963 / 2500Epoch 963 		 Training Loss: 1.4460838181631905
Validation step:0Validation step:1Validation step:2Epoch 963 		 Validation Loss: 4.399531960487366
Validation Loss Decreased(4.399622--->4.399532) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 964 / 2500Epoch 964 		 Training Loss: 1.4481329236711775
Validation step:0Validation step:1Validation step:2Epoch 964 		 Validation Loss: 4.399362564086914
Validation Loss Decreased(4.399532--->4.399363) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 965 / 2500Epoch 965 		 Training Loss: 1.4456509862627303
Validation step:0Validation step:1Validation step:2Epoch 965 		 Validation Loss: 4.399111986160278
Validation Loss Decreased(4.399363--->4.399112) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 966 / 2500Epoch 966 		 Training Loss: 1.4467166066169739
Validation step:0Validation step:1Validation step:2Epoch 966 		 Validation Loss: 4.399181008338928
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 967 / 2500Epoch 967 		 Training Loss: 1.446179986000061
Validation step:0Validation step:1Validation step:2Epoch 967 		 Validation Loss: 4.398993372917175
Validation Loss Decreased(4.399112--->4.398993) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 968 / 2500Epoch 968 		 Training Loss: 1.447061104433877
Validation step:0Validation step:1Validation step:2Epoch 968 		 Validation Loss: 4.398676872253418
Validation Loss Decreased(4.398993--->4.398677) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 969 / 2500Epoch 969 		 Training Loss: 1.446191327912467
Validation step:0Validation step:1Validation step:2Epoch 969 		 Validation Loss: 4.398478865623474
Validation Loss Decreased(4.398677--->4.398479) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 970 / 2500Epoch 970 		 Training Loss: 1.443822171006884
Validation step:0Validation step:1Validation step:2Epoch 970 		 Validation Loss: 4.3983542919158936
Validation Loss Decreased(4.398479--->4.398354) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 971 / 2500Epoch 971 		 Training Loss: 1.4466521399361747
Validation step:0Validation step:1Validation step:2Epoch 971 		 Validation Loss: 4.398212909698486
Validation Loss Decreased(4.398354--->4.398213) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 972 / 2500Epoch 972 		 Training Loss: 1.4459495885031564
Validation step:0Validation step:1Validation step:2Epoch 972 		 Validation Loss: 4.3980759382247925
Validation Loss Decreased(4.398213--->4.398076) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 973 / 2500Epoch 973 		 Training Loss: 1.4457378728049142
Validation step:0Validation step:1Validation step:2Epoch 973 		 Validation Loss: 4.397940635681152
Validation Loss Decreased(4.398076--->4.397941) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 974 / 2500Epoch 974 		 Training Loss: 1.4471221481050764
Validation step:0Validation step:1Validation step:2Epoch 974 		 Validation Loss: 4.397821426391602
Validation Loss Decreased(4.397941--->4.397821) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 975 / 2500Epoch 975 		 Training Loss: 1.4448559880256653
Validation step:0Validation step:1Validation step:2Epoch 975 		 Validation Loss: 4.397584080696106
Validation Loss Decreased(4.397821--->4.397584) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 976 / 2500Epoch 976 		 Training Loss: 1.4462605033602034
Validation step:0Validation step:1Validation step:2Epoch 976 		 Validation Loss: 4.397487044334412
Validation Loss Decreased(4.397584--->4.397487) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 977 / 2500Epoch 977 		 Training Loss: 1.4463270221437727
Validation step:0Validation step:1Validation step:2Epoch 977 		 Validation Loss: 4.397424221038818
Validation Loss Decreased(4.397487--->4.397424) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 978 / 2500Epoch 978 		 Training Loss: 1.4458358883857727
Validation step:0Validation step:1Validation step:2Epoch 978 		 Validation Loss: 4.3971850872039795
Validation Loss Decreased(4.397424--->4.397185) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 979 / 2500Epoch 979 		 Training Loss: 1.447118844304766
Validation step:0Validation step:1Validation step:2Epoch 979 		 Validation Loss: 4.3970643281936646
Validation Loss Decreased(4.397185--->4.397064) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 980 / 2500Epoch 980 		 Training Loss: 1.4467180115836007
Validation step:0Validation step:1Validation step:2Epoch 980 		 Validation Loss: 4.396873831748962
Validation Loss Decreased(4.397064--->4.396874) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 981 / 2500Epoch 981 		 Training Loss: 1.4429780415126257
Validation step:0Validation step:1Validation step:2Epoch 981 		 Validation Loss: 4.396776795387268
Validation Loss Decreased(4.396874--->4.396777) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 982 / 2500Epoch 982 		 Training Loss: 1.4451099463871546
Validation step:0Validation step:1Validation step:2Epoch 982 		 Validation Loss: 4.3967190980911255
Validation Loss Decreased(4.396777--->4.396719) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 983 / 2500Epoch 983 		 Training Loss: 1.4443508301462447
Validation step:0Validation step:1Validation step:2Epoch 983 		 Validation Loss: 4.396450042724609
Validation Loss Decreased(4.396719--->4.396450) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 984 / 2500Epoch 984 		 Training Loss: 1.4464798739978246
Validation step:0Validation step:1Validation step:2Epoch 984 		 Validation Loss: 4.39618194103241
Validation Loss Decreased(4.396450--->4.396182) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 985 / 2500Epoch 985 		 Training Loss: 1.445710974080222
Validation step:0Validation step:1Validation step:2Epoch 985 		 Validation Loss: 4.396081328392029
Validation Loss Decreased(4.396182--->4.396081) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 986 / 2500Epoch 986 		 Training Loss: 1.4429954205240523
Validation step:0Validation step:1Validation step:2Epoch 986 		 Validation Loss: 4.395930767059326
Validation Loss Decreased(4.396081--->4.395931) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 987 / 2500Epoch 987 		 Training Loss: 1.4467079469135828
Validation step:0Validation step:1Validation step:2Epoch 987 		 Validation Loss: 4.395817756652832
Validation Loss Decreased(4.395931--->4.395818) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 988 / 2500Epoch 988 		 Training Loss: 1.4457509177071708
Validation step:0Validation step:1Validation step:2Epoch 988 		 Validation Loss: 4.395662307739258
Validation Loss Decreased(4.395818--->4.395662) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 989 / 2500Epoch 989 		 Training Loss: 1.4447685991014754
Validation step:0Validation step:1Validation step:2Epoch 989 		 Validation Loss: 4.395469665527344
Validation Loss Decreased(4.395662--->4.395470) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 990 / 2500Epoch 990 		 Training Loss: 1.4453762769699097
Validation step:0Validation step:1Validation step:2Epoch 990 		 Validation Loss: 4.395330905914307
Validation Loss Decreased(4.395470--->4.395331) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 991 / 2500Epoch 991 		 Training Loss: 1.4453575355666024
Validation step:0Validation step:1Validation step:2Epoch 991 		 Validation Loss: 4.395164370536804
Validation Loss Decreased(4.395331--->4.395164) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 992 / 2500Epoch 992 		 Training Loss: 1.4458372678075517
Validation step:0Validation step:1Validation step:2Epoch 992 		 Validation Loss: 4.395010352134705
Validation Loss Decreased(4.395164--->4.395010) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 993 / 2500Epoch 993 		 Training Loss: 1.4428431306566512
Validation step:0Validation step:1Validation step:2Epoch 993 		 Validation Loss: 4.394917130470276
Validation Loss Decreased(4.395010--->4.394917) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 994 / 2500Epoch 994 		 Training Loss: 1.4439054727554321
Validation step:0Validation step:1Validation step:2Epoch 994 		 Validation Loss: 4.394773840904236
Validation Loss Decreased(4.394917--->4.394774) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 995 / 2500Epoch 995 		 Training Loss: 1.4452824592590332
Validation step:0Validation step:1Validation step:2Epoch 995 		 Validation Loss: 4.394684076309204
Validation Loss Decreased(4.394774--->4.394684) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 996 / 2500Epoch 996 		 Training Loss: 1.4440158605575562
Validation step:0Validation step:1Validation step:2Epoch 996 		 Validation Loss: 4.3944807052612305
Validation Loss Decreased(4.394684--->4.394481) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 997 / 2500Epoch 997 		 Training Loss: 1.445432254246303
Validation step:0Validation step:1Validation step:2Epoch 997 		 Validation Loss: 4.394301056861877
Validation Loss Decreased(4.394481--->4.394301) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 998 / 2500Epoch 998 		 Training Loss: 1.4442157660211836
Validation step:0Validation step:1Validation step:2Epoch 998 		 Validation Loss: 4.394227385520935
Validation Loss Decreased(4.394301--->4.394227) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 999 / 2500Epoch 999 		 Training Loss: 1.4431843417031425
Validation step:0Validation step:1Validation step:2Epoch 999 		 Validation Loss: 4.39411723613739
Validation Loss Decreased(4.394227--->4.394117) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1000 / 2500Epoch 1000 		 Training Loss: 1.4433444568089075
Validation step:0Validation step:1Validation step:2Epoch 1000 		 Validation Loss: 4.3939173221588135
Validation Loss Decreased(4.394117--->4.393917) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1001 / 2500Epoch 1001 		 Training Loss: 1.445700236729213
Validation step:0Validation step:1Validation step:2Epoch 1001 		 Validation Loss: 4.3937801122665405
Validation Loss Decreased(4.393917--->4.393780) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1002 / 2500Epoch 1002 		 Training Loss: 1.4447580065046037
Validation step:0Validation step:1Validation step:2Epoch 1002 		 Validation Loss: 4.3935699462890625
Validation Loss Decreased(4.393780--->4.393570) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1003 / 2500Epoch 1003 		 Training Loss: 1.4449409076145716
Validation step:0Validation step:1Validation step:2Epoch 1003 		 Validation Loss: 4.393429160118103
Validation Loss Decreased(4.393570--->4.393429) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1004 / 2500Epoch 1004 		 Training Loss: 1.4445023877280099
Validation step:0Validation step:1Validation step:2Epoch 1004 		 Validation Loss: 4.3933587074279785
Validation Loss Decreased(4.393429--->4.393359) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1005 / 2500Epoch 1005 		 Training Loss: 1.443668007850647
Validation step:0Validation step:1Validation step:2Epoch 1005 		 Validation Loss: 4.393097996711731
Validation Loss Decreased(4.393359--->4.393098) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1006 / 2500Epoch 1006 		 Training Loss: 1.4442195040839059
Validation step:0Validation step:1Validation step:2Epoch 1006 		 Validation Loss: 4.392946720123291
Validation Loss Decreased(4.393098--->4.392947) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1007 / 2500Epoch 1007 		 Training Loss: 1.4436357957976205
Validation step:0Validation step:1Validation step:2Epoch 1007 		 Validation Loss: 4.392804980278015
Validation Loss Decreased(4.392947--->4.392805) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1008 / 2500Epoch 1008 		 Training Loss: 1.4432945506913322
Validation step:0Validation step:1Validation step:2Epoch 1008 		 Validation Loss: 4.3926756381988525
Validation Loss Decreased(4.392805--->4.392676) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1009 / 2500Epoch 1009 		 Training Loss: 1.4440930996622359
Validation step:0Validation step:1Validation step:2Epoch 1009 		 Validation Loss: 4.392452597618103
Validation Loss Decreased(4.392676--->4.392453) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1010 / 2500Epoch 1010 		 Training Loss: 1.4432245663234167
Validation step:0Validation step:1Validation step:2Epoch 1010 		 Validation Loss: 4.392347693443298
Validation Loss Decreased(4.392453--->4.392348) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1011 / 2500Epoch 1011 		 Training Loss: 1.4435931273869105
Validation step:0Validation step:1Validation step:2Epoch 1011 		 Validation Loss: 4.392261028289795
Validation Loss Decreased(4.392348--->4.392261) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1012 / 2500Epoch 1012 		 Training Loss: 1.4433284912790572
Validation step:0Validation step:1Validation step:2Epoch 1012 		 Validation Loss: 4.392087936401367
Validation Loss Decreased(4.392261--->4.392088) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1013 / 2500Epoch 1013 		 Training Loss: 1.4409762365477425
Validation step:0Validation step:1Validation step:2Epoch 1013 		 Validation Loss: 4.391883730888367
Validation Loss Decreased(4.392088--->4.391884) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1014 / 2500Epoch 1014 		 Training Loss: 1.4433647649628776
Validation step:0Validation step:1Validation step:2Epoch 1014 		 Validation Loss: 4.391790747642517
Validation Loss Decreased(4.391884--->4.391791) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1015 / 2500Epoch 1015 		 Training Loss: 1.444174519606999
Validation step:0Validation step:1Validation step:2Epoch 1015 		 Validation Loss: 4.391551375389099
Validation Loss Decreased(4.391791--->4.391551) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1016 / 2500Epoch 1016 		 Training Loss: 1.442350149154663
Validation step:0Validation step:1Validation step:2Epoch 1016 		 Validation Loss: 4.391413450241089
Validation Loss Decreased(4.391551--->4.391413) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1017 / 2500Epoch 1017 		 Training Loss: 1.4439795017242432
Validation step:0Validation step:1Validation step:2Epoch 1017 		 Validation Loss: 4.391314506530762
Validation Loss Decreased(4.391413--->4.391315) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1018 / 2500Epoch 1018 		 Training Loss: 1.4434489692960466
Validation step:0Validation step:1Validation step:2Epoch 1018 		 Validation Loss: 4.39121675491333
Validation Loss Decreased(4.391315--->4.391217) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1019 / 2500Epoch 1019 		 Training Loss: 1.4440461141722543
Validation step:0Validation step:1Validation step:2Epoch 1019 		 Validation Loss: 4.39116895198822
Validation Loss Decreased(4.391217--->4.391169) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1020 / 2500Epoch 1020 		 Training Loss: 1.442500616822924
Validation step:0Validation step:1Validation step:2Epoch 1020 		 Validation Loss: 4.390820741653442
Validation Loss Decreased(4.391169--->4.390821) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1021 / 2500Epoch 1021 		 Training Loss: 1.441970842225211
Validation step:0Validation step:1Validation step:2Epoch 1021 		 Validation Loss: 4.390710115432739
Validation Loss Decreased(4.390821--->4.390710) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1022 / 2500Epoch 1022 		 Training Loss: 1.4441219397953577
Validation step:0Validation step:1Validation step:2Epoch 1022 		 Validation Loss: 4.390605211257935
Validation Loss Decreased(4.390710--->4.390605) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1023 / 2500Epoch 1023 		 Training Loss: 1.44388713155474
Validation step:0Validation step:1Validation step:2Epoch 1023 		 Validation Loss: 4.390408992767334
Validation Loss Decreased(4.390605--->4.390409) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1024 / 2500Epoch 1024 		 Training Loss: 1.4428018416677202
Validation step:0Validation step:1Validation step:2Epoch 1024 		 Validation Loss: 4.39026415348053
Validation Loss Decreased(4.390409--->4.390264) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1025 / 2500Epoch 1025 		 Training Loss: 1.441795255456652
Validation step:0Validation step:1Validation step:2Epoch 1025 		 Validation Loss: 4.39009428024292
Validation Loss Decreased(4.390264--->4.390094) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1026 / 2500Epoch 1026 		 Training Loss: 1.4426943404333932
Validation step:0Validation step:1Validation step:2Epoch 1026 		 Validation Loss: 4.389874577522278
Validation Loss Decreased(4.390094--->4.389875) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1027 / 2500Epoch 1027 		 Training Loss: 1.4416551760264806
Validation step:0Validation step:1Validation step:2Epoch 1027 		 Validation Loss: 4.389742851257324
Validation Loss Decreased(4.389875--->4.389743) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1028 / 2500Epoch 1028 		 Training Loss: 1.4432042837142944
Validation step:0Validation step:1Validation step:2Epoch 1028 		 Validation Loss: 4.389676332473755
Validation Loss Decreased(4.389743--->4.389676) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1029 / 2500Epoch 1029 		 Training Loss: 1.442989536694118
Validation step:0Validation step:1Validation step:2Epoch 1029 		 Validation Loss: 4.389531493186951
Validation Loss Decreased(4.389676--->4.389531) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1030 / 2500Epoch 1030 		 Training Loss: 1.4432624748774938
Validation step:0Validation step:1Validation step:2Epoch 1030 		 Validation Loss: 4.389369010925293
Validation Loss Decreased(4.389531--->4.389369) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1031 / 2500Epoch 1031 		 Training Loss: 1.443764397076198
Validation step:0Validation step:1Validation step:2Epoch 1031 		 Validation Loss: 4.38919723033905
Validation Loss Decreased(4.389369--->4.389197) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1032 / 2500Epoch 1032 		 Training Loss: 1.4430205566542489
Validation step:0Validation step:1Validation step:2Epoch 1032 		 Validation Loss: 4.389034867286682
Validation Loss Decreased(4.389197--->4.389035) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1033 / 2500Epoch 1033 		 Training Loss: 1.4430805955614363
Validation step:0Validation step:1Validation step:2Epoch 1033 		 Validation Loss: 4.388823390007019
Validation Loss Decreased(4.389035--->4.388823) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1034 / 2500Epoch 1034 		 Training Loss: 1.442549935409001
Validation step:0Validation step:1Validation step:2Epoch 1034 		 Validation Loss: 4.3887693881988525
Validation Loss Decreased(4.388823--->4.388769) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1035 / 2500Epoch 1035 		 Training Loss: 1.4427289877619063
Validation step:0Validation step:1Validation step:2Epoch 1035 		 Validation Loss: 4.3886672258377075
Validation Loss Decreased(4.388769--->4.388667) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1036 / 2500Epoch 1036 		 Training Loss: 1.442666002682277
Validation step:0Validation step:1Validation step:2Epoch 1036 		 Validation Loss: 4.388401627540588
Validation Loss Decreased(4.388667--->4.388402) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1037 / 2500Epoch 1037 		 Training Loss: 1.4418163895606995
Validation step:0Validation step:1Validation step:2Epoch 1037 		 Validation Loss: 4.38830292224884
Validation Loss Decreased(4.388402--->4.388303) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1038 / 2500Epoch 1038 		 Training Loss: 1.4428545917783464
Validation step:0Validation step:1Validation step:2Epoch 1038 		 Validation Loss: 4.388060092926025
Validation Loss Decreased(4.388303--->4.388060) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1039 / 2500Epoch 1039 		 Training Loss: 1.442197561264038
Validation step:0Validation step:1Validation step:2Epoch 1039 		 Validation Loss: 4.388014435768127
Validation Loss Decreased(4.388060--->4.388014) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1040 / 2500Epoch 1040 		 Training Loss: 1.4413120916911535
Validation step:0Validation step:1Validation step:2Epoch 1040 		 Validation Loss: 4.387796878814697
Validation Loss Decreased(4.388014--->4.387797) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1041 / 2500Epoch 1041 		 Training Loss: 1.44003860439573
Validation step:0Validation step:1Validation step:2Epoch 1041 		 Validation Loss: 4.387645721435547
Validation Loss Decreased(4.387797--->4.387646) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1042 / 2500Epoch 1042 		 Training Loss: 1.4429112843104772
Validation step:0Validation step:1Validation step:2Epoch 1042 		 Validation Loss: 4.387598872184753
Validation Loss Decreased(4.387646--->4.387599) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1043 / 2500Epoch 1043 		 Training Loss: 1.4412670476096017
Validation step:0Validation step:1Validation step:2Epoch 1043 		 Validation Loss: 4.387363791465759
Validation Loss Decreased(4.387599--->4.387364) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1044 / 2500Epoch 1044 		 Training Loss: 1.4425660371780396
Validation step:0Validation step:1Validation step:2Epoch 1044 		 Validation Loss: 4.387170910835266
Validation Loss Decreased(4.387364--->4.387171) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1045 / 2500Epoch 1045 		 Training Loss: 1.4422438996178764
Validation step:0Validation step:1Validation step:2Epoch 1045 		 Validation Loss: 4.3870720863342285
Validation Loss Decreased(4.387171--->4.387072) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1046 / 2500Epoch 1046 		 Training Loss: 1.4408727203096663
Validation step:0Validation step:1Validation step:2Epoch 1046 		 Validation Loss: 4.3869147300720215
Validation Loss Decreased(4.387072--->4.386915) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1047 / 2500Epoch 1047 		 Training Loss: 1.4425774557249886
Validation step:0Validation step:1Validation step:2Epoch 1047 		 Validation Loss: 4.386772155761719
Validation Loss Decreased(4.386915--->4.386772) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1048 / 2500Epoch 1048 		 Training Loss: 1.442910271031516
Validation step:0Validation step:1Validation step:2Epoch 1048 		 Validation Loss: 4.386655688285828
Validation Loss Decreased(4.386772--->4.386656) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1049 / 2500Epoch 1049 		 Training Loss: 1.441099124295371
Validation step:0Validation step:1Validation step:2Epoch 1049 		 Validation Loss: 4.386431336402893
Validation Loss Decreased(4.386656--->4.386431) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1050 / 2500Epoch 1050 		 Training Loss: 1.4425541758537292
Validation step:0Validation step:1Validation step:2Epoch 1050 		 Validation Loss: 4.386219501495361
Validation Loss Decreased(4.386431--->4.386220) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1051 / 2500Epoch 1051 		 Training Loss: 1.442086500780923
Validation step:0Validation step:1Validation step:2Epoch 1051 		 Validation Loss: 4.386251449584961
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1052 / 2500Epoch 1052 		 Training Loss: 1.4421975868088859
Validation step:0Validation step:1Validation step:2Epoch 1052 		 Validation Loss: 4.385960102081299
Validation Loss Decreased(4.386220--->4.385960) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1053 / 2500Epoch 1053 		 Training Loss: 1.440838669027601
Validation step:0Validation step:1Validation step:2Epoch 1053 		 Validation Loss: 4.385826826095581
Validation Loss Decreased(4.385960--->4.385827) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1054 / 2500Epoch 1054 		 Training Loss: 1.4412645612444197
Validation step:0Validation step:1Validation step:2Epoch 1054 		 Validation Loss: 4.385710716247559
Validation Loss Decreased(4.385827--->4.385711) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1055 / 2500Epoch 1055 		 Training Loss: 1.4404941030911036
Validation step:0Validation step:1Validation step:2Epoch 1055 		 Validation Loss: 4.385589957237244
Validation Loss Decreased(4.385711--->4.385590) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1056 / 2500Epoch 1056 		 Training Loss: 1.441519456250327
Validation step:0Validation step:1Validation step:2Epoch 1056 		 Validation Loss: 4.385408520698547
Validation Loss Decreased(4.385590--->4.385409) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1057 / 2500Epoch 1057 		 Training Loss: 1.4410422018596105
Validation step:0Validation step:1Validation step:2Epoch 1057 		 Validation Loss: 4.385219931602478
Validation Loss Decreased(4.385409--->4.385220) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1058 / 2500Epoch 1058 		 Training Loss: 1.441859747682299
Validation step:0Validation step:1Validation step:2Epoch 1058 		 Validation Loss: 4.3851025104522705
Validation Loss Decreased(4.385220--->4.385103) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1059 / 2500Epoch 1059 		 Training Loss: 1.4394282698631287
Validation step:0Validation step:1Validation step:2Epoch 1059 		 Validation Loss: 4.38501513004303
Validation Loss Decreased(4.385103--->4.385015) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1060 / 2500Epoch 1060 		 Training Loss: 1.441706316811698
Validation step:0Validation step:1Validation step:2Epoch 1060 		 Validation Loss: 4.384693622589111
Validation Loss Decreased(4.385015--->4.384694) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1061 / 2500Epoch 1061 		 Training Loss: 1.4414385046277727
Validation step:0Validation step:1Validation step:2Epoch 1061 		 Validation Loss: 4.384619116783142
Validation Loss Decreased(4.384694--->4.384619) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1062 / 2500Epoch 1062 		 Training Loss: 1.4402236938476562
Validation step:0Validation step:1Validation step:2Epoch 1062 		 Validation Loss: 4.384474992752075
Validation Loss Decreased(4.384619--->4.384475) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1063 / 2500Epoch 1063 		 Training Loss: 1.4412834984915597
Validation step:0Validation step:1Validation step:2Epoch 1063 		 Validation Loss: 4.384302377700806
Validation Loss Decreased(4.384475--->4.384302) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1064 / 2500Epoch 1064 		 Training Loss: 1.4400056174823217
Validation step:0Validation step:1Validation step:2Epoch 1064 		 Validation Loss: 4.384145736694336
Validation Loss Decreased(4.384302--->4.384146) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1065 / 2500Epoch 1065 		 Training Loss: 1.4410098195075989
Validation step:0Validation step:1Validation step:2Epoch 1065 		 Validation Loss: 4.384029030799866
Validation Loss Decreased(4.384146--->4.384029) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1066 / 2500Epoch 1066 		 Training Loss: 1.4410646983555384
Validation step:0Validation step:1Validation step:2Epoch 1066 		 Validation Loss: 4.3838207721710205
Validation Loss Decreased(4.384029--->4.383821) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1067 / 2500Epoch 1067 		 Training Loss: 1.4413779718535287
Validation step:0Validation step:1Validation step:2Epoch 1067 		 Validation Loss: 4.383687376976013
Validation Loss Decreased(4.383821--->4.383687) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1068 / 2500Epoch 1068 		 Training Loss: 1.4413909486361913
Validation step:0Validation step:1Validation step:2Epoch 1068 		 Validation Loss: 4.383639216423035
Validation Loss Decreased(4.383687--->4.383639) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1069 / 2500Epoch 1069 		 Training Loss: 1.441672146320343
Validation step:0Validation step:1Validation step:2Epoch 1069 		 Validation Loss: 4.383375644683838
Validation Loss Decreased(4.383639--->4.383376) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1070 / 2500Epoch 1070 		 Training Loss: 1.4393923708370753
Validation step:0Validation step:1Validation step:2Epoch 1070 		 Validation Loss: 4.38320517539978
Validation Loss Decreased(4.383376--->4.383205) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1071 / 2500Epoch 1071 		 Training Loss: 1.4396635804857527
Validation step:0Validation step:1Validation step:2Epoch 1071 		 Validation Loss: 4.383077502250671
Validation Loss Decreased(4.383205--->4.383078) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1072 / 2500Epoch 1072 		 Training Loss: 1.44035519020898
Validation step:0Validation step:1Validation step:2Epoch 1072 		 Validation Loss: 4.382876873016357
Validation Loss Decreased(4.383078--->4.382877) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1073 / 2500Epoch 1073 		 Training Loss: 1.4408542598996843
Validation step:0Validation step:1Validation step:2Epoch 1073 		 Validation Loss: 4.382755398750305
Validation Loss Decreased(4.382877--->4.382755) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1074 / 2500Epoch 1074 		 Training Loss: 1.4403185929570879
Validation step:0Validation step:1Validation step:2Epoch 1074 		 Validation Loss: 4.3825905323028564
Validation Loss Decreased(4.382755--->4.382591) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1075 / 2500Epoch 1075 		 Training Loss: 1.4401715227535792
Validation step:0Validation step:1Validation step:2Epoch 1075 		 Validation Loss: 4.382414817810059
Validation Loss Decreased(4.382591--->4.382415) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1076 / 2500Epoch 1076 		 Training Loss: 1.4399385026523046
Validation step:0Validation step:1Validation step:2Epoch 1076 		 Validation Loss: 4.382275104522705
Validation Loss Decreased(4.382415--->4.382275) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1077 / 2500Epoch 1077 		 Training Loss: 1.439687192440033
Validation step:0Validation step:1Validation step:2Epoch 1077 		 Validation Loss: 4.382177472114563
Validation Loss Decreased(4.382275--->4.382177) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1078 / 2500Epoch 1078 		 Training Loss: 1.4408095138413566
Validation step:0Validation step:1Validation step:2Epoch 1078 		 Validation Loss: 4.381960868835449
Validation Loss Decreased(4.382177--->4.381961) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1079 / 2500Epoch 1079 		 Training Loss: 1.4400836655071803
Validation step:0Validation step:1Validation step:2Epoch 1079 		 Validation Loss: 4.381774544715881
Validation Loss Decreased(4.381961--->4.381775) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1080 / 2500Epoch 1080 		 Training Loss: 1.4402026704379491
Validation step:0Validation step:1Validation step:2Epoch 1080 		 Validation Loss: 4.381608963012695
Validation Loss Decreased(4.381775--->4.381609) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1081 / 2500Epoch 1081 		 Training Loss: 1.440070356641497
Validation step:0Validation step:1Validation step:2Epoch 1081 		 Validation Loss: 4.381529808044434
Validation Loss Decreased(4.381609--->4.381530) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1082 / 2500Epoch 1082 		 Training Loss: 1.439323467867715
Validation step:0Validation step:1Validation step:2Epoch 1082 		 Validation Loss: 4.381311416625977
Validation Loss Decreased(4.381530--->4.381311) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1083 / 2500Epoch 1083 		 Training Loss: 1.4407202431133814
Validation step:0Validation step:1Validation step:2Epoch 1083 		 Validation Loss: 4.381162166595459
Validation Loss Decreased(4.381311--->4.381162) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1084 / 2500Epoch 1084 		 Training Loss: 1.439577383654458
Validation step:0Validation step:1Validation step:2Epoch 1084 		 Validation Loss: 4.381167888641357
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1085 / 2500Epoch 1085 		 Training Loss: 1.4389531527246748
Validation step:0Validation step:1Validation step:2Epoch 1085 		 Validation Loss: 4.380842566490173
Validation Loss Decreased(4.381162--->4.380843) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1086 / 2500Epoch 1086 		 Training Loss: 1.4409892899649483
Validation step:0Validation step:1Validation step:2Epoch 1086 		 Validation Loss: 4.380724787712097
Validation Loss Decreased(4.380843--->4.380725) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1087 / 2500Epoch 1087 		 Training Loss: 1.4394455126353674
Validation step:0Validation step:1Validation step:2Epoch 1087 		 Validation Loss: 4.380612015724182
Validation Loss Decreased(4.380725--->4.380612) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1088 / 2500Epoch 1088 		 Training Loss: 1.4387171523911613
Validation step:0Validation step:1Validation step:2Epoch 1088 		 Validation Loss: 4.380525827407837
Validation Loss Decreased(4.380612--->4.380526) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1089 / 2500Epoch 1089 		 Training Loss: 1.4395421487944466
Validation step:0Validation step:1Validation step:2Epoch 1089 		 Validation Loss: 4.380310535430908
Validation Loss Decreased(4.380526--->4.380311) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1090 / 2500Epoch 1090 		 Training Loss: 1.4398563248770577
Validation step:0Validation step:1Validation step:2Epoch 1090 		 Validation Loss: 4.380135774612427
Validation Loss Decreased(4.380311--->4.380136) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1091 / 2500Epoch 1091 		 Training Loss: 1.4379205448286874
Validation step:0Validation step:1Validation step:2Epoch 1091 		 Validation Loss: 4.380015254020691
Validation Loss Decreased(4.380136--->4.380015) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1092 / 2500Epoch 1092 		 Training Loss: 1.439826488494873
Validation step:0Validation step:1Validation step:2Epoch 1092 		 Validation Loss: 4.37982702255249
Validation Loss Decreased(4.380015--->4.379827) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1093 / 2500Epoch 1093 		 Training Loss: 1.4381728853498186
Validation step:0Validation step:1Validation step:2Epoch 1093 		 Validation Loss: 4.3796937465667725
Validation Loss Decreased(4.379827--->4.379694) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1094 / 2500Epoch 1094 		 Training Loss: 1.4380116888454981
Validation step:0Validation step:1Validation step:2Epoch 1094 		 Validation Loss: 4.379570722579956
Validation Loss Decreased(4.379694--->4.379571) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1095 / 2500Epoch 1095 		 Training Loss: 1.4397722567830766
Validation step:0Validation step:1Validation step:2Epoch 1095 		 Validation Loss: 4.379401206970215
Validation Loss Decreased(4.379571--->4.379401) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1096 / 2500Epoch 1096 		 Training Loss: 1.4395197119031633
Validation step:0Validation step:1Validation step:2Epoch 1096 		 Validation Loss: 4.379229426383972
Validation Loss Decreased(4.379401--->4.379229) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1097 / 2500Epoch 1097 		 Training Loss: 1.4371869478906905
Validation step:0Validation step:1Validation step:2Epoch 1097 		 Validation Loss: 4.379038333892822
Validation Loss Decreased(4.379229--->4.379038) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1098 / 2500Epoch 1098 		 Training Loss: 1.4392721227237157
Validation step:0Validation step:1Validation step:2Epoch 1098 		 Validation Loss: 4.37886369228363
Validation Loss Decreased(4.379038--->4.378864) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1099 / 2500Epoch 1099 		 Training Loss: 1.4384848475456238
Validation step:0Validation step:1Validation step:2Epoch 1099 		 Validation Loss: 4.378731608390808
Validation Loss Decreased(4.378864--->4.378732) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1100 / 2500Epoch 1100 		 Training Loss: 1.4386220574378967
Validation step:0Validation step:1Validation step:2Epoch 1100 		 Validation Loss: 4.3785823583602905
Validation Loss Decreased(4.378732--->4.378582) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1101 / 2500Epoch 1101 		 Training Loss: 1.4383653146880013
Validation step:0Validation step:1Validation step:2Epoch 1101 		 Validation Loss: 4.3784366846084595
Validation Loss Decreased(4.378582--->4.378437) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1102 / 2500Epoch 1102 		 Training Loss: 1.4392780917031425
Validation step:0Validation step:1Validation step:2Epoch 1102 		 Validation Loss: 4.378327131271362
Validation Loss Decreased(4.378437--->4.378327) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1103 / 2500Epoch 1103 		 Training Loss: 1.4405183792114258
Validation step:0Validation step:1Validation step:2Epoch 1103 		 Validation Loss: 4.3781434297561646
Validation Loss Decreased(4.378327--->4.378143) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1104 / 2500Epoch 1104 		 Training Loss: 1.4401431764875139
Validation step:0Validation step:1Validation step:2Epoch 1104 		 Validation Loss: 4.377990126609802
Validation Loss Decreased(4.378143--->4.377990) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1105 / 2500Epoch 1105 		 Training Loss: 1.437274158000946
Validation step:0Validation step:1Validation step:2Epoch 1105 		 Validation Loss: 4.3778746128082275
Validation Loss Decreased(4.377990--->4.377875) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1106 / 2500Epoch 1106 		 Training Loss: 1.439504018851689
Validation step:0Validation step:1Validation step:2Epoch 1106 		 Validation Loss: 4.377697825431824
Validation Loss Decreased(4.377875--->4.377698) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1107 / 2500Epoch 1107 		 Training Loss: 1.4366058281489782
Validation step:0Validation step:1Validation step:2Epoch 1107 		 Validation Loss: 4.3775471448898315
Validation Loss Decreased(4.377698--->4.377547) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1108 / 2500Epoch 1108 		 Training Loss: 1.4383537854467119
Validation step:0Validation step:1Validation step:2Epoch 1108 		 Validation Loss: 4.377407670021057
Validation Loss Decreased(4.377547--->4.377408) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1109 / 2500Epoch 1109 		 Training Loss: 1.4373532107898168
Validation step:0Validation step:1Validation step:2Epoch 1109 		 Validation Loss: 4.377233624458313
Validation Loss Decreased(4.377408--->4.377234) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1110 / 2500Epoch 1110 		 Training Loss: 1.4385767408779688
Validation step:0Validation step:1Validation step:2Epoch 1110 		 Validation Loss: 4.377166271209717
Validation Loss Decreased(4.377234--->4.377166) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1111 / 2500Epoch 1111 		 Training Loss: 1.4384657910891943
Validation step:0Validation step:1Validation step:2Epoch 1111 		 Validation Loss: 4.376908302307129
Validation Loss Decreased(4.377166--->4.376908) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1112 / 2500Epoch 1112 		 Training Loss: 1.438836702278682
Validation step:0Validation step:1Validation step:2Epoch 1112 		 Validation Loss: 4.376856565475464
Validation Loss Decreased(4.376908--->4.376857) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1113 / 2500Epoch 1113 		 Training Loss: 1.437340293611799
Validation step:0Validation step:1Validation step:2Epoch 1113 		 Validation Loss: 4.376671075820923
Validation Loss Decreased(4.376857--->4.376671) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1114 / 2500Epoch 1114 		 Training Loss: 1.43911098582404
Validation step:0Validation step:1Validation step:2Epoch 1114 		 Validation Loss: 4.376475095748901
Validation Loss Decreased(4.376671--->4.376475) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1115 / 2500Epoch 1115 		 Training Loss: 1.4379366636276245
Validation step:0Validation step:1Validation step:2Epoch 1115 		 Validation Loss: 4.3763861656188965
Validation Loss Decreased(4.376475--->4.376386) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1116 / 2500Epoch 1116 		 Training Loss: 1.4391899364335197
Validation step:0Validation step:1Validation step:2Epoch 1116 		 Validation Loss: 4.376174807548523
Validation Loss Decreased(4.376386--->4.376175) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1117 / 2500Epoch 1117 		 Training Loss: 1.4387746793883187
Validation step:0Validation step:1Validation step:2Epoch 1117 		 Validation Loss: 4.375990152359009
Validation Loss Decreased(4.376175--->4.375990) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1118 / 2500Epoch 1118 		 Training Loss: 1.4396068028041296
Validation step:0Validation step:1Validation step:2Epoch 1118 		 Validation Loss: 4.375884294509888
Validation Loss Decreased(4.375990--->4.375884) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1119 / 2500Epoch 1119 		 Training Loss: 1.436943096773965
Validation step:0Validation step:1Validation step:2Epoch 1119 		 Validation Loss: 4.37589430809021
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1120 / 2500Epoch 1120 		 Training Loss: 1.4391400984355383
Validation step:0Validation step:1Validation step:2Epoch 1120 		 Validation Loss: 4.375576019287109
Validation Loss Decreased(4.375884--->4.375576) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1121 / 2500Epoch 1121 		 Training Loss: 1.4371890340532576
Validation step:0Validation step:1Validation step:2Epoch 1121 		 Validation Loss: 4.375418186187744
Validation Loss Decreased(4.375576--->4.375418) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1122 / 2500Epoch 1122 		 Training Loss: 1.4385495952197485
Validation step:0Validation step:1Validation step:2Epoch 1122 		 Validation Loss: 4.3753135204315186
Validation Loss Decreased(4.375418--->4.375314) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1123 / 2500Epoch 1123 		 Training Loss: 1.4381232602255685
Validation step:0Validation step:1Validation step:2Epoch 1123 		 Validation Loss: 4.375131845474243
Validation Loss Decreased(4.375314--->4.375132) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1124 / 2500Epoch 1124 		 Training Loss: 1.4385864734649658
Validation step:0Validation step:1Validation step:2Epoch 1124 		 Validation Loss: 4.374998688697815
Validation Loss Decreased(4.375132--->4.374999) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1125 / 2500Epoch 1125 		 Training Loss: 1.4386985727718897
Validation step:0Validation step:1Validation step:2Epoch 1125 		 Validation Loss: 4.374877214431763
Validation Loss Decreased(4.374999--->4.374877) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1126 / 2500Epoch 1126 		 Training Loss: 1.4376444986888341
Validation step:0Validation step:1Validation step:2Epoch 1126 		 Validation Loss: 4.3747453689575195
Validation Loss Decreased(4.374877--->4.374745) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1127 / 2500Epoch 1127 		 Training Loss: 1.437618144920894
Validation step:0Validation step:1Validation step:2Epoch 1127 		 Validation Loss: 4.3745269775390625
Validation Loss Decreased(4.374745--->4.374527) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1128 / 2500Epoch 1128 		 Training Loss: 1.4365864396095276
Validation step:0Validation step:1Validation step:2Epoch 1128 		 Validation Loss: 4.374483108520508
Validation Loss Decreased(4.374527--->4.374483) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1129 / 2500Epoch 1129 		 Training Loss: 1.4371826989310128
Validation step:0Validation step:1Validation step:2Epoch 1129 		 Validation Loss: 4.374268054962158
Validation Loss Decreased(4.374483--->4.374268) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1130 / 2500Epoch 1130 		 Training Loss: 1.4376537203788757
Validation step:0Validation step:1Validation step:2Epoch 1130 		 Validation Loss: 4.3741819858551025
Validation Loss Decreased(4.374268--->4.374182) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1131 / 2500Epoch 1131 		 Training Loss: 1.4383442401885986
Validation step:0Validation step:1Validation step:2Epoch 1131 		 Validation Loss: 4.37400221824646
Validation Loss Decreased(4.374182--->4.374002) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1132 / 2500Epoch 1132 		 Training Loss: 1.4373602526528495
Validation step:0Validation step:1Validation step:2Epoch 1132 		 Validation Loss: 4.373775601387024
Validation Loss Decreased(4.374002--->4.373776) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1133 / 2500Epoch 1133 		 Training Loss: 1.4380362033843994
Validation step:0Validation step:1Validation step:2Epoch 1133 		 Validation Loss: 4.373679161071777
Validation Loss Decreased(4.373776--->4.373679) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1134 / 2500Epoch 1134 		 Training Loss: 1.4373173543385096
Validation step:0Validation step:1Validation step:2Epoch 1134 		 Validation Loss: 4.3734859228134155
Validation Loss Decreased(4.373679--->4.373486) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1135 / 2500Epoch 1135 		 Training Loss: 1.438293925353459
Validation step:0Validation step:1Validation step:2Epoch 1135 		 Validation Loss: 4.373508334159851
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1136 / 2500Epoch 1136 		 Training Loss: 1.4388241001537867
Validation step:0Validation step:1Validation step:2Epoch 1136 		 Validation Loss: 4.373336672782898
Validation Loss Decreased(4.373486--->4.373337) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1137 / 2500Epoch 1137 		 Training Loss: 1.43854193176542
Validation step:0Validation step:1Validation step:2Epoch 1137 		 Validation Loss: 4.373044729232788
Validation Loss Decreased(4.373337--->4.373045) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1138 / 2500Epoch 1138 		 Training Loss: 1.435892071042742
Validation step:0Validation step:1Validation step:2Epoch 1138 		 Validation Loss: 4.372892260551453
Validation Loss Decreased(4.373045--->4.372892) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1139 / 2500Epoch 1139 		 Training Loss: 1.43723178761346
Validation step:0Validation step:1Validation step:2Epoch 1139 		 Validation Loss: 4.3727864027023315
Validation Loss Decreased(4.372892--->4.372786) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1140 / 2500Epoch 1140 		 Training Loss: 1.4372201221329826
Validation step:0Validation step:1Validation step:2Epoch 1140 		 Validation Loss: 4.372585296630859
Validation Loss Decreased(4.372786--->4.372585) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1141 / 2500Epoch 1141 		 Training Loss: 1.4365651096616472
Validation step:0Validation step:1Validation step:2Epoch 1141 		 Validation Loss: 4.3724857568740845
Validation Loss Decreased(4.372585--->4.372486) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1142 / 2500Epoch 1142 		 Training Loss: 1.4368605017662048
Validation step:0Validation step:1Validation step:2Epoch 1142 		 Validation Loss: 4.37234628200531
Validation Loss Decreased(4.372486--->4.372346) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1143 / 2500Epoch 1143 		 Training Loss: 1.4365079062325614
Validation step:0Validation step:1Validation step:2Epoch 1143 		 Validation Loss: 4.372270226478577
Validation Loss Decreased(4.372346--->4.372270) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1144 / 2500Epoch 1144 		 Training Loss: 1.4368677479880196
Validation step:0Validation step:1Validation step:2Epoch 1144 		 Validation Loss: 4.372016072273254
Validation Loss Decreased(4.372270--->4.372016) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1145 / 2500Epoch 1145 		 Training Loss: 1.436858858380999
Validation step:0Validation step:1Validation step:2Epoch 1145 		 Validation Loss: 4.371950626373291
Validation Loss Decreased(4.372016--->4.371951) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1146 / 2500Epoch 1146 		 Training Loss: 1.4349886519568307
Validation step:0Validation step:1Validation step:2Epoch 1146 		 Validation Loss: 4.3718181848526
Validation Loss Decreased(4.371951--->4.371818) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1147 / 2500Epoch 1147 		 Training Loss: 1.4355133857045854
Validation step:0Validation step:1Validation step:2Epoch 1147 		 Validation Loss: 4.3716044425964355
Validation Loss Decreased(4.371818--->4.371604) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1148 / 2500Epoch 1148 		 Training Loss: 1.4352538755961828
Validation step:0Validation step:1Validation step:2Epoch 1148 		 Validation Loss: 4.371465682983398
Validation Loss Decreased(4.371604--->4.371466) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1149 / 2500Epoch 1149 		 Training Loss: 1.4376889722687858
Validation step:0Validation step:1Validation step:2Epoch 1149 		 Validation Loss: 4.371385216712952
Validation Loss Decreased(4.371466--->4.371385) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1150 / 2500Epoch 1150 		 Training Loss: 1.4351393495287215
Validation step:0Validation step:1Validation step:2Epoch 1150 		 Validation Loss: 4.371224880218506
Validation Loss Decreased(4.371385--->4.371225) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1151 / 2500Epoch 1151 		 Training Loss: 1.4378636734826225
Validation step:0Validation step:1Validation step:2Epoch 1151 		 Validation Loss: 4.371091842651367
Validation Loss Decreased(4.371225--->4.371092) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1152 / 2500Epoch 1152 		 Training Loss: 1.4364824805940901
Validation step:0Validation step:1Validation step:2Epoch 1152 		 Validation Loss: 4.370814204216003
Validation Loss Decreased(4.371092--->4.370814) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1153 / 2500Epoch 1153 		 Training Loss: 1.436053557055337
Validation step:0Validation step:1Validation step:2Epoch 1153 		 Validation Loss: 4.370715379714966
Validation Loss Decreased(4.370814--->4.370715) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1154 / 2500Epoch 1154 		 Training Loss: 1.4363950065204076
Validation step:0Validation step:1Validation step:2Epoch 1154 		 Validation Loss: 4.3705360889434814
Validation Loss Decreased(4.370715--->4.370536) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1155 / 2500Epoch 1155 		 Training Loss: 1.4372933762414115
Validation step:0Validation step:1Validation step:2Epoch 1155 		 Validation Loss: 4.370345592498779
Validation Loss Decreased(4.370536--->4.370346) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1156 / 2500Epoch 1156 		 Training Loss: 1.4367363878658839
Validation step:0Validation step:1Validation step:2Epoch 1156 		 Validation Loss: 4.370285511016846
Validation Loss Decreased(4.370346--->4.370286) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1157 / 2500Epoch 1157 		 Training Loss: 1.436627549784524
Validation step:0Validation step:1Validation step:2Epoch 1157 		 Validation Loss: 4.370091438293457
Validation Loss Decreased(4.370286--->4.370091) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1158 / 2500Epoch 1158 		 Training Loss: 1.4343363046646118
Validation step:0Validation step:1Validation step:2Epoch 1158 		 Validation Loss: 4.37007200717926
Validation Loss Decreased(4.370091--->4.370072) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1159 / 2500Epoch 1159 		 Training Loss: 1.4335632153919764
Validation step:0Validation step:1Validation step:2Epoch 1159 		 Validation Loss: 4.369784712791443
Validation Loss Decreased(4.370072--->4.369785) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1160 / 2500Epoch 1160 		 Training Loss: 1.436795745577131
Validation step:0Validation step:1Validation step:2Epoch 1160 		 Validation Loss: 4.369711637496948
Validation Loss Decreased(4.369785--->4.369712) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1161 / 2500Epoch 1161 		 Training Loss: 1.4358358638627189
Validation step:0Validation step:1Validation step:2Epoch 1161 		 Validation Loss: 4.369555234909058
Validation Loss Decreased(4.369712--->4.369555) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1162 / 2500Epoch 1162 		 Training Loss: 1.4364580512046814
Validation step:0Validation step:1Validation step:2Epoch 1162 		 Validation Loss: 4.369447588920593
Validation Loss Decreased(4.369555--->4.369448) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1163 / 2500Epoch 1163 		 Training Loss: 1.4369061844689506
Validation step:0Validation step:1Validation step:2Epoch 1163 		 Validation Loss: 4.36922824382782
Validation Loss Decreased(4.369448--->4.369228) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1164 / 2500Epoch 1164 		 Training Loss: 1.4355072123663766
Validation step:0Validation step:1Validation step:2Epoch 1164 		 Validation Loss: 4.369075179100037
Validation Loss Decreased(4.369228--->4.369075) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1165 / 2500Epoch 1165 		 Training Loss: 1.4358536686216081
Validation step:0Validation step:1Validation step:2Epoch 1165 		 Validation Loss: 4.369004845619202
Validation Loss Decreased(4.369075--->4.369005) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1166 / 2500Epoch 1166 		 Training Loss: 1.4347039205687386
Validation step:0Validation step:1Validation step:2Epoch 1166 		 Validation Loss: 4.368797302246094
Validation Loss Decreased(4.369005--->4.368797) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1167 / 2500Epoch 1167 		 Training Loss: 1.4344259755952018
Validation step:0Validation step:1Validation step:2Epoch 1167 		 Validation Loss: 4.368839502334595
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1168 / 2500Epoch 1168 		 Training Loss: 1.436568226133074
Validation step:0Validation step:1Validation step:2Epoch 1168 		 Validation Loss: 4.368601202964783
Validation Loss Decreased(4.368797--->4.368601) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1169 / 2500Epoch 1169 		 Training Loss: 1.4343069536345345
Validation step:0Validation step:1Validation step:2Epoch 1169 		 Validation Loss: 4.368437051773071
Validation Loss Decreased(4.368601--->4.368437) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1170 / 2500Epoch 1170 		 Training Loss: 1.4350757428577967
Validation step:0Validation step:1Validation step:2Epoch 1170 		 Validation Loss: 4.368357539176941
Validation Loss Decreased(4.368437--->4.368358) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1171 / 2500Epoch 1171 		 Training Loss: 1.4351402265684945
Validation step:0Validation step:1Validation step:2Epoch 1171 		 Validation Loss: 4.368173360824585
Validation Loss Decreased(4.368358--->4.368173) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1172 / 2500Epoch 1172 		 Training Loss: 1.4350995080811637
Validation step:0Validation step:1Validation step:2Epoch 1172 		 Validation Loss: 4.367955327033997
Validation Loss Decreased(4.368173--->4.367955) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1173 / 2500Epoch 1173 		 Training Loss: 1.4366012471062797
Validation step:0Validation step:1Validation step:2Epoch 1173 		 Validation Loss: 4.367923021316528
Validation Loss Decreased(4.367955--->4.367923) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1174 / 2500Epoch 1174 		 Training Loss: 1.4354329875537328
Validation step:0Validation step:1Validation step:2Epoch 1174 		 Validation Loss: 4.367685914039612
Validation Loss Decreased(4.367923--->4.367686) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1175 / 2500Epoch 1175 		 Training Loss: 1.4338819640023368
Validation step:0Validation step:1Validation step:2Epoch 1175 		 Validation Loss: 4.367737650871277
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1176 / 2500Epoch 1176 		 Training Loss: 1.4346506340163094
Validation step:0Validation step:1Validation step:2Epoch 1176 		 Validation Loss: 4.36738133430481
Validation Loss Decreased(4.367686--->4.367381) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1177 / 2500Epoch 1177 		 Training Loss: 1.4345531037875585
Validation step:0Validation step:1Validation step:2Epoch 1177 		 Validation Loss: 4.3672730922698975
Validation Loss Decreased(4.367381--->4.367273) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1178 / 2500Epoch 1178 		 Training Loss: 1.434850079672677
Validation step:0Validation step:1Validation step:2Epoch 1178 		 Validation Loss: 4.367215275764465
Validation Loss Decreased(4.367273--->4.367215) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1179 / 2500Epoch 1179 		 Training Loss: 1.434562393597194
Validation step:0Validation step:1Validation step:2Epoch 1179 		 Validation Loss: 4.3670172691345215
Validation Loss Decreased(4.367215--->4.367017) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1180 / 2500Epoch 1180 		 Training Loss: 1.4354279126439775
Validation step:0Validation step:1Validation step:2Epoch 1180 		 Validation Loss: 4.3669188022613525
Validation Loss Decreased(4.367017--->4.366919) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1181 / 2500Epoch 1181 		 Training Loss: 1.4337159906114851
Validation step:0Validation step:1Validation step:2Epoch 1181 		 Validation Loss: 4.366759777069092
Validation Loss Decreased(4.366919--->4.366760) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1182 / 2500Epoch 1182 		 Training Loss: 1.4345973815236772
Validation step:0Validation step:1Validation step:2Epoch 1182 		 Validation Loss: 4.366572380065918
Validation Loss Decreased(4.366760--->4.366572) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1183 / 2500Epoch 1183 		 Training Loss: 1.4355207766805376
Validation step:0Validation step:1Validation step:2Epoch 1183 		 Validation Loss: 4.366574764251709
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1184 / 2500Epoch 1184 		 Training Loss: 1.4363106659480505
Validation step:0Validation step:1Validation step:2Epoch 1184 		 Validation Loss: 4.366280198097229
Validation Loss Decreased(4.366572--->4.366280) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1185 / 2500Epoch 1185 		 Training Loss: 1.4346710017749242
Validation step:0Validation step:1Validation step:2Epoch 1185 		 Validation Loss: 4.3661322593688965
Validation Loss Decreased(4.366280--->4.366132) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1186 / 2500Epoch 1186 		 Training Loss: 1.4338379502296448
Validation step:0Validation step:1Validation step:2Epoch 1186 		 Validation Loss: 4.366057753562927
Validation Loss Decreased(4.366132--->4.366058) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1187 / 2500Epoch 1187 		 Training Loss: 1.434103216443743
Validation step:0Validation step:1Validation step:2Epoch 1187 		 Validation Loss: 4.365943789482117
Validation Loss Decreased(4.366058--->4.365944) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1188 / 2500Epoch 1188 		 Training Loss: 1.4339978098869324
Validation step:0Validation step:1Validation step:2Epoch 1188 		 Validation Loss: 4.365769743919373
Validation Loss Decreased(4.365944--->4.365770) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1189 / 2500Epoch 1189 		 Training Loss: 1.4345470581735884
Validation step:0Validation step:1Validation step:2Epoch 1189 		 Validation Loss: 4.365689277648926
Validation Loss Decreased(4.365770--->4.365689) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1190 / 2500Epoch 1190 		 Training Loss: 1.4330288512366158
Validation step:0Validation step:1Validation step:2Epoch 1190 		 Validation Loss: 4.365480184555054
Validation Loss Decreased(4.365689--->4.365480) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1191 / 2500Epoch 1191 		 Training Loss: 1.4348378011158534
Validation step:0Validation step:1Validation step:2Epoch 1191 		 Validation Loss: 4.365304946899414
Validation Loss Decreased(4.365480--->4.365305) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1192 / 2500Epoch 1192 		 Training Loss: 1.4341253297669547
Validation step:0Validation step:1Validation step:2Epoch 1192 		 Validation Loss: 4.365185856819153
Validation Loss Decreased(4.365305--->4.365186) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1193 / 2500Epoch 1193 		 Training Loss: 1.4337957331112452
Validation step:0Validation step:1Validation step:2Epoch 1193 		 Validation Loss: 4.365220546722412
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1194 / 2500Epoch 1194 		 Training Loss: 1.4341027396065849
Validation step:0Validation step:1Validation step:2Epoch 1194 		 Validation Loss: 4.36491847038269
Validation Loss Decreased(4.365186--->4.364918) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1195 / 2500Epoch 1195 		 Training Loss: 1.4346669145992823
Validation step:0Validation step:1Validation step:2Epoch 1195 		 Validation Loss: 4.36476194858551
Validation Loss Decreased(4.364918--->4.364762) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1196 / 2500Epoch 1196 		 Training Loss: 1.432637563773564
Validation step:0Validation step:1Validation step:2Epoch 1196 		 Validation Loss: 4.3646146059036255
Validation Loss Decreased(4.364762--->4.364615) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1197 / 2500Epoch 1197 		 Training Loss: 1.4332729918616158
Validation step:0Validation step:1Validation step:2Epoch 1197 		 Validation Loss: 4.364572644233704
Validation Loss Decreased(4.364615--->4.364573) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1198 / 2500Epoch 1198 		 Training Loss: 1.4339348673820496
Validation step:0Validation step:1Validation step:2Epoch 1198 		 Validation Loss: 4.364368915557861
Validation Loss Decreased(4.364573--->4.364369) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1199 / 2500Epoch 1199 		 Training Loss: 1.4342194710459029
Validation step:0Validation step:1Validation step:2Epoch 1199 		 Validation Loss: 4.364216566085815
Validation Loss Decreased(4.364369--->4.364217) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1200 / 2500Epoch 1200 		 Training Loss: 1.4338644061769759
Validation step:0Validation step:1Validation step:2Epoch 1200 		 Validation Loss: 4.364090442657471
Validation Loss Decreased(4.364217--->4.364090) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1201 / 2500Epoch 1201 		 Training Loss: 1.433305995804923
Validation step:0Validation step:1Validation step:2Epoch 1201 		 Validation Loss: 4.364094257354736
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1202 / 2500Epoch 1202 		 Training Loss: 1.4335687586239405
Validation step:0Validation step:1Validation step:2Epoch 1202 		 Validation Loss: 4.363797426223755
Validation Loss Decreased(4.364090--->4.363797) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1203 / 2500Epoch 1203 		 Training Loss: 1.4349867446081979
Validation step:0Validation step:1Validation step:2Epoch 1203 		 Validation Loss: 4.363706946372986
Validation Loss Decreased(4.363797--->4.363707) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1204 / 2500Epoch 1204 		 Training Loss: 1.4344868149076189
Validation step:0Validation step:1Validation step:2Epoch 1204 		 Validation Loss: 4.363566875457764
Validation Loss Decreased(4.363707--->4.363567) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1205 / 2500Epoch 1205 		 Training Loss: 1.433062834399087
Validation step:0Validation step:1Validation step:2Epoch 1205 		 Validation Loss: 4.363418936729431
Validation Loss Decreased(4.363567--->4.363419) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1206 / 2500Epoch 1206 		 Training Loss: 1.4332716805594308
Validation step:0Validation step:1Validation step:2Epoch 1206 		 Validation Loss: 4.363254547119141
Validation Loss Decreased(4.363419--->4.363255) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1207 / 2500Epoch 1207 		 Training Loss: 1.433170633656638
Validation step:0Validation step:1Validation step:2Epoch 1207 		 Validation Loss: 4.3631051778793335
Validation Loss Decreased(4.363255--->4.363105) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1208 / 2500Epoch 1208 		 Training Loss: 1.4339242492403304
Validation step:0Validation step:1Validation step:2Epoch 1208 		 Validation Loss: 4.363049507141113
Validation Loss Decreased(4.363105--->4.363050) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1209 / 2500Epoch 1209 		 Training Loss: 1.4332221065248762
Validation step:0Validation step:1Validation step:2Epoch 1209 		 Validation Loss: 4.362864017486572
Validation Loss Decreased(4.363050--->4.362864) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1210 / 2500Epoch 1210 		 Training Loss: 1.432780112539019
Validation step:0Validation step:1Validation step:2Epoch 1210 		 Validation Loss: 4.362680196762085
Validation Loss Decreased(4.362864--->4.362680) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1211 / 2500Epoch 1211 		 Training Loss: 1.433351959500994
Validation step:0Validation step:1Validation step:2Epoch 1211 		 Validation Loss: 4.362560749053955
Validation Loss Decreased(4.362680--->4.362561) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1212 / 2500Epoch 1212 		 Training Loss: 1.4341822011130196
Validation step:0Validation step:1Validation step:2Epoch 1212 		 Validation Loss: 4.362491726875305
Validation Loss Decreased(4.362561--->4.362492) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1213 / 2500Epoch 1213 		 Training Loss: 1.432811677455902
Validation step:0Validation step:1Validation step:2Epoch 1213 		 Validation Loss: 4.362353205680847
Validation Loss Decreased(4.362492--->4.362353) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1214 / 2500Epoch 1214 		 Training Loss: 1.4347485389028276
Validation step:0Validation step:1Validation step:2Epoch 1214 		 Validation Loss: 4.362151503562927
Validation Loss Decreased(4.362353--->4.362152) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1215 / 2500Epoch 1215 		 Training Loss: 1.4333408645221166
Validation step:0Validation step:1Validation step:2Epoch 1215 		 Validation Loss: 4.362048625946045
Validation Loss Decreased(4.362152--->4.362049) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1216 / 2500Epoch 1216 		 Training Loss: 1.4338857786996024
Validation step:0Validation step:1Validation step:2Epoch 1216 		 Validation Loss: 4.361974716186523
Validation Loss Decreased(4.362049--->4.361975) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1217 / 2500Epoch 1217 		 Training Loss: 1.4326410038130624
Validation step:0Validation step:1Validation step:2Epoch 1217 		 Validation Loss: 4.3617905378341675
Validation Loss Decreased(4.361975--->4.361791) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1218 / 2500Epoch 1218 		 Training Loss: 1.432475439139775
Validation step:0Validation step:1Validation step:2Epoch 1218 		 Validation Loss: 4.361693620681763
Validation Loss Decreased(4.361791--->4.361694) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1219 / 2500Epoch 1219 		 Training Loss: 1.433692651135581
Validation step:0Validation step:1Validation step:2Epoch 1219 		 Validation Loss: 4.361594915390015
Validation Loss Decreased(4.361694--->4.361595) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1220 / 2500Epoch 1220 		 Training Loss: 1.431579325880323
Validation step:0Validation step:1Validation step:2Epoch 1220 		 Validation Loss: 4.361436605453491
Validation Loss Decreased(4.361595--->4.361437) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1221 / 2500Epoch 1221 		 Training Loss: 1.4334512948989868
Validation step:0Validation step:1Validation step:2Epoch 1221 		 Validation Loss: 4.361319661140442
Validation Loss Decreased(4.361437--->4.361320) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1222 / 2500Epoch 1222 		 Training Loss: 1.4312195522444588
Validation step:0Validation step:1Validation step:2Epoch 1222 		 Validation Loss: 4.361086130142212
Validation Loss Decreased(4.361320--->4.361086) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1223 / 2500Epoch 1223 		 Training Loss: 1.4321350710732597
Validation step:0Validation step:1Validation step:2Epoch 1223 		 Validation Loss: 4.360981583595276
Validation Loss Decreased(4.361086--->4.360982) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1224 / 2500Epoch 1224 		 Training Loss: 1.4333077754293169
Validation step:0Validation step:1Validation step:2Epoch 1224 		 Validation Loss: 4.360908627510071
Validation Loss Decreased(4.360982--->4.360909) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1225 / 2500Epoch 1225 		 Training Loss: 1.4330745083945138
Validation step:0Validation step:1Validation step:2Epoch 1225 		 Validation Loss: 4.360662460327148
Validation Loss Decreased(4.360909--->4.360662) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1226 / 2500Epoch 1226 		 Training Loss: 1.4323779600007194
Validation step:0Validation step:1Validation step:2Epoch 1226 		 Validation Loss: 4.360649228096008
Validation Loss Decreased(4.360662--->4.360649) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1227 / 2500Epoch 1227 		 Training Loss: 1.4327449883733476
Validation step:0Validation step:1Validation step:2Epoch 1227 		 Validation Loss: 4.360505938529968
Validation Loss Decreased(4.360649--->4.360506) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1228 / 2500Epoch 1228 		 Training Loss: 1.432054306779589
Validation step:0Validation step:1Validation step:2Epoch 1228 		 Validation Loss: 4.360319018363953
Validation Loss Decreased(4.360506--->4.360319) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1229 / 2500Epoch 1229 		 Training Loss: 1.4331661718232291
Validation step:0Validation step:1Validation step:2Epoch 1229 		 Validation Loss: 4.360130429267883
Validation Loss Decreased(4.360319--->4.360130) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1230 / 2500Epoch 1230 		 Training Loss: 1.4321818947792053
Validation step:0Validation step:1Validation step:2Epoch 1230 		 Validation Loss: 4.360149502754211
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1231 / 2500Epoch 1231 		 Training Loss: 1.4323858278138297
Validation step:0Validation step:1Validation step:2Epoch 1231 		 Validation Loss: 4.359881401062012
Validation Loss Decreased(4.360130--->4.359881) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1232 / 2500Epoch 1232 		 Training Loss: 1.4316357629639762
Validation step:0Validation step:1Validation step:2Epoch 1232 		 Validation Loss: 4.359768390655518
Validation Loss Decreased(4.359881--->4.359768) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1233 / 2500Epoch 1233 		 Training Loss: 1.4331289529800415
Validation step:0Validation step:1Validation step:2Epoch 1233 		 Validation Loss: 4.359808325767517
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1234 / 2500Epoch 1234 		 Training Loss: 1.4324910640716553
Validation step:0Validation step:1Validation step:2Epoch 1234 		 Validation Loss: 4.359490156173706
Validation Loss Decreased(4.359768--->4.359490) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1235 / 2500Epoch 1235 		 Training Loss: 1.4312074780464172
Validation step:0Validation step:1Validation step:2Epoch 1235 		 Validation Loss: 4.359405279159546
Validation Loss Decreased(4.359490--->4.359405) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1236 / 2500Epoch 1236 		 Training Loss: 1.4318523577281408
Validation step:0Validation step:1Validation step:2Epoch 1236 		 Validation Loss: 4.3592529296875
Validation Loss Decreased(4.359405--->4.359253) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1237 / 2500Epoch 1237 		 Training Loss: 1.4298050659043449
Validation step:0Validation step:1Validation step:2Epoch 1237 		 Validation Loss: 4.359176754951477
Validation Loss Decreased(4.359253--->4.359177) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1238 / 2500Epoch 1238 		 Training Loss: 1.432772261755807
Validation step:0Validation step:1Validation step:2Epoch 1238 		 Validation Loss: 4.358948469161987
Validation Loss Decreased(4.359177--->4.358948) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1239 / 2500Epoch 1239 		 Training Loss: 1.4325007455689567
Validation step:0Validation step:1Validation step:2Epoch 1239 		 Validation Loss: 4.358797669410706
Validation Loss Decreased(4.358948--->4.358798) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1240 / 2500Epoch 1240 		 Training Loss: 1.4310506922858102
Validation step:0Validation step:1Validation step:2Epoch 1240 		 Validation Loss: 4.358753323554993
Validation Loss Decreased(4.358798--->4.358753) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1241 / 2500Epoch 1241 		 Training Loss: 1.4330732566969735
Validation step:0Validation step:1Validation step:2Epoch 1241 		 Validation Loss: 4.3585838079452515
Validation Loss Decreased(4.358753--->4.358584) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1242 / 2500Epoch 1242 		 Training Loss: 1.4316302793366569
Validation step:0Validation step:1Validation step:2Epoch 1242 		 Validation Loss: 4.3583903312683105
Validation Loss Decreased(4.358584--->4.358390) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1243 / 2500Epoch 1243 		 Training Loss: 1.4310084240777152
Validation step:0Validation step:1Validation step:2Epoch 1243 		 Validation Loss: 4.358354330062866
Validation Loss Decreased(4.358390--->4.358354) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1244 / 2500Epoch 1244 		 Training Loss: 1.431741280215127
Validation step:0Validation step:1Validation step:2Epoch 1244 		 Validation Loss: 4.358229398727417
Validation Loss Decreased(4.358354--->4.358229) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1245 / 2500Epoch 1245 		 Training Loss: 1.4326961210795812
Validation step:0Validation step:1Validation step:2Epoch 1245 		 Validation Loss: 4.358104586601257
Validation Loss Decreased(4.358229--->4.358105) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1246 / 2500Epoch 1246 		 Training Loss: 1.432352670601436
Validation step:0Validation step:1Validation step:2Epoch 1246 		 Validation Loss: 4.357899904251099
Validation Loss Decreased(4.358105--->4.357900) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1247 / 2500Epoch 1247 		 Training Loss: 1.4293290717261178
Validation step:0Validation step:1Validation step:2Epoch 1247 		 Validation Loss: 4.3578596115112305
Validation Loss Decreased(4.357900--->4.357860) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1248 / 2500Epoch 1248 		 Training Loss: 1.4314203432628088
Validation step:0Validation step:1Validation step:2Epoch 1248 		 Validation Loss: 4.357648849487305
Validation Loss Decreased(4.357860--->4.357649) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1249 / 2500Epoch 1249 		 Training Loss: 1.4317217043467931
Validation step:0Validation step:1Validation step:2Epoch 1249 		 Validation Loss: 4.357475638389587
Validation Loss Decreased(4.357649--->4.357476) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1250 / 2500Epoch 1250 		 Training Loss: 1.4330170239721025
Validation step:0Validation step:1Validation step:2Epoch 1250 		 Validation Loss: 4.3573548793792725
Validation Loss Decreased(4.357476--->4.357355) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1251 / 2500Epoch 1251 		 Training Loss: 1.4329185570989336
Validation step:0Validation step:1Validation step:2Epoch 1251 		 Validation Loss: 4.357388734817505
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1252 / 2500Epoch 1252 		 Training Loss: 1.429510167666844
Validation step:0Validation step:1Validation step:2Epoch 1252 		 Validation Loss: 4.357041716575623
Validation Loss Decreased(4.357355--->4.357042) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1253 / 2500Epoch 1253 		 Training Loss: 1.4308920162064689
Validation step:0Validation step:1Validation step:2Epoch 1253 		 Validation Loss: 4.356945633888245
Validation Loss Decreased(4.357042--->4.356946) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1254 / 2500Epoch 1254 		 Training Loss: 1.4318495052201408
Validation step:0Validation step:1Validation step:2Epoch 1254 		 Validation Loss: 4.356876611709595
Validation Loss Decreased(4.356946--->4.356877) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1255 / 2500Epoch 1255 		 Training Loss: 1.4324219567435128
Validation step:0Validation step:1Validation step:2Epoch 1255 		 Validation Loss: 4.35667359828949
Validation Loss Decreased(4.356877--->4.356674) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1256 / 2500Epoch 1256 		 Training Loss: 1.430747389793396
Validation step:0Validation step:1Validation step:2Epoch 1256 		 Validation Loss: 4.356599926948547
Validation Loss Decreased(4.356674--->4.356600) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1257 / 2500Epoch 1257 		 Training Loss: 1.432040810585022
Validation step:0Validation step:1Validation step:2Epoch 1257 		 Validation Loss: 4.3563655614852905
Validation Loss Decreased(4.356600--->4.356366) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1258 / 2500Epoch 1258 		 Training Loss: 1.4310041666030884
Validation step:0Validation step:1Validation step:2Epoch 1258 		 Validation Loss: 4.356216073036194
Validation Loss Decreased(4.356366--->4.356216) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1259 / 2500Epoch 1259 		 Training Loss: 1.4303871137755257
Validation step:0Validation step:1Validation step:2Epoch 1259 		 Validation Loss: 4.356097221374512
Validation Loss Decreased(4.356216--->4.356097) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1260 / 2500Epoch 1260 		 Training Loss: 1.4308675357273646
Validation step:0Validation step:1Validation step:2Epoch 1260 		 Validation Loss: 4.356008529663086
Validation Loss Decreased(4.356097--->4.356009) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1261 / 2500Epoch 1261 		 Training Loss: 1.4297095452036177
Validation step:0Validation step:1Validation step:2Epoch 1261 		 Validation Loss: 4.355843663215637
Validation Loss Decreased(4.356009--->4.355844) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1262 / 2500Epoch 1262 		 Training Loss: 1.430933109351567
Validation step:0Validation step:1Validation step:2Epoch 1262 		 Validation Loss: 4.355692505836487
Validation Loss Decreased(4.355844--->4.355693) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1263 / 2500Epoch 1263 		 Training Loss: 1.4296710576329912
Validation step:0Validation step:1Validation step:2Epoch 1263 		 Validation Loss: 4.355584263801575
Validation Loss Decreased(4.355693--->4.355584) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1264 / 2500Epoch 1264 		 Training Loss: 1.430225738457271
Validation step:0Validation step:1Validation step:2Epoch 1264 		 Validation Loss: 4.355523586273193
Validation Loss Decreased(4.355584--->4.355524) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1265 / 2500Epoch 1265 		 Training Loss: 1.4293936405863081
Validation step:0Validation step:1Validation step:2Epoch 1265 		 Validation Loss: 4.355307579040527
Validation Loss Decreased(4.355524--->4.355308) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1266 / 2500Epoch 1266 		 Training Loss: 1.4304527129445757
Validation step:0Validation step:1Validation step:2Epoch 1266 		 Validation Loss: 4.355204820632935
Validation Loss Decreased(4.355308--->4.355205) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1267 / 2500Epoch 1267 		 Training Loss: 1.4310355016163416
Validation step:0Validation step:1Validation step:2Epoch 1267 		 Validation Loss: 4.355060577392578
Validation Loss Decreased(4.355205--->4.355061) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1268 / 2500Epoch 1268 		 Training Loss: 1.4312559110777718
Validation step:0Validation step:1Validation step:2Epoch 1268 		 Validation Loss: 4.354909658432007
Validation Loss Decreased(4.355061--->4.354910) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1269 / 2500Epoch 1269 		 Training Loss: 1.4302263515336173
Validation step:0Validation step:1Validation step:2Epoch 1269 		 Validation Loss: 4.35482656955719
Validation Loss Decreased(4.354910--->4.354827) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1270 / 2500Epoch 1270 		 Training Loss: 1.429557238306318
Validation step:0Validation step:1Validation step:2Epoch 1270 		 Validation Loss: 4.354600787162781
Validation Loss Decreased(4.354827--->4.354601) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1271 / 2500Epoch 1271 		 Training Loss: 1.4309383034706116
Validation step:0Validation step:1Validation step:2Epoch 1271 		 Validation Loss: 4.354559898376465
Validation Loss Decreased(4.354601--->4.354560) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1272 / 2500Epoch 1272 		 Training Loss: 1.4313225405556815
Validation step:0Validation step:1Validation step:2Epoch 1272 		 Validation Loss: 4.354400396347046
Validation Loss Decreased(4.354560--->4.354400) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1273 / 2500Epoch 1273 		 Training Loss: 1.4311949270112174
Validation step:0Validation step:1Validation step:2Epoch 1273 		 Validation Loss: 4.354253888130188
Validation Loss Decreased(4.354400--->4.354254) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1274 / 2500Epoch 1274 		 Training Loss: 1.4305218032428197
Validation step:0Validation step:1Validation step:2Epoch 1274 		 Validation Loss: 4.354185223579407
Validation Loss Decreased(4.354254--->4.354185) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1275 / 2500Epoch 1275 		 Training Loss: 1.4311516284942627
Validation step:0Validation step:1Validation step:2Epoch 1275 		 Validation Loss: 4.353973627090454
Validation Loss Decreased(4.354185--->4.353974) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1276 / 2500Epoch 1276 		 Training Loss: 1.4308564407484872
Validation step:0Validation step:1Validation step:2Epoch 1276 		 Validation Loss: 4.35383141040802
Validation Loss Decreased(4.353974--->4.353831) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1277 / 2500Epoch 1277 		 Training Loss: 1.4314562337739127
Validation step:0Validation step:1Validation step:2Epoch 1277 		 Validation Loss: 4.353842854499817
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1278 / 2500Epoch 1278 		 Training Loss: 1.4291992698396956
Validation step:0Validation step:1Validation step:2Epoch 1278 		 Validation Loss: 4.35361635684967
Validation Loss Decreased(4.353831--->4.353616) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1279 / 2500Epoch 1279 		 Training Loss: 1.431038303034646
Validation step:0Validation step:1Validation step:2Epoch 1279 		 Validation Loss: 4.353543996810913
Validation Loss Decreased(4.353616--->4.353544) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1280 / 2500Epoch 1280 		 Training Loss: 1.4304147533008031
Validation step:0Validation step:1Validation step:2Epoch 1280 		 Validation Loss: 4.353359580039978
Validation Loss Decreased(4.353544--->4.353360) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1281 / 2500Epoch 1281 		 Training Loss: 1.4280854974474226
Validation step:0Validation step:1Validation step:2Epoch 1281 		 Validation Loss: 4.353247404098511
Validation Loss Decreased(4.353360--->4.353247) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1282 / 2500Epoch 1282 		 Training Loss: 1.4301206128937858
Validation step:0Validation step:1Validation step:2Epoch 1282 		 Validation Loss: 4.353047013282776
Validation Loss Decreased(4.353247--->4.353047) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1283 / 2500Epoch 1283 		 Training Loss: 1.429787882736751
Validation step:0Validation step:1Validation step:2Epoch 1283 		 Validation Loss: 4.353075385093689
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1284 / 2500Epoch 1284 		 Training Loss: 1.4300968306405204
Validation step:0Validation step:1Validation step:2Epoch 1284 		 Validation Loss: 4.3528372049331665
Validation Loss Decreased(4.353047--->4.352837) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1285 / 2500Epoch 1285 		 Training Loss: 1.4299686125346593
Validation step:0Validation step:1Validation step:2Epoch 1285 		 Validation Loss: 4.35272479057312
Validation Loss Decreased(4.352837--->4.352725) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1286 / 2500Epoch 1286 		 Training Loss: 1.4304227828979492
Validation step:0Validation step:1Validation step:2Epoch 1286 		 Validation Loss: 4.352667689323425
Validation Loss Decreased(4.352725--->4.352668) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1287 / 2500Epoch 1287 		 Training Loss: 1.429580875805446
Validation step:0Validation step:1Validation step:2Epoch 1287 		 Validation Loss: 4.352435946464539
Validation Loss Decreased(4.352668--->4.352436) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1288 / 2500Epoch 1288 		 Training Loss: 1.4296721049717493
Validation step:0Validation step:1Validation step:2Epoch 1288 		 Validation Loss: 4.352320551872253
Validation Loss Decreased(4.352436--->4.352321) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1289 / 2500Epoch 1289 		 Training Loss: 1.4284212929861886
Validation step:0Validation step:1Validation step:2Epoch 1289 		 Validation Loss: 4.35225510597229
Validation Loss Decreased(4.352321--->4.352255) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1290 / 2500Epoch 1290 		 Training Loss: 1.4281334451266698
Validation step:0Validation step:1Validation step:2Epoch 1290 		 Validation Loss: 4.352093935012817
Validation Loss Decreased(4.352255--->4.352094) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1291 / 2500Epoch 1291 		 Training Loss: 1.430182899747576
Validation step:0Validation step:1Validation step:2Epoch 1291 		 Validation Loss: 4.351891040802002
Validation Loss Decreased(4.352094--->4.351891) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1292 / 2500Epoch 1292 		 Training Loss: 1.4295196533203125
Validation step:0Validation step:1Validation step:2Epoch 1292 		 Validation Loss: 4.3518571853637695
Validation Loss Decreased(4.351891--->4.351857) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1293 / 2500Epoch 1293 		 Training Loss: 1.42777852501188
Validation step:0Validation step:1Validation step:2Epoch 1293 		 Validation Loss: 4.3516833782196045
Validation Loss Decreased(4.351857--->4.351683) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1294 / 2500Epoch 1294 		 Training Loss: 1.4290217076029097
Validation step:0Validation step:1Validation step:2Epoch 1294 		 Validation Loss: 4.351572632789612
Validation Loss Decreased(4.351683--->4.351573) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1295 / 2500Epoch 1295 		 Training Loss: 1.4296822207314628
Validation step:0Validation step:1Validation step:2Epoch 1295 		 Validation Loss: 4.3513935804367065
Validation Loss Decreased(4.351573--->4.351394) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1296 / 2500Epoch 1296 		 Training Loss: 1.429276100226811
Validation step:0Validation step:1Validation step:2Epoch 1296 		 Validation Loss: 4.351217269897461
Validation Loss Decreased(4.351394--->4.351217) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1297 / 2500Epoch 1297 		 Training Loss: 1.4295348184449332
Validation step:0Validation step:1Validation step:2Epoch 1297 		 Validation Loss: 4.351121544837952
Validation Loss Decreased(4.351217--->4.351122) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1298 / 2500Epoch 1298 		 Training Loss: 1.4299639633723669
Validation step:0Validation step:1Validation step:2Epoch 1298 		 Validation Loss: 4.350963115692139
Validation Loss Decreased(4.351122--->4.350963) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1299 / 2500Epoch 1299 		 Training Loss: 1.4284361686025346
Validation step:0Validation step:1Validation step:2Epoch 1299 		 Validation Loss: 4.350850582122803
Validation Loss Decreased(4.350963--->4.350851) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1300 / 2500Epoch 1300 		 Training Loss: 1.427730211189815
Validation step:0Validation step:1Validation step:2Epoch 1300 		 Validation Loss: 4.350787997245789
Validation Loss Decreased(4.350851--->4.350788) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1301 / 2500Epoch 1301 		 Training Loss: 1.4300072533743722
Validation step:0Validation step:1Validation step:2Epoch 1301 		 Validation Loss: 4.3507267236709595
Validation Loss Decreased(4.350788--->4.350727) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1302 / 2500Epoch 1302 		 Training Loss: 1.42823269537517
Validation step:0Validation step:1Validation step:2Epoch 1302 		 Validation Loss: 4.350470662117004
Validation Loss Decreased(4.350727--->4.350471) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1303 / 2500Epoch 1303 		 Training Loss: 1.4298296059880937
Validation step:0Validation step:1Validation step:2Epoch 1303 		 Validation Loss: 4.3503737449646
Validation Loss Decreased(4.350471--->4.350374) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1304 / 2500Epoch 1304 		 Training Loss: 1.4288146666118078
Validation step:0Validation step:1Validation step:2Epoch 1304 		 Validation Loss: 4.350240588188171
Validation Loss Decreased(4.350374--->4.350241) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1305 / 2500Epoch 1305 		 Training Loss: 1.4292091982705253
Validation step:0Validation step:1Validation step:2Epoch 1305 		 Validation Loss: 4.350166440010071
Validation Loss Decreased(4.350241--->4.350166) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1306 / 2500Epoch 1306 		 Training Loss: 1.4257547514779227
Validation step:0Validation step:1Validation step:2Epoch 1306 		 Validation Loss: 4.3500401973724365
Validation Loss Decreased(4.350166--->4.350040) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1307 / 2500Epoch 1307 		 Training Loss: 1.4297781160899572
Validation step:0Validation step:1Validation step:2Epoch 1307 		 Validation Loss: 4.3498454093933105
Validation Loss Decreased(4.350040--->4.349845) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1308 / 2500Epoch 1308 		 Training Loss: 1.42911034822464
Validation step:0Validation step:1Validation step:2Epoch 1308 		 Validation Loss: 4.349790453910828
Validation Loss Decreased(4.349845--->4.349790) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1309 / 2500Epoch 1309 		 Training Loss: 1.4278960994311742
Validation step:0Validation step:1Validation step:2Epoch 1309 		 Validation Loss: 4.34963059425354
Validation Loss Decreased(4.349790--->4.349631) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1310 / 2500Epoch 1310 		 Training Loss: 1.4292609776769365
Validation step:0Validation step:1Validation step:2Epoch 1310 		 Validation Loss: 4.349491000175476
Validation Loss Decreased(4.349631--->4.349491) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1311 / 2500Epoch 1311 		 Training Loss: 1.4280685952731542
Validation step:0Validation step:1Validation step:2Epoch 1311 		 Validation Loss: 4.349360704421997
Validation Loss Decreased(4.349491--->4.349361) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1312 / 2500Epoch 1312 		 Training Loss: 1.4275695170675005
Validation step:0Validation step:1Validation step:2Epoch 1312 		 Validation Loss: 4.3493324518203735
Validation Loss Decreased(4.349361--->4.349332) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1313 / 2500Epoch 1313 		 Training Loss: 1.4285567487989153
Validation step:0Validation step:1Validation step:2Epoch 1313 		 Validation Loss: 4.349108457565308
Validation Loss Decreased(4.349332--->4.349108) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1314 / 2500Epoch 1314 		 Training Loss: 1.4282393540654863
Validation step:0Validation step:1Validation step:2Epoch 1314 		 Validation Loss: 4.34902548789978
Validation Loss Decreased(4.349108--->4.349025) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1315 / 2500Epoch 1315 		 Training Loss: 1.4285691039902824
Validation step:0Validation step:1Validation step:2Epoch 1315 		 Validation Loss: 4.348825931549072
Validation Loss Decreased(4.349025--->4.348826) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1316 / 2500Epoch 1316 		 Training Loss: 1.4294617772102356
Validation step:0Validation step:1Validation step:2Epoch 1316 		 Validation Loss: 4.348719120025635
Validation Loss Decreased(4.348826--->4.348719) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1317 / 2500Epoch 1317 		 Training Loss: 1.4272007516452245
Validation step:0Validation step:1Validation step:2Epoch 1317 		 Validation Loss: 4.348698139190674
Validation Loss Decreased(4.348719--->4.348698) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1318 / 2500Epoch 1318 		 Training Loss: 1.427797521863665
Validation step:0Validation step:1Validation step:2Epoch 1318 		 Validation Loss: 4.3485002517700195
Validation Loss Decreased(4.348698--->4.348500) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1319 / 2500Epoch 1319 		 Training Loss: 1.4272147502217973
Validation step:0Validation step:1Validation step:2Epoch 1319 		 Validation Loss: 4.3483922481536865
Validation Loss Decreased(4.348500--->4.348392) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1320 / 2500Epoch 1320 		 Training Loss: 1.4291637114116125
Validation step:0Validation step:1Validation step:2Epoch 1320 		 Validation Loss: 4.348236799240112
Validation Loss Decreased(4.348392--->4.348237) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1321 / 2500Epoch 1321 		 Training Loss: 1.4271285023008073
Validation step:0Validation step:1Validation step:2Epoch 1321 		 Validation Loss: 4.348133683204651
Validation Loss Decreased(4.348237--->4.348134) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1322 / 2500Epoch 1322 		 Training Loss: 1.4274810211999076
Validation step:0Validation step:1Validation step:2Epoch 1322 		 Validation Loss: 4.34798276424408
Validation Loss Decreased(4.348134--->4.347983) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1323 / 2500Epoch 1323 		 Training Loss: 1.42737877368927
Validation step:0Validation step:1Validation step:2Epoch 1323 		 Validation Loss: 4.347991228103638
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1324 / 2500Epoch 1324 		 Training Loss: 1.4277835062571935
Validation step:0Validation step:1Validation step:2Epoch 1324 		 Validation Loss: 4.347715377807617
Validation Loss Decreased(4.347983--->4.347715) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1325 / 2500Epoch 1325 		 Training Loss: 1.427696738924299
Validation step:0Validation step:1Validation step:2Epoch 1325 		 Validation Loss: 4.3476808071136475
Validation Loss Decreased(4.347715--->4.347681) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1326 / 2500Epoch 1326 		 Training Loss: 1.4268468022346497
Validation step:0Validation step:1Validation step:2Epoch 1326 		 Validation Loss: 4.347534656524658
Validation Loss Decreased(4.347681--->4.347535) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1327 / 2500Epoch 1327 		 Training Loss: 1.4282013092722212
Validation step:0Validation step:1Validation step:2Epoch 1327 		 Validation Loss: 4.347437620162964
Validation Loss Decreased(4.347535--->4.347438) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1328 / 2500Epoch 1328 		 Training Loss: 1.4267906291144234
Validation step:0Validation step:1Validation step:2Epoch 1328 		 Validation Loss: 4.3472676277160645
Validation Loss Decreased(4.347438--->4.347268) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1329 / 2500Epoch 1329 		 Training Loss: 1.4279396533966064
Validation step:0Validation step:1Validation step:2Epoch 1329 		 Validation Loss: 4.347158193588257
Validation Loss Decreased(4.347268--->4.347158) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1330 / 2500Epoch 1330 		 Training Loss: 1.4272284167153495
Validation step:0Validation step:1Validation step:2Epoch 1330 		 Validation Loss: 4.34697961807251
Validation Loss Decreased(4.347158--->4.346980) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1331 / 2500Epoch 1331 		 Training Loss: 1.4281596882002694
Validation step:0Validation step:1Validation step:2Epoch 1331 		 Validation Loss: 4.346907615661621
Validation Loss Decreased(4.346980--->4.346908) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1332 / 2500Epoch 1332 		 Training Loss: 1.4268419572285242
Validation step:0Validation step:1Validation step:2Epoch 1332 		 Validation Loss: 4.346824526786804
Validation Loss Decreased(4.346908--->4.346825) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1333 / 2500Epoch 1333 		 Training Loss: 1.427223903792245
Validation step:0Validation step:1Validation step:2Epoch 1333 		 Validation Loss: 4.3466620445251465
Validation Loss Decreased(4.346825--->4.346662) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1334 / 2500Epoch 1334 		 Training Loss: 1.426951289176941
Validation step:0Validation step:1Validation step:2Epoch 1334 		 Validation Loss: 4.346474528312683
Validation Loss Decreased(4.346662--->4.346475) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1335 / 2500Epoch 1335 		 Training Loss: 1.4263813155038017
Validation step:0Validation step:1Validation step:2Epoch 1335 		 Validation Loss: 4.346396446228027
Validation Loss Decreased(4.346475--->4.346396) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1336 / 2500Epoch 1336 		 Training Loss: 1.4283536246844701
Validation step:0Validation step:1Validation step:2Epoch 1336 		 Validation Loss: 4.346293807029724
Validation Loss Decreased(4.346396--->4.346294) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1337 / 2500Epoch 1337 		 Training Loss: 1.4277056881359644
Validation step:0Validation step:1Validation step:2Epoch 1337 		 Validation Loss: 4.346148729324341
Validation Loss Decreased(4.346294--->4.346149) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1338 / 2500Epoch 1338 		 Training Loss: 1.427640667983464
Validation step:0Validation step:1Validation step:2Epoch 1338 		 Validation Loss: 4.346037030220032
Validation Loss Decreased(4.346149--->4.346037) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1339 / 2500Epoch 1339 		 Training Loss: 1.427223333290645
Validation step:0Validation step:1Validation step:2Epoch 1339 		 Validation Loss: 4.345926523208618
Validation Loss Decreased(4.346037--->4.345927) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1340 / 2500Epoch 1340 		 Training Loss: 1.4272727285112654
Validation step:0Validation step:1Validation step:2Epoch 1340 		 Validation Loss: 4.345778465270996
Validation Loss Decreased(4.345927--->4.345778) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1341 / 2500Epoch 1341 		 Training Loss: 1.428018024989537
Validation step:0Validation step:1Validation step:2Epoch 1341 		 Validation Loss: 4.345615863800049
Validation Loss Decreased(4.345778--->4.345616) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1342 / 2500Epoch 1342 		 Training Loss: 1.4281653591564722
Validation step:0Validation step:1Validation step:2Epoch 1342 		 Validation Loss: 4.345522403717041
Validation Loss Decreased(4.345616--->4.345522) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1343 / 2500Epoch 1343 		 Training Loss: 1.4273375102451868
Validation step:0Validation step:1Validation step:2Epoch 1343 		 Validation Loss: 4.345418453216553
Validation Loss Decreased(4.345522--->4.345418) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1344 / 2500Epoch 1344 		 Training Loss: 1.4281597903796606
Validation step:0Validation step:1Validation step:2Epoch 1344 		 Validation Loss: 4.345516204833984
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1345 / 2500Epoch 1345 		 Training Loss: 1.4279081906591142
Validation step:0Validation step:1Validation step:2Epoch 1345 		 Validation Loss: 4.3451032638549805
Validation Loss Decreased(4.345418--->4.345103) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1346 / 2500Epoch 1346 		 Training Loss: 1.4263189605304174
Validation step:0Validation step:1Validation step:2Epoch 1346 		 Validation Loss: 4.34497594833374
Validation Loss Decreased(4.345103--->4.344976) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1347 / 2500Epoch 1347 		 Training Loss: 1.4270509481430054
Validation step:0Validation step:1Validation step:2Epoch 1347 		 Validation Loss: 4.344985246658325
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1348 / 2500Epoch 1348 		 Training Loss: 1.4271459068570818
Validation step:0Validation step:1Validation step:2Epoch 1348 		 Validation Loss: 4.344748377799988
Validation Loss Decreased(4.344976--->4.344748) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1349 / 2500Epoch 1349 		 Training Loss: 1.42518664257867
Validation step:0Validation step:1Validation step:2Epoch 1349 		 Validation Loss: 4.34471595287323
Validation Loss Decreased(4.344748--->4.344716) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1350 / 2500Epoch 1350 		 Training Loss: 1.4272048558507646
Validation step:0Validation step:1Validation step:2Epoch 1350 		 Validation Loss: 4.344530344009399
Validation Loss Decreased(4.344716--->4.344530) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1351 / 2500Epoch 1351 		 Training Loss: 1.426070945603507
Validation step:0Validation step:1Validation step:2Epoch 1351 		 Validation Loss: 4.344371795654297
Validation Loss Decreased(4.344530--->4.344372) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1352 / 2500Epoch 1352 		 Training Loss: 1.426919903073992
Validation step:0Validation step:1Validation step:2Epoch 1352 		 Validation Loss: 4.344364166259766
Validation Loss Decreased(4.344372--->4.344364) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1353 / 2500Epoch 1353 		 Training Loss: 1.427466767174857
Validation step:0Validation step:1Validation step:2Epoch 1353 		 Validation Loss: 4.344214200973511
Validation Loss Decreased(4.344364--->4.344214) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1354 / 2500Epoch 1354 		 Training Loss: 1.427216717175075
Validation step:0Validation step:1Validation step:2Epoch 1354 		 Validation Loss: 4.34402334690094
Validation Loss Decreased(4.344214--->4.344023) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1355 / 2500Epoch 1355 		 Training Loss: 1.4275450025285994
Validation step:0Validation step:1Validation step:2Epoch 1355 		 Validation Loss: 4.343921065330505
Validation Loss Decreased(4.344023--->4.343921) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1356 / 2500Epoch 1356 		 Training Loss: 1.4261513267244612
Validation step:0Validation step:1Validation step:2Epoch 1356 		 Validation Loss: 4.3438087701797485
Validation Loss Decreased(4.343921--->4.343809) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1357 / 2500Epoch 1357 		 Training Loss: 1.426740757056645
Validation step:0Validation step:1Validation step:2Epoch 1357 		 Validation Loss: 4.34371542930603
Validation Loss Decreased(4.343809--->4.343715) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1358 / 2500Epoch 1358 		 Training Loss: 1.426996452467782
Validation step:0Validation step:1Validation step:2Epoch 1358 		 Validation Loss: 4.343557119369507
Validation Loss Decreased(4.343715--->4.343557) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1359 / 2500Epoch 1359 		 Training Loss: 1.426556408405304
Validation step:0Validation step:1Validation step:2Epoch 1359 		 Validation Loss: 4.3435118198394775
Validation Loss Decreased(4.343557--->4.343512) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1360 / 2500Epoch 1360 		 Training Loss: 1.4258808153016227
Validation step:0Validation step:1Validation step:2Epoch 1360 		 Validation Loss: 4.34333598613739
Validation Loss Decreased(4.343512--->4.343336) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1361 / 2500Epoch 1361 		 Training Loss: 1.427418087209974
Validation step:0Validation step:1Validation step:2Epoch 1361 		 Validation Loss: 4.343172311782837
Validation Loss Decreased(4.343336--->4.343172) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1362 / 2500Epoch 1362 		 Training Loss: 1.4265152556555611
Validation step:0Validation step:1Validation step:2Epoch 1362 		 Validation Loss: 4.343063712120056
Validation Loss Decreased(4.343172--->4.343064) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1363 / 2500Epoch 1363 		 Training Loss: 1.4273166571344649
Validation step:0Validation step:1Validation step:2Epoch 1363 		 Validation Loss: 4.342970609664917
Validation Loss Decreased(4.343064--->4.342971) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1364 / 2500Epoch 1364 		 Training Loss: 1.4262858714376176
Validation step:0Validation step:1Validation step:2Epoch 1364 		 Validation Loss: 4.342899560928345
Validation Loss Decreased(4.342971--->4.342900) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1365 / 2500Epoch 1365 		 Training Loss: 1.4265653150422233
Validation step:0Validation step:1Validation step:2Epoch 1365 		 Validation Loss: 4.342851400375366
Validation Loss Decreased(4.342900--->4.342851) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1366 / 2500Epoch 1366 		 Training Loss: 1.4261102420943124
Validation step:0Validation step:1Validation step:2Epoch 1366 		 Validation Loss: 4.3427547216415405
Validation Loss Decreased(4.342851--->4.342755) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1367 / 2500Epoch 1367 		 Training Loss: 1.4266481058938163
Validation step:0Validation step:1Validation step:2Epoch 1367 		 Validation Loss: 4.342418432235718
Validation Loss Decreased(4.342755--->4.342418) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1368 / 2500Epoch 1368 		 Training Loss: 1.4271329471043177
Validation step:0Validation step:1Validation step:2Epoch 1368 		 Validation Loss: 4.342288255691528
Validation Loss Decreased(4.342418--->4.342288) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1369 / 2500Epoch 1369 		 Training Loss: 1.426505105836051
Validation step:0Validation step:1Validation step:2Epoch 1369 		 Validation Loss: 4.342252492904663
Validation Loss Decreased(4.342288--->4.342252) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1370 / 2500Epoch 1370 		 Training Loss: 1.426478726523263
Validation step:0Validation step:1Validation step:2Epoch 1370 		 Validation Loss: 4.342094540596008
Validation Loss Decreased(4.342252--->4.342095) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1371 / 2500Epoch 1371 		 Training Loss: 1.4256552628108434
Validation step:0Validation step:1Validation step:2Epoch 1371 		 Validation Loss: 4.342005610466003
Validation Loss Decreased(4.342095--->4.342006) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1372 / 2500Epoch 1372 		 Training Loss: 1.4253363439014979
Validation step:0Validation step:1Validation step:2Epoch 1372 		 Validation Loss: 4.341864705085754
Validation Loss Decreased(4.342006--->4.341865) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1373 / 2500Epoch 1373 		 Training Loss: 1.42643175806318
Validation step:0Validation step:1Validation step:2Epoch 1373 		 Validation Loss: 4.3417805433273315
Validation Loss Decreased(4.341865--->4.341781) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1374 / 2500Epoch 1374 		 Training Loss: 1.4268826416560583
Validation step:0Validation step:1Validation step:2Epoch 1374 		 Validation Loss: 4.3417041301727295
Validation Loss Decreased(4.341781--->4.341704) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1375 / 2500Epoch 1375 		 Training Loss: 1.4261376006262643
Validation step:0Validation step:1Validation step:2Epoch 1375 		 Validation Loss: 4.341536164283752
Validation Loss Decreased(4.341704--->4.341536) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1376 / 2500Epoch 1376 		 Training Loss: 1.4262263689722334
Validation step:0Validation step:1Validation step:2Epoch 1376 		 Validation Loss: 4.341445803642273
Validation Loss Decreased(4.341536--->4.341446) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1377 / 2500Epoch 1377 		 Training Loss: 1.4244000230516707
Validation step:0Validation step:1Validation step:2Epoch 1377 		 Validation Loss: 4.341455578804016
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1378 / 2500Epoch 1378 		 Training Loss: 1.422876979623522
Validation step:0Validation step:1Validation step:2Epoch 1378 		 Validation Loss: 4.341109752655029
Validation Loss Decreased(4.341446--->4.341110) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1379 / 2500Epoch 1379 		 Training Loss: 1.4259468913078308
Validation step:0Validation step:1Validation step:2Epoch 1379 		 Validation Loss: 4.341074824333191
Validation Loss Decreased(4.341110--->4.341075) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1380 / 2500Epoch 1380 		 Training Loss: 1.4237476927893502
Validation step:0Validation step:1Validation step:2Epoch 1380 		 Validation Loss: 4.340872406959534
Validation Loss Decreased(4.341075--->4.340872) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1381 / 2500Epoch 1381 		 Training Loss: 1.4256425755364555
Validation step:0Validation step:1Validation step:2Epoch 1381 		 Validation Loss: 4.340799927711487
Validation Loss Decreased(4.340872--->4.340800) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1382 / 2500Epoch 1382 		 Training Loss: 1.4266474161829268
Validation step:0Validation step:1Validation step:2Epoch 1382 		 Validation Loss: 4.34071958065033
Validation Loss Decreased(4.340800--->4.340720) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1383 / 2500Epoch 1383 		 Training Loss: 1.4259403518268041
Validation step:0Validation step:1Validation step:2Epoch 1383 		 Validation Loss: 4.340502619743347
Validation Loss Decreased(4.340720--->4.340503) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1384 / 2500Epoch 1384 		 Training Loss: 1.4248886278697424
Validation step:0Validation step:1Validation step:2Epoch 1384 		 Validation Loss: 4.340432524681091
Validation Loss Decreased(4.340503--->4.340433) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1385 / 2500Epoch 1385 		 Training Loss: 1.4248646242277963
Validation step:0Validation step:1Validation step:2Epoch 1385 		 Validation Loss: 4.340369939804077
Validation Loss Decreased(4.340433--->4.340370) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1386 / 2500Epoch 1386 		 Training Loss: 1.423670870917184
Validation step:0Validation step:1Validation step:2Epoch 1386 		 Validation Loss: 4.340152382850647
Validation Loss Decreased(4.340370--->4.340152) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1387 / 2500Epoch 1387 		 Training Loss: 1.4248830420630318
Validation step:0Validation step:1Validation step:2Epoch 1387 		 Validation Loss: 4.340034127235413
Validation Loss Decreased(4.340152--->4.340034) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1388 / 2500Epoch 1388 		 Training Loss: 1.423506694180625
Validation step:0Validation step:1Validation step:2Epoch 1388 		 Validation Loss: 4.339904189109802
Validation Loss Decreased(4.340034--->4.339904) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1389 / 2500Epoch 1389 		 Training Loss: 1.4250279835292272
Validation step:0Validation step:1Validation step:2Epoch 1389 		 Validation Loss: 4.340016603469849
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1390 / 2500Epoch 1390 		 Training Loss: 1.425080452646528
Validation step:0Validation step:1Validation step:2Epoch 1390 		 Validation Loss: 4.339755535125732
Validation Loss Decreased(4.339904--->4.339756) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1391 / 2500Epoch 1391 		 Training Loss: 1.4253425257546561
Validation step:0Validation step:1Validation step:2Epoch 1391 		 Validation Loss: 4.339534044265747
Validation Loss Decreased(4.339756--->4.339534) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1392 / 2500Epoch 1392 		 Training Loss: 1.4239312154906136
Validation step:0Validation step:1Validation step:2Epoch 1392 		 Validation Loss: 4.339638590812683
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1393 / 2500Epoch 1393 		 Training Loss: 1.425491716180529
Validation step:0Validation step:1Validation step:2Epoch 1393 		 Validation Loss: 4.339542031288147
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1394 / 2500Epoch 1394 		 Training Loss: 1.4263079421860831
Validation step:0Validation step:1Validation step:2Epoch 1394 		 Validation Loss: 4.339163661003113
Validation Loss Decreased(4.339534--->4.339164) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1395 / 2500Epoch 1395 		 Training Loss: 1.4237449765205383
Validation step:0Validation step:1Validation step:2Epoch 1395 		 Validation Loss: 4.339109301567078
Validation Loss Decreased(4.339164--->4.339109) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1396 / 2500Epoch 1396 		 Training Loss: 1.424138035093035
Validation step:0Validation step:1Validation step:2Epoch 1396 		 Validation Loss: 4.339054822921753
Validation Loss Decreased(4.339109--->4.339055) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1397 / 2500Epoch 1397 		 Training Loss: 1.425324993474143
Validation step:0Validation step:1Validation step:2Epoch 1397 		 Validation Loss: 4.338893294334412
Validation Loss Decreased(4.339055--->4.338893) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1398 / 2500Epoch 1398 		 Training Loss: 1.4242244703429086
Validation step:0Validation step:1Validation step:2Epoch 1398 		 Validation Loss: 4.338823437690735
Validation Loss Decreased(4.338893--->4.338823) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1399 / 2500Epoch 1399 		 Training Loss: 1.423840616430555
Validation step:0Validation step:1Validation step:2Epoch 1399 		 Validation Loss: 4.338620543479919
Validation Loss Decreased(4.338823--->4.338621) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1400 / 2500Epoch 1400 		 Training Loss: 1.4250868984631129
Validation step:0Validation step:1Validation step:2Epoch 1400 		 Validation Loss: 4.338582396507263
Validation Loss Decreased(4.338621--->4.338582) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1401 / 2500Epoch 1401 		 Training Loss: 1.4231717160769872
Validation step:0Validation step:1Validation step:2Epoch 1401 		 Validation Loss: 4.3384400606155396
Validation Loss Decreased(4.338582--->4.338440) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1402 / 2500Epoch 1402 		 Training Loss: 1.4248869674546378
Validation step:0Validation step:1Validation step:2Epoch 1402 		 Validation Loss: 4.338312983512878
Validation Loss Decreased(4.338440--->4.338313) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1403 / 2500Epoch 1403 		 Training Loss: 1.4241121922220503
Validation step:0Validation step:1Validation step:2Epoch 1403 		 Validation Loss: 4.338126182556152
Validation Loss Decreased(4.338313--->4.338126) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1404 / 2500Epoch 1404 		 Training Loss: 1.4253459317343575
Validation step:0Validation step:1Validation step:2Epoch 1404 		 Validation Loss: 4.338040828704834
Validation Loss Decreased(4.338126--->4.338041) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1405 / 2500Epoch 1405 		 Training Loss: 1.4248984030314855
Validation step:0Validation step:1Validation step:2Epoch 1405 		 Validation Loss: 4.338033676147461
Validation Loss Decreased(4.338041--->4.338034) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1406 / 2500Epoch 1406 		 Training Loss: 1.425178689616067
Validation step:0Validation step:1Validation step:2Epoch 1406 		 Validation Loss: 4.337743639945984
Validation Loss Decreased(4.338034--->4.337744) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1407 / 2500Epoch 1407 		 Training Loss: 1.4238367932183402
Validation step:0Validation step:1Validation step:2Epoch 1407 		 Validation Loss: 4.337597370147705
Validation Loss Decreased(4.337744--->4.337597) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1408 / 2500Epoch 1408 		 Training Loss: 1.4223968812397547
Validation step:0Validation step:1Validation step:2Epoch 1408 		 Validation Loss: 4.337514638900757
Validation Loss Decreased(4.337597--->4.337515) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1409 / 2500Epoch 1409 		 Training Loss: 1.4226720673697335
Validation step:0Validation step:1Validation step:2Epoch 1409 		 Validation Loss: 4.33745801448822
Validation Loss Decreased(4.337515--->4.337458) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1410 / 2500Epoch 1410 		 Training Loss: 1.425453543663025
Validation step:0Validation step:1Validation step:2Epoch 1410 		 Validation Loss: 4.337286114692688
Validation Loss Decreased(4.337458--->4.337286) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1411 / 2500Epoch 1411 		 Training Loss: 1.423829666205815
Validation step:0Validation step:1Validation step:2Epoch 1411 		 Validation Loss: 4.337389826774597
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1412 / 2500Epoch 1412 		 Training Loss: 1.4232831937926156
Validation step:0Validation step:1Validation step:2Epoch 1412 		 Validation Loss: 4.337051153182983
Validation Loss Decreased(4.337286--->4.337051) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1413 / 2500Epoch 1413 		 Training Loss: 1.4220171059880937
Validation step:0Validation step:1Validation step:2Epoch 1413 		 Validation Loss: 4.337080478668213
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1414 / 2500Epoch 1414 		 Training Loss: 1.4216217654091972
Validation step:0Validation step:1Validation step:2Epoch 1414 		 Validation Loss: 4.3367942571640015
Validation Loss Decreased(4.337051--->4.336794) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1415 / 2500Epoch 1415 		 Training Loss: 1.422973394393921
Validation step:0Validation step:1Validation step:2Epoch 1415 		 Validation Loss: 4.336820125579834
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1416 / 2500Epoch 1416 		 Training Loss: 1.4216609171458654
Validation step:0Validation step:1Validation step:2Epoch 1416 		 Validation Loss: 4.336576581001282
Validation Loss Decreased(4.336794--->4.336577) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1417 / 2500Epoch 1417 		 Training Loss: 1.4237867934363229
Validation step:0Validation step:1Validation step:2Epoch 1417 		 Validation Loss: 4.3364540338516235
Validation Loss Decreased(4.336577--->4.336454) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1418 / 2500Epoch 1418 		 Training Loss: 1.4231886267662048
Validation step:0Validation step:1Validation step:2Epoch 1418 		 Validation Loss: 4.336346864700317
Validation Loss Decreased(4.336454--->4.336347) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1419 / 2500Epoch 1419 		 Training Loss: 1.4243404013769967
Validation step:0Validation step:1Validation step:2Epoch 1419 		 Validation Loss: 4.3362168073654175
Validation Loss Decreased(4.336347--->4.336217) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1420 / 2500Epoch 1420 		 Training Loss: 1.4240358642169408
Validation step:0Validation step:1Validation step:2Epoch 1420 		 Validation Loss: 4.336156964302063
Validation Loss Decreased(4.336217--->4.336157) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1421 / 2500Epoch 1421 		 Training Loss: 1.4230459332466125
Validation step:0Validation step:1Validation step:2Epoch 1421 		 Validation Loss: 4.33625864982605
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1422 / 2500Epoch 1422 		 Training Loss: 1.4232267907687597
Validation step:0Validation step:1Validation step:2Epoch 1422 		 Validation Loss: 4.335874557495117
Validation Loss Decreased(4.336157--->4.335875) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1423 / 2500Epoch 1423 		 Training Loss: 1.4240835990224565
Validation step:0Validation step:1Validation step:2Epoch 1423 		 Validation Loss: 4.335851430892944
Validation Loss Decreased(4.335875--->4.335851) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1424 / 2500Epoch 1424 		 Training Loss: 1.4243819798742021
Validation step:0Validation step:1Validation step:2Epoch 1424 		 Validation Loss: 4.3357391357421875
Validation Loss Decreased(4.335851--->4.335739) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1425 / 2500Epoch 1425 		 Training Loss: 1.4240275451115199
Validation step:0Validation step:1Validation step:2Epoch 1425 		 Validation Loss: 4.335612773895264
Validation Loss Decreased(4.335739--->4.335613) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1426 / 2500Epoch 1426 		 Training Loss: 1.4243111099515642
Validation step:0Validation step:1Validation step:2Epoch 1426 		 Validation Loss: 4.335450291633606
Validation Loss Decreased(4.335613--->4.335450) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1427 / 2500Epoch 1427 		 Training Loss: 1.4242201106888908
Validation step:0Validation step:1Validation step:2Epoch 1427 		 Validation Loss: 4.335273265838623
Validation Loss Decreased(4.335450--->4.335273) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1428 / 2500Epoch 1428 		 Training Loss: 1.4229676808629717
Validation step:0Validation step:1Validation step:2Epoch 1428 		 Validation Loss: 4.335143804550171
Validation Loss Decreased(4.335273--->4.335144) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1429 / 2500Epoch 1429 		 Training Loss: 1.423474712031228
Validation step:0Validation step:1Validation step:2Epoch 1429 		 Validation Loss: 4.3350876569747925
Validation Loss Decreased(4.335144--->4.335088) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1430 / 2500Epoch 1430 		 Training Loss: 1.422264848436628
Validation step:0Validation step:1Validation step:2Epoch 1430 		 Validation Loss: 4.335053443908691
Validation Loss Decreased(4.335088--->4.335053) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1431 / 2500Epoch 1431 		 Training Loss: 1.422443790095193
Validation step:0Validation step:1Validation step:2Epoch 1431 		 Validation Loss: 4.3349369764328
Validation Loss Decreased(4.335053--->4.334937) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1432 / 2500Epoch 1432 		 Training Loss: 1.4225740262440272
Validation step:0Validation step:1Validation step:2Epoch 1432 		 Validation Loss: 4.334808826446533
Validation Loss Decreased(4.334937--->4.334809) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1433 / 2500Epoch 1433 		 Training Loss: 1.4236049822398595
Validation step:0Validation step:1Validation step:2Epoch 1433 		 Validation Loss: 4.334648489952087
Validation Loss Decreased(4.334809--->4.334648) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1434 / 2500Epoch 1434 		 Training Loss: 1.4247424602508545
Validation step:0Validation step:1Validation step:2Epoch 1434 		 Validation Loss: 4.334562420845032
Validation Loss Decreased(4.334648--->4.334562) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1435 / 2500Epoch 1435 		 Training Loss: 1.4230085611343384
Validation step:0Validation step:1Validation step:2Epoch 1435 		 Validation Loss: 4.334453105926514
Validation Loss Decreased(4.334562--->4.334453) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1436 / 2500Epoch 1436 		 Training Loss: 1.4232809373310633
Validation step:0Validation step:1Validation step:2Epoch 1436 		 Validation Loss: 4.334332227706909
Validation Loss Decreased(4.334453--->4.334332) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1437 / 2500Epoch 1437 		 Training Loss: 1.422549341406141
Validation step:0Validation step:1Validation step:2Epoch 1437 		 Validation Loss: 4.334193468093872
Validation Loss Decreased(4.334332--->4.334193) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1438 / 2500Epoch 1438 		 Training Loss: 1.4231715542929513
Validation step:0Validation step:1Validation step:2Epoch 1438 		 Validation Loss: 4.334090232849121
Validation Loss Decreased(4.334193--->4.334090) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1439 / 2500Epoch 1439 		 Training Loss: 1.4238939114979334
Validation step:0Validation step:1Validation step:2Epoch 1439 		 Validation Loss: 4.334001660346985
Validation Loss Decreased(4.334090--->4.334002) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1440 / 2500Epoch 1440 		 Training Loss: 1.4235952581678117
Validation step:0Validation step:1Validation step:2Epoch 1440 		 Validation Loss: 4.333807945251465
Validation Loss Decreased(4.334002--->4.333808) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1441 / 2500Epoch 1441 		 Training Loss: 1.422119906970433
Validation step:0Validation step:1Validation step:2Epoch 1441 		 Validation Loss: 4.333693027496338
Validation Loss Decreased(4.333808--->4.333693) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1442 / 2500Epoch 1442 		 Training Loss: 1.4231730358941215
Validation step:0Validation step:1Validation step:2Epoch 1442 		 Validation Loss: 4.333650469779968
Validation Loss Decreased(4.333693--->4.333650) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1443 / 2500Epoch 1443 		 Training Loss: 1.423347098486764
Validation step:0Validation step:1Validation step:2Epoch 1443 		 Validation Loss: 4.333492994308472
Validation Loss Decreased(4.333650--->4.333493) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1444 / 2500Epoch 1444 		 Training Loss: 1.4223203999655587
Validation step:0Validation step:1Validation step:2Epoch 1444 		 Validation Loss: 4.333446383476257
Validation Loss Decreased(4.333493--->4.333446) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1445 / 2500Epoch 1445 		 Training Loss: 1.4229951415743147
Validation step:0Validation step:1Validation step:2Epoch 1445 		 Validation Loss: 4.333289623260498
Validation Loss Decreased(4.333446--->4.333290) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1446 / 2500Epoch 1446 		 Training Loss: 1.4228283166885376
Validation step:0Validation step:1Validation step:2Epoch 1446 		 Validation Loss: 4.333145976066589
Validation Loss Decreased(4.333290--->4.333146) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1447 / 2500Epoch 1447 		 Training Loss: 1.4214593512671334
Validation step:0Validation step:1Validation step:2Epoch 1447 		 Validation Loss: 4.332980632781982
Validation Loss Decreased(4.333146--->4.332981) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1448 / 2500Epoch 1448 		 Training Loss: 1.421436837741307
Validation step:0Validation step:1Validation step:2Epoch 1448 		 Validation Loss: 4.3328105211257935
Validation Loss Decreased(4.332981--->4.332811) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1449 / 2500Epoch 1449 		 Training Loss: 1.4222837601389204
Validation step:0Validation step:1Validation step:2Epoch 1449 		 Validation Loss: 4.332752227783203
Validation Loss Decreased(4.332811--->4.332752) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1450 / 2500Epoch 1450 		 Training Loss: 1.4225686022213526
Validation step:0Validation step:1Validation step:2Epoch 1450 		 Validation Loss: 4.332628011703491
Validation Loss Decreased(4.332752--->4.332628) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1451 / 2500Epoch 1451 		 Training Loss: 1.422685478414808
Validation step:0Validation step:1Validation step:2Epoch 1451 		 Validation Loss: 4.3325148820877075
Validation Loss Decreased(4.332628--->4.332515) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1452 / 2500Epoch 1452 		 Training Loss: 1.4225617391722543
Validation step:0Validation step:1Validation step:2Epoch 1452 		 Validation Loss: 4.332399249076843
Validation Loss Decreased(4.332515--->4.332399) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1453 / 2500Epoch 1453 		 Training Loss: 1.4232216477394104
Validation step:0Validation step:1Validation step:2Epoch 1453 		 Validation Loss: 4.332295775413513
Validation Loss Decreased(4.332399--->4.332296) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1454 / 2500Epoch 1454 		 Training Loss: 1.4215301019804818
Validation step:0Validation step:1Validation step:2Epoch 1454 		 Validation Loss: 4.33219051361084
Validation Loss Decreased(4.332296--->4.332191) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1455 / 2500Epoch 1455 		 Training Loss: 1.421643853187561
Validation step:0Validation step:1Validation step:2Epoch 1455 		 Validation Loss: 4.332053065299988
Validation Loss Decreased(4.332191--->4.332053) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1456 / 2500Epoch 1456 		 Training Loss: 1.4220110177993774
Validation step:0Validation step:1Validation step:2Epoch 1456 		 Validation Loss: 4.331968784332275
Validation Loss Decreased(4.332053--->4.331969) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1457 / 2500Epoch 1457 		 Training Loss: 1.4196475488798959
Validation step:0Validation step:1Validation step:2Epoch 1457 		 Validation Loss: 4.331858038902283
Validation Loss Decreased(4.331969--->4.331858) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1458 / 2500Epoch 1458 		 Training Loss: 1.421438796179635
Validation step:0Validation step:1Validation step:2Epoch 1458 		 Validation Loss: 4.3319783210754395
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1459 / 2500Epoch 1459 		 Training Loss: 1.420954201902662
Validation step:0Validation step:1Validation step:2Epoch 1459 		 Validation Loss: 4.331644773483276
Validation Loss Decreased(4.331858--->4.331645) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1460 / 2500Epoch 1460 		 Training Loss: 1.4224515642438615
Validation step:0Validation step:1Validation step:2Epoch 1460 		 Validation Loss: 4.3315112590789795
Validation Loss Decreased(4.331645--->4.331511) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1461 / 2500Epoch 1461 		 Training Loss: 1.4199585914611816
Validation step:0Validation step:1Validation step:2Epoch 1461 		 Validation Loss: 4.331387281417847
Validation Loss Decreased(4.331511--->4.331387) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1462 / 2500Epoch 1462 		 Training Loss: 1.4217049734933036
Validation step:0Validation step:1Validation step:2Epoch 1462 		 Validation Loss: 4.331441640853882
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1463 / 2500Epoch 1463 		 Training Loss: 1.4215633017676217
Validation step:0Validation step:1Validation step:2Epoch 1463 		 Validation Loss: 4.331346392631531
Validation Loss Decreased(4.331387--->4.331346) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1464 / 2500Epoch 1464 		 Training Loss: 1.422595739364624
Validation step:0Validation step:1Validation step:2Epoch 1464 		 Validation Loss: 4.331103563308716
Validation Loss Decreased(4.331346--->4.331104) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1465 / 2500Epoch 1465 		 Training Loss: 1.420182500566755
Validation step:0Validation step:1Validation step:2Epoch 1465 		 Validation Loss: 4.330880880355835
Validation Loss Decreased(4.331104--->4.330881) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1466 / 2500Epoch 1466 		 Training Loss: 1.4204166872160775
Validation step:0Validation step:1Validation step:2Epoch 1466 		 Validation Loss: 4.3307836055755615
Validation Loss Decreased(4.330881--->4.330784) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1467 / 2500Epoch 1467 		 Training Loss: 1.422144089426313
Validation step:0Validation step:1Validation step:2Epoch 1467 		 Validation Loss: 4.330902338027954
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1468 / 2500Epoch 1468 		 Training Loss: 1.4214046256882804
Validation step:0Validation step:1Validation step:2Epoch 1468 		 Validation Loss: 4.330721735954285
Validation Loss Decreased(4.330784--->4.330722) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1469 / 2500Epoch 1469 		 Training Loss: 1.4214535525866918
Validation step:0Validation step:1Validation step:2Epoch 1469 		 Validation Loss: 4.3304760456085205
Validation Loss Decreased(4.330722--->4.330476) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1470 / 2500Epoch 1470 		 Training Loss: 1.4202918750899178
Validation step:0Validation step:1Validation step:2Epoch 1470 		 Validation Loss: 4.330495834350586
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1471 / 2500Epoch 1471 		 Training Loss: 1.4235947302409582
Validation step:0Validation step:1Validation step:2Epoch 1471 		 Validation Loss: 4.330225706100464
Validation Loss Decreased(4.330476--->4.330226) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1472 / 2500Epoch 1472 		 Training Loss: 1.4206835201808385
Validation step:0Validation step:1Validation step:2Epoch 1472 		 Validation Loss: 4.330138444900513
Validation Loss Decreased(4.330226--->4.330138) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1473 / 2500Epoch 1473 		 Training Loss: 1.4215476257460458
Validation step:0Validation step:1Validation step:2Epoch 1473 		 Validation Loss: 4.329996228218079
Validation Loss Decreased(4.330138--->4.329996) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1474 / 2500Epoch 1474 		 Training Loss: 1.421937542302268
Validation step:0Validation step:1Validation step:2Epoch 1474 		 Validation Loss: 4.330015659332275
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1475 / 2500Epoch 1475 		 Training Loss: 1.4195546507835388
Validation step:0Validation step:1Validation step:2Epoch 1475 		 Validation Loss: 4.329889416694641
Validation Loss Decreased(4.329996--->4.329889) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1476 / 2500Epoch 1476 		 Training Loss: 1.4219634192330497
Validation step:0Validation step:1Validation step:2Epoch 1476 		 Validation Loss: 4.329800248146057
Validation Loss Decreased(4.329889--->4.329800) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1477 / 2500Epoch 1477 		 Training Loss: 1.421521612576076
Validation step:0Validation step:1Validation step:2Epoch 1477 		 Validation Loss: 4.329722285270691
Validation Loss Decreased(4.329800--->4.329722) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1478 / 2500Epoch 1478 		 Training Loss: 1.4215042420795985
Validation step:0Validation step:1Validation step:2Epoch 1478 		 Validation Loss: 4.3296568393707275
Validation Loss Decreased(4.329722--->4.329657) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1479 / 2500Epoch 1479 		 Training Loss: 1.4212492874690466
Validation step:0Validation step:1Validation step:2Epoch 1479 		 Validation Loss: 4.329519867897034
Validation Loss Decreased(4.329657--->4.329520) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1480 / 2500Epoch 1480 		 Training Loss: 1.4206939254488264
Validation step:0Validation step:1Validation step:2Epoch 1480 		 Validation Loss: 4.32928466796875
Validation Loss Decreased(4.329520--->4.329285) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1481 / 2500Epoch 1481 		 Training Loss: 1.4217786959239416
Validation step:0Validation step:1Validation step:2Epoch 1481 		 Validation Loss: 4.329140067100525
Validation Loss Decreased(4.329285--->4.329140) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1482 / 2500Epoch 1482 		 Training Loss: 1.4207890374319894
Validation step:0Validation step:1Validation step:2Epoch 1482 		 Validation Loss: 4.3290112018585205
Validation Loss Decreased(4.329140--->4.329011) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1483 / 2500Epoch 1483 		 Training Loss: 1.421621365206582
Validation step:0Validation step:1Validation step:2Epoch 1483 		 Validation Loss: 4.329304337501526
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1484 / 2500Epoch 1484 		 Training Loss: 1.421124415738242
Validation step:0Validation step:1Validation step:2Epoch 1484 		 Validation Loss: 4.328929305076599
Validation Loss Decreased(4.329011--->4.328929) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1485 / 2500Epoch 1485 		 Training Loss: 1.4195322053773063
Validation step:0Validation step:1Validation step:2Epoch 1485 		 Validation Loss: 4.328766107559204
Validation Loss Decreased(4.328929--->4.328766) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1486 / 2500Epoch 1486 		 Training Loss: 1.4208028997693742
Validation step:0Validation step:1Validation step:2Epoch 1486 		 Validation Loss: 4.328570127487183
Validation Loss Decreased(4.328766--->4.328570) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1487 / 2500Epoch 1487 		 Training Loss: 1.420925063746316
Validation step:0Validation step:1Validation step:2Epoch 1487 		 Validation Loss: 4.328567624092102
Validation Loss Decreased(4.328570--->4.328568) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1488 / 2500Epoch 1488 		 Training Loss: 1.4205893874168396
Validation step:0Validation step:1Validation step:2Epoch 1488 		 Validation Loss: 4.328353404998779
Validation Loss Decreased(4.328568--->4.328353) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1489 / 2500Epoch 1489 		 Training Loss: 1.420210361480713
Validation step:0Validation step:1Validation step:2Epoch 1489 		 Validation Loss: 4.328222990036011
Validation Loss Decreased(4.328353--->4.328223) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1490 / 2500Epoch 1490 		 Training Loss: 1.418856143951416
Validation step:0Validation step:1Validation step:2Epoch 1490 		 Validation Loss: 4.328139543533325
Validation Loss Decreased(4.328223--->4.328140) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1491 / 2500Epoch 1491 		 Training Loss: 1.4205084953989302
Validation step:0Validation step:1Validation step:2Epoch 1491 		 Validation Loss: 4.328100204467773
Validation Loss Decreased(4.328140--->4.328100) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1492 / 2500Epoch 1492 		 Training Loss: 1.4204390815326147
Validation step:0Validation step:1Validation step:2Epoch 1492 		 Validation Loss: 4.327894806861877
Validation Loss Decreased(4.328100--->4.327895) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1493 / 2500Epoch 1493 		 Training Loss: 1.4207717095102583
Validation step:0Validation step:1Validation step:2Epoch 1493 		 Validation Loss: 4.3280028104782104
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1494 / 2500Epoch 1494 		 Training Loss: 1.4213225586073739
Validation step:0Validation step:1Validation step:2Epoch 1494 		 Validation Loss: 4.327774167060852
Validation Loss Decreased(4.327895--->4.327774) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1495 / 2500Epoch 1495 		 Training Loss: 1.4200319051742554
Validation step:0Validation step:1Validation step:2Epoch 1495 		 Validation Loss: 4.327669620513916
Validation Loss Decreased(4.327774--->4.327670) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1496 / 2500Epoch 1496 		 Training Loss: 1.421614136014666
Validation step:0Validation step:1Validation step:2Epoch 1496 		 Validation Loss: 4.32747483253479
Validation Loss Decreased(4.327670--->4.327475) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1497 / 2500Epoch 1497 		 Training Loss: 1.4219616651535034
Validation step:0Validation step:1Validation step:2Epoch 1497 		 Validation Loss: 4.327469348907471
Validation Loss Decreased(4.327475--->4.327469) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1498 / 2500Epoch 1498 		 Training Loss: 1.4194818139076233
Validation step:0Validation step:1Validation step:2Epoch 1498 		 Validation Loss: 4.327287673950195
Validation Loss Decreased(4.327469--->4.327288) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1499 / 2500Epoch 1499 		 Training Loss: 1.4189921106610979
Validation step:0Validation step:1Validation step:2Epoch 1499 		 Validation Loss: 4.3271284103393555
Validation Loss Decreased(4.327288--->4.327128) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1500 / 2500Epoch 1500 		 Training Loss: 1.4200524687767029
Validation step:0Validation step:1Validation step:2Epoch 1500 		 Validation Loss: 4.327049493789673
Validation Loss Decreased(4.327128--->4.327049) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1501 / 2500Epoch 1501 		 Training Loss: 1.420172827584403
Validation step:0Validation step:1Validation step:2Epoch 1501 		 Validation Loss: 4.326990485191345
Validation Loss Decreased(4.327049--->4.326990) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1502 / 2500Epoch 1502 		 Training Loss: 1.420303293636867
Validation step:0Validation step:1Validation step:2Epoch 1502 		 Validation Loss: 4.32686722278595
Validation Loss Decreased(4.326990--->4.326867) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1503 / 2500Epoch 1503 		 Training Loss: 1.4199914591653007
Validation step:0Validation step:1Validation step:2Epoch 1503 		 Validation Loss: 4.326743006706238
Validation Loss Decreased(4.326867--->4.326743) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1504 / 2500Epoch 1504 		 Training Loss: 1.4201796054840088
Validation step:0Validation step:1Validation step:2Epoch 1504 		 Validation Loss: 4.326914310455322
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1505 / 2500Epoch 1505 		 Training Loss: 1.4189240762165614
Validation step:0Validation step:1Validation step:2Epoch 1505 		 Validation Loss: 4.326674699783325
Validation Loss Decreased(4.326743--->4.326675) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1506 / 2500Epoch 1506 		 Training Loss: 1.420652789728982
Validation step:0Validation step:1Validation step:2Epoch 1506 		 Validation Loss: 4.326461672782898
Validation Loss Decreased(4.326675--->4.326462) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1507 / 2500Epoch 1507 		 Training Loss: 1.4204100200108118
Validation step:0Validation step:1Validation step:2Epoch 1507 		 Validation Loss: 4.326295733451843
Validation Loss Decreased(4.326462--->4.326296) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1508 / 2500Epoch 1508 		 Training Loss: 1.4200295124735152
Validation step:0Validation step:1Validation step:2Epoch 1508 		 Validation Loss: 4.326164722442627
Validation Loss Decreased(4.326296--->4.326165) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1509 / 2500Epoch 1509 		 Training Loss: 1.4204631788390023
Validation step:0Validation step:1Validation step:2Epoch 1509 		 Validation Loss: 4.326111555099487
Validation Loss Decreased(4.326165--->4.326112) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1510 / 2500Epoch 1510 		 Training Loss: 1.421378152711051
Validation step:0Validation step:1Validation step:2Epoch 1510 		 Validation Loss: 4.325894832611084
Validation Loss Decreased(4.326112--->4.325895) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1511 / 2500Epoch 1511 		 Training Loss: 1.421369092805045
Validation step:0Validation step:1Validation step:2Epoch 1511 		 Validation Loss: 4.325774192810059
Validation Loss Decreased(4.325895--->4.325774) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1512 / 2500Epoch 1512 		 Training Loss: 1.4199280823980058
Validation step:0Validation step:1Validation step:2Epoch 1512 		 Validation Loss: 4.325639843940735
Validation Loss Decreased(4.325774--->4.325640) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1513 / 2500Epoch 1513 		 Training Loss: 1.4207674775804793
Validation step:0Validation step:1Validation step:2Epoch 1513 		 Validation Loss: 4.325603485107422
Validation Loss Decreased(4.325640--->4.325603) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1514 / 2500Epoch 1514 		 Training Loss: 1.4194583977971758
Validation step:0Validation step:1Validation step:2Epoch 1514 		 Validation Loss: 4.325480937957764
Validation Loss Decreased(4.325603--->4.325481) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1515 / 2500Epoch 1515 		 Training Loss: 1.4205675210271562
Validation step:0Validation step:1Validation step:2Epoch 1515 		 Validation Loss: 4.3253413438797
Validation Loss Decreased(4.325481--->4.325341) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1516 / 2500Epoch 1516 		 Training Loss: 1.4194463576589311
Validation step:0Validation step:1Validation step:2Epoch 1516 		 Validation Loss: 4.325510263442993
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1517 / 2500Epoch 1517 		 Training Loss: 1.4198491147586279
Validation step:0Validation step:1Validation step:2Epoch 1517 		 Validation Loss: 4.3251848220825195
Validation Loss Decreased(4.325341--->4.325185) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1518 / 2500Epoch 1518 		 Training Loss: 1.418803027697972
Validation step:0Validation step:1Validation step:2Epoch 1518 		 Validation Loss: 4.325001358985901
Validation Loss Decreased(4.325185--->4.325001) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1519 / 2500Epoch 1519 		 Training Loss: 1.4204233288764954
Validation step:0Validation step:1Validation step:2Epoch 1519 		 Validation Loss: 4.324911832809448
Validation Loss Decreased(4.325001--->4.324912) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1520 / 2500Epoch 1520 		 Training Loss: 1.419636607170105
Validation step:0Validation step:1Validation step:2Epoch 1520 		 Validation Loss: 4.324799656867981
Validation Loss Decreased(4.324912--->4.324800) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1521 / 2500Epoch 1521 		 Training Loss: 1.419933898108346
Validation step:0Validation step:1Validation step:2Epoch 1521 		 Validation Loss: 4.324692130088806
Validation Loss Decreased(4.324800--->4.324692) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1522 / 2500Epoch 1522 		 Training Loss: 1.419592763696398
Validation step:0Validation step:1Validation step:2Epoch 1522 		 Validation Loss: 4.324600100517273
Validation Loss Decreased(4.324692--->4.324600) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1523 / 2500Epoch 1523 		 Training Loss: 1.417742099080767
Validation step:0Validation step:1Validation step:2Epoch 1523 		 Validation Loss: 4.324557423591614
Validation Loss Decreased(4.324600--->4.324557) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1524 / 2500Epoch 1524 		 Training Loss: 1.4200605835233415
Validation step:0Validation step:1Validation step:2Epoch 1524 		 Validation Loss: 4.324531197547913
Validation Loss Decreased(4.324557--->4.324531) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1525 / 2500Epoch 1525 		 Training Loss: 1.419192910194397
Validation step:0Validation step:1Validation step:2Epoch 1525 		 Validation Loss: 4.324266672134399
Validation Loss Decreased(4.324531--->4.324267) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1526 / 2500Epoch 1526 		 Training Loss: 1.4190564836774553
Validation step:0Validation step:1Validation step:2Epoch 1526 		 Validation Loss: 4.3242045640945435
Validation Loss Decreased(4.324267--->4.324205) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1527 / 2500Epoch 1527 		 Training Loss: 1.4175310475485665
Validation step:0Validation step:1Validation step:2Epoch 1527 		 Validation Loss: 4.324095249176025
Validation Loss Decreased(4.324205--->4.324095) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1528 / 2500Epoch 1528 		 Training Loss: 1.4204702036721366
Validation step:0Validation step:1Validation step:2Epoch 1528 		 Validation Loss: 4.323971152305603
Validation Loss Decreased(4.324095--->4.323971) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1529 / 2500Epoch 1529 		 Training Loss: 1.418453574180603
Validation step:0Validation step:1Validation step:2Epoch 1529 		 Validation Loss: 4.323892831802368
Validation Loss Decreased(4.323971--->4.323893) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1530 / 2500Epoch 1530 		 Training Loss: 1.419519535132817
Validation step:0Validation step:1Validation step:2Epoch 1530 		 Validation Loss: 4.3237950801849365
Validation Loss Decreased(4.323893--->4.323795) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1531 / 2500Epoch 1531 		 Training Loss: 1.419218122959137
Validation step:0Validation step:1Validation step:2Epoch 1531 		 Validation Loss: 4.323656678199768
Validation Loss Decreased(4.323795--->4.323657) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1532 / 2500Epoch 1532 		 Training Loss: 1.4205268791743688
Validation step:0Validation step:1Validation step:2Epoch 1532 		 Validation Loss: 4.323549747467041
Validation Loss Decreased(4.323657--->4.323550) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1533 / 2500Epoch 1533 		 Training Loss: 1.418394718851362
Validation step:0Validation step:1Validation step:2Epoch 1533 		 Validation Loss: 4.323544263839722
Validation Loss Decreased(4.323550--->4.323544) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1534 / 2500Epoch 1534 		 Training Loss: 1.4167988726070948
Validation step:0Validation step:1Validation step:2Epoch 1534 		 Validation Loss: 4.323248505592346
Validation Loss Decreased(4.323544--->4.323249) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1535 / 2500Epoch 1535 		 Training Loss: 1.419455579348973
Validation step:0Validation step:1Validation step:2Epoch 1535 		 Validation Loss: 4.323153138160706
Validation Loss Decreased(4.323249--->4.323153) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1536 / 2500Epoch 1536 		 Training Loss: 1.419454642704555
Validation step:0Validation step:1Validation step:2Epoch 1536 		 Validation Loss: 4.323028564453125
Validation Loss Decreased(4.323153--->4.323029) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1537 / 2500Epoch 1537 		 Training Loss: 1.4185596704483032
Validation step:0Validation step:1Validation step:2Epoch 1537 		 Validation Loss: 4.322957754135132
Validation Loss Decreased(4.323029--->4.322958) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1538 / 2500Epoch 1538 		 Training Loss: 1.4192454304013933
Validation step:0Validation step:1Validation step:2Epoch 1538 		 Validation Loss: 4.323032855987549
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1539 / 2500Epoch 1539 		 Training Loss: 1.4186902386801583
Validation step:0Validation step:1Validation step:2Epoch 1539 		 Validation Loss: 4.322847366333008
Validation Loss Decreased(4.322958--->4.322847) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1540 / 2500Epoch 1540 		 Training Loss: 1.417455153805869
Validation step:0Validation step:1Validation step:2Epoch 1540 		 Validation Loss: 4.322688937187195
Validation Loss Decreased(4.322847--->4.322689) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1541 / 2500Epoch 1541 		 Training Loss: 1.4191831350326538
Validation step:0Validation step:1Validation step:2Epoch 1541 		 Validation Loss: 4.322721242904663
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1542 / 2500Epoch 1542 		 Training Loss: 1.418832540512085
Validation step:0Validation step:1Validation step:2Epoch 1542 		 Validation Loss: 4.322611927986145
Validation Loss Decreased(4.322689--->4.322612) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1543 / 2500Epoch 1543 		 Training Loss: 1.419739774295262
Validation step:0Validation step:1Validation step:2Epoch 1543 		 Validation Loss: 4.322402596473694
Validation Loss Decreased(4.322612--->4.322403) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1544 / 2500Epoch 1544 		 Training Loss: 1.4190895216805595
Validation step:0Validation step:1Validation step:2Epoch 1544 		 Validation Loss: 4.322245478630066
Validation Loss Decreased(4.322403--->4.322245) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1545 / 2500Epoch 1545 		 Training Loss: 1.4189505747386388
Validation step:0Validation step:1Validation step:2Epoch 1545 		 Validation Loss: 4.322143912315369
Validation Loss Decreased(4.322245--->4.322144) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1546 / 2500Epoch 1546 		 Training Loss: 1.4172742196491785
Validation step:0Validation step:1Validation step:2Epoch 1546 		 Validation Loss: 4.322082996368408
Validation Loss Decreased(4.322144--->4.322083) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1547 / 2500Epoch 1547 		 Training Loss: 1.417271341596331
Validation step:0Validation step:1Validation step:2Epoch 1547 		 Validation Loss: 4.321995854377747
Validation Loss Decreased(4.322083--->4.321996) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1548 / 2500Epoch 1548 		 Training Loss: 1.4183811119624548
Validation step:0Validation step:1Validation step:2Epoch 1548 		 Validation Loss: 4.3218196630477905
Validation Loss Decreased(4.321996--->4.321820) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1549 / 2500Epoch 1549 		 Training Loss: 1.4181239349501473
Validation step:0Validation step:1Validation step:2Epoch 1549 		 Validation Loss: 4.321611404418945
Validation Loss Decreased(4.321820--->4.321611) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1550 / 2500Epoch 1550 		 Training Loss: 1.4189341494015284
Validation step:0Validation step:1Validation step:2Epoch 1550 		 Validation Loss: 4.321638822555542
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1551 / 2500Epoch 1551 		 Training Loss: 1.4188262479645866
Validation step:0Validation step:1Validation step:2Epoch 1551 		 Validation Loss: 4.321532726287842
Validation Loss Decreased(4.321611--->4.321533) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1552 / 2500Epoch 1552 		 Training Loss: 1.4183089307376318
Validation step:0Validation step:1Validation step:2Epoch 1552 		 Validation Loss: 4.3213770389556885
Validation Loss Decreased(4.321533--->4.321377) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1553 / 2500Epoch 1553 		 Training Loss: 1.4178753920963831
Validation step:0Validation step:1Validation step:2Epoch 1553 		 Validation Loss: 4.321265697479248
Validation Loss Decreased(4.321377--->4.321266) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1554 / 2500Epoch 1554 		 Training Loss: 1.4189555730138506
Validation step:0Validation step:1Validation step:2Epoch 1554 		 Validation Loss: 4.32115912437439
Validation Loss Decreased(4.321266--->4.321159) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1555 / 2500Epoch 1555 		 Training Loss: 1.417031807558877
Validation step:0Validation step:1Validation step:2Epoch 1555 		 Validation Loss: 4.321015357971191
Validation Loss Decreased(4.321159--->4.321015) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1556 / 2500Epoch 1556 		 Training Loss: 1.4192914877619063
Validation step:0Validation step:1Validation step:2Epoch 1556 		 Validation Loss: 4.320984363555908
Validation Loss Decreased(4.321015--->4.320984) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1557 / 2500Epoch 1557 		 Training Loss: 1.4192634565489632
Validation step:0Validation step:1Validation step:2Epoch 1557 		 Validation Loss: 4.320878863334656
Validation Loss Decreased(4.320984--->4.320879) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1558 / 2500Epoch 1558 		 Training Loss: 1.4186763337680273
Validation step:0Validation step:1Validation step:2Epoch 1558 		 Validation Loss: 4.320743680000305
Validation Loss Decreased(4.320879--->4.320744) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1559 / 2500Epoch 1559 		 Training Loss: 1.4196346061570304
Validation step:0Validation step:1Validation step:2Epoch 1559 		 Validation Loss: 4.320571660995483
Validation Loss Decreased(4.320744--->4.320572) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1560 / 2500Epoch 1560 		 Training Loss: 1.4175789526530675
Validation step:0Validation step:1Validation step:2Epoch 1560 		 Validation Loss: 4.320487380027771
Validation Loss Decreased(4.320572--->4.320487) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1561 / 2500Epoch 1561 		 Training Loss: 1.4183258243969508
Validation step:0Validation step:1Validation step:2Epoch 1561 		 Validation Loss: 4.320316195487976
Validation Loss Decreased(4.320487--->4.320316) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1562 / 2500Epoch 1562 		 Training Loss: 1.4180522901671273
Validation step:0Validation step:1Validation step:2Epoch 1562 		 Validation Loss: 4.3202232122421265
Validation Loss Decreased(4.320316--->4.320223) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1563 / 2500Epoch 1563 		 Training Loss: 1.4181339825902666
Validation step:0Validation step:1Validation step:2Epoch 1563 		 Validation Loss: 4.320296883583069
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1564 / 2500Epoch 1564 		 Training Loss: 1.418683954647609
Validation step:0Validation step:1Validation step:2Epoch 1564 		 Validation Loss: 4.320077896118164
Validation Loss Decreased(4.320223--->4.320078) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1565 / 2500Epoch 1565 		 Training Loss: 1.417600222996303
Validation step:0Validation step:1Validation step:2Epoch 1565 		 Validation Loss: 4.31991708278656
Validation Loss Decreased(4.320078--->4.319917) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1566 / 2500Epoch 1566 		 Training Loss: 1.4195756486483984
Validation step:0Validation step:1Validation step:2Epoch 1566 		 Validation Loss: 4.320183873176575
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1567 / 2500Epoch 1567 		 Training Loss: 1.4174197997365678
Validation step:0Validation step:1Validation step:2Epoch 1567 		 Validation Loss: 4.319900155067444
Validation Loss Decreased(4.319917--->4.319900) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1568 / 2500Epoch 1568 		 Training Loss: 1.417995376246316
Validation step:0Validation step:1Validation step:2Epoch 1568 		 Validation Loss: 4.319614410400391
Validation Loss Decreased(4.319900--->4.319614) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1569 / 2500Epoch 1569 		 Training Loss: 1.4183035578046526
Validation step:0Validation step:1Validation step:2Epoch 1569 		 Validation Loss: 4.319444060325623
Validation Loss Decreased(4.319614--->4.319444) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1570 / 2500Epoch 1570 		 Training Loss: 1.4178007330213274
Validation step:0Validation step:1Validation step:2Epoch 1570 		 Validation Loss: 4.319316983222961
Validation Loss Decreased(4.319444--->4.319317) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1571 / 2500Epoch 1571 		 Training Loss: 1.4173785618373327
Validation step:0Validation step:1Validation step:2Epoch 1571 		 Validation Loss: 4.319225430488586
Validation Loss Decreased(4.319317--->4.319225) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1572 / 2500Epoch 1572 		 Training Loss: 1.418250092438289
Validation step:0Validation step:1Validation step:2Epoch 1572 		 Validation Loss: 4.319226980209351
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1573 / 2500Epoch 1573 		 Training Loss: 1.4177971226828439
Validation step:0Validation step:1Validation step:2Epoch 1573 		 Validation Loss: 4.319042921066284
Validation Loss Decreased(4.319225--->4.319043) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1574 / 2500Epoch 1574 		 Training Loss: 1.416518705231803
Validation step:0Validation step:1Validation step:2Epoch 1574 		 Validation Loss: 4.318889617919922
Validation Loss Decreased(4.319043--->4.318890) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1575 / 2500Epoch 1575 		 Training Loss: 1.4177709477288383
Validation step:0Validation step:1Validation step:2Epoch 1575 		 Validation Loss: 4.318764567375183
Validation Loss Decreased(4.318890--->4.318765) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1576 / 2500Epoch 1576 		 Training Loss: 1.4179458107267107
Validation step:0Validation step:1Validation step:2Epoch 1576 		 Validation Loss: 4.318644046783447
Validation Loss Decreased(4.318765--->4.318644) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1577 / 2500Epoch 1577 		 Training Loss: 1.4161377719470434
Validation step:0Validation step:1Validation step:2Epoch 1577 		 Validation Loss: 4.318548321723938
Validation Loss Decreased(4.318644--->4.318548) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1578 / 2500Epoch 1578 		 Training Loss: 1.4182589224406652
Validation step:0Validation step:1Validation step:2Epoch 1578 		 Validation Loss: 4.318358063697815
Validation Loss Decreased(4.318548--->4.318358) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1579 / 2500Epoch 1579 		 Training Loss: 1.415487289428711
Validation step:0Validation step:1Validation step:2Epoch 1579 		 Validation Loss: 4.318312764167786
Validation Loss Decreased(4.318358--->4.318313) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1580 / 2500Epoch 1580 		 Training Loss: 1.4171655348369054
Validation step:0Validation step:1Validation step:2Epoch 1580 		 Validation Loss: 4.318252444267273
Validation Loss Decreased(4.318313--->4.318252) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1581 / 2500Epoch 1581 		 Training Loss: 1.4188580427850996
Validation step:0Validation step:1Validation step:2Epoch 1581 		 Validation Loss: 4.318164825439453
Validation Loss Decreased(4.318252--->4.318165) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1582 / 2500Epoch 1582 		 Training Loss: 1.4182775361197335
Validation step:0Validation step:1Validation step:2Epoch 1582 		 Validation Loss: 4.318042516708374
Validation Loss Decreased(4.318165--->4.318043) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1583 / 2500Epoch 1583 		 Training Loss: 1.417863632951464
Validation step:0Validation step:1Validation step:2Epoch 1583 		 Validation Loss: 4.31785261631012
Validation Loss Decreased(4.318043--->4.317853) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1584 / 2500Epoch 1584 		 Training Loss: 1.4180529883929662
Validation step:0Validation step:1Validation step:2Epoch 1584 		 Validation Loss: 4.317720413208008
Validation Loss Decreased(4.317853--->4.317720) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1585 / 2500Epoch 1585 		 Training Loss: 1.4172151599611555
Validation step:0Validation step:1Validation step:2Epoch 1585 		 Validation Loss: 4.317729234695435
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1586 / 2500Epoch 1586 		 Training Loss: 1.4166392598833357
Validation step:0Validation step:1Validation step:2Epoch 1586 		 Validation Loss: 4.317671060562134
Validation Loss Decreased(4.317720--->4.317671) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1587 / 2500Epoch 1587 		 Training Loss: 1.4162229214395796
Validation step:0Validation step:1Validation step:2Epoch 1587 		 Validation Loss: 4.317394971847534
Validation Loss Decreased(4.317671--->4.317395) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1588 / 2500Epoch 1588 		 Training Loss: 1.4177910770688738
Validation step:0Validation step:1Validation step:2Epoch 1588 		 Validation Loss: 4.3172701597213745
Validation Loss Decreased(4.317395--->4.317270) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1589 / 2500Epoch 1589 		 Training Loss: 1.4176038673945837
Validation step:0Validation step:1Validation step:2Epoch 1589 		 Validation Loss: 4.3172911405563354
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1590 / 2500Epoch 1590 		 Training Loss: 1.4167136890547616
Validation step:0Validation step:1Validation step:2Epoch 1590 		 Validation Loss: 4.317136287689209
Validation Loss Decreased(4.317270--->4.317136) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1591 / 2500Epoch 1591 		 Training Loss: 1.4168261885643005
Validation step:0Validation step:1Validation step:2Epoch 1591 		 Validation Loss: 4.3171706199646
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1592 / 2500Epoch 1592 		 Training Loss: 1.4178925837789262
Validation step:0Validation step:1Validation step:2Epoch 1592 		 Validation Loss: 4.317088007926941
Validation Loss Decreased(4.317136--->4.317088) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1593 / 2500Epoch 1593 		 Training Loss: 1.4179917403629847
Validation step:0Validation step:1Validation step:2Epoch 1593 		 Validation Loss: 4.3168991804122925
Validation Loss Decreased(4.317088--->4.316899) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1594 / 2500Epoch 1594 		 Training Loss: 1.4165221537862505
Validation step:0Validation step:1Validation step:2Epoch 1594 		 Validation Loss: 4.316755294799805
Validation Loss Decreased(4.316899--->4.316755) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1595 / 2500Epoch 1595 		 Training Loss: 1.4160492845943995
Validation step:0Validation step:1Validation step:2Epoch 1595 		 Validation Loss: 4.316744327545166
Validation Loss Decreased(4.316755--->4.316744) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1596 / 2500Epoch 1596 		 Training Loss: 1.4165290934698922
Validation step:0Validation step:1Validation step:2Epoch 1596 		 Validation Loss: 4.316450357437134
Validation Loss Decreased(4.316744--->4.316450) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1597 / 2500Epoch 1597 		 Training Loss: 1.416836874825614
Validation step:0Validation step:1Validation step:2Epoch 1597 		 Validation Loss: 4.3163464069366455
Validation Loss Decreased(4.316450--->4.316346) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1598 / 2500Epoch 1598 		 Training Loss: 1.4178793685776847
Validation step:0Validation step:1Validation step:2Epoch 1598 		 Validation Loss: 4.316310405731201
Validation Loss Decreased(4.316346--->4.316310) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1599 / 2500Epoch 1599 		 Training Loss: 1.4174382856913976
Validation step:0Validation step:1Validation step:2Epoch 1599 		 Validation Loss: 4.316195011138916
Validation Loss Decreased(4.316310--->4.316195) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1600 / 2500Epoch 1600 		 Training Loss: 1.4155742015157426
Validation step:0Validation step:1Validation step:2Epoch 1600 		 Validation Loss: 4.3160719871521
Validation Loss Decreased(4.316195--->4.316072) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1601 / 2500Epoch 1601 		 Training Loss: 1.4171330077307565
Validation step:0Validation step:1Validation step:2Epoch 1601 		 Validation Loss: 4.3160107135772705
Validation Loss Decreased(4.316072--->4.316011) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1602 / 2500Epoch 1602 		 Training Loss: 1.4162579434258598
Validation step:0Validation step:1Validation step:2Epoch 1602 		 Validation Loss: 4.3158118724823
Validation Loss Decreased(4.316011--->4.315812) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1603 / 2500Epoch 1603 		 Training Loss: 1.4149717433112008
Validation step:0Validation step:1Validation step:2Epoch 1603 		 Validation Loss: 4.31593382358551
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1604 / 2500Epoch 1604 		 Training Loss: 1.4163335817200797
Validation step:0Validation step:1Validation step:2Epoch 1604 		 Validation Loss: 4.315675616264343
Validation Loss Decreased(4.315812--->4.315676) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1605 / 2500Epoch 1605 		 Training Loss: 1.4166249803134374
Validation step:0Validation step:1Validation step:2Epoch 1605 		 Validation Loss: 4.315615177154541
Validation Loss Decreased(4.315676--->4.315615) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1606 / 2500Epoch 1606 		 Training Loss: 1.4162185192108154
Validation step:0Validation step:1Validation step:2Epoch 1606 		 Validation Loss: 4.315556287765503
Validation Loss Decreased(4.315615--->4.315556) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1607 / 2500Epoch 1607 		 Training Loss: 1.4166880079678126
Validation step:0Validation step:1Validation step:2Epoch 1607 		 Validation Loss: 4.315417289733887
Validation Loss Decreased(4.315556--->4.315417) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1608 / 2500Epoch 1608 		 Training Loss: 1.416283803326743
Validation step:0Validation step:1Validation step:2Epoch 1608 		 Validation Loss: 4.3152174949646
Validation Loss Decreased(4.315417--->4.315217) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1609 / 2500Epoch 1609 		 Training Loss: 1.4157855681010656
Validation step:0Validation step:1Validation step:2Epoch 1609 		 Validation Loss: 4.31507933139801
Validation Loss Decreased(4.315217--->4.315079) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1610 / 2500Epoch 1610 		 Training Loss: 1.414713638169425
Validation step:0Validation step:1Validation step:2Epoch 1610 		 Validation Loss: 4.314988851547241
Validation Loss Decreased(4.315079--->4.314989) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1611 / 2500Epoch 1611 		 Training Loss: 1.4161670463425773
Validation step:0Validation step:1Validation step:2Epoch 1611 		 Validation Loss: 4.314923048019409
Validation Loss Decreased(4.314989--->4.314923) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1612 / 2500Epoch 1612 		 Training Loss: 1.4163617832320077
Validation step:0Validation step:1Validation step:2Epoch 1612 		 Validation Loss: 4.314855098724365
Validation Loss Decreased(4.314923--->4.314855) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1613 / 2500Epoch 1613 		 Training Loss: 1.4162953666278295
Validation step:0Validation step:1Validation step:2Epoch 1613 		 Validation Loss: 4.314687371253967
Validation Loss Decreased(4.314855--->4.314687) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1614 / 2500Epoch 1614 		 Training Loss: 1.4146175639969962
Validation step:0Validation step:1Validation step:2Epoch 1614 		 Validation Loss: 4.314644932746887
Validation Loss Decreased(4.314687--->4.314645) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1615 / 2500Epoch 1615 		 Training Loss: 1.4158098612512862
Validation step:0Validation step:1Validation step:2Epoch 1615 		 Validation Loss: 4.314666748046875
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1616 / 2500Epoch 1616 		 Training Loss: 1.4151678340775626
Validation step:0Validation step:1Validation step:2Epoch 1616 		 Validation Loss: 4.314514875411987
Validation Loss Decreased(4.314645--->4.314515) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1617 / 2500Epoch 1617 		 Training Loss: 1.4176548208509172
Validation step:0Validation step:1Validation step:2Epoch 1617 		 Validation Loss: 4.314372897148132
Validation Loss Decreased(4.314515--->4.314373) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1618 / 2500Epoch 1618 		 Training Loss: 1.4151474833488464
Validation step:0Validation step:1Validation step:2Epoch 1618 		 Validation Loss: 4.314210653305054
Validation Loss Decreased(4.314373--->4.314211) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1619 / 2500Epoch 1619 		 Training Loss: 1.4165116207940238
Validation step:0Validation step:1Validation step:2Epoch 1619 		 Validation Loss: 4.31413471698761
Validation Loss Decreased(4.314211--->4.314135) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1620 / 2500Epoch 1620 		 Training Loss: 1.4171386190823145
Validation step:0Validation step:1Validation step:2Epoch 1620 		 Validation Loss: 4.314106225967407
Validation Loss Decreased(4.314135--->4.314106) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1621 / 2500Epoch 1621 		 Training Loss: 1.4161961759839738
Validation step:0Validation step:1Validation step:2Epoch 1621 		 Validation Loss: 4.31397271156311
Validation Loss Decreased(4.314106--->4.313973) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1622 / 2500Epoch 1622 		 Training Loss: 1.4161267961774553
Validation step:0Validation step:1Validation step:2Epoch 1622 		 Validation Loss: 4.313884496688843
Validation Loss Decreased(4.313973--->4.313884) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1623 / 2500Epoch 1623 		 Training Loss: 1.416391806943076
Validation step:0Validation step:1Validation step:2Epoch 1623 		 Validation Loss: 4.313656568527222
Validation Loss Decreased(4.313884--->4.313657) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1624 / 2500Epoch 1624 		 Training Loss: 1.4160007749285017
Validation step:0Validation step:1Validation step:2Epoch 1624 		 Validation Loss: 4.313558340072632
Validation Loss Decreased(4.313657--->4.313558) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1625 / 2500Epoch 1625 		 Training Loss: 1.4158974119595118
Validation step:0Validation step:1Validation step:2Epoch 1625 		 Validation Loss: 4.313482999801636
Validation Loss Decreased(4.313558--->4.313483) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1626 / 2500Epoch 1626 		 Training Loss: 1.4148441808564323
Validation step:0Validation step:1Validation step:2Epoch 1626 		 Validation Loss: 4.313369274139404
Validation Loss Decreased(4.313483--->4.313369) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1627 / 2500Epoch 1627 		 Training Loss: 1.4138207350458418
Validation step:0Validation step:1Validation step:2Epoch 1627 		 Validation Loss: 4.313310503959656
Validation Loss Decreased(4.313369--->4.313311) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1628 / 2500Epoch 1628 		 Training Loss: 1.4150730882372176
Validation step:0Validation step:1Validation step:2Epoch 1628 		 Validation Loss: 4.31320321559906
Validation Loss Decreased(4.313311--->4.313203) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1629 / 2500Epoch 1629 		 Training Loss: 1.4152566194534302
Validation step:0Validation step:1Validation step:2Epoch 1629 		 Validation Loss: 4.313068628311157
Validation Loss Decreased(4.313203--->4.313069) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1630 / 2500Epoch 1630 		 Training Loss: 1.4163138014929635
Validation step:0Validation step:1Validation step:2Epoch 1630 		 Validation Loss: 4.3130059242248535
Validation Loss Decreased(4.313069--->4.313006) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1631 / 2500Epoch 1631 		 Training Loss: 1.4160880105836051
Validation step:0Validation step:1Validation step:2Epoch 1631 		 Validation Loss: 4.312912344932556
Validation Loss Decreased(4.313006--->4.312912) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1632 / 2500Epoch 1632 		 Training Loss: 1.4153724993978227
Validation step:0Validation step:1Validation step:2Epoch 1632 		 Validation Loss: 4.3127992153167725
Validation Loss Decreased(4.312912--->4.312799) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1633 / 2500Epoch 1633 		 Training Loss: 1.4152472955839974
Validation step:0Validation step:1Validation step:2Epoch 1633 		 Validation Loss: 4.312694311141968
Validation Loss Decreased(4.312799--->4.312694) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1634 / 2500Epoch 1634 		 Training Loss: 1.4151116354124886
Validation step:0Validation step:1Validation step:2Epoch 1634 		 Validation Loss: 4.312693476676941
Validation Loss Decreased(4.312694--->4.312693) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1635 / 2500Epoch 1635 		 Training Loss: 1.4145384430885315
Validation step:0Validation step:1Validation step:2Epoch 1635 		 Validation Loss: 4.3125364780426025
Validation Loss Decreased(4.312693--->4.312536) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1636 / 2500Epoch 1636 		 Training Loss: 1.4153758372579301
Validation step:0Validation step:1Validation step:2Epoch 1636 		 Validation Loss: 4.312343239784241
Validation Loss Decreased(4.312536--->4.312343) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1637 / 2500Epoch 1637 		 Training Loss: 1.4146439262798853
Validation step:0Validation step:1Validation step:2Epoch 1637 		 Validation Loss: 4.312232851982117
Validation Loss Decreased(4.312343--->4.312233) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1638 / 2500Epoch 1638 		 Training Loss: 1.414781630039215
Validation step:0Validation step:1Validation step:2Epoch 1638 		 Validation Loss: 4.312220811843872
Validation Loss Decreased(4.312233--->4.312221) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1639 / 2500Epoch 1639 		 Training Loss: 1.4157567620277405
Validation step:0Validation step:1Validation step:2Epoch 1639 		 Validation Loss: 4.312048673629761
Validation Loss Decreased(4.312221--->4.312049) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1640 / 2500Epoch 1640 		 Training Loss: 1.415283739566803
Validation step:0Validation step:1Validation step:2Epoch 1640 		 Validation Loss: 4.311917662620544
Validation Loss Decreased(4.312049--->4.311918) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1641 / 2500Epoch 1641 		 Training Loss: 1.4162387251853943
Validation step:0Validation step:1Validation step:2Epoch 1641 		 Validation Loss: 4.3118205070495605
Validation Loss Decreased(4.311918--->4.311821) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1642 / 2500Epoch 1642 		 Training Loss: 1.4141149435724532
Validation step:0Validation step:1Validation step:2Epoch 1642 		 Validation Loss: 4.311685562133789
Validation Loss Decreased(4.311821--->4.311686) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1643 / 2500Epoch 1643 		 Training Loss: 1.4155417765889848
Validation step:0Validation step:1Validation step:2Epoch 1643 		 Validation Loss: 4.31160569190979
Validation Loss Decreased(4.311686--->4.311606) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1644 / 2500Epoch 1644 		 Training Loss: 1.414967690195356
Validation step:0Validation step:1Validation step:2Epoch 1644 		 Validation Loss: 4.3115575313568115
Validation Loss Decreased(4.311606--->4.311558) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1645 / 2500Epoch 1645 		 Training Loss: 1.4158906425748552
Validation step:0Validation step:1Validation step:2Epoch 1645 		 Validation Loss: 4.311395645141602
Validation Loss Decreased(4.311558--->4.311396) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1646 / 2500Epoch 1646 		 Training Loss: 1.415987261704036
Validation step:0Validation step:1Validation step:2Epoch 1646 		 Validation Loss: 4.311295390129089
Validation Loss Decreased(4.311396--->4.311295) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1647 / 2500Epoch 1647 		 Training Loss: 1.415018115724836
Validation step:0Validation step:1Validation step:2Epoch 1647 		 Validation Loss: 4.311227560043335
Validation Loss Decreased(4.311295--->4.311228) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1648 / 2500Epoch 1648 		 Training Loss: 1.4146611945969718
Validation step:0Validation step:1Validation step:2Epoch 1648 		 Validation Loss: 4.3111666440963745
Validation Loss Decreased(4.311228--->4.311167) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1649 / 2500Epoch 1649 		 Training Loss: 1.4143210734639848
Validation step:0Validation step:1Validation step:2Epoch 1649 		 Validation Loss: 4.311047673225403
Validation Loss Decreased(4.311167--->4.311048) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1650 / 2500Epoch 1650 		 Training Loss: 1.413857570716313
Validation step:0Validation step:1Validation step:2Epoch 1650 		 Validation Loss: 4.310961484909058
Validation Loss Decreased(4.311048--->4.310961) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1651 / 2500Epoch 1651 		 Training Loss: 1.4148146510124207
Validation step:0Validation step:1Validation step:2Epoch 1651 		 Validation Loss: 4.310797572135925
Validation Loss Decreased(4.310961--->4.310798) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1652 / 2500Epoch 1652 		 Training Loss: 1.4152462567601884
Validation step:0Validation step:1Validation step:2Epoch 1652 		 Validation Loss: 4.310872554779053
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1653 / 2500Epoch 1653 		 Training Loss: 1.4155539870262146
Validation step:0Validation step:1Validation step:2Epoch 1653 		 Validation Loss: 4.310799717903137
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1654 / 2500Epoch 1654 		 Training Loss: 1.4136880040168762
Validation step:0Validation step:1Validation step:2Epoch 1654 		 Validation Loss: 4.310560584068298
Validation Loss Decreased(4.310798--->4.310561) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1655 / 2500Epoch 1655 		 Training Loss: 1.4144043241228377
Validation step:0Validation step:1Validation step:2Epoch 1655 		 Validation Loss: 4.310377597808838
Validation Loss Decreased(4.310561--->4.310378) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1656 / 2500Epoch 1656 		 Training Loss: 1.4143507310322352
Validation step:0Validation step:1Validation step:2Epoch 1656 		 Validation Loss: 4.310295820236206
Validation Loss Decreased(4.310378--->4.310296) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1657 / 2500Epoch 1657 		 Training Loss: 1.4152517318725586
Validation step:0Validation step:1Validation step:2Epoch 1657 		 Validation Loss: 4.3103978633880615
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1658 / 2500Epoch 1658 		 Training Loss: 1.4144679137638636
Validation step:0Validation step:1Validation step:2Epoch 1658 		 Validation Loss: 4.310133099555969
Validation Loss Decreased(4.310296--->4.310133) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1659 / 2500Epoch 1659 		 Training Loss: 1.4141638789858137
Validation step:0Validation step:1Validation step:2Epoch 1659 		 Validation Loss: 4.309961438179016
Validation Loss Decreased(4.310133--->4.309961) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1660 / 2500Epoch 1660 		 Training Loss: 1.4147658007485526
Validation step:0Validation step:1Validation step:2Epoch 1660 		 Validation Loss: 4.30986213684082
Validation Loss Decreased(4.309961--->4.309862) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1661 / 2500Epoch 1661 		 Training Loss: 1.414654552936554
Validation step:0Validation step:1Validation step:2Epoch 1661 		 Validation Loss: 4.309833526611328
Validation Loss Decreased(4.309862--->4.309834) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1662 / 2500Epoch 1662 		 Training Loss: 1.415238618850708
Validation step:0Validation step:1Validation step:2Epoch 1662 		 Validation Loss: 4.309715390205383
Validation Loss Decreased(4.309834--->4.309715) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1663 / 2500Epoch 1663 		 Training Loss: 1.4112855792045593
Validation step:0Validation step:1Validation step:2Epoch 1663 		 Validation Loss: 4.309559941291809
Validation Loss Decreased(4.309715--->4.309560) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1664 / 2500Epoch 1664 		 Training Loss: 1.4154621618134635
Validation step:0Validation step:1Validation step:2Epoch 1664 		 Validation Loss: 4.309602737426758
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1665 / 2500Epoch 1665 		 Training Loss: 1.4129537684576852
Validation step:0Validation step:1Validation step:2Epoch 1665 		 Validation Loss: 4.309327602386475
Validation Loss Decreased(4.309560--->4.309328) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1666 / 2500Epoch 1666 		 Training Loss: 1.4134103996413094
Validation step:0Validation step:1Validation step:2Epoch 1666 		 Validation Loss: 4.309238910675049
Validation Loss Decreased(4.309328--->4.309239) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1667 / 2500Epoch 1667 		 Training Loss: 1.4153524041175842
Validation step:0Validation step:1Validation step:2Epoch 1667 		 Validation Loss: 4.309180736541748
Validation Loss Decreased(4.309239--->4.309181) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1668 / 2500Epoch 1668 		 Training Loss: 1.4141620227268763
Validation step:0Validation step:1Validation step:2Epoch 1668 		 Validation Loss: 4.309099555015564
Validation Loss Decreased(4.309181--->4.309100) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1669 / 2500Epoch 1669 		 Training Loss: 1.4139549391610282
Validation step:0Validation step:1Validation step:2Epoch 1669 		 Validation Loss: 4.308920860290527
Validation Loss Decreased(4.309100--->4.308921) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1670 / 2500Epoch 1670 		 Training Loss: 1.4146003808294023
Validation step:0Validation step:1Validation step:2Epoch 1670 		 Validation Loss: 4.308787703514099
Validation Loss Decreased(4.308921--->4.308788) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1671 / 2500Epoch 1671 		 Training Loss: 1.4133344207491194
Validation step:0Validation step:1Validation step:2Epoch 1671 		 Validation Loss: 4.3086583614349365
Validation Loss Decreased(4.308788--->4.308658) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1672 / 2500Epoch 1672 		 Training Loss: 1.4144404700824194
Validation step:0Validation step:1Validation step:2Epoch 1672 		 Validation Loss: 4.308646082878113
Validation Loss Decreased(4.308658--->4.308646) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1673 / 2500Epoch 1673 		 Training Loss: 1.414148713861193
Validation step:0Validation step:1Validation step:2Epoch 1673 		 Validation Loss: 4.308505535125732
Validation Loss Decreased(4.308646--->4.308506) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1674 / 2500Epoch 1674 		 Training Loss: 1.413973263331822
Validation step:0Validation step:1Validation step:2Epoch 1674 		 Validation Loss: 4.3083343505859375
Validation Loss Decreased(4.308506--->4.308334) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1675 / 2500Epoch 1675 		 Training Loss: 1.4140137944902693
Validation step:0Validation step:1Validation step:2Epoch 1675 		 Validation Loss: 4.308257341384888
Validation Loss Decreased(4.308334--->4.308257) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1676 / 2500Epoch 1676 		 Training Loss: 1.4141205974987574
Validation step:0Validation step:1Validation step:2Epoch 1676 		 Validation Loss: 4.308129191398621
Validation Loss Decreased(4.308257--->4.308129) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1677 / 2500Epoch 1677 		 Training Loss: 1.4131639514650618
Validation step:0Validation step:1Validation step:2Epoch 1677 		 Validation Loss: 4.3080713748931885
Validation Loss Decreased(4.308129--->4.308071) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1678 / 2500Epoch 1678 		 Training Loss: 1.413586369582585
Validation step:0Validation step:1Validation step:2Epoch 1678 		 Validation Loss: 4.307988524436951
Validation Loss Decreased(4.308071--->4.307989) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1679 / 2500Epoch 1679 		 Training Loss: 1.4121408462524414
Validation step:0Validation step:1Validation step:2Epoch 1679 		 Validation Loss: 4.307866930961609
Validation Loss Decreased(4.307989--->4.307867) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1680 / 2500Epoch 1680 		 Training Loss: 1.4146683812141418
Validation step:0Validation step:1Validation step:2Epoch 1680 		 Validation Loss: 4.307790279388428
Validation Loss Decreased(4.307867--->4.307790) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1681 / 2500Epoch 1681 		 Training Loss: 1.413086942264012
Validation step:0Validation step:1Validation step:2Epoch 1681 		 Validation Loss: 4.307628750801086
Validation Loss Decreased(4.307790--->4.307629) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1682 / 2500Epoch 1682 		 Training Loss: 1.4143028003828866
Validation step:0Validation step:1Validation step:2Epoch 1682 		 Validation Loss: 4.307522535324097
Validation Loss Decreased(4.307629--->4.307523) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1683 / 2500Epoch 1683 		 Training Loss: 1.413977324962616
Validation step:0Validation step:1Validation step:2Epoch 1683 		 Validation Loss: 4.307416200637817
Validation Loss Decreased(4.307523--->4.307416) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1684 / 2500Epoch 1684 		 Training Loss: 1.413614341190883
Validation step:0Validation step:1Validation step:2Epoch 1684 		 Validation Loss: 4.3074012994766235
Validation Loss Decreased(4.307416--->4.307401) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1685 / 2500Epoch 1685 		 Training Loss: 1.4135336024420602
Validation step:0Validation step:1Validation step:2Epoch 1685 		 Validation Loss: 4.3072288036346436
Validation Loss Decreased(4.307401--->4.307229) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1686 / 2500Epoch 1686 		 Training Loss: 1.4147255420684814
Validation step:0Validation step:1Validation step:2Epoch 1686 		 Validation Loss: 4.307048559188843
Validation Loss Decreased(4.307229--->4.307049) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1687 / 2500Epoch 1687 		 Training Loss: 1.4134715710367476
Validation step:0Validation step:1Validation step:2Epoch 1687 		 Validation Loss: 4.307078242301941
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1688 / 2500Epoch 1688 		 Training Loss: 1.4139420986175537
Validation step:0Validation step:1Validation step:2Epoch 1688 		 Validation Loss: 4.306981921195984
Validation Loss Decreased(4.307049--->4.306982) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1689 / 2500Epoch 1689 		 Training Loss: 1.4129474077905928
Validation step:0Validation step:1Validation step:2Epoch 1689 		 Validation Loss: 4.306860327720642
Validation Loss Decreased(4.306982--->4.306860) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1690 / 2500Epoch 1690 		 Training Loss: 1.413900341306414
Validation step:0Validation step:1Validation step:2Epoch 1690 		 Validation Loss: 4.306737065315247
Validation Loss Decreased(4.306860--->4.306737) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1691 / 2500Epoch 1691 		 Training Loss: 1.413982663835798
Validation step:0Validation step:1Validation step:2Epoch 1691 		 Validation Loss: 4.3065783977508545
Validation Loss Decreased(4.306737--->4.306578) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1692 / 2500Epoch 1692 		 Training Loss: 1.4131464958190918
Validation step:0Validation step:1Validation step:2Epoch 1692 		 Validation Loss: 4.30652117729187
Validation Loss Decreased(4.306578--->4.306521) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1693 / 2500Epoch 1693 		 Training Loss: 1.4127163801874434
Validation step:0Validation step:1Validation step:2Epoch 1693 		 Validation Loss: 4.306409597396851
Validation Loss Decreased(4.306521--->4.306410) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1694 / 2500Epoch 1694 		 Training Loss: 1.4141107031277247
Validation step:0Validation step:1Validation step:2Epoch 1694 		 Validation Loss: 4.306385517120361
Validation Loss Decreased(4.306410--->4.306386) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1695 / 2500Epoch 1695 		 Training Loss: 1.413884162902832
Validation step:0Validation step:1Validation step:2Epoch 1695 		 Validation Loss: 4.306211471557617
Validation Loss Decreased(4.306386--->4.306211) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1696 / 2500Epoch 1696 		 Training Loss: 1.4141789759908403
Validation step:0Validation step:1Validation step:2Epoch 1696 		 Validation Loss: 4.306108236312866
Validation Loss Decreased(4.306211--->4.306108) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1697 / 2500Epoch 1697 		 Training Loss: 1.412448218890599
Validation step:0Validation step:1Validation step:2Epoch 1697 		 Validation Loss: 4.30604887008667
Validation Loss Decreased(4.306108--->4.306049) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1698 / 2500Epoch 1698 		 Training Loss: 1.4141981516565596
Validation step:0Validation step:1Validation step:2Epoch 1698 		 Validation Loss: 4.305935859680176
Validation Loss Decreased(4.306049--->4.305936) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1699 / 2500Epoch 1699 		 Training Loss: 1.412640699318477
Validation step:0Validation step:1Validation step:2Epoch 1699 		 Validation Loss: 4.305849552154541
Validation Loss Decreased(4.305936--->4.305850) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1700 / 2500Epoch 1700 		 Training Loss: 1.4121724963188171
Validation step:0Validation step:1Validation step:2Epoch 1700 		 Validation Loss: 4.305649518966675
Validation Loss Decreased(4.305850--->4.305650) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1701 / 2500Epoch 1701 		 Training Loss: 1.4118522575923376
Validation step:0Validation step:1Validation step:2Epoch 1701 		 Validation Loss: 4.305608153343201
Validation Loss Decreased(4.305650--->4.305608) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1702 / 2500Epoch 1702 		 Training Loss: 1.4109937718936376
Validation step:0Validation step:1Validation step:2Epoch 1702 		 Validation Loss: 4.305501937866211
Validation Loss Decreased(4.305608--->4.305502) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1703 / 2500Epoch 1703 		 Training Loss: 1.4139611295291357
Validation step:0Validation step:1Validation step:2Epoch 1703 		 Validation Loss: 4.305408358573914
Validation Loss Decreased(4.305502--->4.305408) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1704 / 2500Epoch 1704 		 Training Loss: 1.4118508441107613
Validation step:0Validation step:1Validation step:2Epoch 1704 		 Validation Loss: 4.305352210998535
Validation Loss Decreased(4.305408--->4.305352) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1705 / 2500Epoch 1705 		 Training Loss: 1.4131250551768713
Validation step:0Validation step:1Validation step:2Epoch 1705 		 Validation Loss: 4.305150151252747
Validation Loss Decreased(4.305352--->4.305150) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1706 / 2500Epoch 1706 		 Training Loss: 1.4128306422914778
Validation step:0Validation step:1Validation step:2Epoch 1706 		 Validation Loss: 4.305077791213989
Validation Loss Decreased(4.305150--->4.305078) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1707 / 2500Epoch 1707 		 Training Loss: 1.4117727449962072
Validation step:0Validation step:1Validation step:2Epoch 1707 		 Validation Loss: 4.304996967315674
Validation Loss Decreased(4.305078--->4.304997) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1708 / 2500Epoch 1708 		 Training Loss: 1.4131414634840829
Validation step:0Validation step:1Validation step:2Epoch 1708 		 Validation Loss: 4.304855227470398
Validation Loss Decreased(4.304997--->4.304855) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1709 / 2500Epoch 1709 		 Training Loss: 1.4127774664333888
Validation step:0Validation step:1Validation step:2Epoch 1709 		 Validation Loss: 4.3047730922698975
Validation Loss Decreased(4.304855--->4.304773) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1710 / 2500Epoch 1710 		 Training Loss: 1.412180517401014
Validation step:0Validation step:1Validation step:2Epoch 1710 		 Validation Loss: 4.304686188697815
Validation Loss Decreased(4.304773--->4.304686) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1711 / 2500Epoch 1711 		 Training Loss: 1.4116302728652954
Validation step:0Validation step:1Validation step:2Epoch 1711 		 Validation Loss: 4.304594874382019
Validation Loss Decreased(4.304686--->4.304595) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1712 / 2500Epoch 1712 		 Training Loss: 1.4129429289272852
Validation step:0Validation step:1Validation step:2Epoch 1712 		 Validation Loss: 4.304568767547607
Validation Loss Decreased(4.304595--->4.304569) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1713 / 2500Epoch 1713 		 Training Loss: 1.4128135783331734
Validation step:0Validation step:1Validation step:2Epoch 1713 		 Validation Loss: 4.304410815238953
Validation Loss Decreased(4.304569--->4.304411) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1714 / 2500Epoch 1714 		 Training Loss: 1.4125572102410453
Validation step:0Validation step:1Validation step:2Epoch 1714 		 Validation Loss: 4.304247736930847
Validation Loss Decreased(4.304411--->4.304248) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1715 / 2500Epoch 1715 		 Training Loss: 1.411559181553977
Validation step:0Validation step:1Validation step:2Epoch 1715 		 Validation Loss: 4.30407989025116
Validation Loss Decreased(4.304248--->4.304080) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1716 / 2500Epoch 1716 		 Training Loss: 1.4117005893162318
Validation step:0Validation step:1Validation step:2Epoch 1716 		 Validation Loss: 4.304109573364258
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1717 / 2500Epoch 1717 		 Training Loss: 1.411634121622358
Validation step:0Validation step:1Validation step:2Epoch 1717 		 Validation Loss: 4.303977012634277
Validation Loss Decreased(4.304080--->4.303977) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1718 / 2500Epoch 1718 		 Training Loss: 1.4120169026511056
Validation step:0Validation step:1Validation step:2Epoch 1718 		 Validation Loss: 4.303805232048035
Validation Loss Decreased(4.303977--->4.303805) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1719 / 2500Epoch 1719 		 Training Loss: 1.4114100081580025
Validation step:0Validation step:1Validation step:2Epoch 1719 		 Validation Loss: 4.3037519454956055
Validation Loss Decreased(4.303805--->4.303752) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1720 / 2500Epoch 1720 		 Training Loss: 1.4130441631589616
Validation step:0Validation step:1Validation step:2Epoch 1720 		 Validation Loss: 4.303582787513733
Validation Loss Decreased(4.303752--->4.303583) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1721 / 2500Epoch 1721 		 Training Loss: 1.4123239346912928
Validation step:0Validation step:1Validation step:2Epoch 1721 		 Validation Loss: 4.303507566452026
Validation Loss Decreased(4.303583--->4.303508) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1722 / 2500Epoch 1722 		 Training Loss: 1.4122316496712821
Validation step:0Validation step:1Validation step:2Epoch 1722 		 Validation Loss: 4.303368330001831
Validation Loss Decreased(4.303508--->4.303368) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1723 / 2500Epoch 1723 		 Training Loss: 1.4105315804481506
Validation step:0Validation step:1Validation step:2Epoch 1723 		 Validation Loss: 4.30326509475708
Validation Loss Decreased(4.303368--->4.303265) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1724 / 2500Epoch 1724 		 Training Loss: 1.4120466453688485
Validation step:0Validation step:1Validation step:2Epoch 1724 		 Validation Loss: 4.303089261054993
Validation Loss Decreased(4.303265--->4.303089) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1725 / 2500Epoch 1725 		 Training Loss: 1.4120003581047058
Validation step:0Validation step:1Validation step:2Epoch 1725 		 Validation Loss: 4.303048849105835
Validation Loss Decreased(4.303089--->4.303049) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1726 / 2500Epoch 1726 		 Training Loss: 1.4124069724764143
Validation step:0Validation step:1Validation step:2Epoch 1726 		 Validation Loss: 4.3029104471206665
Validation Loss Decreased(4.303049--->4.302910) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1727 / 2500Epoch 1727 		 Training Loss: 1.410226779324668
Validation step:0Validation step:1Validation step:2Epoch 1727 		 Validation Loss: 4.302937030792236
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1728 / 2500Epoch 1728 		 Training Loss: 1.4110709769385201
Validation step:0Validation step:1Validation step:2Epoch 1728 		 Validation Loss: 4.302771210670471
Validation Loss Decreased(4.302910--->4.302771) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1729 / 2500Epoch 1729 		 Training Loss: 1.410729808466775
Validation step:0Validation step:1Validation step:2Epoch 1729 		 Validation Loss: 4.302654027938843
Validation Loss Decreased(4.302771--->4.302654) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1730 / 2500Epoch 1730 		 Training Loss: 1.4119934013911657
Validation step:0Validation step:1Validation step:2Epoch 1730 		 Validation Loss: 4.302552700042725
Validation Loss Decreased(4.302654--->4.302553) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1731 / 2500Epoch 1731 		 Training Loss: 1.4118502565792628
Validation step:0Validation step:1Validation step:2Epoch 1731 		 Validation Loss: 4.302419185638428
Validation Loss Decreased(4.302553--->4.302419) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1732 / 2500Epoch 1732 		 Training Loss: 1.4111680047852653
Validation step:0Validation step:1Validation step:2Epoch 1732 		 Validation Loss: 4.3027321100234985
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1733 / 2500Epoch 1733 		 Training Loss: 1.4127745628356934
Validation step:0Validation step:1Validation step:2Epoch 1733 		 Validation Loss: 4.302383899688721
Validation Loss Decreased(4.302419--->4.302384) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1734 / 2500Epoch 1734 		 Training Loss: 1.4118808848517281
Validation step:0Validation step:1Validation step:2Epoch 1734 		 Validation Loss: 4.3022555112838745
Validation Loss Decreased(4.302384--->4.302256) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1735 / 2500Epoch 1735 		 Training Loss: 1.4121904543467931
Validation step:0Validation step:1Validation step:2Epoch 1735 		 Validation Loss: 4.30205225944519
Validation Loss Decreased(4.302256--->4.302052) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1736 / 2500Epoch 1736 		 Training Loss: 1.4126472132546561
Validation step:0Validation step:1Validation step:2Epoch 1736 		 Validation Loss: 4.302009344100952
Validation Loss Decreased(4.302052--->4.302009) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1737 / 2500Epoch 1737 		 Training Loss: 1.4118545736585344
Validation step:0Validation step:1Validation step:2Epoch 1737 		 Validation Loss: 4.301824927330017
Validation Loss Decreased(4.302009--->4.301825) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1738 / 2500Epoch 1738 		 Training Loss: 1.4103842377662659
Validation step:0Validation step:1Validation step:2Epoch 1738 		 Validation Loss: 4.301694631576538
Validation Loss Decreased(4.301825--->4.301695) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1739 / 2500Epoch 1739 		 Training Loss: 1.4107916866030012
Validation step:0Validation step:1Validation step:2Epoch 1739 		 Validation Loss: 4.301607608795166
Validation Loss Decreased(4.301695--->4.301608) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1740 / 2500Epoch 1740 		 Training Loss: 1.4109234980174474
Validation step:0Validation step:1Validation step:2Epoch 1740 		 Validation Loss: 4.30151891708374
Validation Loss Decreased(4.301608--->4.301519) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1741 / 2500Epoch 1741 		 Training Loss: 1.4116589682442802
Validation step:0Validation step:1Validation step:2Epoch 1741 		 Validation Loss: 4.301385521888733
Validation Loss Decreased(4.301519--->4.301386) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1742 / 2500Epoch 1742 		 Training Loss: 1.411467467035566
Validation step:0Validation step:1Validation step:2Epoch 1742 		 Validation Loss: 4.30131208896637
Validation Loss Decreased(4.301386--->4.301312) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1743 / 2500Epoch 1743 		 Training Loss: 1.4105172157287598
Validation step:0Validation step:1Validation step:2Epoch 1743 		 Validation Loss: 4.301262378692627
Validation Loss Decreased(4.301312--->4.301262) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1744 / 2500Epoch 1744 		 Training Loss: 1.411527190889631
Validation step:0Validation step:1Validation step:2Epoch 1744 		 Validation Loss: 4.301108241081238
Validation Loss Decreased(4.301262--->4.301108) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1745 / 2500Epoch 1745 		 Training Loss: 1.412137201854161
Validation step:0Validation step:1Validation step:2Epoch 1745 		 Validation Loss: 4.300955176353455
Validation Loss Decreased(4.301108--->4.300955) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1746 / 2500Epoch 1746 		 Training Loss: 1.4112693497112818
Validation step:0Validation step:1Validation step:2Epoch 1746 		 Validation Loss: 4.301015138626099
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1747 / 2500Epoch 1747 		 Training Loss: 1.4114720395633154
Validation step:0Validation step:1Validation step:2Epoch 1747 		 Validation Loss: 4.300832390785217
Validation Loss Decreased(4.300955--->4.300832) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1748 / 2500Epoch 1748 		 Training Loss: 1.4126768282481603
Validation step:0Validation step:1Validation step:2Epoch 1748 		 Validation Loss: 4.3006967306137085
Validation Loss Decreased(4.300832--->4.300697) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1749 / 2500Epoch 1749 		 Training Loss: 1.4117581333432878
Validation step:0Validation step:1Validation step:2Epoch 1749 		 Validation Loss: 4.300607681274414
Validation Loss Decreased(4.300697--->4.300608) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1750 / 2500Epoch 1750 		 Training Loss: 1.4114568148340498
Validation step:0Validation step:1Validation step:2Epoch 1750 		 Validation Loss: 4.300479173660278
Validation Loss Decreased(4.300608--->4.300479) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1751 / 2500Epoch 1751 		 Training Loss: 1.4113837310246058
Validation step:0Validation step:1Validation step:2Epoch 1751 		 Validation Loss: 4.300412893295288
Validation Loss Decreased(4.300479--->4.300413) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1752 / 2500Epoch 1752 		 Training Loss: 1.4108774321419852
Validation step:0Validation step:1Validation step:2Epoch 1752 		 Validation Loss: 4.300332546234131
Validation Loss Decreased(4.300413--->4.300333) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1753 / 2500Epoch 1753 		 Training Loss: 1.4127034544944763
Validation step:0Validation step:1Validation step:2Epoch 1753 		 Validation Loss: 4.300248146057129
Validation Loss Decreased(4.300333--->4.300248) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1754 / 2500Epoch 1754 		 Training Loss: 1.410829816545759
Validation step:0Validation step:1Validation step:2Epoch 1754 		 Validation Loss: 4.300132751464844
Validation Loss Decreased(4.300248--->4.300133) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1755 / 2500Epoch 1755 		 Training Loss: 1.4117047871862138
Validation step:0Validation step:1Validation step:2Epoch 1755 		 Validation Loss: 4.300023436546326
Validation Loss Decreased(4.300133--->4.300023) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1756 / 2500Epoch 1756 		 Training Loss: 1.4118531686919076
Validation step:0Validation step:1Validation step:2Epoch 1756 		 Validation Loss: 4.299905896186829
Validation Loss Decreased(4.300023--->4.299906) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1757 / 2500Epoch 1757 		 Training Loss: 1.4109861084393092
Validation step:0Validation step:1Validation step:2Epoch 1757 		 Validation Loss: 4.299805641174316
Validation Loss Decreased(4.299906--->4.299806) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1758 / 2500Epoch 1758 		 Training Loss: 1.4099858062607902
Validation step:0Validation step:1Validation step:2Epoch 1758 		 Validation Loss: 4.299824595451355
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1759 / 2500Epoch 1759 		 Training Loss: 1.411521886076246
Validation step:0Validation step:1Validation step:2Epoch 1759 		 Validation Loss: 4.299585461616516
Validation Loss Decreased(4.299806--->4.299585) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1760 / 2500Epoch 1760 		 Training Loss: 1.4105126091412135
Validation step:0Validation step:1Validation step:2Epoch 1760 		 Validation Loss: 4.299679756164551
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1761 / 2500Epoch 1761 		 Training Loss: 1.4103137595312936
Validation step:0Validation step:1Validation step:2Epoch 1761 		 Validation Loss: 4.299470901489258
Validation Loss Decreased(4.299585--->4.299471) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1762 / 2500Epoch 1762 		 Training Loss: 1.4109176312174116
Validation step:0Validation step:1Validation step:2Epoch 1762 		 Validation Loss: 4.29964280128479
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1763 / 2500Epoch 1763 		 Training Loss: 1.4104014805385046
Validation step:0Validation step:1Validation step:2Epoch 1763 		 Validation Loss: 4.299343824386597
Validation Loss Decreased(4.299471--->4.299344) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1764 / 2500Epoch 1764 		 Training Loss: 1.4109297394752502
Validation step:0Validation step:1Validation step:2Epoch 1764 		 Validation Loss: 4.299043774604797
Validation Loss Decreased(4.299344--->4.299044) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1765 / 2500Epoch 1765 		 Training Loss: 1.4100077492850167
Validation step:0Validation step:1Validation step:2Epoch 1765 		 Validation Loss: 4.2989314794540405
Validation Loss Decreased(4.299044--->4.298931) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1766 / 2500Epoch 1766 		 Training Loss: 1.411960712500981
Validation step:0Validation step:1Validation step:2Epoch 1766 		 Validation Loss: 4.298861145973206
Validation Loss Decreased(4.298931--->4.298861) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1767 / 2500Epoch 1767 		 Training Loss: 1.4107652051108224
Validation step:0Validation step:1Validation step:2Epoch 1767 		 Validation Loss: 4.298804521560669
Validation Loss Decreased(4.298861--->4.298805) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1768 / 2500Epoch 1768 		 Training Loss: 1.4104353615215846
Validation step:0Validation step:1Validation step:2Epoch 1768 		 Validation Loss: 4.298725843429565
Validation Loss Decreased(4.298805--->4.298726) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1769 / 2500Epoch 1769 		 Training Loss: 1.410456427506038
Validation step:0Validation step:1Validation step:2Epoch 1769 		 Validation Loss: 4.298642873764038
Validation Loss Decreased(4.298726--->4.298643) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1770 / 2500Epoch 1770 		 Training Loss: 1.409725844860077
Validation step:0Validation step:1Validation step:2Epoch 1770 		 Validation Loss: 4.298481106758118
Validation Loss Decreased(4.298643--->4.298481) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1771 / 2500Epoch 1771 		 Training Loss: 1.4099229574203491
Validation step:0Validation step:1Validation step:2Epoch 1771 		 Validation Loss: 4.298458576202393
Validation Loss Decreased(4.298481--->4.298459) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1772 / 2500Epoch 1772 		 Training Loss: 1.4096115657261439
Validation step:0Validation step:1Validation step:2Epoch 1772 		 Validation Loss: 4.2983094453811646
Validation Loss Decreased(4.298459--->4.298309) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1773 / 2500Epoch 1773 		 Training Loss: 1.4107882806232996
Validation step:0Validation step:1Validation step:2Epoch 1773 		 Validation Loss: 4.298237204551697
Validation Loss Decreased(4.298309--->4.298237) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1774 / 2500Epoch 1774 		 Training Loss: 1.4106388177190508
Validation step:0Validation step:1Validation step:2Epoch 1774 		 Validation Loss: 4.29806125164032
Validation Loss Decreased(4.298237--->4.298061) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1775 / 2500Epoch 1775 		 Training Loss: 1.4105329172951835
Validation step:0Validation step:1Validation step:2Epoch 1775 		 Validation Loss: 4.297925233840942
Validation Loss Decreased(4.298061--->4.297925) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1776 / 2500Epoch 1776 		 Training Loss: 1.4098470977374487
Validation step:0Validation step:1Validation step:2Epoch 1776 		 Validation Loss: 4.297884225845337
Validation Loss Decreased(4.297925--->4.297884) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1777 / 2500Epoch 1777 		 Training Loss: 1.4100751876831055
Validation step:0Validation step:1Validation step:2Epoch 1777 		 Validation Loss: 4.297757148742676
Validation Loss Decreased(4.297884--->4.297757) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1778 / 2500Epoch 1778 		 Training Loss: 1.4092912844249181
Validation step:0Validation step:1Validation step:2Epoch 1778 		 Validation Loss: 4.297668218612671
Validation Loss Decreased(4.297757--->4.297668) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1779 / 2500Epoch 1779 		 Training Loss: 1.4113958307674952
Validation step:0Validation step:1Validation step:2Epoch 1779 		 Validation Loss: 4.29756486415863
Validation Loss Decreased(4.297668--->4.297565) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1780 / 2500Epoch 1780 		 Training Loss: 1.4092505318777901
Validation step:0Validation step:1Validation step:2Epoch 1780 		 Validation Loss: 4.297470688819885
Validation Loss Decreased(4.297565--->4.297471) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1781 / 2500Epoch 1781 		 Training Loss: 1.4105934415544783
Validation step:0Validation step:1Validation step:2Epoch 1781 		 Validation Loss: 4.297371029853821
Validation Loss Decreased(4.297471--->4.297371) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1782 / 2500Epoch 1782 		 Training Loss: 1.4103191154343742
Validation step:0Validation step:1Validation step:2Epoch 1782 		 Validation Loss: 4.297338962554932
Validation Loss Decreased(4.297371--->4.297339) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1783 / 2500Epoch 1783 		 Training Loss: 1.4104510716029577
Validation step:0Validation step:1Validation step:2Epoch 1783 		 Validation Loss: 4.29738986492157
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1784 / 2500Epoch 1784 		 Training Loss: 1.4074241604123796
Validation step:0Validation step:1Validation step:2Epoch 1784 		 Validation Loss: 4.297127366065979
Validation Loss Decreased(4.297339--->4.297127) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1785 / 2500Epoch 1785 		 Training Loss: 1.408370818410601
Validation step:0Validation step:1Validation step:2Epoch 1785 		 Validation Loss: 4.297012567520142
Validation Loss Decreased(4.297127--->4.297013) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1786 / 2500Epoch 1786 		 Training Loss: 1.410800005708422
Validation step:0Validation step:1Validation step:2Epoch 1786 		 Validation Loss: 4.2969032526016235
Validation Loss Decreased(4.297013--->4.296903) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1787 / 2500Epoch 1787 		 Training Loss: 1.4100432055337089
Validation step:0Validation step:1Validation step:2Epoch 1787 		 Validation Loss: 4.296794056892395
Validation Loss Decreased(4.296903--->4.296794) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1788 / 2500Epoch 1788 		 Training Loss: 1.4110663533210754
Validation step:0Validation step:1Validation step:2Epoch 1788 		 Validation Loss: 4.296665906906128
Validation Loss Decreased(4.296794--->4.296666) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1789 / 2500Epoch 1789 		 Training Loss: 1.4087895495550973
Validation step:0Validation step:1Validation step:2Epoch 1789 		 Validation Loss: 4.2965651750564575
Validation Loss Decreased(4.296666--->4.296565) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1790 / 2500Epoch 1790 		 Training Loss: 1.4097395028386797
Validation step:0Validation step:1Validation step:2Epoch 1790 		 Validation Loss: 4.2964982986450195
Validation Loss Decreased(4.296565--->4.296498) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1791 / 2500Epoch 1791 		 Training Loss: 1.4089200581823076
Validation step:0Validation step:1Validation step:2Epoch 1791 		 Validation Loss: 4.296381831169128
Validation Loss Decreased(4.296498--->4.296382) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1792 / 2500Epoch 1792 		 Training Loss: 1.409246334007808
Validation step:0Validation step:1Validation step:2Epoch 1792 		 Validation Loss: 4.296268343925476
Validation Loss Decreased(4.296382--->4.296268) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1793 / 2500Epoch 1793 		 Training Loss: 1.410323543207986
Validation step:0Validation step:1Validation step:2Epoch 1793 		 Validation Loss: 4.296296954154968
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1794 / 2500Epoch 1794 		 Training Loss: 1.4098292248589652
Validation step:0Validation step:1Validation step:2Epoch 1794 		 Validation Loss: 4.296165823936462
Validation Loss Decreased(4.296268--->4.296166) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1795 / 2500Epoch 1795 		 Training Loss: 1.409561472279685
Validation step:0Validation step:1Validation step:2Epoch 1795 		 Validation Loss: 4.29606020450592
Validation Loss Decreased(4.296166--->4.296060) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1796 / 2500Epoch 1796 		 Training Loss: 1.4100698488099235
Validation step:0Validation step:1Validation step:2Epoch 1796 		 Validation Loss: 4.2962504625320435
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1797 / 2500Epoch 1797 		 Training Loss: 1.4095279318945748
Validation step:0Validation step:1Validation step:2Epoch 1797 		 Validation Loss: 4.295893907546997
Validation Loss Decreased(4.296060--->4.295894) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1798 / 2500Epoch 1798 		 Training Loss: 1.4093175785882133
Validation step:0Validation step:1Validation step:2Epoch 1798 		 Validation Loss: 4.29603111743927
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1799 / 2500Epoch 1799 		 Training Loss: 1.4095646142959595
Validation step:0Validation step:1Validation step:2Epoch 1799 		 Validation Loss: 4.295700192451477
Validation Loss Decreased(4.295894--->4.295700) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1800 / 2500Epoch 1800 		 Training Loss: 1.4085751261029924
Validation step:0Validation step:1Validation step:2Epoch 1800 		 Validation Loss: 4.295526623725891
Validation Loss Decreased(4.295700--->4.295527) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1801 / 2500Epoch 1801 		 Training Loss: 1.4079238431794303
Validation step:0Validation step:1Validation step:2Epoch 1801 		 Validation Loss: 4.295409560203552
Validation Loss Decreased(4.295527--->4.295410) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1802 / 2500Epoch 1802 		 Training Loss: 1.408983051776886
Validation step:0Validation step:1Validation step:2Epoch 1802 		 Validation Loss: 4.295341491699219
Validation Loss Decreased(4.295410--->4.295341) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1803 / 2500Epoch 1803 		 Training Loss: 1.4087423852511816
Validation step:0Validation step:1Validation step:2Epoch 1803 		 Validation Loss: 4.295254230499268
Validation Loss Decreased(4.295341--->4.295254) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1804 / 2500Epoch 1804 		 Training Loss: 1.4066757985523768
Validation step:0Validation step:1Validation step:2Epoch 1804 		 Validation Loss: 4.295109272003174
Validation Loss Decreased(4.295254--->4.295109) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1805 / 2500Epoch 1805 		 Training Loss: 1.40986134324755
Validation step:0Validation step:1Validation step:2Epoch 1805 		 Validation Loss: 4.295030236244202
Validation Loss Decreased(4.295109--->4.295030) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1806 / 2500Epoch 1806 		 Training Loss: 1.4097830738340105
Validation step:0Validation step:1Validation step:2Epoch 1806 		 Validation Loss: 4.294830799102783
Validation Loss Decreased(4.295030--->4.294831) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1807 / 2500Epoch 1807 		 Training Loss: 1.4085280043738229
Validation step:0Validation step:1Validation step:2Epoch 1807 		 Validation Loss: 4.294733762741089
Validation Loss Decreased(4.294831--->4.294734) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1808 / 2500Epoch 1808 		 Training Loss: 1.4103845698492867
Validation step:0Validation step:1Validation step:2Epoch 1808 		 Validation Loss: 4.294646739959717
Validation Loss Decreased(4.294734--->4.294647) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1809 / 2500Epoch 1809 		 Training Loss: 1.4098027689116341
Validation step:0Validation step:1Validation step:2Epoch 1809 		 Validation Loss: 4.2945250272750854
Validation Loss Decreased(4.294647--->4.294525) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1810 / 2500Epoch 1810 		 Training Loss: 1.4089811614581518
Validation step:0Validation step:1Validation step:2Epoch 1810 		 Validation Loss: 4.294462442398071
Validation Loss Decreased(4.294525--->4.294462) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1811 / 2500Epoch 1811 		 Training Loss: 1.4088854363986425
Validation step:0Validation step:1Validation step:2Epoch 1811 		 Validation Loss: 4.294353127479553
Validation Loss Decreased(4.294462--->4.294353) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1812 / 2500Epoch 1812 		 Training Loss: 1.4093883378165108
Validation step:0Validation step:1Validation step:2Epoch 1812 		 Validation Loss: 4.294227600097656
Validation Loss Decreased(4.294353--->4.294228) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1813 / 2500Epoch 1813 		 Training Loss: 1.408777219908578
Validation step:0Validation step:1Validation step:2Epoch 1813 		 Validation Loss: 4.294184565544128
Validation Loss Decreased(4.294228--->4.294185) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1814 / 2500Epoch 1814 		 Training Loss: 1.4094085608209883
Validation step:0Validation step:1Validation step:2Epoch 1814 		 Validation Loss: 4.294112682342529
Validation Loss Decreased(4.294185--->4.294113) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1815 / 2500Epoch 1815 		 Training Loss: 1.4086307798113142
Validation step:0Validation step:1Validation step:2Epoch 1815 		 Validation Loss: 4.294018983840942
Validation Loss Decreased(4.294113--->4.294019) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1816 / 2500Epoch 1816 		 Training Loss: 1.4082443799291338
Validation step:0Validation step:1Validation step:2Epoch 1816 		 Validation Loss: 4.293949365615845
Validation Loss Decreased(4.294019--->4.293949) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1817 / 2500Epoch 1817 		 Training Loss: 1.4081255878720964
Validation step:0Validation step:1Validation step:2Epoch 1817 		 Validation Loss: 4.293828368186951
Validation Loss Decreased(4.293949--->4.293828) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1818 / 2500Epoch 1818 		 Training Loss: 1.4079591376440865
Validation step:0Validation step:1Validation step:2Epoch 1818 		 Validation Loss: 4.293788909912109
Validation Loss Decreased(4.293828--->4.293789) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1819 / 2500Epoch 1819 		 Training Loss: 1.4080372963632857
Validation step:0Validation step:1Validation step:2Epoch 1819 		 Validation Loss: 4.293652772903442
Validation Loss Decreased(4.293789--->4.293653) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1820 / 2500Epoch 1820 		 Training Loss: 1.4099633012499129
Validation step:0Validation step:1Validation step:2Epoch 1820 		 Validation Loss: 4.293568849563599
Validation Loss Decreased(4.293653--->4.293569) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1821 / 2500Epoch 1821 		 Training Loss: 1.4095370088304793
Validation step:0Validation step:1Validation step:2Epoch 1821 		 Validation Loss: 4.293456315994263
Validation Loss Decreased(4.293569--->4.293456) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1822 / 2500Epoch 1822 		 Training Loss: 1.4086667725018092
Validation step:0Validation step:1Validation step:2Epoch 1822 		 Validation Loss: 4.293339014053345
Validation Loss Decreased(4.293456--->4.293339) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1823 / 2500Epoch 1823 		 Training Loss: 1.408854033265795
Validation step:0Validation step:1Validation step:2Epoch 1823 		 Validation Loss: 4.29314112663269
Validation Loss Decreased(4.293339--->4.293141) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1824 / 2500Epoch 1824 		 Training Loss: 1.4088672144072396
Validation step:0Validation step:1Validation step:2Epoch 1824 		 Validation Loss: 4.293169260025024
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1825 / 2500Epoch 1825 		 Training Loss: 1.4089980210576738
Validation step:0Validation step:1Validation step:2Epoch 1825 		 Validation Loss: 4.293074131011963
Validation Loss Decreased(4.293141--->4.293074) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1826 / 2500Epoch 1826 		 Training Loss: 1.4088818430900574
Validation step:0Validation step:1Validation step:2Epoch 1826 		 Validation Loss: 4.2929136753082275
Validation Loss Decreased(4.293074--->4.292914) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1827 / 2500Epoch 1827 		 Training Loss: 1.4087922402790614
Validation step:0Validation step:1Validation step:2Epoch 1827 		 Validation Loss: 4.292836904525757
Validation Loss Decreased(4.292914--->4.292837) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1828 / 2500Epoch 1828 		 Training Loss: 1.4071040153503418
Validation step:0Validation step:1Validation step:2Epoch 1828 		 Validation Loss: 4.2927775382995605
Validation Loss Decreased(4.292837--->4.292778) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1829 / 2500Epoch 1829 		 Training Loss: 1.4091941288539342
Validation step:0Validation step:1Validation step:2Epoch 1829 		 Validation Loss: 4.292669892311096
Validation Loss Decreased(4.292778--->4.292670) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1830 / 2500Epoch 1830 		 Training Loss: 1.4098548633711678
Validation step:0Validation step:1Validation step:2Epoch 1830 		 Validation Loss: 4.292618274688721
Validation Loss Decreased(4.292670--->4.292618) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1831 / 2500Epoch 1831 		 Training Loss: 1.4073847361973353
Validation step:0Validation step:1Validation step:2Epoch 1831 		 Validation Loss: 4.292452573776245
Validation Loss Decreased(4.292618--->4.292453) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1832 / 2500Epoch 1832 		 Training Loss: 1.4085210136004858
Validation step:0Validation step:1Validation step:2Epoch 1832 		 Validation Loss: 4.292331576347351
Validation Loss Decreased(4.292453--->4.292332) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1833 / 2500Epoch 1833 		 Training Loss: 1.4078035610062736
Validation step:0Validation step:1Validation step:2Epoch 1833 		 Validation Loss: 4.292271733283997
Validation Loss Decreased(4.292332--->4.292272) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1834 / 2500Epoch 1834 		 Training Loss: 1.4086872339248657
Validation step:0Validation step:1Validation step:2Epoch 1834 		 Validation Loss: 4.292179584503174
Validation Loss Decreased(4.292272--->4.292180) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1835 / 2500Epoch 1835 		 Training Loss: 1.408077827521733
Validation step:0Validation step:1Validation step:2Epoch 1835 		 Validation Loss: 4.292109370231628
Validation Loss Decreased(4.292180--->4.292109) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1836 / 2500Epoch 1836 		 Training Loss: 1.4060708965573991
Validation step:0Validation step:1Validation step:2Epoch 1836 		 Validation Loss: 4.292050242424011
Validation Loss Decreased(4.292109--->4.292050) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1837 / 2500Epoch 1837 		 Training Loss: 1.4091027634484428
Validation step:0Validation step:1Validation step:2Epoch 1837 		 Validation Loss: 4.291955232620239
Validation Loss Decreased(4.292050--->4.291955) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1838 / 2500Epoch 1838 		 Training Loss: 1.407324492931366
Validation step:0Validation step:1Validation step:2Epoch 1838 		 Validation Loss: 4.291843771934509
Validation Loss Decreased(4.291955--->4.291844) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1839 / 2500Epoch 1839 		 Training Loss: 1.4088447519711085
Validation step:0Validation step:1Validation step:2Epoch 1839 		 Validation Loss: 4.291709542274475
Validation Loss Decreased(4.291844--->4.291710) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1840 / 2500Epoch 1840 		 Training Loss: 1.4077680451529366
Validation step:0Validation step:1Validation step:2Epoch 1840 		 Validation Loss: 4.291625738143921
Validation Loss Decreased(4.291710--->4.291626) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1841 / 2500Epoch 1841 		 Training Loss: 1.4073673401560103
Validation step:0Validation step:1Validation step:2Epoch 1841 		 Validation Loss: 4.291860461235046
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1842 / 2500Epoch 1842 		 Training Loss: 1.4074987513678414
Validation step:0Validation step:1Validation step:2Epoch 1842 		 Validation Loss: 4.291532516479492
Validation Loss Decreased(4.291626--->4.291533) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1843 / 2500Epoch 1843 		 Training Loss: 1.4072707465716772
Validation step:0Validation step:1Validation step:2Epoch 1843 		 Validation Loss: 4.291429281234741
Validation Loss Decreased(4.291533--->4.291429) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1844 / 2500Epoch 1844 		 Training Loss: 1.4085846543312073
Validation step:0Validation step:1Validation step:2Epoch 1844 		 Validation Loss: 4.291458964347839
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1845 / 2500Epoch 1845 		 Training Loss: 1.4085329345294408
Validation step:0Validation step:1Validation step:2Epoch 1845 		 Validation Loss: 4.291322946548462
Validation Loss Decreased(4.291429--->4.291323) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1846 / 2500Epoch 1846 		 Training Loss: 1.4081534232412065
Validation step:0Validation step:1Validation step:2Epoch 1846 		 Validation Loss: 4.291120529174805
Validation Loss Decreased(4.291323--->4.291121) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1847 / 2500Epoch 1847 		 Training Loss: 1.4083247440201896
Validation step:0Validation step:1Validation step:2Epoch 1847 		 Validation Loss: 4.291056275367737
Validation Loss Decreased(4.291121--->4.291056) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1848 / 2500Epoch 1848 		 Training Loss: 1.408105092389243
Validation step:0Validation step:1Validation step:2Epoch 1848 		 Validation Loss: 4.290935635566711
Validation Loss Decreased(4.291056--->4.290936) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1849 / 2500Epoch 1849 		 Training Loss: 1.407703970159803
Validation step:0Validation step:1Validation step:2Epoch 1849 		 Validation Loss: 4.290831685066223
Validation Loss Decreased(4.290936--->4.290832) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1850 / 2500Epoch 1850 		 Training Loss: 1.4065257396016801
Validation step:0Validation step:1Validation step:2Epoch 1850 		 Validation Loss: 4.2908501625061035
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1851 / 2500Epoch 1851 		 Training Loss: 1.407903594630105
Validation step:0Validation step:1Validation step:2Epoch 1851 		 Validation Loss: 4.29067075252533
Validation Loss Decreased(4.290832--->4.290671) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1852 / 2500Epoch 1852 		 Training Loss: 1.4073235307421004
Validation step:0Validation step:1Validation step:2Epoch 1852 		 Validation Loss: 4.2905014753341675
Validation Loss Decreased(4.290671--->4.290501) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1853 / 2500Epoch 1853 		 Training Loss: 1.4069156561579024
Validation step:0Validation step:1Validation step:2Epoch 1853 		 Validation Loss: 4.290406823158264
Validation Loss Decreased(4.290501--->4.290407) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1854 / 2500Epoch 1854 		 Training Loss: 1.407482385635376
Validation step:0Validation step:1Validation step:2Epoch 1854 		 Validation Loss: 4.290316700935364
Validation Loss Decreased(4.290407--->4.290317) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1855 / 2500Epoch 1855 		 Training Loss: 1.4073565432003565
Validation step:0Validation step:1Validation step:2Epoch 1855 		 Validation Loss: 4.290240168571472
Validation Loss Decreased(4.290317--->4.290240) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1856 / 2500Epoch 1856 		 Training Loss: 1.407065314905984
Validation step:0Validation step:1Validation step:2Epoch 1856 		 Validation Loss: 4.290126442909241
Validation Loss Decreased(4.290240--->4.290126) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1857 / 2500Epoch 1857 		 Training Loss: 1.4069915924753462
Validation step:0Validation step:1Validation step:2Epoch 1857 		 Validation Loss: 4.290013074874878
Validation Loss Decreased(4.290126--->4.290013) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1858 / 2500Epoch 1858 		 Training Loss: 1.408516722066062
Validation step:0Validation step:1Validation step:2Epoch 1858 		 Validation Loss: 4.289960026741028
Validation Loss Decreased(4.290013--->4.289960) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1859 / 2500Epoch 1859 		 Training Loss: 1.4084422843796867
Validation step:0Validation step:1Validation step:2Epoch 1859 		 Validation Loss: 4.289950609207153
Validation Loss Decreased(4.289960--->4.289951) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1860 / 2500Epoch 1860 		 Training Loss: 1.4082745483943395
Validation step:0Validation step:1Validation step:2Epoch 1860 		 Validation Loss: 4.2899826765060425
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1861 / 2500Epoch 1861 		 Training Loss: 1.4078925081661768
Validation step:0Validation step:1Validation step:2Epoch 1861 		 Validation Loss: 4.2897515296936035
Validation Loss Decreased(4.289951--->4.289752) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1862 / 2500Epoch 1862 		 Training Loss: 1.4069411839757646
Validation step:0Validation step:1Validation step:2Epoch 1862 		 Validation Loss: 4.2897645235061646
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1863 / 2500Epoch 1863 		 Training Loss: 1.406059375831059
Validation step:0Validation step:1Validation step:2Epoch 1863 		 Validation Loss: 4.289515733718872
Validation Loss Decreased(4.289752--->4.289516) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1864 / 2500Epoch 1864 		 Training Loss: 1.4073132276535034
Validation step:0Validation step:1Validation step:2Epoch 1864 		 Validation Loss: 4.289400935173035
Validation Loss Decreased(4.289516--->4.289401) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1865 / 2500Epoch 1865 		 Training Loss: 1.406494643007006
Validation step:0Validation step:1Validation step:2Epoch 1865 		 Validation Loss: 4.289279341697693
Validation Loss Decreased(4.289401--->4.289279) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1866 / 2500Epoch 1866 		 Training Loss: 1.4075131160872323
Validation step:0Validation step:1Validation step:2Epoch 1866 		 Validation Loss: 4.289129734039307
Validation Loss Decreased(4.289279--->4.289130) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1867 / 2500Epoch 1867 		 Training Loss: 1.4083050063678197
Validation step:0Validation step:1Validation step:2Epoch 1867 		 Validation Loss: 4.289090156555176
Validation Loss Decreased(4.289130--->4.289090) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1868 / 2500Epoch 1868 		 Training Loss: 1.4065863149506705
Validation step:0Validation step:1Validation step:2Epoch 1868 		 Validation Loss: 4.2889463901519775
Validation Loss Decreased(4.289090--->4.288946) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1869 / 2500Epoch 1869 		 Training Loss: 1.4076916405132838
Validation step:0Validation step:1Validation step:2Epoch 1869 		 Validation Loss: 4.288883328437805
Validation Loss Decreased(4.288946--->4.288883) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1870 / 2500Epoch 1870 		 Training Loss: 1.4074528643063136
Validation step:0Validation step:1Validation step:2Epoch 1870 		 Validation Loss: 4.288782835006714
Validation Loss Decreased(4.288883--->4.288783) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1871 / 2500Epoch 1871 		 Training Loss: 1.4082152588026864
Validation step:0Validation step:1Validation step:2Epoch 1871 		 Validation Loss: 4.288682341575623
Validation Loss Decreased(4.288783--->4.288682) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1872 / 2500Epoch 1872 		 Training Loss: 1.4072460276739938
Validation step:0Validation step:1Validation step:2Epoch 1872 		 Validation Loss: 4.288657188415527
Validation Loss Decreased(4.288682--->4.288657) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1873 / 2500Epoch 1873 		 Training Loss: 1.4069166609219141
Validation step:0Validation step:1Validation step:2Epoch 1873 		 Validation Loss: 4.288529634475708
Validation Loss Decreased(4.288657--->4.288530) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1874 / 2500Epoch 1874 		 Training Loss: 1.4054394790104456
Validation step:0Validation step:1Validation step:2Epoch 1874 		 Validation Loss: 4.288436055183411
Validation Loss Decreased(4.288530--->4.288436) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1875 / 2500Epoch 1875 		 Training Loss: 1.4070513589041573
Validation step:0Validation step:1Validation step:2Epoch 1875 		 Validation Loss: 4.2883371114730835
Validation Loss Decreased(4.288436--->4.288337) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1876 / 2500Epoch 1876 		 Training Loss: 1.406540836606707
Validation step:0Validation step:1Validation step:2Epoch 1876 		 Validation Loss: 4.288223743438721
Validation Loss Decreased(4.288337--->4.288224) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1877 / 2500Epoch 1877 		 Training Loss: 1.4067075422831945
Validation step:0Validation step:1Validation step:2Epoch 1877 		 Validation Loss: 4.288080930709839
Validation Loss Decreased(4.288224--->4.288081) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1878 / 2500Epoch 1878 		 Training Loss: 1.4077875869614738
Validation step:0Validation step:1Validation step:2Epoch 1878 		 Validation Loss: 4.288090467453003
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1879 / 2500Epoch 1879 		 Training Loss: 1.4069715653147017
Validation step:0Validation step:1Validation step:2Epoch 1879 		 Validation Loss: 4.287963271141052
Validation Loss Decreased(4.288081--->4.287963) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1880 / 2500Epoch 1880 		 Training Loss: 1.4072208404541016
Validation step:0Validation step:1Validation step:2Epoch 1880 		 Validation Loss: 4.287917852401733
Validation Loss Decreased(4.287963--->4.287918) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1881 / 2500Epoch 1881 		 Training Loss: 1.4075083221708025
Validation step:0Validation step:1Validation step:2Epoch 1881 		 Validation Loss: 4.28780734539032
Validation Loss Decreased(4.287918--->4.287807) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1882 / 2500Epoch 1882 		 Training Loss: 1.405742108821869
Validation step:0Validation step:1Validation step:2Epoch 1882 		 Validation Loss: 4.287684679031372
Validation Loss Decreased(4.287807--->4.287685) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1883 / 2500Epoch 1883 		 Training Loss: 1.4067306348255701
Validation step:0Validation step:1Validation step:2Epoch 1883 		 Validation Loss: 4.287840723991394
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1884 / 2500Epoch 1884 		 Training Loss: 1.4071692313466753
Validation step:0Validation step:1Validation step:2Epoch 1884 		 Validation Loss: 4.28757917881012
Validation Loss Decreased(4.287685--->4.287579) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1885 / 2500Epoch 1885 		 Training Loss: 1.4059907708849226
Validation step:0Validation step:1Validation step:2Epoch 1885 		 Validation Loss: 4.287468791007996
Validation Loss Decreased(4.287579--->4.287469) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1886 / 2500Epoch 1886 		 Training Loss: 1.40630418913705
Validation step:0Validation step:1Validation step:2Epoch 1886 		 Validation Loss: 4.28726327419281
Validation Loss Decreased(4.287469--->4.287263) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1887 / 2500Epoch 1887 		 Training Loss: 1.406617053917476
Validation step:0Validation step:1Validation step:2Epoch 1887 		 Validation Loss: 4.287179350852966
Validation Loss Decreased(4.287263--->4.287179) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1888 / 2500Epoch 1888 		 Training Loss: 1.4077111652919225
Validation step:0Validation step:1Validation step:2Epoch 1888 		 Validation Loss: 4.287135720252991
Validation Loss Decreased(4.287179--->4.287136) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1889 / 2500Epoch 1889 		 Training Loss: 1.405403162751879
Validation step:0Validation step:1Validation step:2Epoch 1889 		 Validation Loss: 4.287040829658508
Validation Loss Decreased(4.287136--->4.287041) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1890 / 2500Epoch 1890 		 Training Loss: 1.4065166796956743
Validation step:0Validation step:1Validation step:2Epoch 1890 		 Validation Loss: 4.286959171295166
Validation Loss Decreased(4.287041--->4.286959) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1891 / 2500Epoch 1891 		 Training Loss: 1.4065331731523787
Validation step:0Validation step:1Validation step:2Epoch 1891 		 Validation Loss: 4.286897301673889
Validation Loss Decreased(4.286959--->4.286897) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1892 / 2500Epoch 1892 		 Training Loss: 1.4065103105136327
Validation step:0Validation step:1Validation step:2Epoch 1892 		 Validation Loss: 4.286754131317139
Validation Loss Decreased(4.286897--->4.286754) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1893 / 2500Epoch 1893 		 Training Loss: 1.4074014340128218
Validation step:0Validation step:1Validation step:2Epoch 1893 		 Validation Loss: 4.28668749332428
Validation Loss Decreased(4.286754--->4.286687) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1894 / 2500Epoch 1894 		 Training Loss: 1.4065265910966056
Validation step:0Validation step:1Validation step:2Epoch 1894 		 Validation Loss: 4.286653637886047
Validation Loss Decreased(4.286687--->4.286654) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1895 / 2500Epoch 1895 		 Training Loss: 1.4068286333765303
Validation step:0Validation step:1Validation step:2Epoch 1895 		 Validation Loss: 4.286629557609558
Validation Loss Decreased(4.286654--->4.286630) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1896 / 2500Epoch 1896 		 Training Loss: 1.4050428015845162
Validation step:0Validation step:1Validation step:2Epoch 1896 		 Validation Loss: 4.286417365074158
Validation Loss Decreased(4.286630--->4.286417) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1897 / 2500Epoch 1897 		 Training Loss: 1.4075722779546465
Validation step:0Validation step:1Validation step:2Epoch 1897 		 Validation Loss: 4.286281228065491
Validation Loss Decreased(4.286417--->4.286281) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1898 / 2500Epoch 1898 		 Training Loss: 1.4065607956477575
Validation step:0Validation step:1Validation step:2Epoch 1898 		 Validation Loss: 4.286275506019592
Validation Loss Decreased(4.286281--->4.286276) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1899 / 2500Epoch 1899 		 Training Loss: 1.4066992231777735
Validation step:0Validation step:1Validation step:2Epoch 1899 		 Validation Loss: 4.286119103431702
Validation Loss Decreased(4.286276--->4.286119) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1900 / 2500Epoch 1900 		 Training Loss: 1.4063562154769897
Validation step:0Validation step:1Validation step:2Epoch 1900 		 Validation Loss: 4.286131739616394
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1901 / 2500Epoch 1901 		 Training Loss: 1.4069964630263192
Validation step:0Validation step:1Validation step:2Epoch 1901 		 Validation Loss: 4.285920977592468
Validation Loss Decreased(4.286119--->4.285921) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1902 / 2500Epoch 1902 		 Training Loss: 1.403701399053846
Validation step:0Validation step:1Validation step:2Epoch 1902 		 Validation Loss: 4.285755634307861
Validation Loss Decreased(4.285921--->4.285756) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1903 / 2500Epoch 1903 		 Training Loss: 1.4053679704666138
Validation step:0Validation step:1Validation step:2Epoch 1903 		 Validation Loss: 4.285745859146118
Validation Loss Decreased(4.285756--->4.285746) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1904 / 2500Epoch 1904 		 Training Loss: 1.407247713633946
Validation step:0Validation step:1Validation step:2Epoch 1904 		 Validation Loss: 4.285642027854919
Validation Loss Decreased(4.285746--->4.285642) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1905 / 2500Epoch 1905 		 Training Loss: 1.4057011093412126
Validation step:0Validation step:1Validation step:2Epoch 1905 		 Validation Loss: 4.285593509674072
Validation Loss Decreased(4.285642--->4.285594) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1906 / 2500Epoch 1906 		 Training Loss: 1.4047605991363525
Validation step:0Validation step:1Validation step:2Epoch 1906 		 Validation Loss: 4.285459876060486
Validation Loss Decreased(4.285594--->4.285460) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1907 / 2500Epoch 1907 		 Training Loss: 1.4050318343298775
Validation step:0Validation step:1Validation step:2Epoch 1907 		 Validation Loss: 4.285483241081238
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1908 / 2500Epoch 1908 		 Training Loss: 1.406467114176069
Validation step:0Validation step:1Validation step:2Epoch 1908 		 Validation Loss: 4.285322546958923
Validation Loss Decreased(4.285460--->4.285323) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1909 / 2500Epoch 1909 		 Training Loss: 1.4074674078396388
Validation step:0Validation step:1Validation step:2Epoch 1909 		 Validation Loss: 4.285171031951904
Validation Loss Decreased(4.285323--->4.285171) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1910 / 2500Epoch 1910 		 Training Loss: 1.406603923865727
Validation step:0Validation step:1Validation step:2Epoch 1910 		 Validation Loss: 4.285077810287476
Validation Loss Decreased(4.285171--->4.285078) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1911 / 2500Epoch 1911 		 Training Loss: 1.4062057052339827
Validation step:0Validation step:1Validation step:2Epoch 1911 		 Validation Loss: 4.285070061683655
Validation Loss Decreased(4.285078--->4.285070) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1912 / 2500Epoch 1912 		 Training Loss: 1.4059301614761353
Validation step:0Validation step:1Validation step:2Epoch 1912 		 Validation Loss: 4.284989356994629
Validation Loss Decreased(4.285070--->4.284989) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1913 / 2500Epoch 1913 		 Training Loss: 1.4063139728137426
Validation step:0Validation step:1Validation step:2Epoch 1913 		 Validation Loss: 4.285015106201172
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1914 / 2500Epoch 1914 		 Training Loss: 1.4056820188249861
Validation step:0Validation step:1Validation step:2Epoch 1914 		 Validation Loss: 4.284908175468445
Validation Loss Decreased(4.284989--->4.284908) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1915 / 2500Epoch 1915 		 Training Loss: 1.4059354748044695
Validation step:0Validation step:1Validation step:2Epoch 1915 		 Validation Loss: 4.284693479537964
Validation Loss Decreased(4.284908--->4.284693) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1916 / 2500Epoch 1916 		 Training Loss: 1.406254598072597
Validation step:0Validation step:1Validation step:2Epoch 1916 		 Validation Loss: 4.284640789031982
Validation Loss Decreased(4.284693--->4.284641) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1917 / 2500Epoch 1917 		 Training Loss: 1.4062486631529671
Validation step:0Validation step:1Validation step:2Epoch 1917 		 Validation Loss: 4.284541845321655
Validation Loss Decreased(4.284641--->4.284542) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1918 / 2500Epoch 1918 		 Training Loss: 1.4064245905194963
Validation step:0Validation step:1Validation step:2Epoch 1918 		 Validation Loss: 4.28445827960968
Validation Loss Decreased(4.284542--->4.284458) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1919 / 2500Epoch 1919 		 Training Loss: 1.4043133854866028
Validation step:0Validation step:1Validation step:2Epoch 1919 		 Validation Loss: 4.284353494644165
Validation Loss Decreased(4.284458--->4.284353) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1920 / 2500Epoch 1920 		 Training Loss: 1.4056036387171065
Validation step:0Validation step:1Validation step:2Epoch 1920 		 Validation Loss: 4.284292697906494
Validation Loss Decreased(4.284353--->4.284293) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1921 / 2500Epoch 1921 		 Training Loss: 1.4049879823412215
Validation step:0Validation step:1Validation step:2Epoch 1921 		 Validation Loss: 4.284315586090088
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1922 / 2500Epoch 1922 		 Training Loss: 1.4050936188016618
Validation step:0Validation step:1Validation step:2Epoch 1922 		 Validation Loss: 4.28414249420166
Validation Loss Decreased(4.284293--->4.284142) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1923 / 2500Epoch 1923 		 Training Loss: 1.4048854964120048
Validation step:0Validation step:1Validation step:2Epoch 1923 		 Validation Loss: 4.283980846405029
Validation Loss Decreased(4.284142--->4.283981) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1924 / 2500Epoch 1924 		 Training Loss: 1.4047857097217016
Validation step:0Validation step:1Validation step:2Epoch 1924 		 Validation Loss: 4.283919811248779
Validation Loss Decreased(4.283981--->4.283920) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1925 / 2500Epoch 1925 		 Training Loss: 1.405170168195452
Validation step:0Validation step:1Validation step:2Epoch 1925 		 Validation Loss: 4.283763766288757
Validation Loss Decreased(4.283920--->4.283764) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1926 / 2500Epoch 1926 		 Training Loss: 1.4056921345846993
Validation step:0Validation step:1Validation step:2Epoch 1926 		 Validation Loss: 4.28368353843689
Validation Loss Decreased(4.283764--->4.283684) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1927 / 2500Epoch 1927 		 Training Loss: 1.4058987072535925
Validation step:0Validation step:1Validation step:2Epoch 1927 		 Validation Loss: 4.28351628780365
Validation Loss Decreased(4.283684--->4.283516) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1928 / 2500Epoch 1928 		 Training Loss: 1.4063376017979212
Validation step:0Validation step:1Validation step:2Epoch 1928 		 Validation Loss: 4.28345799446106
Validation Loss Decreased(4.283516--->4.283458) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1929 / 2500Epoch 1929 		 Training Loss: 1.4049076778548104
Validation step:0Validation step:1Validation step:2Epoch 1929 		 Validation Loss: 4.2833826541900635
Validation Loss Decreased(4.283458--->4.283383) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1930 / 2500Epoch 1930 		 Training Loss: 1.4060226849147253
Validation step:0Validation step:1Validation step:2Epoch 1930 		 Validation Loss: 4.283316969871521
Validation Loss Decreased(4.283383--->4.283317) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1931 / 2500Epoch 1931 		 Training Loss: 1.4050458925110954
Validation step:0Validation step:1Validation step:2Epoch 1931 		 Validation Loss: 4.283257007598877
Validation Loss Decreased(4.283317--->4.283257) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1932 / 2500Epoch 1932 		 Training Loss: 1.4054411138807024
Validation step:0Validation step:1Validation step:2Epoch 1932 		 Validation Loss: 4.28317391872406
Validation Loss Decreased(4.283257--->4.283174) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1933 / 2500Epoch 1933 		 Training Loss: 1.4053973640714372
Validation step:0Validation step:1Validation step:2Epoch 1933 		 Validation Loss: 4.283063530921936
Validation Loss Decreased(4.283174--->4.283064) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1934 / 2500Epoch 1934 		 Training Loss: 1.4046957407678877
Validation step:0Validation step:1Validation step:2Epoch 1934 		 Validation Loss: 4.282943487167358
Validation Loss Decreased(4.283064--->4.282943) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1935 / 2500Epoch 1935 		 Training Loss: 1.4053826928138733
Validation step:0Validation step:1Validation step:2Epoch 1935 		 Validation Loss: 4.282925486564636
Validation Loss Decreased(4.282943--->4.282925) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1936 / 2500Epoch 1936 		 Training Loss: 1.4047880853925432
Validation step:0Validation step:1Validation step:2Epoch 1936 		 Validation Loss: 4.282835006713867
Validation Loss Decreased(4.282925--->4.282835) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1937 / 2500Epoch 1937 		 Training Loss: 1.4048508746283395
Validation step:0Validation step:1Validation step:2Epoch 1937 		 Validation Loss: 4.282660603523254
Validation Loss Decreased(4.282835--->4.282661) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1938 / 2500Epoch 1938 		 Training Loss: 1.404237381049565
Validation step:0Validation step:1Validation step:2Epoch 1938 		 Validation Loss: 4.282625913619995
Validation Loss Decreased(4.282661--->4.282626) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1939 / 2500Epoch 1939 		 Training Loss: 1.404997902257102
Validation step:0Validation step:1Validation step:2Epoch 1939 		 Validation Loss: 4.282506108283997
Validation Loss Decreased(4.282626--->4.282506) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1940 / 2500Epoch 1940 		 Training Loss: 1.4052143692970276
Validation step:0Validation step:1Validation step:2Epoch 1940 		 Validation Loss: 4.282413959503174
Validation Loss Decreased(4.282506--->4.282414) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1941 / 2500Epoch 1941 		 Training Loss: 1.405503817967006
Validation step:0Validation step:1Validation step:2Epoch 1941 		 Validation Loss: 4.282301306724548
Validation Loss Decreased(4.282414--->4.282301) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1942 / 2500Epoch 1942 		 Training Loss: 1.4052046537399292
Validation step:0Validation step:1Validation step:2Epoch 1942 		 Validation Loss: 4.282250881195068
Validation Loss Decreased(4.282301--->4.282251) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1943 / 2500Epoch 1943 		 Training Loss: 1.404676377773285
Validation step:0Validation step:1Validation step:2Epoch 1943 		 Validation Loss: 4.282199144363403
Validation Loss Decreased(4.282251--->4.282199) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1944 / 2500Epoch 1944 		 Training Loss: 1.405010495867048
Validation step:0Validation step:1Validation step:2Epoch 1944 		 Validation Loss: 4.282282471656799
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1945 / 2500Epoch 1945 		 Training Loss: 1.4041546753474645
Validation step:0Validation step:1Validation step:2Epoch 1945 		 Validation Loss: 4.282052040100098
Validation Loss Decreased(4.282199--->4.282052) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1946 / 2500Epoch 1946 		 Training Loss: 1.4055780257497514
Validation step:0Validation step:1Validation step:2Epoch 1946 		 Validation Loss: 4.281911730766296
Validation Loss Decreased(4.282052--->4.281912) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1947 / 2500Epoch 1947 		 Training Loss: 1.4058961187090193
Validation step:0Validation step:1Validation step:2Epoch 1947 		 Validation Loss: 4.281769156455994
Validation Loss Decreased(4.281912--->4.281769) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1948 / 2500Epoch 1948 		 Training Loss: 1.4057823930467879
Validation step:0Validation step:1Validation step:2Epoch 1948 		 Validation Loss: 4.2817223072052
Validation Loss Decreased(4.281769--->4.281722) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1949 / 2500Epoch 1949 		 Training Loss: 1.4044951455933707
Validation step:0Validation step:1Validation step:2Epoch 1949 		 Validation Loss: 4.281628370285034
Validation Loss Decreased(4.281722--->4.281628) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1950 / 2500Epoch 1950 		 Training Loss: 1.4048887746674674
Validation step:0Validation step:1Validation step:2Epoch 1950 		 Validation Loss: 4.2814637422561646
Validation Loss Decreased(4.281628--->4.281464) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1951 / 2500Epoch 1951 		 Training Loss: 1.4034018175942558
Validation step:0Validation step:1Validation step:2Epoch 1951 		 Validation Loss: 4.281409978866577
Validation Loss Decreased(4.281464--->4.281410) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1952 / 2500Epoch 1952 		 Training Loss: 1.404700722013201
Validation step:0Validation step:1Validation step:2Epoch 1952 		 Validation Loss: 4.281497955322266
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1953 / 2500Epoch 1953 		 Training Loss: 1.4037376046180725
Validation step:0Validation step:1Validation step:2Epoch 1953 		 Validation Loss: 4.281301379203796
Validation Loss Decreased(4.281410--->4.281301) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1954 / 2500Epoch 1954 		 Training Loss: 1.403936735221318
Validation step:0Validation step:1Validation step:2Epoch 1954 		 Validation Loss: 4.281177520751953
Validation Loss Decreased(4.281301--->4.281178) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1955 / 2500Epoch 1955 		 Training Loss: 1.4046041369438171
Validation step:0Validation step:1Validation step:2Epoch 1955 		 Validation Loss: 4.281163692474365
Validation Loss Decreased(4.281178--->4.281164) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1956 / 2500Epoch 1956 		 Training Loss: 1.4043306367737907
Validation step:0Validation step:1Validation step:2Epoch 1956 		 Validation Loss: 4.280983090400696
Validation Loss Decreased(4.281164--->4.280983) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1957 / 2500Epoch 1957 		 Training Loss: 1.4042373640196664
Validation step:0Validation step:1Validation step:2Epoch 1957 		 Validation Loss: 4.280837416648865
Validation Loss Decreased(4.280983--->4.280837) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1958 / 2500Epoch 1958 		 Training Loss: 1.4055619069508143
Validation step:0Validation step:1Validation step:2Epoch 1958 		 Validation Loss: 4.2807745933532715
Validation Loss Decreased(4.280837--->4.280775) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1959 / 2500Epoch 1959 		 Training Loss: 1.4046233296394348
Validation step:0Validation step:1Validation step:2Epoch 1959 		 Validation Loss: 4.280688524246216
Validation Loss Decreased(4.280775--->4.280689) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1960 / 2500Epoch 1960 		 Training Loss: 1.4050631523132324
Validation step:0Validation step:1Validation step:2Epoch 1960 		 Validation Loss: 4.28059709072113
Validation Loss Decreased(4.280689--->4.280597) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1961 / 2500Epoch 1961 		 Training Loss: 1.4037520800318037
Validation step:0Validation step:1Validation step:2Epoch 1961 		 Validation Loss: 4.280530095100403
Validation Loss Decreased(4.280597--->4.280530) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1962 / 2500Epoch 1962 		 Training Loss: 1.40249902009964
Validation step:0Validation step:1Validation step:2Epoch 1962 		 Validation Loss: 4.280419826507568
Validation Loss Decreased(4.280530--->4.280420) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1963 / 2500Epoch 1963 		 Training Loss: 1.4044542738369532
Validation step:0Validation step:1Validation step:2Epoch 1963 		 Validation Loss: 4.2802815437316895
Validation Loss Decreased(4.280420--->4.280282) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1964 / 2500Epoch 1964 		 Training Loss: 1.404351098196847
Validation step:0Validation step:1Validation step:2Epoch 1964 		 Validation Loss: 4.280213117599487
Validation Loss Decreased(4.280282--->4.280213) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1965 / 2500Epoch 1965 		 Training Loss: 1.4046491384506226
Validation step:0Validation step:1Validation step:2Epoch 1965 		 Validation Loss: 4.280131936073303
Validation Loss Decreased(4.280213--->4.280132) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1966 / 2500Epoch 1966 		 Training Loss: 1.4033066289765495
Validation step:0Validation step:1Validation step:2Epoch 1966 		 Validation Loss: 4.2800294160842896
Validation Loss Decreased(4.280132--->4.280029) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1967 / 2500Epoch 1967 		 Training Loss: 1.4047857693263464
Validation step:0Validation step:1Validation step:2Epoch 1967 		 Validation Loss: 4.279965400695801
Validation Loss Decreased(4.280029--->4.279965) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1968 / 2500Epoch 1968 		 Training Loss: 1.4042193974767412
Validation step:0Validation step:1Validation step:2Epoch 1968 		 Validation Loss: 4.279878497123718
Validation Loss Decreased(4.279965--->4.279878) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1969 / 2500Epoch 1969 		 Training Loss: 1.404639916760581
Validation step:0Validation step:1Validation step:2Epoch 1969 		 Validation Loss: 4.2797592878341675
Validation Loss Decreased(4.279878--->4.279759) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1970 / 2500Epoch 1970 		 Training Loss: 1.4035928675106593
Validation step:0Validation step:1Validation step:2Epoch 1970 		 Validation Loss: 4.279703378677368
Validation Loss Decreased(4.279759--->4.279703) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1971 / 2500Epoch 1971 		 Training Loss: 1.4038807494299752
Validation step:0Validation step:1Validation step:2Epoch 1971 		 Validation Loss: 4.279630780220032
Validation Loss Decreased(4.279703--->4.279631) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1972 / 2500Epoch 1972 		 Training Loss: 1.4040317790848869
Validation step:0Validation step:1Validation step:2Epoch 1972 		 Validation Loss: 4.279534816741943
Validation Loss Decreased(4.279631--->4.279535) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1973 / 2500Epoch 1973 		 Training Loss: 1.4029499292373657
Validation step:0Validation step:1Validation step:2Epoch 1973 		 Validation Loss: 4.27953028678894
Validation Loss Decreased(4.279535--->4.279530) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1974 / 2500Epoch 1974 		 Training Loss: 1.4040529813085283
Validation step:0Validation step:1Validation step:2Epoch 1974 		 Validation Loss: 4.279394626617432
Validation Loss Decreased(4.279530--->4.279395) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1975 / 2500Epoch 1975 		 Training Loss: 1.4045267701148987
Validation step:0Validation step:1Validation step:2Epoch 1975 		 Validation Loss: 4.279252290725708
Validation Loss Decreased(4.279395--->4.279252) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1976 / 2500Epoch 1976 		 Training Loss: 1.4048410228320531
Validation step:0Validation step:1Validation step:2Epoch 1976 		 Validation Loss: 4.279321074485779
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1977 / 2500Epoch 1977 		 Training Loss: 1.404692564691816
Validation step:0Validation step:1Validation step:2Epoch 1977 		 Validation Loss: 4.279162645339966
Validation Loss Decreased(4.279252--->4.279163) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1978 / 2500Epoch 1978 		 Training Loss: 1.404002070426941
Validation step:0Validation step:1Validation step:2Epoch 1978 		 Validation Loss: 4.2790961265563965
Validation Loss Decreased(4.279163--->4.279096) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1979 / 2500Epoch 1979 		 Training Loss: 1.4033969725881303
Validation step:0Validation step:1Validation step:2Epoch 1979 		 Validation Loss: 4.2789952754974365
Validation Loss Decreased(4.279096--->4.278995) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1980 / 2500Epoch 1980 		 Training Loss: 1.401796477181571
Validation step:0Validation step:1Validation step:2Epoch 1980 		 Validation Loss: 4.279014706611633
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1981 / 2500Epoch 1981 		 Training Loss: 1.4036528723580497
Validation step:0Validation step:1Validation step:2Epoch 1981 		 Validation Loss: 4.2787781953811646
Validation Loss Decreased(4.278995--->4.278778) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1982 / 2500Epoch 1982 		 Training Loss: 1.4033948183059692
Validation step:0Validation step:1Validation step:2Epoch 1982 		 Validation Loss: 4.278748631477356
Validation Loss Decreased(4.278778--->4.278749) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1983 / 2500Epoch 1983 		 Training Loss: 1.4039058770452226
Validation step:0Validation step:1Validation step:2Epoch 1983 		 Validation Loss: 4.278632879257202
Validation Loss Decreased(4.278749--->4.278633) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1984 / 2500Epoch 1984 		 Training Loss: 1.4031707644462585
Validation step:0Validation step:1Validation step:2Epoch 1984 		 Validation Loss: 4.278539776802063
Validation Loss Decreased(4.278633--->4.278540) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1985 / 2500Epoch 1985 		 Training Loss: 1.40399945633752
Validation step:0Validation step:1Validation step:2Epoch 1985 		 Validation Loss: 4.278427243232727
Validation Loss Decreased(4.278540--->4.278427) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1986 / 2500Epoch 1986 		 Training Loss: 1.4036498410361153
Validation step:0Validation step:1Validation step:2Epoch 1986 		 Validation Loss: 4.278274893760681
Validation Loss Decreased(4.278427--->4.278275) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1987 / 2500Epoch 1987 		 Training Loss: 1.4034464018685477
Validation step:0Validation step:1Validation step:2Epoch 1987 		 Validation Loss: 4.2783509492874146
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1988 / 2500Epoch 1988 		 Training Loss: 1.4034349066870553
Validation step:0Validation step:1Validation step:2Epoch 1988 		 Validation Loss: 4.278210878372192
Validation Loss Decreased(4.278275--->4.278211) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1989 / 2500Epoch 1989 		 Training Loss: 1.4023457510130746
Validation step:0Validation step:1Validation step:2Epoch 1989 		 Validation Loss: 4.278142333030701
Validation Loss Decreased(4.278211--->4.278142) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1990 / 2500Epoch 1990 		 Training Loss: 1.403606116771698
Validation step:0Validation step:1Validation step:2Epoch 1990 		 Validation Loss: 4.277994394302368
Validation Loss Decreased(4.278142--->4.277994) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1991 / 2500Epoch 1991 		 Training Loss: 1.4026869876044137
Validation step:0Validation step:1Validation step:2Epoch 1991 		 Validation Loss: 4.277838706970215
Validation Loss Decreased(4.277994--->4.277839) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1992 / 2500Epoch 1992 		 Training Loss: 1.4041829875537328
Validation step:0Validation step:1Validation step:2Epoch 1992 		 Validation Loss: 4.277864575386047
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1993 / 2500Epoch 1993 		 Training Loss: 1.4036334327289037
Validation step:0Validation step:1Validation step:2Epoch 1993 		 Validation Loss: 4.277687072753906
Validation Loss Decreased(4.277839--->4.277687) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1994 / 2500Epoch 1994 		 Training Loss: 1.4036938803536552
Validation step:0Validation step:1Validation step:2Epoch 1994 		 Validation Loss: 4.277538299560547
Validation Loss Decreased(4.277687--->4.277538) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1995 / 2500Epoch 1995 		 Training Loss: 1.4014768770762853
Validation step:0Validation step:1Validation step:2Epoch 1995 		 Validation Loss: 4.2774258852005005
Validation Loss Decreased(4.277538--->4.277426) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1996 / 2500Epoch 1996 		 Training Loss: 1.40417104107993
Validation step:0Validation step:1Validation step:2Epoch 1996 		 Validation Loss: 4.277511954307556
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1997 / 2500Epoch 1997 		 Training Loss: 1.403633109160832
Validation step:0Validation step:1Validation step:2Epoch 1997 		 Validation Loss: 4.277305006980896
Validation Loss Decreased(4.277426--->4.277305) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1998 / 2500Epoch 1998 		 Training Loss: 1.402763613632747
Validation step:0Validation step:1Validation step:2Epoch 1998 		 Validation Loss: 4.2773072719573975
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 1999 / 2500Epoch 1999 		 Training Loss: 1.403184745992933
Validation step:0Validation step:1Validation step:2Epoch 1999 		 Validation Loss: 4.277163863182068
Validation Loss Decreased(4.277305--->4.277164) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2000 / 2500Epoch 2000 		 Training Loss: 1.403097893510546
Validation step:0Validation step:1Validation step:2Epoch 2000 		 Validation Loss: 4.277059316635132
Validation Loss Decreased(4.277164--->4.277059) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2001 / 2500Epoch 2001 		 Training Loss: 1.4023180603981018
Validation step:0Validation step:1Validation step:2Epoch 2001 		 Validation Loss: 4.276972532272339
Validation Loss Decreased(4.277059--->4.276973) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2002 / 2500Epoch 2002 		 Training Loss: 1.4030957051685877
Validation step:0Validation step:1Validation step:2Epoch 2002 		 Validation Loss: 4.276905179023743
Validation Loss Decreased(4.276973--->4.276905) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2003 / 2500Epoch 2003 		 Training Loss: 1.4041798540524073
Validation step:0Validation step:1Validation step:2Epoch 2003 		 Validation Loss: 4.276787161827087
Validation Loss Decreased(4.276905--->4.276787) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2004 / 2500Epoch 2004 		 Training Loss: 1.4033894368580409
Validation step:0Validation step:1Validation step:2Epoch 2004 		 Validation Loss: 4.276689887046814
Validation Loss Decreased(4.276787--->4.276690) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2005 / 2500Epoch 2005 		 Training Loss: 1.402395784854889
Validation step:0Validation step:1Validation step:2Epoch 2005 		 Validation Loss: 4.276856422424316
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2006 / 2500Epoch 2006 		 Training Loss: 1.4015454649925232
Validation step:0Validation step:1Validation step:2Epoch 2006 		 Validation Loss: 4.276566863059998
Validation Loss Decreased(4.276690--->4.276567) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2007 / 2500Epoch 2007 		 Training Loss: 1.4030836820602417
Validation step:0Validation step:1Validation step:2Epoch 2007 		 Validation Loss: 4.27646541595459
Validation Loss Decreased(4.276567--->4.276465) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2008 / 2500Epoch 2008 		 Training Loss: 1.4032759751592363
Validation step:0Validation step:1Validation step:2Epoch 2008 		 Validation Loss: 4.276331067085266
Validation Loss Decreased(4.276465--->4.276331) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2009 / 2500Epoch 2009 		 Training Loss: 1.4019034249441964
Validation step:0Validation step:1Validation step:2Epoch 2009 		 Validation Loss: 4.276187539100647
Validation Loss Decreased(4.276331--->4.276188) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2010 / 2500Epoch 2010 		 Training Loss: 1.4011076177869524
Validation step:0Validation step:1Validation step:2Epoch 2010 		 Validation Loss: 4.276178956031799
Validation Loss Decreased(4.276188--->4.276179) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2011 / 2500Epoch 2011 		 Training Loss: 1.4024490543774195
Validation step:0Validation step:1Validation step:2Epoch 2011 		 Validation Loss: 4.27608859539032
Validation Loss Decreased(4.276179--->4.276089) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2012 / 2500Epoch 2012 		 Training Loss: 1.4021373731749398
Validation step:0Validation step:1Validation step:2Epoch 2012 		 Validation Loss: 4.275983572006226
Validation Loss Decreased(4.276089--->4.275984) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2013 / 2500Epoch 2013 		 Training Loss: 1.4036767653056554
Validation step:0Validation step:1Validation step:2Epoch 2013 		 Validation Loss: 4.275973796844482
Validation Loss Decreased(4.275984--->4.275974) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2014 / 2500Epoch 2014 		 Training Loss: 1.4038297278540475
Validation step:0Validation step:1Validation step:2Epoch 2014 		 Validation Loss: 4.275876522064209
Validation Loss Decreased(4.275974--->4.275877) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2015 / 2500Epoch 2015 		 Training Loss: 1.4023011411939348
Validation step:0Validation step:1Validation step:2Epoch 2015 		 Validation Loss: 4.275777339935303
Validation Loss Decreased(4.275877--->4.275777) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2016 / 2500Epoch 2016 		 Training Loss: 1.4035503779138838
Validation step:0Validation step:1Validation step:2Epoch 2016 		 Validation Loss: 4.275661587715149
Validation Loss Decreased(4.275777--->4.275662) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2017 / 2500Epoch 2017 		 Training Loss: 1.4015417524746485
Validation step:0Validation step:1Validation step:2Epoch 2017 		 Validation Loss: 4.275665044784546
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2018 / 2500Epoch 2018 		 Training Loss: 1.403266327721732
Validation step:0Validation step:1Validation step:2Epoch 2018 		 Validation Loss: 4.275512933731079
Validation Loss Decreased(4.275662--->4.275513) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2019 / 2500Epoch 2019 		 Training Loss: 1.4034513064793177
Validation step:0Validation step:1Validation step:2Epoch 2019 		 Validation Loss: 4.275669097900391
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2020 / 2500Epoch 2020 		 Training Loss: 1.4027158617973328
Validation step:0Validation step:1Validation step:2Epoch 2020 		 Validation Loss: 4.275365352630615
Validation Loss Decreased(4.275513--->4.275365) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2021 / 2500Epoch 2021 		 Training Loss: 1.4027196509497506
Validation step:0Validation step:1Validation step:2Epoch 2021 		 Validation Loss: 4.2752978801727295
Validation Loss Decreased(4.275365--->4.275298) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2022 / 2500Epoch 2022 		 Training Loss: 1.4037214602742876
Validation step:0Validation step:1Validation step:2Epoch 2022 		 Validation Loss: 4.275160074234009
Validation Loss Decreased(4.275298--->4.275160) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2023 / 2500Epoch 2023 		 Training Loss: 1.4014082380703516
Validation step:0Validation step:1Validation step:2Epoch 2023 		 Validation Loss: 4.275105237960815
Validation Loss Decreased(4.275160--->4.275105) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2024 / 2500Epoch 2024 		 Training Loss: 1.4004305260522025
Validation step:0Validation step:1Validation step:2Epoch 2024 		 Validation Loss: 4.2750164270401
Validation Loss Decreased(4.275105--->4.275016) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2025 / 2500Epoch 2025 		 Training Loss: 1.401293729032789
Validation step:0Validation step:1Validation step:2Epoch 2025 		 Validation Loss: 4.274878978729248
Validation Loss Decreased(4.275016--->4.274879) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2026 / 2500Epoch 2026 		 Training Loss: 1.4022456918443953
Validation step:0Validation step:1Validation step:2Epoch 2026 		 Validation Loss: 4.274780511856079
Validation Loss Decreased(4.274879--->4.274781) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2027 / 2500Epoch 2027 		 Training Loss: 1.401824721268245
Validation step:0Validation step:1Validation step:2Epoch 2027 		 Validation Loss: 4.274874448776245
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2028 / 2500Epoch 2028 		 Training Loss: 1.4021630031721932
Validation step:0Validation step:1Validation step:2Epoch 2028 		 Validation Loss: 4.274646997451782
Validation Loss Decreased(4.274781--->4.274647) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2029 / 2500Epoch 2029 		 Training Loss: 1.403055455003466
Validation step:0Validation step:1Validation step:2Epoch 2029 		 Validation Loss: 4.274549245834351
Validation Loss Decreased(4.274647--->4.274549) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2030 / 2500Epoch 2030 		 Training Loss: 1.4015083483287267
Validation step:0Validation step:1Validation step:2Epoch 2030 		 Validation Loss: 4.274462699890137
Validation Loss Decreased(4.274549--->4.274463) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2031 / 2500Epoch 2031 		 Training Loss: 1.4009166274751936
Validation step:0Validation step:1Validation step:2Epoch 2031 		 Validation Loss: 4.274388909339905
Validation Loss Decreased(4.274463--->4.274389) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2032 / 2500Epoch 2032 		 Training Loss: 1.4016409005437578
Validation step:0Validation step:1Validation step:2Epoch 2032 		 Validation Loss: 4.274355173110962
Validation Loss Decreased(4.274389--->4.274355) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2033 / 2500Epoch 2033 		 Training Loss: 1.401942593710763
Validation step:0Validation step:1Validation step:2Epoch 2033 		 Validation Loss: 4.274251341819763
Validation Loss Decreased(4.274355--->4.274251) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2034 / 2500Epoch 2034 		 Training Loss: 1.4029978173119682
Validation step:0Validation step:1Validation step:2Epoch 2034 		 Validation Loss: 4.274110794067383
Validation Loss Decreased(4.274251--->4.274111) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2035 / 2500Epoch 2035 		 Training Loss: 1.4028577378817968
Validation step:0Validation step:1Validation step:2Epoch 2035 		 Validation Loss: 4.273991703987122
Validation Loss Decreased(4.274111--->4.273992) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2036 / 2500Epoch 2036 		 Training Loss: 1.4025410413742065
Validation step:0Validation step:1Validation step:2Epoch 2036 		 Validation Loss: 4.273952126502991
Validation Loss Decreased(4.273992--->4.273952) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2037 / 2500Epoch 2037 		 Training Loss: 1.4003600478172302
Validation step:0Validation step:1Validation step:2Epoch 2037 		 Validation Loss: 4.273805022239685
Validation Loss Decreased(4.273952--->4.273805) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2038 / 2500Epoch 2038 		 Training Loss: 1.4027600628989083
Validation step:0Validation step:1Validation step:2Epoch 2038 		 Validation Loss: 4.273736953735352
Validation Loss Decreased(4.273805--->4.273737) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2039 / 2500Epoch 2039 		 Training Loss: 1.4005247865404402
Validation step:0Validation step:1Validation step:2Epoch 2039 		 Validation Loss: 4.273776888847351
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2040 / 2500Epoch 2040 		 Training Loss: 1.402182868548802
Validation step:0Validation step:1Validation step:2Epoch 2040 		 Validation Loss: 4.273696064949036
Validation Loss Decreased(4.273737--->4.273696) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2041 / 2500Epoch 2041 		 Training Loss: 1.4027955957821436
Validation step:0Validation step:1Validation step:2Epoch 2041 		 Validation Loss: 4.273546457290649
Validation Loss Decreased(4.273696--->4.273546) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2042 / 2500Epoch 2042 		 Training Loss: 1.401911003249032
Validation step:0Validation step:1Validation step:2Epoch 2042 		 Validation Loss: 4.2736656665802
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2043 / 2500Epoch 2043 		 Training Loss: 1.4023411529404777
Validation step:0Validation step:1Validation step:2Epoch 2043 		 Validation Loss: 4.273393630981445
Validation Loss Decreased(4.273546--->4.273394) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2044 / 2500Epoch 2044 		 Training Loss: 1.4014853579657418
Validation step:0Validation step:1Validation step:2Epoch 2044 		 Validation Loss: 4.273250102996826
Validation Loss Decreased(4.273394--->4.273250) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2045 / 2500Epoch 2045 		 Training Loss: 1.401628051485334
Validation step:0Validation step:1Validation step:2Epoch 2045 		 Validation Loss: 4.2732826471328735
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2046 / 2500Epoch 2046 		 Training Loss: 1.40118841614042
Validation step:0Validation step:1Validation step:2Epoch 2046 		 Validation Loss: 4.273065090179443
Validation Loss Decreased(4.273250--->4.273065) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2047 / 2500Epoch 2047 		 Training Loss: 1.4022156170436315
Validation step:0Validation step:1Validation step:2Epoch 2047 		 Validation Loss: 4.272950530052185
Validation Loss Decreased(4.273065--->4.272951) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2048 / 2500Epoch 2048 		 Training Loss: 1.4016801459448678
Validation step:0Validation step:1Validation step:2Epoch 2048 		 Validation Loss: 4.272919654846191
Validation Loss Decreased(4.272951--->4.272920) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2049 / 2500Epoch 2049 		 Training Loss: 1.4010268790381295
Validation step:0Validation step:1Validation step:2Epoch 2049 		 Validation Loss: 4.272781848907471
Validation Loss Decreased(4.272920--->4.272782) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2050 / 2500Epoch 2050 		 Training Loss: 1.4025740708623613
Validation step:0Validation step:1Validation step:2Epoch 2050 		 Validation Loss: 4.272709131240845
Validation Loss Decreased(4.272782--->4.272709) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2051 / 2500Epoch 2051 		 Training Loss: 1.4014452525547572
Validation step:0Validation step:1Validation step:2Epoch 2051 		 Validation Loss: 4.2726287841796875
Validation Loss Decreased(4.272709--->4.272629) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2052 / 2500Epoch 2052 		 Training Loss: 1.4023695162364416
Validation step:0Validation step:1Validation step:2Epoch 2052 		 Validation Loss: 4.2725197076797485
Validation Loss Decreased(4.272629--->4.272520) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2053 / 2500Epoch 2053 		 Training Loss: 1.401580342224666
Validation step:0Validation step:1Validation step:2Epoch 2053 		 Validation Loss: 4.2723881006240845
Validation Loss Decreased(4.272520--->4.272388) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2054 / 2500Epoch 2054 		 Training Loss: 1.4018129876681737
Validation step:0Validation step:1Validation step:2Epoch 2054 		 Validation Loss: 4.2723166942596436
Validation Loss Decreased(4.272388--->4.272317) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2055 / 2500Epoch 2055 		 Training Loss: 1.4001315065792628
Validation step:0Validation step:1Validation step:2Epoch 2055 		 Validation Loss: 4.272485852241516
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2056 / 2500Epoch 2056 		 Training Loss: 1.3997954726219177
Validation step:0Validation step:1Validation step:2Epoch 2056 		 Validation Loss: 4.272318720817566
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2057 / 2500Epoch 2057 		 Training Loss: 1.4013215729168482
Validation step:0Validation step:1Validation step:2Epoch 2057 		 Validation Loss: 4.272285580635071
Validation Loss Decreased(4.272317--->4.272286) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2058 / 2500Epoch 2058 		 Training Loss: 1.4019807406834193
Validation step:0Validation step:1Validation step:2Epoch 2058 		 Validation Loss: 4.272128582000732
Validation Loss Decreased(4.272286--->4.272129) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2059 / 2500Epoch 2059 		 Training Loss: 1.4017219288008553
Validation step:0Validation step:1Validation step:2Epoch 2059 		 Validation Loss: 4.272108674049377
Validation Loss Decreased(4.272129--->4.272109) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2060 / 2500Epoch 2060 		 Training Loss: 1.4014678682599748
Validation step:0Validation step:1Validation step:2Epoch 2060 		 Validation Loss: 4.2719234228134155
Validation Loss Decreased(4.272109--->4.271923) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2061 / 2500Epoch 2061 		 Training Loss: 1.4005655135427202
Validation step:0Validation step:1Validation step:2Epoch 2061 		 Validation Loss: 4.271822452545166
Validation Loss Decreased(4.271923--->4.271822) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2062 / 2500Epoch 2062 		 Training Loss: 1.4002096567835127
Validation step:0Validation step:1Validation step:2Epoch 2062 		 Validation Loss: 4.27184534072876
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2063 / 2500Epoch 2063 		 Training Loss: 1.4009663803236825
Validation step:0Validation step:1Validation step:2Epoch 2063 		 Validation Loss: 4.271687984466553
Validation Loss Decreased(4.271822--->4.271688) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2064 / 2500Epoch 2064 		 Training Loss: 1.4011873688016618
Validation step:0Validation step:1Validation step:2Epoch 2064 		 Validation Loss: 4.271829724311829
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2065 / 2500Epoch 2065 		 Training Loss: 1.4006119200161524
Validation step:0Validation step:1Validation step:2Epoch 2065 		 Validation Loss: 4.271481513977051
Validation Loss Decreased(4.271688--->4.271482) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2066 / 2500Epoch 2066 		 Training Loss: 1.3993464367730277
Validation step:0Validation step:1Validation step:2Epoch 2066 		 Validation Loss: 4.271382689476013
Validation Loss Decreased(4.271482--->4.271383) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2067 / 2500Epoch 2067 		 Training Loss: 1.4008876085281372
Validation step:0Validation step:1Validation step:2Epoch 2067 		 Validation Loss: 4.271272778511047
Validation Loss Decreased(4.271383--->4.271273) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2068 / 2500Epoch 2068 		 Training Loss: 1.3997939910207475
Validation step:0Validation step:1Validation step:2Epoch 2068 		 Validation Loss: 4.271174311637878
Validation Loss Decreased(4.271273--->4.271174) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2069 / 2500Epoch 2069 		 Training Loss: 1.4020686149597168
Validation step:0Validation step:1Validation step:2Epoch 2069 		 Validation Loss: 4.271097779273987
Validation Loss Decreased(4.271174--->4.271098) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2070 / 2500Epoch 2070 		 Training Loss: 1.401285001209804
Validation step:0Validation step:1Validation step:2Epoch 2070 		 Validation Loss: 4.271036744117737
Validation Loss Decreased(4.271098--->4.271037) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2071 / 2500Epoch 2071 		 Training Loss: 1.4003681625638689
Validation step:0Validation step:1Validation step:2Epoch 2071 		 Validation Loss: 4.270910024642944
Validation Loss Decreased(4.271037--->4.270910) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2072 / 2500Epoch 2072 		 Training Loss: 1.4000858494213648
Validation step:0Validation step:1Validation step:2Epoch 2072 		 Validation Loss: 4.270808100700378
Validation Loss Decreased(4.270910--->4.270808) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2073 / 2500Epoch 2073 		 Training Loss: 1.399884283542633
Validation step:0Validation step:1Validation step:2Epoch 2073 		 Validation Loss: 4.270712971687317
Validation Loss Decreased(4.270808--->4.270713) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2074 / 2500Epoch 2074 		 Training Loss: 1.40024334192276
Validation step:0Validation step:1Validation step:2Epoch 2074 		 Validation Loss: 4.270599007606506
Validation Loss Decreased(4.270713--->4.270599) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2075 / 2500Epoch 2075 		 Training Loss: 1.400218904018402
Validation step:0Validation step:1Validation step:2Epoch 2075 		 Validation Loss: 4.270548105239868
Validation Loss Decreased(4.270599--->4.270548) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2076 / 2500Epoch 2076 		 Training Loss: 1.4017292090824671
Validation step:0Validation step:1Validation step:2Epoch 2076 		 Validation Loss: 4.270555257797241
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2077 / 2500Epoch 2077 		 Training Loss: 1.3991900427000863
Validation step:0Validation step:1Validation step:2Epoch 2077 		 Validation Loss: 4.270414352416992
Validation Loss Decreased(4.270548--->4.270414) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2078 / 2500Epoch 2078 		 Training Loss: 1.4001710414886475
Validation step:0Validation step:1Validation step:2Epoch 2078 		 Validation Loss: 4.270287871360779
Validation Loss Decreased(4.270414--->4.270288) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2079 / 2500Epoch 2079 		 Training Loss: 1.4007379242352076
Validation step:0Validation step:1Validation step:2Epoch 2079 		 Validation Loss: 4.270252823829651
Validation Loss Decreased(4.270288--->4.270253) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2080 / 2500Epoch 2080 		 Training Loss: 1.4004532779966081
Validation step:0Validation step:1Validation step:2Epoch 2080 		 Validation Loss: 4.2701557874679565
Validation Loss Decreased(4.270253--->4.270156) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2081 / 2500Epoch 2081 		 Training Loss: 1.4008806432996477
Validation step:0Validation step:1Validation step:2Epoch 2081 		 Validation Loss: 4.270131945610046
Validation Loss Decreased(4.270156--->4.270132) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2082 / 2500Epoch 2082 		 Training Loss: 1.4012327875409807
Validation step:0Validation step:1Validation step:2Epoch 2082 		 Validation Loss: 4.2699891328811646
Validation Loss Decreased(4.270132--->4.269989) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2083 / 2500Epoch 2083 		 Training Loss: 1.4009747760636466
Validation step:0Validation step:1Validation step:2Epoch 2083 		 Validation Loss: 4.269863724708557
Validation Loss Decreased(4.269989--->4.269864) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2084 / 2500Epoch 2084 		 Training Loss: 1.4009239077568054
Validation step:0Validation step:1Validation step:2Epoch 2084 		 Validation Loss: 4.269773483276367
Validation Loss Decreased(4.269864--->4.269773) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2085 / 2500Epoch 2085 		 Training Loss: 1.4010411841528756
Validation step:0Validation step:1Validation step:2Epoch 2085 		 Validation Loss: 4.269723176956177
Validation Loss Decreased(4.269773--->4.269723) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2086 / 2500Epoch 2086 		 Training Loss: 1.3992417028972082
Validation step:0Validation step:1Validation step:2Epoch 2086 		 Validation Loss: 4.269651174545288
Validation Loss Decreased(4.269723--->4.269651) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2087 / 2500Epoch 2087 		 Training Loss: 1.4006730573517936
Validation step:0Validation step:1Validation step:2Epoch 2087 		 Validation Loss: 4.269547462463379
Validation Loss Decreased(4.269651--->4.269547) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2088 / 2500Epoch 2088 		 Training Loss: 1.4002064211027963
Validation step:0Validation step:1Validation step:2Epoch 2088 		 Validation Loss: 4.269518136978149
Validation Loss Decreased(4.269547--->4.269518) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2089 / 2500Epoch 2089 		 Training Loss: 1.399929506438119
Validation step:0Validation step:1Validation step:2Epoch 2089 		 Validation Loss: 4.269420266151428
Validation Loss Decreased(4.269518--->4.269420) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2090 / 2500Epoch 2090 		 Training Loss: 1.3993953040667944
Validation step:0Validation step:1Validation step:2Epoch 2090 		 Validation Loss: 4.26935887336731
Validation Loss Decreased(4.269420--->4.269359) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2091 / 2500Epoch 2091 		 Training Loss: 1.3993183033806937
Validation step:0Validation step:1Validation step:2Epoch 2091 		 Validation Loss: 4.269234299659729
Validation Loss Decreased(4.269359--->4.269234) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2092 / 2500Epoch 2092 		 Training Loss: 1.3995795164789473
Validation step:0Validation step:1Validation step:2Epoch 2092 		 Validation Loss: 4.269160628318787
Validation Loss Decreased(4.269234--->4.269161) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2093 / 2500Epoch 2093 		 Training Loss: 1.4003992421286446
Validation step:0Validation step:1Validation step:2Epoch 2093 		 Validation Loss: 4.2690640687942505
Validation Loss Decreased(4.269161--->4.269064) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2094 / 2500Epoch 2094 		 Training Loss: 1.4014108266149248
Validation step:0Validation step:1Validation step:2Epoch 2094 		 Validation Loss: 4.269101977348328
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2095 / 2500Epoch 2095 		 Training Loss: 1.398645281791687
Validation step:0Validation step:1Validation step:2Epoch 2095 		 Validation Loss: 4.268963813781738
Validation Loss Decreased(4.269064--->4.268964) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2096 / 2500Epoch 2096 		 Training Loss: 1.400136947631836
Validation step:0Validation step:1Validation step:2Epoch 2096 		 Validation Loss: 4.268821716308594
Validation Loss Decreased(4.268964--->4.268822) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2097 / 2500Epoch 2097 		 Training Loss: 1.4011637653623308
Validation step:0Validation step:1Validation step:2Epoch 2097 		 Validation Loss: 4.268749475479126
Validation Loss Decreased(4.268822--->4.268749) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2098 / 2500Epoch 2098 		 Training Loss: 1.398642897605896
Validation step:0Validation step:1Validation step:2Epoch 2098 		 Validation Loss: 4.268632769584656
Validation Loss Decreased(4.268749--->4.268633) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2099 / 2500Epoch 2099 		 Training Loss: 1.3998473967824663
Validation step:0Validation step:1Validation step:2Epoch 2099 		 Validation Loss: 4.268526792526245
Validation Loss Decreased(4.268633--->4.268527) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2100 / 2500Epoch 2100 		 Training Loss: 1.400092533656529
Validation step:0Validation step:1Validation step:2Epoch 2100 		 Validation Loss: 4.268462896347046
Validation Loss Decreased(4.268527--->4.268463) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2101 / 2500Epoch 2101 		 Training Loss: 1.4013883301189967
Validation step:0Validation step:1Validation step:2Epoch 2101 		 Validation Loss: 4.2684149742126465
Validation Loss Decreased(4.268463--->4.268415) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2102 / 2500Epoch 2102 		 Training Loss: 1.4008249725614275
Validation step:0Validation step:1Validation step:2Epoch 2102 		 Validation Loss: 4.268273830413818
Validation Loss Decreased(4.268415--->4.268274) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2103 / 2500Epoch 2103 		 Training Loss: 1.4005702989442008
Validation step:0Validation step:1Validation step:2Epoch 2103 		 Validation Loss: 4.26816463470459
Validation Loss Decreased(4.268274--->4.268165) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2104 / 2500Epoch 2104 		 Training Loss: 1.400115089757102
Validation step:0Validation step:1Validation step:2Epoch 2104 		 Validation Loss: 4.2682154178619385
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2105 / 2500Epoch 2105 		 Training Loss: 1.3995188134057182
Validation step:0Validation step:1Validation step:2Epoch 2105 		 Validation Loss: 4.2680511474609375
Validation Loss Decreased(4.268165--->4.268051) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2106 / 2500Epoch 2106 		 Training Loss: 1.39913352898189
Validation step:0Validation step:1Validation step:2Epoch 2106 		 Validation Loss: 4.268008828163147
Validation Loss Decreased(4.268051--->4.268009) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2107 / 2500Epoch 2107 		 Training Loss: 1.3985765831811088
Validation step:0Validation step:1Validation step:2Epoch 2107 		 Validation Loss: 4.267876982688904
Validation Loss Decreased(4.268009--->4.267877) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2108 / 2500Epoch 2108 		 Training Loss: 1.3983994296618871
Validation step:0Validation step:1Validation step:2Epoch 2108 		 Validation Loss: 4.267748951911926
Validation Loss Decreased(4.267877--->4.267749) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2109 / 2500Epoch 2109 		 Training Loss: 1.399703221661704
Validation step:0Validation step:1Validation step:2Epoch 2109 		 Validation Loss: 4.267669916152954
Validation Loss Decreased(4.267749--->4.267670) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2110 / 2500Epoch 2110 		 Training Loss: 1.3998000281197684
Validation step:0Validation step:1Validation step:2Epoch 2110 		 Validation Loss: 4.267659783363342
Validation Loss Decreased(4.267670--->4.267660) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2111 / 2500Epoch 2111 		 Training Loss: 1.3992738894053869
Validation step:0Validation step:1Validation step:2Epoch 2111 		 Validation Loss: 4.267543077468872
Validation Loss Decreased(4.267660--->4.267543) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2112 / 2500Epoch 2112 		 Training Loss: 1.399793199130467
Validation step:0Validation step:1Validation step:2Epoch 2112 		 Validation Loss: 4.26745867729187
Validation Loss Decreased(4.267543--->4.267459) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2113 / 2500Epoch 2113 		 Training Loss: 1.4007806607655116
Validation step:0Validation step:1Validation step:2Epoch 2113 		 Validation Loss: 4.267376184463501
Validation Loss Decreased(4.267459--->4.267376) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2114 / 2500Epoch 2114 		 Training Loss: 1.3979602285793848
Validation step:0Validation step:1Validation step:2Epoch 2114 		 Validation Loss: 4.267255783081055
Validation Loss Decreased(4.267376--->4.267256) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2115 / 2500Epoch 2115 		 Training Loss: 1.4002486041613988
Validation step:0Validation step:1Validation step:2Epoch 2115 		 Validation Loss: 4.267298698425293
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2116 / 2500Epoch 2116 		 Training Loss: 1.3995389172009058
Validation step:0Validation step:1Validation step:2Epoch 2116 		 Validation Loss: 4.267107009887695
Validation Loss Decreased(4.267256--->4.267107) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2117 / 2500Epoch 2117 		 Training Loss: 1.3990621055875505
Validation step:0Validation step:1Validation step:2Epoch 2117 		 Validation Loss: 4.267080664634705
Validation Loss Decreased(4.267107--->4.267081) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2118 / 2500Epoch 2118 		 Training Loss: 1.399168951170785
Validation step:0Validation step:1Validation step:2Epoch 2118 		 Validation Loss: 4.266996502876282
Validation Loss Decreased(4.267081--->4.266997) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2119 / 2500Epoch 2119 		 Training Loss: 1.4004594939095634
Validation step:0Validation step:1Validation step:2Epoch 2119 		 Validation Loss: 4.26686954498291
Validation Loss Decreased(4.266997--->4.266870) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2120 / 2500Epoch 2120 		 Training Loss: 1.4000226429530553
Validation step:0Validation step:1Validation step:2Epoch 2120 		 Validation Loss: 4.266840934753418
Validation Loss Decreased(4.266870--->4.266841) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2121 / 2500Epoch 2121 		 Training Loss: 1.398413462298257
Validation step:0Validation step:1Validation step:2Epoch 2121 		 Validation Loss: 4.266795039176941
Validation Loss Decreased(4.266841--->4.266795) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2122 / 2500Epoch 2122 		 Training Loss: 1.3980684110096522
Validation step:0Validation step:1Validation step:2Epoch 2122 		 Validation Loss: 4.26654326915741
Validation Loss Decreased(4.266795--->4.266543) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2123 / 2500Epoch 2123 		 Training Loss: 1.4006499988692147
Validation step:0Validation step:1Validation step:2Epoch 2123 		 Validation Loss: 4.266476154327393
Validation Loss Decreased(4.266543--->4.266476) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2124 / 2500Epoch 2124 		 Training Loss: 1.3998224820409502
Validation step:0Validation step:1Validation step:2Epoch 2124 		 Validation Loss: 4.266371846199036
Validation Loss Decreased(4.266476--->4.266372) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2125 / 2500Epoch 2125 		 Training Loss: 1.4001521979059492
Validation step:0Validation step:1Validation step:2Epoch 2125 		 Validation Loss: 4.2663795948028564
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2126 / 2500Epoch 2126 		 Training Loss: 1.399161125932421
Validation step:0Validation step:1Validation step:2Epoch 2126 		 Validation Loss: 4.266269326210022
Validation Loss Decreased(4.266372--->4.266269) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2127 / 2500Epoch 2127 		 Training Loss: 1.3992062040737696
Validation step:0Validation step:1Validation step:2Epoch 2127 		 Validation Loss: 4.2662341594696045
Validation Loss Decreased(4.266269--->4.266234) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2128 / 2500Epoch 2128 		 Training Loss: 1.3977315851620264
Validation step:0Validation step:1Validation step:2Epoch 2128 		 Validation Loss: 4.266347646713257
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2129 / 2500Epoch 2129 		 Training Loss: 1.3992777466773987
Validation step:0Validation step:1Validation step:2Epoch 2129 		 Validation Loss: 4.26601779460907
Validation Loss Decreased(4.266234--->4.266018) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2130 / 2500Epoch 2130 		 Training Loss: 1.3962786197662354
Validation step:0Validation step:1Validation step:2Epoch 2130 		 Validation Loss: 4.266067743301392
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2131 / 2500Epoch 2131 		 Training Loss: 1.3987469332558768
Validation step:0Validation step:1Validation step:2Epoch 2131 		 Validation Loss: 4.265876650810242
Validation Loss Decreased(4.266018--->4.265877) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2132 / 2500Epoch 2132 		 Training Loss: 1.3996574878692627
Validation step:0Validation step:1Validation step:2Epoch 2132 		 Validation Loss: 4.26587176322937
Validation Loss Decreased(4.265877--->4.265872) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2133 / 2500Epoch 2133 		 Training Loss: 1.3978698253631592
Validation step:0Validation step:1Validation step:2Epoch 2133 		 Validation Loss: 4.26575779914856
Validation Loss Decreased(4.265872--->4.265758) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2134 / 2500Epoch 2134 		 Training Loss: 1.3982553907803126
Validation step:0Validation step:1Validation step:2Epoch 2134 		 Validation Loss: 4.265619993209839
Validation Loss Decreased(4.265758--->4.265620) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2135 / 2500Epoch 2135 		 Training Loss: 1.4000060898917062
Validation step:0Validation step:1Validation step:2Epoch 2135 		 Validation Loss: 4.265605688095093
Validation Loss Decreased(4.265620--->4.265606) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2136 / 2500Epoch 2136 		 Training Loss: 1.3998482312474931
Validation step:0Validation step:1Validation step:2Epoch 2136 		 Validation Loss: 4.26545786857605
Validation Loss Decreased(4.265606--->4.265458) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2137 / 2500Epoch 2137 		 Training Loss: 1.3981775556291853
Validation step:0Validation step:1Validation step:2Epoch 2137 		 Validation Loss: 4.265517354011536
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2138 / 2500Epoch 2138 		 Training Loss: 1.399595218045371
Validation step:0Validation step:1Validation step:2Epoch 2138 		 Validation Loss: 4.26534104347229
Validation Loss Decreased(4.265458--->4.265341) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2139 / 2500Epoch 2139 		 Training Loss: 1.399665219443185
Validation step:0Validation step:1Validation step:2Epoch 2139 		 Validation Loss: 4.26545250415802
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2140 / 2500Epoch 2140 		 Training Loss: 1.3983755196843828
Validation step:0Validation step:1Validation step:2Epoch 2140 		 Validation Loss: 4.265239477157593
Validation Loss Decreased(4.265341--->4.265239) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2141 / 2500Epoch 2141 		 Training Loss: 1.39821400812694
Validation step:0Validation step:1Validation step:2Epoch 2141 		 Validation Loss: 4.265031933784485
Validation Loss Decreased(4.265239--->4.265032) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2142 / 2500Epoch 2142 		 Training Loss: 1.3983200447899955
Validation step:0Validation step:1Validation step:2Epoch 2142 		 Validation Loss: 4.2649005651474
Validation Loss Decreased(4.265032--->4.264901) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2143 / 2500Epoch 2143 		 Training Loss: 1.3980526838983809
Validation step:0Validation step:1Validation step:2Epoch 2143 		 Validation Loss: 4.264834880828857
Validation Loss Decreased(4.264901--->4.264835) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2144 / 2500Epoch 2144 		 Training Loss: 1.397915584700448
Validation step:0Validation step:1Validation step:2Epoch 2144 		 Validation Loss: 4.264769434928894
Validation Loss Decreased(4.264835--->4.264769) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2145 / 2500Epoch 2145 		 Training Loss: 1.3978202513286047
Validation step:0Validation step:1Validation step:2Epoch 2145 		 Validation Loss: 4.264621376991272
Validation Loss Decreased(4.264769--->4.264621) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2146 / 2500Epoch 2146 		 Training Loss: 1.3976663095610482
Validation step:0Validation step:1Validation step:2Epoch 2146 		 Validation Loss: 4.264561295509338
Validation Loss Decreased(4.264621--->4.264561) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2147 / 2500Epoch 2147 		 Training Loss: 1.3993613719940186
Validation step:0Validation step:1Validation step:2Epoch 2147 		 Validation Loss: 4.264462351799011
Validation Loss Decreased(4.264561--->4.264462) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2148 / 2500Epoch 2148 		 Training Loss: 1.399389122213636
Validation step:0Validation step:1Validation step:2Epoch 2148 		 Validation Loss: 4.264351725578308
Validation Loss Decreased(4.264462--->4.264352) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2149 / 2500Epoch 2149 		 Training Loss: 1.3985281075750078
Validation step:0Validation step:1Validation step:2Epoch 2149 		 Validation Loss: 4.264524817466736
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2150 / 2500Epoch 2150 		 Training Loss: 1.3993836300713676
Validation step:0Validation step:1Validation step:2Epoch 2150 		 Validation Loss: 4.2642234563827515
Validation Loss Decreased(4.264352--->4.264223) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2151 / 2500Epoch 2151 		 Training Loss: 1.3988202129091536
Validation step:0Validation step:1Validation step:2Epoch 2151 		 Validation Loss: 4.26426374912262
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2152 / 2500Epoch 2152 		 Training Loss: 1.3985072544642858
Validation step:0Validation step:1Validation step:2Epoch 2152 		 Validation Loss: 4.264131307601929
Validation Loss Decreased(4.264223--->4.264131) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2153 / 2500Epoch 2153 		 Training Loss: 1.3990739669118608
Validation step:0Validation step:1Validation step:2Epoch 2153 		 Validation Loss: 4.264038324356079
Validation Loss Decreased(4.264131--->4.264038) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2154 / 2500Epoch 2154 		 Training Loss: 1.399021634033748
Validation step:0Validation step:1Validation step:2Epoch 2154 		 Validation Loss: 4.263996601104736
Validation Loss Decreased(4.264038--->4.263997) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2155 / 2500Epoch 2155 		 Training Loss: 1.3979337981769018
Validation step:0Validation step:1Validation step:2Epoch 2155 		 Validation Loss: 4.263889670372009
Validation Loss Decreased(4.263997--->4.263890) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2156 / 2500Epoch 2156 		 Training Loss: 1.3981097510882787
Validation step:0Validation step:1Validation step:2Epoch 2156 		 Validation Loss: 4.263848543167114
Validation Loss Decreased(4.263890--->4.263849) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2157 / 2500Epoch 2157 		 Training Loss: 1.3989727326801844
Validation step:0Validation step:1Validation step:2Epoch 2157 		 Validation Loss: 4.263673663139343
Validation Loss Decreased(4.263849--->4.263674) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2158 / 2500Epoch 2158 		 Training Loss: 1.397781559399196
Validation step:0Validation step:1Validation step:2Epoch 2158 		 Validation Loss: 4.263617157936096
Validation Loss Decreased(4.263674--->4.263617) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2159 / 2500Epoch 2159 		 Training Loss: 1.3978991253035409
Validation step:0Validation step:1Validation step:2Epoch 2159 		 Validation Loss: 4.2634711265563965
Validation Loss Decreased(4.263617--->4.263471) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2160 / 2500Epoch 2160 		 Training Loss: 1.3978501132556371
Validation step:0Validation step:1Validation step:2Epoch 2160 		 Validation Loss: 4.263354539871216
Validation Loss Decreased(4.263471--->4.263355) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2161 / 2500Epoch 2161 		 Training Loss: 1.3979959062167577
Validation step:0Validation step:1Validation step:2Epoch 2161 		 Validation Loss: 4.263303756713867
Validation Loss Decreased(4.263355--->4.263304) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2162 / 2500Epoch 2162 		 Training Loss: 1.399039694241115
Validation step:0Validation step:1Validation step:2Epoch 2162 		 Validation Loss: 4.263156771659851
Validation Loss Decreased(4.263304--->4.263157) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2163 / 2500Epoch 2163 		 Training Loss: 1.3977638738495963
Validation step:0Validation step:1Validation step:2Epoch 2163 		 Validation Loss: 4.263140082359314
Validation Loss Decreased(4.263157--->4.263140) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2164 / 2500Epoch 2164 		 Training Loss: 1.3979170407567705
Validation step:0Validation step:1Validation step:2Epoch 2164 		 Validation Loss: 4.263076066970825
Validation Loss Decreased(4.263140--->4.263076) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2165 / 2500Epoch 2165 		 Training Loss: 1.39784209217344
Validation step:0Validation step:1Validation step:2Epoch 2165 		 Validation Loss: 4.2629594802856445
Validation Loss Decreased(4.263076--->4.262959) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2166 / 2500Epoch 2166 		 Training Loss: 1.3979453359331404
Validation step:0Validation step:1Validation step:2Epoch 2166 		 Validation Loss: 4.262885332107544
Validation Loss Decreased(4.262959--->4.262885) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2167 / 2500Epoch 2167 		 Training Loss: 1.3982301609856742
Validation step:0Validation step:1Validation step:2Epoch 2167 		 Validation Loss: 4.262892007827759
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2168 / 2500Epoch 2168 		 Training Loss: 1.3973633306367057
Validation step:0Validation step:1Validation step:2Epoch 2168 		 Validation Loss: 4.262753486633301
Validation Loss Decreased(4.262885--->4.262753) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2169 / 2500Epoch 2169 		 Training Loss: 1.398617787020547
Validation step:0Validation step:1Validation step:2Epoch 2169 		 Validation Loss: 4.262686252593994
Validation Loss Decreased(4.262753--->4.262686) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2170 / 2500Epoch 2170 		 Training Loss: 1.3986988493374415
Validation step:0Validation step:1Validation step:2Epoch 2170 		 Validation Loss: 4.2625415325164795
Validation Loss Decreased(4.262686--->4.262542) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2171 / 2500Epoch 2171 		 Training Loss: 1.3981664180755615
Validation step:0Validation step:1Validation step:2Epoch 2171 		 Validation Loss: 4.262474775314331
Validation Loss Decreased(4.262542--->4.262475) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2172 / 2500Epoch 2172 		 Training Loss: 1.3979171855109078
Validation step:0Validation step:1Validation step:2Epoch 2172 		 Validation Loss: 4.2623714208602905
Validation Loss Decreased(4.262475--->4.262371) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2173 / 2500Epoch 2173 		 Training Loss: 1.3971012915883745
Validation step:0Validation step:1Validation step:2Epoch 2173 		 Validation Loss: 4.262277841567993
Validation Loss Decreased(4.262371--->4.262278) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2174 / 2500Epoch 2174 		 Training Loss: 1.3987699576786585
Validation step:0Validation step:1Validation step:2Epoch 2174 		 Validation Loss: 4.2622023820877075
Validation Loss Decreased(4.262278--->4.262202) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2175 / 2500Epoch 2175 		 Training Loss: 1.3975319266319275
Validation step:0Validation step:1Validation step:2Epoch 2175 		 Validation Loss: 4.262349605560303
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2176 / 2500Epoch 2176 		 Training Loss: 1.3974263753209795
Validation step:0Validation step:1Validation step:2Epoch 2176 		 Validation Loss: 4.262052893638611
Validation Loss Decreased(4.262202--->4.262053) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2177 / 2500Epoch 2177 		 Training Loss: 1.3986016937664576
Validation step:0Validation step:1Validation step:2Epoch 2177 		 Validation Loss: 4.261918425559998
Validation Loss Decreased(4.262053--->4.261918) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2178 / 2500Epoch 2178 		 Training Loss: 1.3959285446575709
Validation step:0Validation step:1Validation step:2Epoch 2178 		 Validation Loss: 4.26186740398407
Validation Loss Decreased(4.261918--->4.261867) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2179 / 2500Epoch 2179 		 Training Loss: 1.3970941560609
Validation step:0Validation step:1Validation step:2Epoch 2179 		 Validation Loss: 4.26171875
Validation Loss Decreased(4.261867--->4.261719) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2180 / 2500Epoch 2180 		 Training Loss: 1.3962194919586182
Validation step:0Validation step:1Validation step:2Epoch 2180 		 Validation Loss: 4.261631727218628
Validation Loss Decreased(4.261719--->4.261632) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2181 / 2500Epoch 2181 		 Training Loss: 1.3963353889329093
Validation step:0Validation step:1Validation step:2Epoch 2181 		 Validation Loss: 4.261553168296814
Validation Loss Decreased(4.261632--->4.261553) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2182 / 2500Epoch 2182 		 Training Loss: 1.3974965725626265
Validation step:0Validation step:1Validation step:2Epoch 2182 		 Validation Loss: 4.261570930480957
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2183 / 2500Epoch 2183 		 Training Loss: 1.3976882611002241
Validation step:0Validation step:1Validation step:2Epoch 2183 		 Validation Loss: 4.261476635932922
Validation Loss Decreased(4.261553--->4.261477) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2184 / 2500Epoch 2184 		 Training Loss: 1.3982693212372916
Validation step:0Validation step:1Validation step:2Epoch 2184 		 Validation Loss: 4.261290788650513
Validation Loss Decreased(4.261477--->4.261291) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2185 / 2500Epoch 2185 		 Training Loss: 1.3970564688955034
Validation step:0Validation step:1Validation step:2Epoch 2185 		 Validation Loss: 4.261224150657654
Validation Loss Decreased(4.261291--->4.261224) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2186 / 2500Epoch 2186 		 Training Loss: 1.3975522433008467
Validation step:0Validation step:1Validation step:2Epoch 2186 		 Validation Loss: 4.2611247301101685
Validation Loss Decreased(4.261224--->4.261125) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2187 / 2500Epoch 2187 		 Training Loss: 1.3970919251441956
Validation step:0Validation step:1Validation step:2Epoch 2187 		 Validation Loss: 4.260991454124451
Validation Loss Decreased(4.261125--->4.260991) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2188 / 2500Epoch 2188 		 Training Loss: 1.395858951977321
Validation step:0Validation step:1Validation step:2Epoch 2188 		 Validation Loss: 4.260900139808655
Validation Loss Decreased(4.260991--->4.260900) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2189 / 2500Epoch 2189 		 Training Loss: 1.3975261620112829
Validation step:0Validation step:1Validation step:2Epoch 2189 		 Validation Loss: 4.260838508605957
Validation Loss Decreased(4.260900--->4.260839) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2190 / 2500Epoch 2190 		 Training Loss: 1.397127858230046
Validation step:0Validation step:1Validation step:2Epoch 2190 		 Validation Loss: 4.260771751403809
Validation Loss Decreased(4.260839--->4.260772) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2191 / 2500Epoch 2191 		 Training Loss: 1.3970519304275513
Validation step:0Validation step:1Validation step:2Epoch 2191 		 Validation Loss: 4.260660886764526
Validation Loss Decreased(4.260772--->4.260661) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2192 / 2500Epoch 2192 		 Training Loss: 1.3979140945843287
Validation step:0Validation step:1Validation step:2Epoch 2192 		 Validation Loss: 4.2606202363967896
Validation Loss Decreased(4.260661--->4.260620) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2193 / 2500Epoch 2193 		 Training Loss: 1.3981328862054008
Validation step:0Validation step:1Validation step:2Epoch 2193 		 Validation Loss: 4.260534644126892
Validation Loss Decreased(4.260620--->4.260535) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2194 / 2500Epoch 2194 		 Training Loss: 1.3964529037475586
Validation step:0Validation step:1Validation step:2Epoch 2194 		 Validation Loss: 4.260421633720398
Validation Loss Decreased(4.260535--->4.260422) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2195 / 2500Epoch 2195 		 Training Loss: 1.3959149037088667
Validation step:0Validation step:1Validation step:2Epoch 2195 		 Validation Loss: 4.260302186012268
Validation Loss Decreased(4.260422--->4.260302) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2196 / 2500Epoch 2196 		 Training Loss: 1.397170262677329
Validation step:0Validation step:1Validation step:2Epoch 2196 		 Validation Loss: 4.260175108909607
Validation Loss Decreased(4.260302--->4.260175) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2197 / 2500Epoch 2197 		 Training Loss: 1.3974597709519523
Validation step:0Validation step:1Validation step:2Epoch 2197 		 Validation Loss: 4.260100603103638
Validation Loss Decreased(4.260175--->4.260101) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2198 / 2500Epoch 2198 		 Training Loss: 1.396718876702445
Validation step:0Validation step:1Validation step:2Epoch 2198 		 Validation Loss: 4.260121941566467
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2199 / 2500Epoch 2199 		 Training Loss: 1.396883717605046
Validation step:0Validation step:1Validation step:2Epoch 2199 		 Validation Loss: 4.260012149810791
Validation Loss Decreased(4.260101--->4.260012) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2200 / 2500Epoch 2200 		 Training Loss: 1.396542685372489
Validation step:0Validation step:1Validation step:2Epoch 2200 		 Validation Loss: 4.259926199913025
Validation Loss Decreased(4.260012--->4.259926) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2201 / 2500Epoch 2201 		 Training Loss: 1.3970322949545724
Validation step:0Validation step:1Validation step:2Epoch 2201 		 Validation Loss: 4.259845972061157
Validation Loss Decreased(4.259926--->4.259846) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2202 / 2500Epoch 2202 		 Training Loss: 1.3947861620358057
Validation step:0Validation step:1Validation step:2Epoch 2202 		 Validation Loss: 4.259690642356873
Validation Loss Decreased(4.259846--->4.259691) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2203 / 2500Epoch 2203 		 Training Loss: 1.3967063341821944
Validation step:0Validation step:1Validation step:2Epoch 2203 		 Validation Loss: 4.259594202041626
Validation Loss Decreased(4.259691--->4.259594) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2204 / 2500Epoch 2204 		 Training Loss: 1.3975409950528825
Validation step:0Validation step:1Validation step:2Epoch 2204 		 Validation Loss: 4.25950562953949
Validation Loss Decreased(4.259594--->4.259506) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2205 / 2500Epoch 2205 		 Training Loss: 1.3970137749399458
Validation step:0Validation step:1Validation step:2Epoch 2205 		 Validation Loss: 4.259362697601318
Validation Loss Decreased(4.259506--->4.259363) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2206 / 2500Epoch 2206 		 Training Loss: 1.3962659410067968
Validation step:0Validation step:1Validation step:2Epoch 2206 		 Validation Loss: 4.259257078170776
Validation Loss Decreased(4.259363--->4.259257) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2207 / 2500Epoch 2207 		 Training Loss: 1.3970002446855818
Validation step:0Validation step:1Validation step:2Epoch 2207 		 Validation Loss: 4.259274482727051
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2208 / 2500Epoch 2208 		 Training Loss: 1.3977333988462175
Validation step:0Validation step:1Validation step:2Epoch 2208 		 Validation Loss: 4.259112358093262
Validation Loss Decreased(4.259257--->4.259112) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2209 / 2500Epoch 2209 		 Training Loss: 1.395959837096078
Validation step:0Validation step:1Validation step:2Epoch 2209 		 Validation Loss: 4.259274125099182
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2210 / 2500Epoch 2210 		 Training Loss: 1.3968872342790877
Validation step:0Validation step:1Validation step:2Epoch 2210 		 Validation Loss: 4.2590110301971436
Validation Loss Decreased(4.259112--->4.259011) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2211 / 2500Epoch 2211 		 Training Loss: 1.3961818643978663
Validation step:0Validation step:1Validation step:2Epoch 2211 		 Validation Loss: 4.258884310722351
Validation Loss Decreased(4.259011--->4.258884) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2212 / 2500Epoch 2212 		 Training Loss: 1.3977308443614416
Validation step:0Validation step:1Validation step:2Epoch 2212 		 Validation Loss: 4.25875985622406
Validation Loss Decreased(4.258884--->4.258760) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2213 / 2500Epoch 2213 		 Training Loss: 1.397375966821398
Validation step:0Validation step:1Validation step:2Epoch 2213 		 Validation Loss: 4.258658289909363
Validation Loss Decreased(4.258760--->4.258658) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2214 / 2500Epoch 2214 		 Training Loss: 1.3976781453405107
Validation step:0Validation step:1Validation step:2Epoch 2214 		 Validation Loss: 4.258763909339905
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2215 / 2500Epoch 2215 		 Training Loss: 1.3962951302528381
Validation step:0Validation step:1Validation step:2Epoch 2215 		 Validation Loss: 4.258504629135132
Validation Loss Decreased(4.258658--->4.258505) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2216 / 2500Epoch 2216 		 Training Loss: 1.395199520247323
Validation step:0Validation step:1Validation step:2Epoch 2216 		 Validation Loss: 4.2584205865859985
Validation Loss Decreased(4.258505--->4.258421) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2217 / 2500Epoch 2217 		 Training Loss: 1.395146472113473
Validation step:0Validation step:1Validation step:2Epoch 2217 		 Validation Loss: 4.258399248123169
Validation Loss Decreased(4.258421--->4.258399) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2218 / 2500Epoch 2218 		 Training Loss: 1.3950748784201485
Validation step:0Validation step:1Validation step:2Epoch 2218 		 Validation Loss: 4.258346080780029
Validation Loss Decreased(4.258399--->4.258346) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2219 / 2500Epoch 2219 		 Training Loss: 1.3965057049478804
Validation step:0Validation step:1Validation step:2Epoch 2219 		 Validation Loss: 4.258153915405273
Validation Loss Decreased(4.258346--->4.258154) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2220 / 2500Epoch 2220 		 Training Loss: 1.3967298695019312
Validation step:0Validation step:1Validation step:2Epoch 2220 		 Validation Loss: 4.2580283880233765
Validation Loss Decreased(4.258154--->4.258028) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2221 / 2500Epoch 2221 		 Training Loss: 1.396691688469478
Validation step:0Validation step:1Validation step:2Epoch 2221 		 Validation Loss: 4.257975697517395
Validation Loss Decreased(4.258028--->4.257976) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2222 / 2500Epoch 2222 		 Training Loss: 1.3959403378622872
Validation step:0Validation step:1Validation step:2Epoch 2222 		 Validation Loss: 4.257940649986267
Validation Loss Decreased(4.257976--->4.257941) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2223 / 2500Epoch 2223 		 Training Loss: 1.3979404653821672
Validation step:0Validation step:1Validation step:2Epoch 2223 		 Validation Loss: 4.257696032524109
Validation Loss Decreased(4.257941--->4.257696) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2224 / 2500Epoch 2224 		 Training Loss: 1.3969790254320418
Validation step:0Validation step:1Validation step:2Epoch 2224 		 Validation Loss: 4.257625937461853
Validation Loss Decreased(4.257696--->4.257626) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2225 / 2500Epoch 2225 		 Training Loss: 1.396549573966435
Validation step:0Validation step:1Validation step:2Epoch 2225 		 Validation Loss: 4.257620692253113
Validation Loss Decreased(4.257626--->4.257621) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2226 / 2500Epoch 2226 		 Training Loss: 1.3963279809270586
Validation step:0Validation step:1Validation step:2Epoch 2226 		 Validation Loss: 4.257556319236755
Validation Loss Decreased(4.257621--->4.257556) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2227 / 2500Epoch 2227 		 Training Loss: 1.3962199602808272
Validation step:0Validation step:1Validation step:2Epoch 2227 		 Validation Loss: 4.257482171058655
Validation Loss Decreased(4.257556--->4.257482) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2228 / 2500Epoch 2228 		 Training Loss: 1.39416869197573
Validation step:0Validation step:1Validation step:2Epoch 2228 		 Validation Loss: 4.257430076599121
Validation Loss Decreased(4.257482--->4.257430) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2229 / 2500Epoch 2229 		 Training Loss: 1.3966417397771562
Validation step:0Validation step:1Validation step:2Epoch 2229 		 Validation Loss: 4.257339596748352
Validation Loss Decreased(4.257430--->4.257340) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2230 / 2500Epoch 2230 		 Training Loss: 1.3956684385027205
Validation step:0Validation step:1Validation step:2Epoch 2230 		 Validation Loss: 4.257200479507446
Validation Loss Decreased(4.257340--->4.257200) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2231 / 2500Epoch 2231 		 Training Loss: 1.395991631916591
Validation step:0Validation step:1Validation step:2Epoch 2231 		 Validation Loss: 4.2571234703063965
Validation Loss Decreased(4.257200--->4.257123) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2232 / 2500Epoch 2232 		 Training Loss: 1.3965268560818263
Validation step:0Validation step:1Validation step:2Epoch 2232 		 Validation Loss: 4.257001161575317
Validation Loss Decreased(4.257123--->4.257001) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2233 / 2500Epoch 2233 		 Training Loss: 1.396005630493164
Validation step:0Validation step:1Validation step:2Epoch 2233 		 Validation Loss: 4.256945252418518
Validation Loss Decreased(4.257001--->4.256945) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2234 / 2500Epoch 2234 		 Training Loss: 1.3958603824887956
Validation step:0Validation step:1Validation step:2Epoch 2234 		 Validation Loss: 4.2568827867507935
Validation Loss Decreased(4.256945--->4.256883) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2235 / 2500Epoch 2235 		 Training Loss: 1.3974436180932182
Validation step:0Validation step:1Validation step:2Epoch 2235 		 Validation Loss: 4.256790518760681
Validation Loss Decreased(4.256883--->4.256791) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2236 / 2500Epoch 2236 		 Training Loss: 1.396899904523577
Validation step:0Validation step:1Validation step:2Epoch 2236 		 Validation Loss: 4.25665283203125
Validation Loss Decreased(4.256791--->4.256653) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2237 / 2500Epoch 2237 		 Training Loss: 1.3965105499540056
Validation step:0Validation step:1Validation step:2Epoch 2237 		 Validation Loss: 4.2565635442733765
Validation Loss Decreased(4.256653--->4.256564) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2238 / 2500Epoch 2238 		 Training Loss: 1.3966498374938965
Validation step:0Validation step:1Validation step:2Epoch 2238 		 Validation Loss: 4.2564544677734375
Validation Loss Decreased(4.256564--->4.256454) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2239 / 2500Epoch 2239 		 Training Loss: 1.3948794092450822
Validation step:0Validation step:1Validation step:2Epoch 2239 		 Validation Loss: 4.256413102149963
Validation Loss Decreased(4.256454--->4.256413) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2240 / 2500Epoch 2240 		 Training Loss: 1.3957938637052263
Validation step:0Validation step:1Validation step:2Epoch 2240 		 Validation Loss: 4.256306767463684
Validation Loss Decreased(4.256413--->4.256307) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2241 / 2500Epoch 2241 		 Training Loss: 1.395914077758789
Validation step:0Validation step:1Validation step:2Epoch 2241 		 Validation Loss: 4.256207346916199
Validation Loss Decreased(4.256307--->4.256207) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2242 / 2500Epoch 2242 		 Training Loss: 1.3967782003538949
Validation step:0Validation step:1Validation step:2Epoch 2242 		 Validation Loss: 4.256213188171387
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2243 / 2500Epoch 2243 		 Training Loss: 1.3944952487945557
Validation step:0Validation step:1Validation step:2Epoch 2243 		 Validation Loss: 4.256027102470398
Validation Loss Decreased(4.256207--->4.256027) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2244 / 2500Epoch 2244 		 Training Loss: 1.3966857365199499
Validation step:0Validation step:1Validation step:2Epoch 2244 		 Validation Loss: 4.256005883216858
Validation Loss Decreased(4.256027--->4.256006) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2245 / 2500Epoch 2245 		 Training Loss: 1.3961863006864275
Validation step:0Validation step:1Validation step:2Epoch 2245 		 Validation Loss: 4.255883812904358
Validation Loss Decreased(4.256006--->4.255884) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2246 / 2500Epoch 2246 		 Training Loss: 1.3934950402804784
Validation step:0Validation step:1Validation step:2Epoch 2246 		 Validation Loss: 4.25580096244812
Validation Loss Decreased(4.255884--->4.255801) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2247 / 2500Epoch 2247 		 Training Loss: 1.3950396095003401
Validation step:0Validation step:1Validation step:2Epoch 2247 		 Validation Loss: 4.255616903305054
Validation Loss Decreased(4.255801--->4.255617) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2248 / 2500Epoch 2248 		 Training Loss: 1.3962779811450414
Validation step:0Validation step:1Validation step:2Epoch 2248 		 Validation Loss: 4.255577206611633
Validation Loss Decreased(4.255617--->4.255577) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2249 / 2500Epoch 2249 		 Training Loss: 1.3953645484788078
Validation step:0Validation step:1Validation step:2Epoch 2249 		 Validation Loss: 4.25555682182312
Validation Loss Decreased(4.255577--->4.255557) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2250 / 2500Epoch 2250 		 Training Loss: 1.3944663149969918
Validation step:0Validation step:1Validation step:2Epoch 2250 		 Validation Loss: 4.255448222160339
Validation Loss Decreased(4.255557--->4.255448) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2251 / 2500Epoch 2251 		 Training Loss: 1.3951176404953003
Validation step:0Validation step:1Validation step:2Epoch 2251 		 Validation Loss: 4.255346059799194
Validation Loss Decreased(4.255448--->4.255346) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2252 / 2500Epoch 2252 		 Training Loss: 1.3938708901405334
Validation step:0Validation step:1Validation step:2Epoch 2252 		 Validation Loss: 4.255328893661499
Validation Loss Decreased(4.255346--->4.255329) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2253 / 2500Epoch 2253 		 Training Loss: 1.3962648596082414
Validation step:0Validation step:1Validation step:2Epoch 2253 		 Validation Loss: 4.2551939487457275
Validation Loss Decreased(4.255329--->4.255194) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2254 / 2500Epoch 2254 		 Training Loss: 1.3940072059631348
Validation step:0Validation step:1Validation step:2Epoch 2254 		 Validation Loss: 4.255115509033203
Validation Loss Decreased(4.255194--->4.255116) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2255 / 2500Epoch 2255 		 Training Loss: 1.3953331453459603
Validation step:0Validation step:1Validation step:2Epoch 2255 		 Validation Loss: 4.2549906969070435
Validation Loss Decreased(4.255116--->4.254991) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2256 / 2500Epoch 2256 		 Training Loss: 1.39527405159814
Validation step:0Validation step:1Validation step:2Epoch 2256 		 Validation Loss: 4.254924893379211
Validation Loss Decreased(4.254991--->4.254925) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2257 / 2500Epoch 2257 		 Training Loss: 1.3940480181149073
Validation step:0Validation step:1Validation step:2Epoch 2257 		 Validation Loss: 4.254794955253601
Validation Loss Decreased(4.254925--->4.254795) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2258 / 2500Epoch 2258 		 Training Loss: 1.3960062265396118
Validation step:0Validation step:1Validation step:2Epoch 2258 		 Validation Loss: 4.25474214553833
Validation Loss Decreased(4.254795--->4.254742) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2259 / 2500Epoch 2259 		 Training Loss: 1.3952858788626534
Validation step:0Validation step:1Validation step:2Epoch 2259 		 Validation Loss: 4.25469970703125
Validation Loss Decreased(4.254742--->4.254700) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2260 / 2500Epoch 2260 		 Training Loss: 1.3958909852164132
Validation step:0Validation step:1Validation step:2Epoch 2260 		 Validation Loss: 4.254570722579956
Validation Loss Decreased(4.254700--->4.254571) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2261 / 2500Epoch 2261 		 Training Loss: 1.394432851246425
Validation step:0Validation step:1Validation step:2Epoch 2261 		 Validation Loss: 4.2545225620269775
Validation Loss Decreased(4.254571--->4.254523) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2262 / 2500Epoch 2262 		 Training Loss: 1.3942278623580933
Validation step:0Validation step:1Validation step:2Epoch 2262 		 Validation Loss: 4.254372000694275
Validation Loss Decreased(4.254523--->4.254372) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2263 / 2500Epoch 2263 		 Training Loss: 1.395676118986947
Validation step:0Validation step:1Validation step:2Epoch 2263 		 Validation Loss: 4.25432276725769
Validation Loss Decreased(4.254372--->4.254323) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2264 / 2500Epoch 2264 		 Training Loss: 1.3966320242200578
Validation step:0Validation step:1Validation step:2Epoch 2264 		 Validation Loss: 4.254144072532654
Validation Loss Decreased(4.254323--->4.254144) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2265 / 2500Epoch 2265 		 Training Loss: 1.3965654798916407
Validation step:0Validation step:1Validation step:2Epoch 2265 		 Validation Loss: 4.25408935546875
Validation Loss Decreased(4.254144--->4.254089) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2266 / 2500Epoch 2266 		 Training Loss: 1.3958131500652857
Validation step:0Validation step:1Validation step:2Epoch 2266 		 Validation Loss: 4.2540165185928345
Validation Loss Decreased(4.254089--->4.254017) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2267 / 2500Epoch 2267 		 Training Loss: 1.3932912605149406
Validation step:0Validation step:1Validation step:2Epoch 2267 		 Validation Loss: 4.253950238227844
Validation Loss Decreased(4.254017--->4.253950) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2268 / 2500Epoch 2268 		 Training Loss: 1.395582914352417
Validation step:0Validation step:1Validation step:2Epoch 2268 		 Validation Loss: 4.253856420516968
Validation Loss Decreased(4.253950--->4.253856) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2269 / 2500Epoch 2269 		 Training Loss: 1.3962950961930412
Validation step:0Validation step:1Validation step:2Epoch 2269 		 Validation Loss: 4.253771543502808
Validation Loss Decreased(4.253856--->4.253772) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2270 / 2500Epoch 2270 		 Training Loss: 1.3962250351905823
Validation step:0Validation step:1Validation step:2Epoch 2270 		 Validation Loss: 4.253648996353149
Validation Loss Decreased(4.253772--->4.253649) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2271 / 2500Epoch 2271 		 Training Loss: 1.3946375932012285
Validation step:0Validation step:1Validation step:2Epoch 2271 		 Validation Loss: 4.25366473197937
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2272 / 2500Epoch 2272 		 Training Loss: 1.3943718416350228
Validation step:0Validation step:1Validation step:2Epoch 2272 		 Validation Loss: 4.253463268280029
Validation Loss Decreased(4.253649--->4.253463) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2273 / 2500Epoch 2273 		 Training Loss: 1.3935698441096716
Validation step:0Validation step:1Validation step:2Epoch 2273 		 Validation Loss: 4.253286600112915
Validation Loss Decreased(4.253463--->4.253287) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2274 / 2500Epoch 2274 		 Training Loss: 1.3938865150724138
Validation step:0Validation step:1Validation step:2Epoch 2274 		 Validation Loss: 4.253275275230408
Validation Loss Decreased(4.253287--->4.253275) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2275 / 2500Epoch 2275 		 Training Loss: 1.3943294371877397
Validation step:0Validation step:1Validation step:2Epoch 2275 		 Validation Loss: 4.253223776817322
Validation Loss Decreased(4.253275--->4.253224) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2276 / 2500Epoch 2276 		 Training Loss: 1.394427410193852
Validation step:0Validation step:1Validation step:2Epoch 2276 		 Validation Loss: 4.2531116008758545
Validation Loss Decreased(4.253224--->4.253112) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2277 / 2500Epoch 2277 		 Training Loss: 1.3941565666879927
Validation step:0Validation step:1Validation step:2Epoch 2277 		 Validation Loss: 4.253019094467163
Validation Loss Decreased(4.253112--->4.253019) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2278 / 2500Epoch 2278 		 Training Loss: 1.3955323610986983
Validation step:0Validation step:1Validation step:2Epoch 2278 		 Validation Loss: 4.25299334526062
Validation Loss Decreased(4.253019--->4.252993) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2279 / 2500Epoch 2279 		 Training Loss: 1.3951471192496163
Validation step:0Validation step:1Validation step:2Epoch 2279 		 Validation Loss: 4.252872347831726
Validation Loss Decreased(4.252993--->4.252872) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2280 / 2500Epoch 2280 		 Training Loss: 1.3949947953224182
Validation step:0Validation step:1Validation step:2Epoch 2280 		 Validation Loss: 4.252812623977661
Validation Loss Decreased(4.252872--->4.252813) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2281 / 2500Epoch 2281 		 Training Loss: 1.3939265779086523
Validation step:0Validation step:1Validation step:2Epoch 2281 		 Validation Loss: 4.252775192260742
Validation Loss Decreased(4.252813--->4.252775) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2282 / 2500Epoch 2282 		 Training Loss: 1.3953768355505807
Validation step:0Validation step:1Validation step:2Epoch 2282 		 Validation Loss: 4.252612233161926
Validation Loss Decreased(4.252775--->4.252612) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2283 / 2500Epoch 2283 		 Training Loss: 1.3939818143844604
Validation step:0Validation step:1Validation step:2Epoch 2283 		 Validation Loss: 4.252621054649353
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2284 / 2500Epoch 2284 		 Training Loss: 1.3964931624276298
Validation step:0Validation step:1Validation step:2Epoch 2284 		 Validation Loss: 4.252645969390869
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2285 / 2500Epoch 2285 		 Training Loss: 1.3937834245818002
Validation step:0Validation step:1Validation step:2Epoch 2285 		 Validation Loss: 4.252475380897522
Validation Loss Decreased(4.252612--->4.252475) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2286 / 2500Epoch 2286 		 Training Loss: 1.3949010457311357
Validation step:0Validation step:1Validation step:2Epoch 2286 		 Validation Loss: 4.252240180969238
Validation Loss Decreased(4.252475--->4.252240) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2287 / 2500Epoch 2287 		 Training Loss: 1.394585703100477
Validation step:0Validation step:1Validation step:2Epoch 2287 		 Validation Loss: 4.252091288566589
Validation Loss Decreased(4.252240--->4.252091) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2288 / 2500Epoch 2288 		 Training Loss: 1.3947320154735021
Validation step:0Validation step:1Validation step:2Epoch 2288 		 Validation Loss: 4.252122759819031
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2289 / 2500Epoch 2289 		 Training Loss: 1.3951743926320757
Validation step:0Validation step:1Validation step:2Epoch 2289 		 Validation Loss: 4.251991510391235
Validation Loss Decreased(4.252091--->4.251992) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2290 / 2500Epoch 2290 		 Training Loss: 1.3938536558832442
Validation step:0Validation step:1Validation step:2Epoch 2290 		 Validation Loss: 4.251863121986389
Validation Loss Decreased(4.251992--->4.251863) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2291 / 2500Epoch 2291 		 Training Loss: 1.392963511603219
Validation step:0Validation step:1Validation step:2Epoch 2291 		 Validation Loss: 4.251832962036133
Validation Loss Decreased(4.251863--->4.251833) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2292 / 2500Epoch 2292 		 Training Loss: 1.3938557931355067
Validation step:0Validation step:1Validation step:2Epoch 2292 		 Validation Loss: 4.251764297485352
Validation Loss Decreased(4.251833--->4.251764) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2293 / 2500Epoch 2293 		 Training Loss: 1.3947412541934423
Validation step:0Validation step:1Validation step:2Epoch 2293 		 Validation Loss: 4.251683473587036
Validation Loss Decreased(4.251764--->4.251683) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2294 / 2500Epoch 2294 		 Training Loss: 1.395692331450326
Validation step:0Validation step:1Validation step:2Epoch 2294 		 Validation Loss: 4.2516093254089355
Validation Loss Decreased(4.251683--->4.251609) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2295 / 2500Epoch 2295 		 Training Loss: 1.3939852714538574
Validation step:0Validation step:1Validation step:2Epoch 2295 		 Validation Loss: 4.2515705823898315
Validation Loss Decreased(4.251609--->4.251571) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2296 / 2500Epoch 2296 		 Training Loss: 1.3950559496879578
Validation step:0Validation step:1Validation step:2Epoch 2296 		 Validation Loss: 4.251499772071838
Validation Loss Decreased(4.251571--->4.251500) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2297 / 2500Epoch 2297 		 Training Loss: 1.3947797332491194
Validation step:0Validation step:1Validation step:2Epoch 2297 		 Validation Loss: 4.251357316970825
Validation Loss Decreased(4.251500--->4.251357) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2298 / 2500Epoch 2298 		 Training Loss: 1.3931779520852225
Validation step:0Validation step:1Validation step:2Epoch 2298 		 Validation Loss: 4.251405119895935
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2299 / 2500Epoch 2299 		 Training Loss: 1.3944821613175529
Validation step:0Validation step:1Validation step:2Epoch 2299 		 Validation Loss: 4.25131094455719
Validation Loss Decreased(4.251357--->4.251311) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2300 / 2500Epoch 2300 		 Training Loss: 1.3949159298624312
Validation step:0Validation step:1Validation step:2Epoch 2300 		 Validation Loss: 4.251163959503174
Validation Loss Decreased(4.251311--->4.251164) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2301 / 2500Epoch 2301 		 Training Loss: 1.3930062651634216
Validation step:0Validation step:1Validation step:2Epoch 2301 		 Validation Loss: 4.251097202301025
Validation Loss Decreased(4.251164--->4.251097) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2302 / 2500Epoch 2302 		 Training Loss: 1.3956278903143746
Validation step:0Validation step:1Validation step:2Epoch 2302 		 Validation Loss: 4.251046419143677
Validation Loss Decreased(4.251097--->4.251046) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2303 / 2500Epoch 2303 		 Training Loss: 1.3943468247141158
Validation step:0Validation step:1Validation step:2Epoch 2303 		 Validation Loss: 4.2509565353393555
Validation Loss Decreased(4.251046--->4.250957) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2304 / 2500Epoch 2304 		 Training Loss: 1.3945462107658386
Validation step:0Validation step:1Validation step:2Epoch 2304 		 Validation Loss: 4.250981688499451
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2305 / 2500Epoch 2305 		 Training Loss: 1.3949406061853682
Validation step:0Validation step:1Validation step:2Epoch 2305 		 Validation Loss: 4.250913619995117
Validation Loss Decreased(4.250957--->4.250914) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2306 / 2500Epoch 2306 		 Training Loss: 1.3947283625602722
Validation step:0Validation step:1Validation step:2Epoch 2306 		 Validation Loss: 4.250744819641113
Validation Loss Decreased(4.250914--->4.250745) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2307 / 2500Epoch 2307 		 Training Loss: 1.3937598722321647
Validation step:0Validation step:1Validation step:2Epoch 2307 		 Validation Loss: 4.250646233558655
Validation Loss Decreased(4.250745--->4.250646) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2308 / 2500Epoch 2308 		 Training Loss: 1.3937229258673531
Validation step:0Validation step:1Validation step:2Epoch 2308 		 Validation Loss: 4.250643253326416
Validation Loss Decreased(4.250646--->4.250643) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2309 / 2500Epoch 2309 		 Training Loss: 1.3945478371211462
Validation step:0Validation step:1Validation step:2Epoch 2309 		 Validation Loss: 4.2504730224609375
Validation Loss Decreased(4.250643--->4.250473) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2310 / 2500Epoch 2310 		 Training Loss: 1.3937962651252747
Validation step:0Validation step:1Validation step:2Epoch 2310 		 Validation Loss: 4.250384330749512
Validation Loss Decreased(4.250473--->4.250384) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2311 / 2500Epoch 2311 		 Training Loss: 1.391678810119629
Validation step:0Validation step:1Validation step:2Epoch 2311 		 Validation Loss: 4.250371217727661
Validation Loss Decreased(4.250384--->4.250371) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2312 / 2500Epoch 2312 		 Training Loss: 1.3942637358392989
Validation step:0Validation step:1Validation step:2Epoch 2312 		 Validation Loss: 4.250286221504211
Validation Loss Decreased(4.250371--->4.250286) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2313 / 2500Epoch 2313 		 Training Loss: 1.3943041477884566
Validation step:0Validation step:1Validation step:2Epoch 2313 		 Validation Loss: 4.250194311141968
Validation Loss Decreased(4.250286--->4.250194) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2314 / 2500Epoch 2314 		 Training Loss: 1.393205497946058
Validation step:0Validation step:1Validation step:2Epoch 2314 		 Validation Loss: 4.250051140785217
Validation Loss Decreased(4.250194--->4.250051) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2315 / 2500Epoch 2315 		 Training Loss: 1.39425927400589
Validation step:0Validation step:1Validation step:2Epoch 2315 		 Validation Loss: 4.24995219707489
Validation Loss Decreased(4.250051--->4.249952) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2316 / 2500Epoch 2316 		 Training Loss: 1.39431665624891
Validation step:0Validation step:1Validation step:2Epoch 2316 		 Validation Loss: 4.250032424926758
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2317 / 2500Epoch 2317 		 Training Loss: 1.393525447164263
Validation step:0Validation step:1Validation step:2Epoch 2317 		 Validation Loss: 4.249918699264526
Validation Loss Decreased(4.249952--->4.249919) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2318 / 2500Epoch 2318 		 Training Loss: 1.3941968594278609
Validation step:0Validation step:1Validation step:2Epoch 2318 		 Validation Loss: 4.249798893928528
Validation Loss Decreased(4.249919--->4.249799) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2319 / 2500Epoch 2319 		 Training Loss: 1.3943051270076208
Validation step:0Validation step:1Validation step:2Epoch 2319 		 Validation Loss: 4.249758243560791
Validation Loss Decreased(4.249799--->4.249758) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2320 / 2500Epoch 2320 		 Training Loss: 1.3948566913604736
Validation step:0Validation step:1Validation step:2Epoch 2320 		 Validation Loss: 4.2496418952941895
Validation Loss Decreased(4.249758--->4.249642) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2321 / 2500Epoch 2321 		 Training Loss: 1.3928875923156738
Validation step:0Validation step:1Validation step:2Epoch 2321 		 Validation Loss: 4.249534368515015
Validation Loss Decreased(4.249642--->4.249534) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2322 / 2500Epoch 2322 		 Training Loss: 1.3932582821164812
Validation step:0Validation step:1Validation step:2Epoch 2322 		 Validation Loss: 4.249463081359863
Validation Loss Decreased(4.249534--->4.249463) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2323 / 2500Epoch 2323 		 Training Loss: 1.3924559780529566
Validation step:0Validation step:1Validation step:2Epoch 2323 		 Validation Loss: 4.249404311180115
Validation Loss Decreased(4.249463--->4.249404) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2324 / 2500Epoch 2324 		 Training Loss: 1.3945054582187109
Validation step:0Validation step:1Validation step:2Epoch 2324 		 Validation Loss: 4.249305605888367
Validation Loss Decreased(4.249404--->4.249306) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2325 / 2500Epoch 2325 		 Training Loss: 1.394977799483708
Validation step:0Validation step:1Validation step:2Epoch 2325 		 Validation Loss: 4.249255418777466
Validation Loss Decreased(4.249306--->4.249255) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2326 / 2500Epoch 2326 		 Training Loss: 1.393391226019178
Validation step:0Validation step:1Validation step:2Epoch 2326 		 Validation Loss: 4.2491782903671265
Validation Loss Decreased(4.249255--->4.249178) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2327 / 2500Epoch 2327 		 Training Loss: 1.3936167785099574
Validation step:0Validation step:1Validation step:2Epoch 2327 		 Validation Loss: 4.249038934707642
Validation Loss Decreased(4.249178--->4.249039) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2328 / 2500Epoch 2328 		 Training Loss: 1.393750548362732
Validation step:0Validation step:1Validation step:2Epoch 2328 		 Validation Loss: 4.248927354812622
Validation Loss Decreased(4.249039--->4.248927) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2329 / 2500Epoch 2329 		 Training Loss: 1.3937036820820399
Validation step:0Validation step:1Validation step:2Epoch 2329 		 Validation Loss: 4.248948097229004
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2330 / 2500Epoch 2330 		 Training Loss: 1.3944102440561568
Validation step:0Validation step:1Validation step:2Epoch 2330 		 Validation Loss: 4.248916268348694
Validation Loss Decreased(4.248927--->4.248916) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2331 / 2500Epoch 2331 		 Training Loss: 1.3936899644987923
Validation step:0Validation step:1Validation step:2Epoch 2331 		 Validation Loss: 4.24878716468811
Validation Loss Decreased(4.248916--->4.248787) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2332 / 2500Epoch 2332 		 Training Loss: 1.3929871235574995
Validation step:0Validation step:1Validation step:2Epoch 2332 		 Validation Loss: 4.248699426651001
Validation Loss Decreased(4.248787--->4.248699) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2333 / 2500Epoch 2333 		 Training Loss: 1.3932665841920036
Validation step:0Validation step:1Validation step:2Epoch 2333 		 Validation Loss: 4.248582363128662
Validation Loss Decreased(4.248699--->4.248582) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2334 / 2500Epoch 2334 		 Training Loss: 1.3929101313863481
Validation step:0Validation step:1Validation step:2Epoch 2334 		 Validation Loss: 4.248541831970215
Validation Loss Decreased(4.248582--->4.248542) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2335 / 2500Epoch 2335 		 Training Loss: 1.3943229147366114
Validation step:0Validation step:1Validation step:2Epoch 2335 		 Validation Loss: 4.248543620109558
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2336 / 2500Epoch 2336 		 Training Loss: 1.3921444416046143
Validation step:0Validation step:1Validation step:2Epoch 2336 		 Validation Loss: 4.248351812362671
Validation Loss Decreased(4.248542--->4.248352) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2337 / 2500Epoch 2337 		 Training Loss: 1.3919636522020613
Validation step:0Validation step:1Validation step:2Epoch 2337 		 Validation Loss: 4.248346567153931
Validation Loss Decreased(4.248352--->4.248347) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2338 / 2500Epoch 2338 		 Training Loss: 1.3937359622546606
Validation step:0Validation step:1Validation step:2Epoch 2338 		 Validation Loss: 4.248252630233765
Validation Loss Decreased(4.248347--->4.248253) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2339 / 2500Epoch 2339 		 Training Loss: 1.3932364242417472
Validation step:0Validation step:1Validation step:2Epoch 2339 		 Validation Loss: 4.248187303543091
Validation Loss Decreased(4.248253--->4.248187) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2340 / 2500Epoch 2340 		 Training Loss: 1.3936089447566442
Validation step:0Validation step:1Validation step:2Epoch 2340 		 Validation Loss: 4.24817156791687
Validation Loss Decreased(4.248187--->4.248172) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2341 / 2500Epoch 2341 		 Training Loss: 1.3923814722469874
Validation step:0Validation step:1Validation step:2Epoch 2341 		 Validation Loss: 4.2480995655059814
Validation Loss Decreased(4.248172--->4.248100) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2342 / 2500Epoch 2342 		 Training Loss: 1.3934934309550695
Validation step:0Validation step:1Validation step:2Epoch 2342 		 Validation Loss: 4.248012900352478
Validation Loss Decreased(4.248100--->4.248013) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2343 / 2500Epoch 2343 		 Training Loss: 1.3921346749578203
Validation step:0Validation step:1Validation step:2Epoch 2343 		 Validation Loss: 4.247880935668945
Validation Loss Decreased(4.248013--->4.247881) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2344 / 2500Epoch 2344 		 Training Loss: 1.3939931988716125
Validation step:0Validation step:1Validation step:2Epoch 2344 		 Validation Loss: 4.247841715812683
Validation Loss Decreased(4.247881--->4.247842) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2345 / 2500Epoch 2345 		 Training Loss: 1.3931068692888533
Validation step:0Validation step:1Validation step:2Epoch 2345 		 Validation Loss: 4.247804760932922
Validation Loss Decreased(4.247842--->4.247805) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2346 / 2500Epoch 2346 		 Training Loss: 1.3933817829404558
Validation step:0Validation step:1Validation step:2Epoch 2346 		 Validation Loss: 4.247640609741211
Validation Loss Decreased(4.247805--->4.247641) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2347 / 2500Epoch 2347 		 Training Loss: 1.3930560094969613
Validation step:0Validation step:1Validation step:2Epoch 2347 		 Validation Loss: 4.247492074966431
Validation Loss Decreased(4.247641--->4.247492) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2348 / 2500Epoch 2348 		 Training Loss: 1.3922404732022966
Validation step:0Validation step:1Validation step:2Epoch 2348 		 Validation Loss: 4.24742329120636
Validation Loss Decreased(4.247492--->4.247423) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2349 / 2500Epoch 2349 		 Training Loss: 1.3932624885014124
Validation step:0Validation step:1Validation step:2Epoch 2349 		 Validation Loss: 4.24730908870697
Validation Loss Decreased(4.247423--->4.247309) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2350 / 2500Epoch 2350 		 Training Loss: 1.3936673232487269
Validation step:0Validation step:1Validation step:2Epoch 2350 		 Validation Loss: 4.247238755226135
Validation Loss Decreased(4.247309--->4.247239) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2351 / 2500Epoch 2351 		 Training Loss: 1.3936325992856706
Validation step:0Validation step:1Validation step:2Epoch 2351 		 Validation Loss: 4.247404456138611
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2352 / 2500Epoch 2352 		 Training Loss: 1.3940129790987288
Validation step:0Validation step:1Validation step:2Epoch 2352 		 Validation Loss: 4.247176766395569
Validation Loss Decreased(4.247239--->4.247177) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2353 / 2500Epoch 2353 		 Training Loss: 1.3931005341666085
Validation step:0Validation step:1Validation step:2Epoch 2353 		 Validation Loss: 4.247115135192871
Validation Loss Decreased(4.247177--->4.247115) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2354 / 2500Epoch 2354 		 Training Loss: 1.3929571168763297
Validation step:0Validation step:1Validation step:2Epoch 2354 		 Validation Loss: 4.24705958366394
Validation Loss Decreased(4.247115--->4.247060) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2355 / 2500Epoch 2355 		 Training Loss: 1.3924761244228907
Validation step:0Validation step:1Validation step:2Epoch 2355 		 Validation Loss: 4.246906995773315
Validation Loss Decreased(4.247060--->4.246907) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2356 / 2500Epoch 2356 		 Training Loss: 1.3922023262296404
Validation step:0Validation step:1Validation step:2Epoch 2356 		 Validation Loss: 4.246950149536133
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2357 / 2500Epoch 2357 		 Training Loss: 1.3925259028162276
Validation step:0Validation step:1Validation step:2Epoch 2357 		 Validation Loss: 4.2467756271362305
Validation Loss Decreased(4.246907--->4.246776) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2358 / 2500Epoch 2358 		 Training Loss: 1.3933600272451128
Validation step:0Validation step:1Validation step:2Epoch 2358 		 Validation Loss: 4.246749639511108
Validation Loss Decreased(4.246776--->4.246750) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2359 / 2500Epoch 2359 		 Training Loss: 1.3930340664727348
Validation step:0Validation step:1Validation step:2Epoch 2359 		 Validation Loss: 4.246647477149963
Validation Loss Decreased(4.246750--->4.246647) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2360 / 2500Epoch 2360 		 Training Loss: 1.3914606145450048
Validation step:0Validation step:1Validation step:2Epoch 2360 		 Validation Loss: 4.24667751789093
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2361 / 2500Epoch 2361 		 Training Loss: 1.3920305030686515
Validation step:0Validation step:1Validation step:2Epoch 2361 		 Validation Loss: 4.246391296386719
Validation Loss Decreased(4.246647--->4.246391) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2362 / 2500Epoch 2362 		 Training Loss: 1.3930853264672416
Validation step:0Validation step:1Validation step:2Epoch 2362 		 Validation Loss: 4.246395707130432
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2363 / 2500Epoch 2363 		 Training Loss: 1.3921264154570443
Validation step:0Validation step:1Validation step:2Epoch 2363 		 Validation Loss: 4.246365785598755
Validation Loss Decreased(4.246391--->4.246366) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2364 / 2500Epoch 2364 		 Training Loss: 1.3929876599993025
Validation step:0Validation step:1Validation step:2Epoch 2364 		 Validation Loss: 4.246259450912476
Validation Loss Decreased(4.246366--->4.246259) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2365 / 2500Epoch 2365 		 Training Loss: 1.3929122345788139
Validation step:0Validation step:1Validation step:2Epoch 2365 		 Validation Loss: 4.246119022369385
Validation Loss Decreased(4.246259--->4.246119) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2366 / 2500Epoch 2366 		 Training Loss: 1.393351205757686
Validation step:0Validation step:1Validation step:2Epoch 2366 		 Validation Loss: 4.246062517166138
Validation Loss Decreased(4.246119--->4.246063) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2367 / 2500Epoch 2367 		 Training Loss: 1.3908662029675074
Validation step:0Validation step:1Validation step:2Epoch 2367 		 Validation Loss: 4.245960712432861
Validation Loss Decreased(4.246063--->4.245961) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2368 / 2500Epoch 2368 		 Training Loss: 1.391907240663256
Validation step:0Validation step:1Validation step:2Epoch 2368 		 Validation Loss: 4.245834231376648
Validation Loss Decreased(4.245961--->4.245834) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2369 / 2500Epoch 2369 		 Training Loss: 1.3920600243977137
Validation step:0Validation step:1Validation step:2Epoch 2369 		 Validation Loss: 4.245789051055908
Validation Loss Decreased(4.245834--->4.245789) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2370 / 2500Epoch 2370 		 Training Loss: 1.3916417445455278
Validation step:0Validation step:1Validation step:2Epoch 2370 		 Validation Loss: 4.2457239627838135
Validation Loss Decreased(4.245789--->4.245724) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2371 / 2500Epoch 2371 		 Training Loss: 1.3925894073077612
Validation step:0Validation step:1Validation step:2Epoch 2371 		 Validation Loss: 4.2456971406936646
Validation Loss Decreased(4.245724--->4.245697) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2372 / 2500Epoch 2372 		 Training Loss: 1.3923807740211487
Validation step:0Validation step:1Validation step:2Epoch 2372 		 Validation Loss: 4.245601177215576
Validation Loss Decreased(4.245697--->4.245601) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2373 / 2500Epoch 2373 		 Training Loss: 1.3909278426851546
Validation step:0Validation step:1Validation step:2Epoch 2373 		 Validation Loss: 4.245489478111267
Validation Loss Decreased(4.245601--->4.245489) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2374 / 2500Epoch 2374 		 Training Loss: 1.3917038355554854
Validation step:0Validation step:1Validation step:2Epoch 2374 		 Validation Loss: 4.245532155036926
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2375 / 2500Epoch 2375 		 Training Loss: 1.3925326551709856
Validation step:0Validation step:1Validation step:2Epoch 2375 		 Validation Loss: 4.2453824281692505
Validation Loss Decreased(4.245489--->4.245382) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2376 / 2500Epoch 2376 		 Training Loss: 1.3918573430606298
Validation step:0Validation step:1Validation step:2Epoch 2376 		 Validation Loss: 4.245339274406433
Validation Loss Decreased(4.245382--->4.245339) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2377 / 2500Epoch 2377 		 Training Loss: 1.3919780339513506
Validation step:0Validation step:1Validation step:2Epoch 2377 		 Validation Loss: 4.245215654373169
Validation Loss Decreased(4.245339--->4.245216) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2378 / 2500Epoch 2378 		 Training Loss: 1.392009198665619
Validation step:0Validation step:1Validation step:2Epoch 2378 		 Validation Loss: 4.245123386383057
Validation Loss Decreased(4.245216--->4.245123) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2379 / 2500Epoch 2379 		 Training Loss: 1.3912771003586906
Validation step:0Validation step:1Validation step:2Epoch 2379 		 Validation Loss: 4.245089530944824
Validation Loss Decreased(4.245123--->4.245090) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2380 / 2500Epoch 2380 		 Training Loss: 1.3923775724002294
Validation step:0Validation step:1Validation step:2Epoch 2380 		 Validation Loss: 4.244972348213196
Validation Loss Decreased(4.245090--->4.244972) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2381 / 2500Epoch 2381 		 Training Loss: 1.3919082369123186
Validation step:0Validation step:1Validation step:2Epoch 2381 		 Validation Loss: 4.244947671890259
Validation Loss Decreased(4.244972--->4.244948) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2382 / 2500Epoch 2382 		 Training Loss: 1.3913344059671675
Validation step:0Validation step:1Validation step:2Epoch 2382 		 Validation Loss: 4.244830012321472
Validation Loss Decreased(4.244948--->4.244830) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2383 / 2500Epoch 2383 		 Training Loss: 1.3917143940925598
Validation step:0Validation step:1Validation step:2Epoch 2383 		 Validation Loss: 4.244857549667358
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2384 / 2500Epoch 2384 		 Training Loss: 1.3921935217721122
Validation step:0Validation step:1Validation step:2Epoch 2384 		 Validation Loss: 4.244696378707886
Validation Loss Decreased(4.244830--->4.244696) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2385 / 2500Epoch 2385 		 Training Loss: 1.392307358128684
Validation step:0Validation step:1Validation step:2Epoch 2385 		 Validation Loss: 4.244742155075073
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2386 / 2500Epoch 2386 		 Training Loss: 1.3918429868561881
Validation step:0Validation step:1Validation step:2Epoch 2386 		 Validation Loss: 4.244506239891052
Validation Loss Decreased(4.244696--->4.244506) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2387 / 2500Epoch 2387 		 Training Loss: 1.3907618096896581
Validation step:0Validation step:1Validation step:2Epoch 2387 		 Validation Loss: 4.24446713924408
Validation Loss Decreased(4.244506--->4.244467) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2388 / 2500Epoch 2388 		 Training Loss: 1.3912433981895447
Validation step:0Validation step:1Validation step:2Epoch 2388 		 Validation Loss: 4.244400382041931
Validation Loss Decreased(4.244467--->4.244400) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2389 / 2500Epoch 2389 		 Training Loss: 1.3922675933156694
Validation step:0Validation step:1Validation step:2Epoch 2389 		 Validation Loss: 4.2443459033966064
Validation Loss Decreased(4.244400--->4.244346) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2390 / 2500Epoch 2390 		 Training Loss: 1.3919798731803894
Validation step:0Validation step:1Validation step:2Epoch 2390 		 Validation Loss: 4.2444905042648315
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2391 / 2500Epoch 2391 		 Training Loss: 1.391519376209804
Validation step:0Validation step:1Validation step:2Epoch 2391 		 Validation Loss: 4.244271159172058
Validation Loss Decreased(4.244346--->4.244271) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2392 / 2500Epoch 2392 		 Training Loss: 1.3922162907464164
Validation step:0Validation step:1Validation step:2Epoch 2392 		 Validation Loss: 4.244193077087402
Validation Loss Decreased(4.244271--->4.244193) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2393 / 2500Epoch 2393 		 Training Loss: 1.3903811488832747
Validation step:0Validation step:1Validation step:2Epoch 2393 		 Validation Loss: 4.244139552116394
Validation Loss Decreased(4.244193--->4.244140) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2394 / 2500Epoch 2394 		 Training Loss: 1.3904623474393571
Validation step:0Validation step:1Validation step:2Epoch 2394 		 Validation Loss: 4.2440245151519775
Validation Loss Decreased(4.244140--->4.244025) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2395 / 2500Epoch 2395 		 Training Loss: 1.3915028742381506
Validation step:0Validation step:1Validation step:2Epoch 2395 		 Validation Loss: 4.244203686714172
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2396 / 2500Epoch 2396 		 Training Loss: 1.3929226568767004
Validation step:0Validation step:1Validation step:2Epoch 2396 		 Validation Loss: 4.243836879730225
Validation Loss Decreased(4.244025--->4.243837) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2397 / 2500Epoch 2397 		 Training Loss: 1.3917692133358546
Validation step:0Validation step:1Validation step:2Epoch 2397 		 Validation Loss: 4.243779182434082
Validation Loss Decreased(4.243837--->4.243779) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2398 / 2500Epoch 2398 		 Training Loss: 1.390807330608368
Validation step:0Validation step:1Validation step:2Epoch 2398 		 Validation Loss: 4.24370265007019
Validation Loss Decreased(4.243779--->4.243703) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2399 / 2500Epoch 2399 		 Training Loss: 1.3917586633137293
Validation step:0Validation step:1Validation step:2Epoch 2399 		 Validation Loss: 4.243571400642395
Validation Loss Decreased(4.243703--->4.243571) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2400 / 2500Epoch 2400 		 Training Loss: 1.3910023825509208
Validation step:0Validation step:1Validation step:2Epoch 2400 		 Validation Loss: 4.243459463119507
Validation Loss Decreased(4.243571--->4.243459) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2401 / 2500Epoch 2401 		 Training Loss: 1.3908863919121879
Validation step:0Validation step:1Validation step:2Epoch 2401 		 Validation Loss: 4.243388772010803
Validation Loss Decreased(4.243459--->4.243389) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2402 / 2500Epoch 2402 		 Training Loss: 1.390789236341204
Validation step:0Validation step:1Validation step:2Epoch 2402 		 Validation Loss: 4.243446946144104
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2403 / 2500Epoch 2403 		 Training Loss: 1.3926362991333008
Validation step:0Validation step:1Validation step:2Epoch 2403 		 Validation Loss: 4.243302702903748
Validation Loss Decreased(4.243389--->4.243303) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2404 / 2500Epoch 2404 		 Training Loss: 1.3893676825932093
Validation step:0Validation step:1Validation step:2Epoch 2404 		 Validation Loss: 4.2431960105896
Validation Loss Decreased(4.243303--->4.243196) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2405 / 2500Epoch 2405 		 Training Loss: 1.3916261196136475
Validation step:0Validation step:1Validation step:2Epoch 2405 		 Validation Loss: 4.24313497543335
Validation Loss Decreased(4.243196--->4.243135) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2406 / 2500Epoch 2406 		 Training Loss: 1.3931246399879456
Validation step:0Validation step:1Validation step:2Epoch 2406 		 Validation Loss: 4.2431007623672485
Validation Loss Decreased(4.243135--->4.243101) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2407 / 2500Epoch 2407 		 Training Loss: 1.3916398542267936
Validation step:0Validation step:1Validation step:2Epoch 2407 		 Validation Loss: 4.242933988571167
Validation Loss Decreased(4.243101--->4.242934) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2408 / 2500Epoch 2408 		 Training Loss: 1.3913826090948922
Validation step:0Validation step:1Validation step:2Epoch 2408 		 Validation Loss: 4.242903232574463
Validation Loss Decreased(4.242934--->4.242903) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2409 / 2500Epoch 2409 		 Training Loss: 1.3921833038330078
Validation step:0Validation step:1Validation step:2Epoch 2409 		 Validation Loss: 4.242828011512756
Validation Loss Decreased(4.242903--->4.242828) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2410 / 2500Epoch 2410 		 Training Loss: 1.391420568738665
Validation step:0Validation step:1Validation step:2Epoch 2410 		 Validation Loss: 4.242752552032471
Validation Loss Decreased(4.242828--->4.242753) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2411 / 2500Epoch 2411 		 Training Loss: 1.3915486591202872
Validation step:0Validation step:1Validation step:2Epoch 2411 		 Validation Loss: 4.242736577987671
Validation Loss Decreased(4.242753--->4.242737) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2412 / 2500Epoch 2412 		 Training Loss: 1.3903676612036568
Validation step:0Validation step:1Validation step:2Epoch 2412 		 Validation Loss: 4.242628574371338
Validation Loss Decreased(4.242737--->4.242629) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2413 / 2500Epoch 2413 		 Training Loss: 1.3925064972468786
Validation step:0Validation step:1Validation step:2Epoch 2413 		 Validation Loss: 4.242559552192688
Validation Loss Decreased(4.242629--->4.242560) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2414 / 2500Epoch 2414 		 Training Loss: 1.390573833669935
Validation step:0Validation step:1Validation step:2Epoch 2414 		 Validation Loss: 4.242417097091675
Validation Loss Decreased(4.242560--->4.242417) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2415 / 2500Epoch 2415 		 Training Loss: 1.3916749698775155
Validation step:0Validation step:1Validation step:2Epoch 2415 		 Validation Loss: 4.2424397468566895
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2416 / 2500Epoch 2416 		 Training Loss: 1.3902316008295332
Validation step:0Validation step:1Validation step:2Epoch 2416 		 Validation Loss: 4.242345452308655
Validation Loss Decreased(4.242417--->4.242345) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2417 / 2500Epoch 2417 		 Training Loss: 1.391795311655317
Validation step:0Validation step:1Validation step:2Epoch 2417 		 Validation Loss: 4.242254137992859
Validation Loss Decreased(4.242345--->4.242254) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2418 / 2500Epoch 2418 		 Training Loss: 1.387906321457454
Validation step:0Validation step:1Validation step:2Epoch 2418 		 Validation Loss: 4.24222719669342
Validation Loss Decreased(4.242254--->4.242227) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2419 / 2500Epoch 2419 		 Training Loss: 1.3900450468063354
Validation step:0Validation step:1Validation step:2Epoch 2419 		 Validation Loss: 4.242157936096191
Validation Loss Decreased(4.242227--->4.242158) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2420 / 2500Epoch 2420 		 Training Loss: 1.3905744297163827
Validation step:0Validation step:1Validation step:2Epoch 2420 		 Validation Loss: 4.242450714111328
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2421 / 2500Epoch 2421 		 Training Loss: 1.39039489201137
Validation step:0Validation step:1Validation step:2Epoch 2421 		 Validation Loss: 4.241993188858032
Validation Loss Decreased(4.242158--->4.241993) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2422 / 2500Epoch 2422 		 Training Loss: 1.3921567457062858
Validation step:0Validation step:1Validation step:2Epoch 2422 		 Validation Loss: 4.241846561431885
Validation Loss Decreased(4.241993--->4.241847) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2423 / 2500Epoch 2423 		 Training Loss: 1.3901173983301436
Validation step:0Validation step:1Validation step:2Epoch 2423 		 Validation Loss: 4.241785407066345
Validation Loss Decreased(4.241847--->4.241785) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2424 / 2500Epoch 2424 		 Training Loss: 1.391447194984981
Validation step:0Validation step:1Validation step:2Epoch 2424 		 Validation Loss: 4.241709232330322
Validation Loss Decreased(4.241785--->4.241709) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2425 / 2500Epoch 2425 		 Training Loss: 1.3912235498428345
Validation step:0Validation step:1Validation step:2Epoch 2425 		 Validation Loss: 4.241607189178467
Validation Loss Decreased(4.241709--->4.241607) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2426 / 2500Epoch 2426 		 Training Loss: 1.3901715278625488
Validation step:0Validation step:1Validation step:2Epoch 2426 		 Validation Loss: 4.24162757396698
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2427 / 2500Epoch 2427 		 Training Loss: 1.3895932606288366
Validation step:0Validation step:1Validation step:2Epoch 2427 		 Validation Loss: 4.2415443658828735
Validation Loss Decreased(4.241607--->4.241544) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2428 / 2500Epoch 2428 		 Training Loss: 1.390559366771153
Validation step:0Validation step:1Validation step:2Epoch 2428 		 Validation Loss: 4.241409420967102
Validation Loss Decreased(4.241544--->4.241409) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2429 / 2500Epoch 2429 		 Training Loss: 1.3916602730751038
Validation step:0Validation step:1Validation step:2Epoch 2429 		 Validation Loss: 4.241448283195496
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2430 / 2500Epoch 2430 		 Training Loss: 1.3910187653132848
Validation step:0Validation step:1Validation step:2Epoch 2430 		 Validation Loss: 4.241318464279175
Validation Loss Decreased(4.241409--->4.241318) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2431 / 2500Epoch 2431 		 Training Loss: 1.3914118238857813
Validation step:0Validation step:1Validation step:2Epoch 2431 		 Validation Loss: 4.2412965297698975
Validation Loss Decreased(4.241318--->4.241297) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2432 / 2500Epoch 2432 		 Training Loss: 1.3905087539127894
Validation step:0Validation step:1Validation step:2Epoch 2432 		 Validation Loss: 4.2412238121032715
Validation Loss Decreased(4.241297--->4.241224) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2433 / 2500Epoch 2433 		 Training Loss: 1.3905386754444666
Validation step:0Validation step:1Validation step:2Epoch 2433 		 Validation Loss: 4.241071462631226
Validation Loss Decreased(4.241224--->4.241071) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2434 / 2500Epoch 2434 		 Training Loss: 1.3911772455487932
Validation step:0Validation step:1Validation step:2Epoch 2434 		 Validation Loss: 4.2410643100738525
Validation Loss Decreased(4.241071--->4.241064) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2435 / 2500Epoch 2435 		 Training Loss: 1.3906613162585668
Validation step:0Validation step:1Validation step:2Epoch 2435 		 Validation Loss: 4.240953207015991
Validation Loss Decreased(4.241064--->4.240953) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2436 / 2500Epoch 2436 		 Training Loss: 1.389553998197828
Validation step:0Validation step:1Validation step:2Epoch 2436 		 Validation Loss: 4.240853190422058
Validation Loss Decreased(4.240953--->4.240853) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2437 / 2500Epoch 2437 		 Training Loss: 1.391404620238713
Validation step:0Validation step:1Validation step:2Epoch 2437 		 Validation Loss: 4.240743517875671
Validation Loss Decreased(4.240853--->4.240744) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2438 / 2500Epoch 2438 		 Training Loss: 1.3911280206271581
Validation step:0Validation step:1Validation step:2Epoch 2438 		 Validation Loss: 4.240685701370239
Validation Loss Decreased(4.240744--->4.240686) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2439 / 2500Epoch 2439 		 Training Loss: 1.3903049315725053
Validation step:0Validation step:1Validation step:2Epoch 2439 		 Validation Loss: 4.24061131477356
Validation Loss Decreased(4.240686--->4.240611) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2440 / 2500Epoch 2440 		 Training Loss: 1.3891510367393494
Validation step:0Validation step:1Validation step:2Epoch 2440 		 Validation Loss: 4.240564823150635
Validation Loss Decreased(4.240611--->4.240565) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2441 / 2500Epoch 2441 		 Training Loss: 1.3903497116906303
Validation step:0Validation step:1Validation step:2Epoch 2441 		 Validation Loss: 4.240469813346863
Validation Loss Decreased(4.240565--->4.240470) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2442 / 2500Epoch 2442 		 Training Loss: 1.3914521592003959
Validation step:0Validation step:1Validation step:2Epoch 2442 		 Validation Loss: 4.240337610244751
Validation Loss Decreased(4.240470--->4.240338) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2443 / 2500Epoch 2443 		 Training Loss: 1.3904636757714408
Validation step:0Validation step:1Validation step:2Epoch 2443 		 Validation Loss: 4.240285277366638
Validation Loss Decreased(4.240338--->4.240285) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2444 / 2500Epoch 2444 		 Training Loss: 1.3889427014759608
Validation step:0Validation step:1Validation step:2Epoch 2444 		 Validation Loss: 4.240147233009338
Validation Loss Decreased(4.240285--->4.240147) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2445 / 2500Epoch 2445 		 Training Loss: 1.3902647580419267
Validation step:0Validation step:1Validation step:2Epoch 2445 		 Validation Loss: 4.240097522735596
Validation Loss Decreased(4.240147--->4.240098) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2446 / 2500Epoch 2446 		 Training Loss: 1.3914571404457092
Validation step:0Validation step:1Validation step:2Epoch 2446 		 Validation Loss: 4.240081191062927
Validation Loss Decreased(4.240098--->4.240081) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2447 / 2500Epoch 2447 		 Training Loss: 1.390351619039263
Validation step:0Validation step:1Validation step:2Epoch 2447 		 Validation Loss: 4.2400816679000854
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2448 / 2500Epoch 2448 		 Training Loss: 1.3900553669248308
Validation step:0Validation step:1Validation step:2Epoch 2448 		 Validation Loss: 4.239944100379944
Validation Loss Decreased(4.240081--->4.239944) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2449 / 2500Epoch 2449 		 Training Loss: 1.3909570574760437
Validation step:0Validation step:1Validation step:2Epoch 2449 		 Validation Loss: 4.239858865737915
Validation Loss Decreased(4.239944--->4.239859) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2450 / 2500Epoch 2450 		 Training Loss: 1.391456629548754
Validation step:0Validation step:1Validation step:2Epoch 2450 		 Validation Loss: 4.239779353141785
Validation Loss Decreased(4.239859--->4.239779) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2451 / 2500Epoch 2451 		 Training Loss: 1.3903533475739616
Validation step:0Validation step:1Validation step:2Epoch 2451 		 Validation Loss: 4.239841103553772
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2452 / 2500Epoch 2452 		 Training Loss: 1.3894909024238586
Validation step:0Validation step:1Validation step:2Epoch 2452 		 Validation Loss: 4.239721775054932
Validation Loss Decreased(4.239779--->4.239722) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2453 / 2500Epoch 2453 		 Training Loss: 1.3919451832771301
Validation step:0Validation step:1Validation step:2Epoch 2453 		 Validation Loss: 4.23959493637085
Validation Loss Decreased(4.239722--->4.239595) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2454 / 2500Epoch 2454 		 Training Loss: 1.3883423124040877
Validation step:0Validation step:1Validation step:2Epoch 2454 		 Validation Loss: 4.239437222480774
Validation Loss Decreased(4.239595--->4.239437) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2455 / 2500Epoch 2455 		 Training Loss: 1.3907430682863509
Validation step:0Validation step:1Validation step:2Epoch 2455 		 Validation Loss: 4.239322781562805
Validation Loss Decreased(4.239437--->4.239323) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2456 / 2500Epoch 2456 		 Training Loss: 1.3894718033926827
Validation step:0Validation step:1Validation step:2Epoch 2456 		 Validation Loss: 4.239374041557312
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2457 / 2500Epoch 2457 		 Training Loss: 1.3894715649741036
Validation step:0Validation step:1Validation step:2Epoch 2457 		 Validation Loss: 4.239288568496704
Validation Loss Decreased(4.239323--->4.239289) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2458 / 2500Epoch 2458 		 Training Loss: 1.3889111195291792
Validation step:0Validation step:1Validation step:2Epoch 2458 		 Validation Loss: 4.2391732931137085
Validation Loss Decreased(4.239289--->4.239173) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2459 / 2500Epoch 2459 		 Training Loss: 1.389335104397365
Validation step:0Validation step:1Validation step:2Epoch 2459 		 Validation Loss: 4.239183783531189
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2460 / 2500Epoch 2460 		 Training Loss: 1.3912966847419739
Validation step:0Validation step:1Validation step:2Epoch 2460 		 Validation Loss: 4.239089131355286
Validation Loss Decreased(4.239173--->4.239089) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2461 / 2500Epoch 2461 		 Training Loss: 1.3902182238442558
Validation step:0Validation step:1Validation step:2Epoch 2461 		 Validation Loss: 4.239019989967346
Validation Loss Decreased(4.239089--->4.239020) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2462 / 2500Epoch 2462 		 Training Loss: 1.389973291328975
Validation step:0Validation step:1Validation step:2Epoch 2462 		 Validation Loss: 4.238971829414368
Validation Loss Decreased(4.239020--->4.238972) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2463 / 2500Epoch 2463 		 Training Loss: 1.3883952924183436
Validation step:0Validation step:1Validation step:2Epoch 2463 		 Validation Loss: 4.238834261894226
Validation Loss Decreased(4.238972--->4.238834) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2464 / 2500Epoch 2464 		 Training Loss: 1.3898231812885828
Validation step:0Validation step:1Validation step:2Epoch 2464 		 Validation Loss: 4.238828659057617
Validation Loss Decreased(4.238834--->4.238829) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2465 / 2500Epoch 2465 		 Training Loss: 1.388748483998435
Validation step:0Validation step:1Validation step:2Epoch 2465 		 Validation Loss: 4.238767981529236
Validation Loss Decreased(4.238829--->4.238768) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2466 / 2500Epoch 2466 		 Training Loss: 1.3898267149925232
Validation step:0Validation step:1Validation step:2Epoch 2466 		 Validation Loss: 4.238608717918396
Validation Loss Decreased(4.238768--->4.238609) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2467 / 2500Epoch 2467 		 Training Loss: 1.3906752552304948
Validation step:0Validation step:1Validation step:2Epoch 2467 		 Validation Loss: 4.238560199737549
Validation Loss Decreased(4.238609--->4.238560) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2468 / 2500Epoch 2468 		 Training Loss: 1.3900259562901087
Validation step:0Validation step:1Validation step:2Epoch 2468 		 Validation Loss: 4.238538026809692
Validation Loss Decreased(4.238560--->4.238538) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2469 / 2500Epoch 2469 		 Training Loss: 1.3903948324067252
Validation step:0Validation step:1Validation step:2Epoch 2469 		 Validation Loss: 4.2384034395217896
Validation Loss Decreased(4.238538--->4.238403) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2470 / 2500Epoch 2470 		 Training Loss: 1.3900117533547538
Validation step:0Validation step:1Validation step:2Epoch 2470 		 Validation Loss: 4.238342046737671
Validation Loss Decreased(4.238403--->4.238342) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2471 / 2500Epoch 2471 		 Training Loss: 1.388888886996678
Validation step:0Validation step:1Validation step:2Epoch 2471 		 Validation Loss: 4.238219499588013
Validation Loss Decreased(4.238342--->4.238219) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2472 / 2500Epoch 2472 		 Training Loss: 1.3897076504571098
Validation step:0Validation step:1Validation step:2Epoch 2472 		 Validation Loss: 4.238420248031616
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2473 / 2500Epoch 2473 		 Training Loss: 1.3887030908039637
Validation step:0Validation step:1Validation step:2Epoch 2473 		 Validation Loss: 4.238152861595154
Validation Loss Decreased(4.238219--->4.238153) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2474 / 2500Epoch 2474 		 Training Loss: 1.3903498138700212
Validation step:0Validation step:1Validation step:2Epoch 2474 		 Validation Loss: 4.237979054450989
Validation Loss Decreased(4.238153--->4.237979) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2475 / 2500Epoch 2475 		 Training Loss: 1.3892377785273962
Validation step:0Validation step:1Validation step:2Epoch 2475 		 Validation Loss: 4.237931251525879
Validation Loss Decreased(4.237979--->4.237931) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2476 / 2500Epoch 2476 		 Training Loss: 1.3887319649968828
Validation step:0Validation step:1Validation step:2Epoch 2476 		 Validation Loss: 4.237835168838501
Validation Loss Decreased(4.237931--->4.237835) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2477 / 2500Epoch 2477 		 Training Loss: 1.3893622245107378
Validation step:0Validation step:1Validation step:2Epoch 2477 		 Validation Loss: 4.237766861915588
Validation Loss Decreased(4.237835--->4.237767) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2478 / 2500Epoch 2478 		 Training Loss: 1.3904759798731123
Validation step:0Validation step:1Validation step:2Epoch 2478 		 Validation Loss: 4.237744450569153
Validation Loss Decreased(4.237767--->4.237744) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2479 / 2500Epoch 2479 		 Training Loss: 1.3892405714307512
Validation step:0Validation step:1Validation step:2Epoch 2479 		 Validation Loss: 4.237637042999268
Validation Loss Decreased(4.237744--->4.237637) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2480 / 2500Epoch 2480 		 Training Loss: 1.3893380420548576
Validation step:0Validation step:1Validation step:2Epoch 2480 		 Validation Loss: 4.237571597099304
Validation Loss Decreased(4.237637--->4.237572) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2481 / 2500Epoch 2481 		 Training Loss: 1.3886706488473075
Validation step:0Validation step:1Validation step:2Epoch 2481 		 Validation Loss: 4.237513184547424
Validation Loss Decreased(4.237572--->4.237513) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2482 / 2500Epoch 2482 		 Training Loss: 1.3893153156552995
Validation step:0Validation step:1Validation step:2Epoch 2482 		 Validation Loss: 4.23744535446167
Validation Loss Decreased(4.237513--->4.237445) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2483 / 2500Epoch 2483 		 Training Loss: 1.3908123288835799
Validation step:0Validation step:1Validation step:2Epoch 2483 		 Validation Loss: 4.237419009208679
Validation Loss Decreased(4.237445--->4.237419) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2484 / 2500Epoch 2484 		 Training Loss: 1.3897666505404882
Validation step:0Validation step:1Validation step:2Epoch 2484 		 Validation Loss: 4.237239360809326
Validation Loss Decreased(4.237419--->4.237239) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2485 / 2500Epoch 2485 		 Training Loss: 1.3894324898719788
Validation step:0Validation step:1Validation step:2Epoch 2485 		 Validation Loss: 4.237257957458496
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2486 / 2500Epoch 2486 		 Training Loss: 1.3891592196055822
Validation step:0Validation step:1Validation step:2Epoch 2486 		 Validation Loss: 4.237135529518127
Validation Loss Decreased(4.237239--->4.237136) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2487 / 2500Epoch 2487 		 Training Loss: 1.3909704429762704
Validation step:0Validation step:1Validation step:2Epoch 2487 		 Validation Loss: 4.237035155296326
Validation Loss Decreased(4.237136--->4.237035) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2488 / 2500Epoch 2488 		 Training Loss: 1.3902180109705244
Validation step:0Validation step:1Validation step:2Epoch 2488 		 Validation Loss: 4.236931204795837
Validation Loss Decreased(4.237035--->4.236931) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2489 / 2500Epoch 2489 		 Training Loss: 1.3895474927765983
Validation step:0Validation step:1Validation step:2Epoch 2489 		 Validation Loss: 4.2368669509887695
Validation Loss Decreased(4.236931--->4.236867) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2490 / 2500Epoch 2490 		 Training Loss: 1.3898248502186366
Validation step:0Validation step:1Validation step:2Epoch 2490 		 Validation Loss: 4.236902475357056
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2491 / 2500Epoch 2491 		 Training Loss: 1.3897467170442854
Validation step:0Validation step:1Validation step:2Epoch 2491 		 Validation Loss: 4.236744046211243
Validation Loss Decreased(4.236867--->4.236744) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2492 / 2500Epoch 2492 		 Training Loss: 1.388487023966653
Validation step:0Validation step:1Validation step:2Epoch 2492 		 Validation Loss: 4.236755013465881
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2493 / 2500Epoch 2493 		 Training Loss: 1.3888205800737654
Validation step:0Validation step:1Validation step:2Epoch 2493 		 Validation Loss: 4.236626863479614
Validation Loss Decreased(4.236744--->4.236627) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2494 / 2500Epoch 2494 		 Training Loss: 1.3894076943397522
Validation step:0Validation step:1Validation step:2Epoch 2494 		 Validation Loss: 4.23654842376709
Validation Loss Decreased(4.236627--->4.236548) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2495 / 2500Epoch 2495 		 Training Loss: 1.3899864554405212
Validation step:0Validation step:1Validation step:2Epoch 2495 		 Validation Loss: 4.2364983558654785
Validation Loss Decreased(4.236548--->4.236498) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2496 / 2500Epoch 2496 		 Training Loss: 1.3895798240389143
Validation step:0Validation step:1Validation step:2Epoch 2496 		 Validation Loss: 4.236422419548035
Validation Loss Decreased(4.236498--->4.236422) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2497 / 2500Epoch 2497 		 Training Loss: 1.3880023871149336
Validation step:0Validation step:1Validation step:2Epoch 2497 		 Validation Loss: 4.236325621604919
Validation Loss Decreased(4.236422--->4.236326) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2498 / 2500Epoch 2498 		 Training Loss: 1.3891376852989197
Validation step:0Validation step:1Validation step:2Epoch 2498 		 Validation Loss: 4.236193537712097
Validation Loss Decreased(4.236326--->4.236194) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2499 / 2500Epoch 2499 		 Training Loss: 1.3872876167297363
Validation step:0Validation step:1Validation step:2Epoch 2499 		 Validation Loss: 4.236165165901184
Validation Loss Decreased(4.236194--->4.236165) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
Epoch: 2500 / 2500Epoch 2500 		 Training Loss: 1.3887601239340646
Validation step:0Validation step:1Validation step:2Epoch 2500 		 Validation Loss: 4.236073136329651
Validation Loss Decreased(4.236165--->4.236073) 	 Saving model ...
Adjusting learning rate of group 0 to 1.0000e-07.
                         Finished Training
#-----------------------------------------------------------------------#
