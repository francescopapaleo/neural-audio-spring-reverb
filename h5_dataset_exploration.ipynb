{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "R8F3RwyzNY0Z"
      },
      "source": [
        "# hdf5 dataset\n",
        "\n",
        "Original dataset in h5 format:\n",
        "https://zenodo.org/record/3746119#.ZCPs7exBwq-"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WD2zLjdiILd-"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Vqu3t1D8_ePE"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "import os\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "from pathlib import Path"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OxO84nYc6IL-"
      },
      "source": [
        "## h5py data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uMwmEk9jQsV",
        "outputId": "8e7aaad0-c62b-49b2-b00b-ee332a2fd6a0"
      },
      "outputs": [],
      "source": [
        "H5_DATA = '/homedtic/fpapaleo/smc-spring-reverb/dataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbUiqcJA6c4o",
        "outputId": "e00cac3c-fb11-4f57-eb95-3a0a8eaae478"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<KeysViewHDF5 []>\n",
            "ValuesViewHDF5(<Attributes of HDF5 object at 22474360750224>)\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "# Verify if the dataset contains any metadata\n",
        "with h5py.File(os.path.join(H5_DATA,'dry_train.h5'), 'r') as f:\n",
        "    print(f['Xtrain'].attrs.keys())\n",
        "    print(f['Xtrain'].attrs.values())\n",
        "    values = list(f['Xtrain'].attrs.values())\n",
        "    print(values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: dry_val_test.h5\n",
            "['Xvalidation']\n",
            "Dataset: Xvalidation\n",
            "(64, 32000, 1)\n",
            "float64\n",
            "\n",
            "File: wet_val_test.h5\n",
            "['Yvalidation_0']\n",
            "Dataset: Yvalidation_0\n",
            "(64, 32000, 1)\n",
            "float64\n",
            "\n",
            "File: wet_train.h5\n",
            "['Ytrain_0']\n",
            "Dataset: Ytrain_0\n",
            "(1122, 32000, 1)\n",
            "float64\n",
            "\n",
            "File: dry_train.h5\n",
            "['Xtrain']\n",
            "Dataset: Xtrain\n",
            "(1122, 32000, 1)\n",
            "float64\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Printing the dataset names and shapes\n",
        "\n",
        "# Iterate over all files in the H5_DATA directory\n",
        "for file_name in os.listdir(H5_DATA):\n",
        "    # Check if the file has the .h5 extension\n",
        "    if file_name.endswith('.h5'):\n",
        "        with h5py.File(os.path.join(H5_DATA, file_name), 'r') as f:\n",
        "            # Print the list of datasets in the file\n",
        "            print(f\"File: {file_name}\")\n",
        "            print(list(f.keys()))\n",
        "\n",
        "            # Iterate over all datasets in the file\n",
        "            for dataset_name in f.keys():\n",
        "                # Load the dataset\n",
        "                data = np.array(f[dataset_name])\n",
        "\n",
        "                # Print information about the dataset\n",
        "                print(f\"Dataset: {dataset_name}\")\n",
        "                print(data.shape)\n",
        "                print(data.dtype)\n",
        "                print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instantiate the dataset\n",
        "\n",
        "class CustomH5Dataset(Dataset):\n",
        "    def __init__(self, data_list):\n",
        "        self.data_list = data_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data_list[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data_list = []\n",
        "val_data_list = []\n",
        "\n",
        "for file_name in os.listdir(H5_DATA):\n",
        "    if file_name.endswith('.h5'):\n",
        "        with h5py.File(os.path.join(H5_DATA, file_name), 'r') as f:\n",
        "            for dataset_name in f.keys():\n",
        "                data = torch.from_numpy(np.array(f[dataset_name]))\n",
        "\n",
        "                if 'train' in file_name:\n",
        "                    train_data_list.append(data)\n",
        "                elif 'val' in file_name or 'validation' in file_name:\n",
        "                    val_data_list.append(data)\n",
        "\n",
        "train_dataset = CustomH5Dataset(train_data_list)\n",
        "val_dataset = CustomH5Dataset(val_data_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 0:\n",
            "Data shape: torch.Size([2, 1122, 32000, 1])\n",
            "Data type: torch.float64\n",
            "\n",
            "Batch 0:\n",
            "Data shape: torch.Size([2, 64, 32000, 1])\n",
            "Data type: torch.float64\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Iterate over the train_dataloader\n",
        "for batch_idx, data in enumerate(train_dataloader):\n",
        "    print(f\"Batch {batch_idx}:\")\n",
        "    print(f\"Data shape: {data.shape}\")\n",
        "    print(f\"Data type: {data.dtype}\")\n",
        "    print()\n",
        "\n",
        "    # You can break the loop after the first iteration to see just one batch\n",
        "    break\n",
        "\n",
        "# Iterate over the val_dataloader\n",
        "for batch_idx, data in enumerate(val_dataloader):\n",
        "    print(f\"Batch {batch_idx}:\")\n",
        "    print(f\"Data shape: {data.shape}\")\n",
        "    print(f\"Data type: {data.dtype}\")\n",
        "    print()\n",
        "\n",
        "    # You can break the loop after the first iteration to see just one batch\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Audio file: dry_val_test.h5, Total Length: 128.00 seconds, 2048000 samples\n",
            "Audio file: wet_val_test.h5, Total Length: 128.00 seconds, 2048000 samples\n",
            "Audio file: wet_train.h5, Total Length: 2244.00 seconds, 35904000 samples\n",
            "Audio file: dry_train.h5, Total Length: 2244.00 seconds, 35904000 samples\n"
          ]
        }
      ],
      "source": [
        "def get_audio_length(file_path, sample_rate=16000):\n",
        "    total_length_seconds = 0\n",
        "    total_length_samples = 0\n",
        "    \n",
        "    with h5py.File(file_path, 'r') as f:\n",
        "        for dataset_key in f.keys():\n",
        "            audio_data = f[dataset_key][:]\n",
        "            num_samples = audio_data.shape[0]\n",
        "            audio_length_samples = audio_data.shape[1]\n",
        "            audio_length_seconds = num_samples * audio_length_samples / sample_rate\n",
        "            total_length_seconds += audio_length_seconds\n",
        "            total_length_samples += num_samples * audio_length_samples\n",
        "    \n",
        "    return total_length_seconds, total_length_samples\n",
        "\n",
        "for file_name in os.listdir(H5_DATA):\n",
        "    file_path = os.path.join(H5_DATA, file_name)\n",
        "\n",
        "    # Check if the file is an .h5 file and if it contains the word 'train' in its name\n",
        "    if file_path.endswith('.h5'):\n",
        "        file_length_seconds, file_length_samples = get_audio_length(file_path)\n",
        "        print(f'Audio file: {file_name}, Total Length: {file_length_seconds:.2f} seconds, {file_length_samples} samples')\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
