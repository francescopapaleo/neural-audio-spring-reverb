Training with lr=0.1, batch_size=64, n_epochs=50
Initializing Training Process..

Torch version: 1.11.0 ------ Selected Device: cuda:0
Sample Rate: 16000 Hz ------  Crop Lenght:3200 samples

Found 4 files in ../plate-spring/spring
Using dry_train.h5 and wet_train.h5 for train split.
Parameters: 395.339 k
Receptive field: 3495251 samples or 218453.2 ms

Training Loop

Validation Loss Decreased(inf--->3248592896.000000) Saving model ...
Epoch 1 		 Validation Loss: 3248592896.000000, 		 Training Loss: 27297475026.204273Epoch 2 		 Validation Loss: 48261932373.333336, 		 Training Loss: 95710425069.714279Epoch 3 		 Validation Loss: 2474598203392.000000, 		 Training Loss: 3132172268982.856934Epoch 4 		 Validation Loss: 400586320554.666687, 		 Training Loss: 1319673160850.285645Epoch 5 		 Validation Loss: 478068725077.333313, 		 Training Loss: 3559262332050.285645Epoch 6 		 Validation Loss: 3878907194026.666504, 		 Training Loss: 2309674470838.856934Epoch 7 		 Validation Loss: 276118945792.000000, 		 Training Loss: 1117483641709.714355Epoch 8 		 Validation Loss: 27519176704.000000, 		 Training Loss: 112037797449.142853Epoch 9 		 Validation Loss: 5624048640.000000, 		 Training Loss: 13081313280.000000Epoch 10 		 Validation Loss: 3844011776.000000, 		 Training Loss: 5525899922.285714Epoch 11 		 Validation Loss: 4960353621.333333, 		 Training Loss: 3490708114.285714Validation Loss Decreased(3248592896.000000--->1284198869.333333) Saving model ...
Epoch 12 		 Validation Loss: 1284198869.333333, 		 Training Loss: 2754872402.285714Validation Loss Decreased(1284198869.333333--->842159296.000000) Saving model ...
Epoch 13 		 Validation Loss: 842159296.000000, 		 Training Loss: 1111783556.571429Epoch 14 		 Validation Loss: 1117756330.666667, 		 Training Loss: 1108406253.714286Epoch 15 		 Validation Loss: 893885482.666667, 		 Training Loss: 983352196.571429Validation Loss Decreased(842159296.000000--->544813184.000000) Saving model ...
Epoch 16 		 Validation Loss: 544813184.000000, 		 Training Loss: 737126541.714286Epoch 17 		 Validation Loss: 774221354.666667, 		 Training Loss: 520347682.285714Epoch 18 		 Validation Loss: 646428394.666667, 		 Training Loss: 764021330.285714Epoch 19 		 Validation Loss: 564954837.333333, 		 Training Loss: 763060420.571429Epoch 20 		 Validation Loss: 863565034.666667, 		 Training Loss: 638043268.571429Validation Loss Decreased(544813184.000000--->334547114.666667) Saving model ...
Epoch 21 		 Validation Loss: 334547114.666667, 		 Training Loss: 440908486.857143Epoch 22 		 Validation Loss: 343996981.333333, 		 Training Loss: 285956825.142857Epoch 23 		 Validation Loss: 746816362.666667, 		 Training Loss: 436462854.857143Epoch 24 		 Validation Loss: 1038328746.666667, 		 Training Loss: 538202667.428571Epoch 25 		 Validation Loss: 1147048490.666667, 		 Training Loss: 915290209.142857Validation Loss Decreased(334547114.666667--->298557152.000000) Saving model ...
Epoch 26 		 Validation Loss: 298557152.000000, 		 Training Loss: 606712880.000000Epoch 27 		 Validation Loss: 409586442.666667, 		 Training Loss: 390503651.428571Epoch 28 		 Validation Loss: 313734186.666667, 		 Training Loss: 312430365.714286Validation Loss Decreased(298557152.000000--->234362560.000000) Saving model ...
Epoch 29 		 Validation Loss: 234362560.000000, 		 Training Loss: 269987474.285714Validation Loss Decreased(234362560.000000--->185818666.666667) Saving model ...
Epoch 30 		 Validation Loss: 185818666.666667, 		 Training Loss: 237437521.714286Epoch 31 		 Validation Loss: 325431904.000000, 		 Training Loss: 224273867.428571Epoch 32 		 Validation Loss: 264428826.666667, 		 Training Loss: 209926253.142857Epoch 33 		 Validation Loss: 480424000.000000, 		 Training Loss: 313297209.142857Epoch 34 		 Validation Loss: 198306048.000000, 		 Training Loss: 335851969.142857Validation Loss Decreased(185818666.666667--->182451253.333333) Saving model ...
Epoch 35 		 Validation Loss: 182451253.333333, 		 Training Loss: 174033332.571429Validation Loss Decreased(182451253.333333--->171934528.000000) Saving model ...
Epoch 36 		 Validation Loss: 171934528.000000, 		 Training Loss: 165715113.714286Validation Loss Decreased(171934528.000000--->166158453.333333) Saving model ...
Epoch 37 		 Validation Loss: 166158453.333333, 		 Training Loss: 147692584.571429Validation Loss Decreased(166158453.333333--->153308485.333333) Saving model ...
Epoch 38 		 Validation Loss: 153308485.333333, 		 Training Loss: 158291237.142857Epoch 39 		 Validation Loss: 240329445.333333, 		 Training Loss: 157702922.857143Validation Loss Decreased(153308485.333333--->122673221.333333) Saving model ...
Epoch 40 		 Validation Loss: 122673221.333333, 		 Training Loss: 137030105.714286Validation Loss Decreased(122673221.333333--->99251029.333333) Saving model ...
Epoch 41 		 Validation Loss: 99251029.333333, 		 Training Loss: 100714914.285714Epoch 42 		 Validation Loss: 101687832.000000, 		 Training Loss: 92793582.285714Validation Loss Decreased(99251029.333333--->98468565.333333) Saving model ...
Epoch 43 		 Validation Loss: 98468565.333333, 		 Training Loss: 90668980.000000Validation Loss Decreased(98468565.333333--->95740448.000000) Saving model ...
Epoch 44 		 Validation Loss: 95740448.000000, 		 Training Loss: 90014666.857143Validation Loss Decreased(95740448.000000--->94501853.333333) Saving model ...
Epoch 45 		 Validation Loss: 94501853.333333, 		 Training Loss: 86050248.000000Epoch 46 		 Validation Loss: 94800474.666667, 		 Training Loss: 86951540.000000Validation Loss Decreased(94501853.333333--->93082314.666667) Saving model ...
Epoch 47 		 Validation Loss: 93082314.666667, 		 Training Loss: 86054472.571429Validation Loss Decreased(93082314.666667--->92520389.333333) Saving model ...
Epoch 48 		 Validation Loss: 92520389.333333, 		 Training Loss: 83549414.285714Validation Loss Decreased(92520389.333333--->92495650.666667) Saving model ...
Epoch 49 		 Validation Loss: 92495650.666667, 		 Training Loss: 83767318.285714Validation Loss Decreased(92495650.666667--->92358282.666667) Saving model ...
Epoch 50 		 Validation Loss: 92358282.666667, 		 Training Loss: 84067630.000000Training Completed!
Training with lr=0.1, batch_size=64, n_epochs=100
Initializing Training Process..

Torch version: 1.11.0 ------ Selected Device: cuda:0
Sample Rate: 16000 Hz ------  Crop Lenght:3200 samples

Found 4 files in ../plate-spring/spring
Using dry_train.h5 and wet_train.h5 for train split.
Parameters: 395.339 k
Receptive field: 3495251 samples or 218453.2 ms

Training Loop

Validation Loss Decreased(inf--->3732687018.666667) Saving model ...
Epoch 1 		 Validation Loss: 3732687018.666667, 		 Training Loss: 58552213147.412003Epoch 2 		 Validation Loss: 25327527936.000000, 		 Training Loss: 187374388233.142853Epoch 3 		 Validation Loss: 4614155315882.666992, 		 Training Loss: 394692733878.857117Epoch 4 		 Validation Loss: 78845501440.000000, 		 Training Loss: 997351900013.714233Epoch 5 		 Validation Loss: 18955464362.666668, 		 Training Loss: 466549605961.142883Epoch 6 		 Validation Loss: 8345781077.333333, 		 Training Loss: 89864611986.285721Epoch 7 		 Validation Loss: 4467669333.333333, 		 Training Loss: 12372384109.714285Validation Loss Decreased(3732687018.666667--->1062440490.666667) Saving model ...
Epoch 8 		 Validation Loss: 1062440490.666667, 		 Training Loss: 2923827968.000000Validation Loss Decreased(1062440490.666667--->382258378.666667) Saving model ...
Epoch 9 		 Validation Loss: 382258378.666667, 		 Training Loss: 729234061.714286Validation Loss Decreased(382258378.666667--->196448970.666667) Saving model ...
Epoch 10 		 Validation Loss: 196448970.666667, 		 Training Loss: 309777888.000000Validation Loss Decreased(196448970.666667--->133967602.666667) Saving model ...
Epoch 11 		 Validation Loss: 133967602.666667, 		 Training Loss: 179296368.000000Validation Loss Decreased(133967602.666667--->100110690.666667) Saving model ...
Epoch 12 		 Validation Loss: 100110690.666667, 		 Training Loss: 119539084.000000Validation Loss Decreased(100110690.666667--->77473166.666667) Saving model ...
Epoch 13 		 Validation Loss: 77473166.666667, 		 Training Loss: 88746969.714286Validation Loss Decreased(77473166.666667--->63105332.000000) Saving model ...
Epoch 14 		 Validation Loss: 63105332.000000, 		 Training Loss: 73662496.571429Validation Loss Decreased(63105332.000000--->56063428.000000) Saving model ...
Epoch 15 		 Validation Loss: 56063428.000000, 		 Training Loss: 62870900.000000Validation Loss Decreased(56063428.000000--->47320470.666667) Saving model ...
Epoch 16 		 Validation Loss: 47320470.666667, 		 Training Loss: 56921006.285714Epoch 17 		 Validation Loss: 93479944.000000, 		 Training Loss: 62288203.142857Epoch 18 		 Validation Loss: 141813325.333333, 		 Training Loss: 126491604.285714Epoch 19 		 Validation Loss: 62927269.333333, 		 Training Loss: 90494148.285714Epoch 20 		 Validation Loss: 62373717.333333, 		 Training Loss: 62482139.428571Epoch 21 		 Validation Loss: 51412353.333333, 		 Training Loss: 58518472.000000Validation Loss Decreased(47320470.666667--->37229397.333333) Saving model ...
Epoch 22 		 Validation Loss: 37229397.333333, 		 Training Loss: 55396465.714286Epoch 23 		 Validation Loss: 53576857.333333, 		 Training Loss: 52758706.714286Epoch 24 		 Validation Loss: 41168153.333333, 		 Training Loss: 37989007.000000Epoch 25 		 Validation Loss: 85046613.333333, 		 Training Loss: 45491980.428571Validation Loss Decreased(37229397.333333--->29252984.666667) Saving model ...
Epoch 26 		 Validation Loss: 29252984.666667, 		 Training Loss: 61229242.142857Epoch 27 		 Validation Loss: 60739640.000000, 		 Training Loss: 54246682.428571Epoch 28 		 Validation Loss: 32522643.333333, 		 Training Loss: 73022786.857143Epoch 29 		 Validation Loss: 61830581.333333, 		 Training Loss: 47810980.714286Epoch 30 		 Validation Loss: 52872221.333333, 		 Training Loss: 40845677.571429Epoch 31 		 Validation Loss: 98169088.000000, 		 Training Loss: 41475024.142857Epoch 32 		 Validation Loss: 37906634.000000, 		 Training Loss: 53915826.428571Validation Loss Decreased(29252984.666667--->25639376.666667) Saving model ...
Epoch 33 		 Validation Loss: 25639376.666667, 		 Training Loss: 43091244.714286Validation Loss Decreased(25639376.666667--->21987034.666667) Saving model ...
Epoch 34 		 Validation Loss: 21987034.666667, 		 Training Loss: 30191474.857143Epoch 35 		 Validation Loss: 26766232.000000, 		 Training Loss: 38068056.428571Validation Loss Decreased(21987034.666667--->18878221.000000) Saving model ...
Epoch 36 		 Validation Loss: 18878221.000000, 		 Training Loss: 34627035.571429Epoch 37 		 Validation Loss: 36151282.666667, 		 Training Loss: 35824869.000000Epoch 38 		 Validation Loss: 26314253.333333, 		 Training Loss: 35639968.857143Epoch 39 		 Validation Loss: 30047229.333333, 		 Training Loss: 32405013.857143Epoch 40 		 Validation Loss: 36886341.333333, 		 Training Loss: 31953817.571429Validation Loss Decreased(18878221.000000--->15131302.000000) Saving model ...
Epoch 41 		 Validation Loss: 15131302.000000, 		 Training Loss: 31391628.928571Validation Loss Decreased(15131302.000000--->14285889.333333) Saving model ...
Epoch 42 		 Validation Loss: 14285889.333333, 		 Training Loss: 21412010.357143Epoch 43 		 Validation Loss: 22773888.666667, 		 Training Loss: 28919464.285714Epoch 44 		 Validation Loss: 19381921.333333, 		 Training Loss: 26960641.285714Validation Loss Decreased(14285889.333333--->13350695.000000) Saving model ...
Epoch 45 		 Validation Loss: 13350695.000000, 		 Training Loss: 25899145.928571Epoch 46 		 Validation Loss: 26343883.333333, 		 Training Loss: 17038819.785714Epoch 47 		 Validation Loss: 30144392.000000, 		 Training Loss: 19829559.214286Epoch 48 		 Validation Loss: 19314016.666667, 		 Training Loss: 30064631.857143Epoch 49 		 Validation Loss: 19524875.666667, 		 Training Loss: 23960796.571429Validation Loss Decreased(13350695.000000--->10378072.333333) Saving model ...
Epoch 50 		 Validation Loss: 10378072.333333, 		 Training Loss: 15039536.571429Epoch 51 		 Validation Loss: 35471291.333333, 		 Training Loss: 14642731.071429Validation Loss Decreased(10378072.333333--->9862251.833333) Saving model ...
Epoch 52 		 Validation Loss: 9862251.833333, 		 Training Loss: 22789217.500000Epoch 53 		 Validation Loss: 14208847.000000, 		 Training Loss: 15012641.571429Epoch 54 		 Validation Loss: 10166299.000000, 		 Training Loss: 19978586.892857Epoch 55 		 Validation Loss: 16238390.000000, 		 Training Loss: 22161140.285714Epoch 56 		 Validation Loss: 17713785.666667, 		 Training Loss: 22301293.857143Epoch 57 		 Validation Loss: 22628632.000000, 		 Training Loss: 19053296.642857Epoch 58 		 Validation Loss: 16515317.000000, 		 Training Loss: 18621409.285714Epoch 59 		 Validation Loss: 24434512.000000, 		 Training Loss: 19109979.571429Epoch 60 		 Validation Loss: 11029937.666667, 		 Training Loss: 22272401.928571Validation Loss Decreased(9862251.833333--->8289225.500000) Saving model ...
Epoch 61 		 Validation Loss: 8289225.500000, 		 Training Loss: 11377874.321429Epoch 62 		 Validation Loss: 22424416.666667, 		 Training Loss: 16881711.535714Epoch 63 		 Validation Loss: 10885581.666667, 		 Training Loss: 19068444.500000Epoch 64 		 Validation Loss: 20541175.333333, 		 Training Loss: 15516110.071429Epoch 65 		 Validation Loss: 15541623.333333, 		 Training Loss: 15912997.571429Epoch 66 		 Validation Loss: 29338187.333333, 		 Training Loss: 21831265.142857Epoch 67 		 Validation Loss: 19809546.000000, 		 Training Loss: 22339903.500000Epoch 68 		 Validation Loss: 10097155.333333, 		 Training Loss: 15841522.142857Epoch 69 		 Validation Loss: 11800363.333333, 		 Training Loss: 9908482.535714Epoch 70 		 Validation Loss: 8858166.500000, 		 Training Loss: 13952066.142857Validation Loss Decreased(8289225.500000--->6901995.500000) Saving model ...
Epoch 71 		 Validation Loss: 6901995.500000, 		 Training Loss: 9509697.035714Epoch 72 		 Validation Loss: 7030029.000000, 		 Training Loss: 8084647.357143Epoch 73 		 Validation Loss: 9463517.833333, 		 Training Loss: 7443419.071429Validation Loss Decreased(6901995.500000--->5213469.166667) Saving model ...
Epoch 74 		 Validation Loss: 5213469.166667, 		 Training Loss: 8814598.071429Epoch 75 		 Validation Loss: 6821638.000000, 		 Training Loss: 13911311.428571Epoch 76 		 Validation Loss: 8020317.666667, 		 Training Loss: 14546622.178571Epoch 77 		 Validation Loss: 9553149.666667, 		 Training Loss: 10108258.000000Epoch 78 		 Validation Loss: 12699530.666667, 		 Training Loss: 8948928.928571Epoch 79 		 Validation Loss: 13758711.666667, 		 Training Loss: 18970425.678571Epoch 80 		 Validation Loss: 10330414.000000, 		 Training Loss: 9716488.857143Epoch 81 		 Validation Loss: 6768673.666667, 		 Training Loss: 8442965.607143Epoch 82 		 Validation Loss: 5415993.166667, 		 Training Loss: 6579095.821429Validation Loss Decreased(5213469.166667--->4924990.583333) Saving model ...
Epoch 83 		 Validation Loss: 4924990.583333, 		 Training Loss: 5979739.428571Validation Loss Decreased(4924990.583333--->4770177.416667) Saving model ...
Epoch 84 		 Validation Loss: 4770177.416667, 		 Training Loss: 5583068.000000Validation Loss Decreased(4770177.416667--->4674545.666667) Saving model ...
Epoch 85 		 Validation Loss: 4674545.666667, 		 Training Loss: 5396409.982143Validation Loss Decreased(4674545.666667--->4601355.083333) Saving model ...
Epoch 86 		 Validation Loss: 4601355.083333, 		 Training Loss: 5313772.696429Validation Loss Decreased(4601355.083333--->4519494.416667) Saving model ...
Epoch 87 		 Validation Loss: 4519494.416667, 		 Training Loss: 5285471.410714Validation Loss Decreased(4519494.416667--->4469564.500000) Saving model ...
Epoch 88 		 Validation Loss: 4469564.500000, 		 Training Loss: 5203129.464286Validation Loss Decreased(4469564.500000--->4417284.000000) Saving model ...
Epoch 89 		 Validation Loss: 4417284.000000, 		 Training Loss: 4983598.250000Validation Loss Decreased(4417284.000000--->4368919.250000) Saving model ...
Epoch 90 		 Validation Loss: 4368919.250000, 		 Training Loss: 4992647.482143Validation Loss Decreased(4368919.250000--->4348228.416667) Saving model ...
Epoch 91 		 Validation Loss: 4348228.416667, 		 Training Loss: 4969749.053571Validation Loss Decreased(4348228.416667--->4302935.916667) Saving model ...
Epoch 92 		 Validation Loss: 4302935.916667, 		 Training Loss: 4907425.767857Validation Loss Decreased(4302935.916667--->4244131.333333) Saving model ...
Epoch 93 		 Validation Loss: 4244131.333333, 		 Training Loss: 4993720.017857Validation Loss Decreased(4244131.333333--->4225678.833333) Saving model ...
Epoch 94 		 Validation Loss: 4225678.833333, 		 Training Loss: 4866187.946429Validation Loss Decreased(4225678.833333--->4171838.666667) Saving model ...
Epoch 95 		 Validation Loss: 4171838.666667, 		 Training Loss: 4796994.410714Validation Loss Decreased(4171838.666667--->4167664.333333) Saving model ...
Epoch 96 		 Validation Loss: 4167664.333333, 		 Training Loss: 4736934.357143Validation Loss Decreased(4167664.333333--->4162854.666667) Saving model ...
Epoch 97 		 Validation Loss: 4162854.666667, 		 Training Loss: 4759916.910714Validation Loss Decreased(4162854.666667--->4158893.916667) Saving model ...
Epoch 98 		 Validation Loss: 4158893.916667, 		 Training Loss: 4787831.607143Validation Loss Decreased(4158893.916667--->4155117.583333) Saving model ...
Epoch 99 		 Validation Loss: 4155117.583333, 		 Training Loss: 4840077.714286Validation Loss Decreased(4155117.583333--->4151993.416667) Saving model ...
Epoch 100 		 Validation Loss: 4151993.416667, 		 Training Loss: 4772341.107143Training Completed!
Training with lr=0.1, batch_size=64, n_epochs=250
Initializing Training Process..

Torch version: 1.11.0 ------ Selected Device: cuda:0
Sample Rate: 16000 Hz ------  Crop Lenght:3200 samples

Found 4 files in ../plate-spring/spring
Using dry_train.h5 and wet_train.h5 for train split.
Parameters: 395.339 k
Receptive field: 3495251 samples or 218453.2 ms

Training Loop

Validation Loss Decreased(inf--->15152933205.333334) Saving model ...
Epoch 1 		 Validation Loss: 15152933205.333334, 		 Training Loss: 72842520704.553268Epoch 2 		 Validation Loss: 157109794133.333344, 		 Training Loss: 26521849005.714287Validation Loss Decreased(15152933205.333334--->6549357738.666667) Saving model ...
Epoch 3 		 Validation Loss: 6549357738.666667, 		 Training Loss: 213433189229.714294Validation Loss Decreased(6549357738.666667--->6438971562.666667) Saving model ...
Epoch 4 		 Validation Loss: 6438971562.666667, 		 Training Loss: 18454107977.142857Validation Loss Decreased(6438971562.666667--->6172983637.333333) Saving model ...
Epoch 5 		 Validation Loss: 6172983637.333333, 		 Training Loss: 32615552329.142857Validation Loss Decreased(6172983637.333333--->1383284266.666667) Saving model ...
Epoch 6 		 Validation Loss: 1383284266.666667, 		 Training Loss: 4590301618.285714Validation Loss Decreased(1383284266.666667--->432585824.000000) Saving model ...
Epoch 7 		 Validation Loss: 432585824.000000, 		 Training Loss: 1023741083.428571Validation Loss Decreased(432585824.000000--->150004936.000000) Saving model ...
Epoch 8 		 Validation Loss: 150004936.000000, 		 Training Loss: 246489642.857143Validation Loss Decreased(150004936.000000--->74535144.000000) Saving model ...
Epoch 9 		 Validation Loss: 74535144.000000, 		 Training Loss: 90752349.714286Validation Loss Decreased(74535144.000000--->34729684.000000) Saving model ...
Epoch 10 		 Validation Loss: 34729684.000000, 		 Training Loss: 42414128.428571Validation Loss Decreased(34729684.000000--->31141724.666667) Saving model ...
Epoch 11 		 Validation Loss: 31141724.666667, 		 Training Loss: 25072425.428571Validation Loss Decreased(31141724.666667--->21892333.000000) Saving model ...
Epoch 12 		 Validation Loss: 21892333.000000, 		 Training Loss: 21974451.571429Validation Loss Decreased(21892333.000000--->20103838.666667) Saving model ...
Epoch 13 		 Validation Loss: 20103838.666667, 		 Training Loss: 26610949.071429Epoch 14 		 Validation Loss: 39477345.333333, 		 Training Loss: 34688482.785714Epoch 15 		 Validation Loss: 42580914.666667, 		 Training Loss: 29263411.500000Epoch 16 		 Validation Loss: 26693811.333333, 		 Training Loss: 27324744.714286Validation Loss Decreased(20103838.666667--->19863222.000000) Saving model ...
Epoch 17 		 Validation Loss: 19863222.000000, 		 Training Loss: 17348693.142857Validation Loss Decreased(19863222.000000--->17167905.333333) Saving model ...
Epoch 18 		 Validation Loss: 17167905.333333, 		 Training Loss: 22054332.214286Validation Loss Decreased(17167905.333333--->16070087.666667) Saving model ...
Epoch 19 		 Validation Loss: 16070087.666667, 		 Training Loss: 13722982.928571Validation Loss Decreased(16070087.666667--->15087704.666667) Saving model ...
Epoch 20 		 Validation Loss: 15087704.666667, 		 Training Loss: 11518689.392857Validation Loss Decreased(15087704.666667--->12111193.000000) Saving model ...
Epoch 21 		 Validation Loss: 12111193.000000, 		 Training Loss: 10573247.285714Epoch 22 		 Validation Loss: 55262885.333333, 		 Training Loss: 20796250.000000Epoch 23 		 Validation Loss: 25728667.333333, 		 Training Loss: 24069143.071429Validation Loss Decreased(12111193.000000--->9566394.000000) Saving model ...
Epoch 24 		 Validation Loss: 9566394.000000, 		 Training Loss: 15821107.500000Epoch 25 		 Validation Loss: 10803128.166667, 		 Training Loss: 8951380.714286Epoch 26 		 Validation Loss: 11355430.333333, 		 Training Loss: 12285031.678571Epoch 27 		 Validation Loss: 16153365.666667, 		 Training Loss: 12775668.857143Validation Loss Decreased(9566394.000000--->8857398.666667) Saving model ...
Epoch 28 		 Validation Loss: 8857398.666667, 		 Training Loss: 13153980.107143Epoch 29 		 Validation Loss: 12909503.333333, 		 Training Loss: 13719909.321429Epoch 30 		 Validation Loss: 22418954.666667, 		 Training Loss: 9555936.750000Epoch 31 		 Validation Loss: 19208726.666667, 		 Training Loss: 15561595.821429Validation Loss Decreased(8857398.666667--->7870484.333333) Saving model ...
Epoch 32 		 Validation Loss: 7870484.333333, 		 Training Loss: 9493338.142857Epoch 33 		 Validation Loss: 13591763.000000, 		 Training Loss: 7863461.892857Validation Loss Decreased(7870484.333333--->6686844.333333) Saving model ...
Epoch 34 		 Validation Loss: 6686844.333333, 		 Training Loss: 6663890.607143Validation Loss Decreased(6686844.333333--->5231226.333333) Saving model ...
Epoch 35 		 Validation Loss: 5231226.333333, 		 Training Loss: 4726816.982143Epoch 36 		 Validation Loss: 7355234.000000, 		 Training Loss: 8770149.017857Epoch 37 		 Validation Loss: 11172876.000000, 		 Training Loss: 8402140.750000Epoch 38 		 Validation Loss: 7295879.333333, 		 Training Loss: 7056017.303571Epoch 39 		 Validation Loss: 10391789.500000, 		 Training Loss: 11058611.785714Epoch 40 		 Validation Loss: 6757291.666667, 		 Training Loss: 10342800.857143Epoch 41 		 Validation Loss: 11954372.000000, 		 Training Loss: 7794019.107143Epoch 42 		 Validation Loss: 5848469.666667, 		 Training Loss: 6449220.142857Epoch 43 		 Validation Loss: 5397001.000000, 		 Training Loss: 5978609.553571Validation Loss Decreased(5231226.333333--->4878642.833333) Saving model ...
Epoch 44 		 Validation Loss: 4878642.833333, 		 Training Loss: 5751166.482143Epoch 45 		 Validation Loss: 10692805.000000, 		 Training Loss: 6420070.357143Epoch 46 		 Validation Loss: 8809821.333333, 		 Training Loss: 7809069.410714Epoch 47 		 Validation Loss: 5824577.166667, 		 Training Loss: 5602684.714286Epoch 48 		 Validation Loss: 5200905.583333, 		 Training Loss: 4576178.982143Epoch 49 		 Validation Loss: 7889822.666667, 		 Training Loss: 6545268.446429Epoch 50 		 Validation Loss: 7930926.500000, 		 Training Loss: 7628101.857143Epoch 51 		 Validation Loss: 6516919.166667, 		 Training Loss: 5887275.428571Epoch 52 		 Validation Loss: 4986033.250000, 		 Training Loss: 4714096.464286Validation Loss Decreased(4878642.833333--->4675404.000000) Saving model ...
Epoch 53 		 Validation Loss: 4675404.000000, 		 Training Loss: 3863038.964286Validation Loss Decreased(4675404.000000--->4029850.166667) Saving model ...
Epoch 54 		 Validation Loss: 4029850.166667, 		 Training Loss: 3696109.267857Validation Loss Decreased(4029850.166667--->2490708.125000) Saving model ...
Epoch 55 		 Validation Loss: 2490708.125000, 		 Training Loss: 3581538.598214Epoch 56 		 Validation Loss: 2969887.333333, 		 Training Loss: 3664333.589286Epoch 57 		 Validation Loss: 5212292.166667, 		 Training Loss: 3513760.982143Epoch 58 		 Validation Loss: 3537795.250000, 		 Training Loss: 3575030.848214Validation Loss Decreased(2490708.125000--->2129791.625000) Saving model ...
Epoch 59 		 Validation Loss: 2129791.625000, 		 Training Loss: 2605530.089286Epoch 60 		 Validation Loss: 2195580.791667, 		 Training Loss: 2012948.464286Epoch 61 		 Validation Loss: 10811220.333333, 		 Training Loss: 3372826.821429Epoch 62 		 Validation Loss: 5409595.000000, 		 Training Loss: 5344195.642857Epoch 63 		 Validation Loss: 3515609.833333, 		 Training Loss: 5290209.875000Epoch 64 		 Validation Loss: 2627585.625000, 		 Training Loss: 5423442.803571Validation Loss Decreased(2129791.625000--->1944153.625000) Saving model ...
Epoch 65 		 Validation Loss: 1944153.625000, 		 Training Loss: 2596957.857143Validation Loss Decreased(1944153.625000--->1871757.041667) Saving model ...
Epoch 66 		 Validation Loss: 1871757.041667, 		 Training Loss: 1900568.785714Epoch 67 		 Validation Loss: 2125146.750000, 		 Training Loss: 1517081.580357Epoch 68 		 Validation Loss: 2319243.041667, 		 Training Loss: 1800285.133929Epoch 69 		 Validation Loss: 1949852.083333, 		 Training Loss: 1608542.446429Validation Loss Decreased(1871757.041667--->1548460.625000) Saving model ...
Epoch 70 		 Validation Loss: 1548460.625000, 		 Training Loss: 1680093.437500Epoch 71 		 Validation Loss: 3664607.250000, 		 Training Loss: 2177337.098214Epoch 72 		 Validation Loss: 2505689.166667, 		 Training Loss: 2872668.991071Epoch 73 		 Validation Loss: 1702329.375000, 		 Training Loss: 1913554.276786Epoch 74 		 Validation Loss: 3311037.333333, 		 Training Loss: 2983440.022321Epoch 75 		 Validation Loss: 3168607.166667, 		 Training Loss: 2534307.473214Validation Loss Decreased(1548460.625000--->1507847.791667) Saving model ...
Epoch 76 		 Validation Loss: 1507847.791667, 		 Training Loss: 1442308.151786Epoch 77 		 Validation Loss: 1511608.333333, 		 Training Loss: 1472428.625000Epoch 78 		 Validation Loss: 1634814.250000, 		 Training Loss: 2815564.151786Epoch 79 		 Validation Loss: 8481403.333333, 		 Training Loss: 3932833.625000Epoch 80 		 Validation Loss: 2805863.750000, 		 Training Loss: 3454350.830357Validation Loss Decreased(1507847.791667--->1341946.854167) Saving model ...
Epoch 81 		 Validation Loss: 1341946.854167, 		 Training Loss: 1623163.968750Epoch 82 		 Validation Loss: 1350894.291667, 		 Training Loss: 1325774.316964Epoch 83 		 Validation Loss: 1709286.958333, 		 Training Loss: 1528237.142857Epoch 84 		 Validation Loss: 1881970.458333, 		 Training Loss: 3711323.437500Epoch 85 		 Validation Loss: 4868758.916667, 		 Training Loss: 3411403.187500Epoch 86 		 Validation Loss: 1385353.416667, 		 Training Loss: 2250121.455357Epoch 87 		 Validation Loss: 4831531.083333, 		 Training Loss: 2136163.897321Epoch 88 		 Validation Loss: 5007126.416667, 		 Training Loss: 4023288.446429Epoch 89 		 Validation Loss: 1876239.875000, 		 Training Loss: 2642879.633929Epoch 90 		 Validation Loss: 3105779.416667, 		 Training Loss: 1817702.392857Epoch 91 		 Validation Loss: 2311008.208333, 		 Training Loss: 2104434.549107Epoch 92 		 Validation Loss: 2476678.833333, 		 Training Loss: 1749471.531250Epoch 93 		 Validation Loss: 2224768.708333, 		 Training Loss: 1781296.062500Epoch 94 		 Validation Loss: 2326789.083333, 		 Training Loss: 1797761.919643Validation Loss Decreased(1341946.854167--->1147474.312500) Saving model ...
Epoch 95 		 Validation Loss: 1147474.312500, 		 Training Loss: 1897748.080357Epoch 96 		 Validation Loss: 1152118.958333, 		 Training Loss: 1698280.794643Epoch 97 		 Validation Loss: 1237646.687500, 		 Training Loss: 1121301.879464Validation Loss Decreased(1147474.312500--->1080276.979167) Saving model ...
Epoch 98 		 Validation Loss: 1080276.979167, 		 Training Loss: 1536777.924107Validation Loss Decreased(1080276.979167--->970522.000000) Saving model ...
Epoch 99 		 Validation Loss: 970522.000000, 		 Training Loss: 1065343.174107Validation Loss Decreased(970522.000000--->946924.333333) Saving model ...
Epoch 100 		 Validation Loss: 946924.333333, 		 Training Loss: 1124597.040179Epoch 101 		 Validation Loss: 4480279.583333, 		 Training Loss: 1693139.321429Epoch 102 		 Validation Loss: 1210520.479167, 		 Training Loss: 3019377.241071Epoch 103 		 Validation Loss: 2042202.416667, 		 Training Loss: 2714678.633929Epoch 104 		 Validation Loss: 4094587.916667, 		 Training Loss: 1616466.464286Epoch 105 		 Validation Loss: 3017423.916667, 		 Training Loss: 3050462.861607Epoch 106 		 Validation Loss: 1529732.458333, 		 Training Loss: 1422855.142857Validation Loss Decreased(946924.333333--->890128.125000) Saving model ...
Epoch 107 		 Validation Loss: 890128.125000, 		 Training Loss: 964015.285714Epoch 108 		 Validation Loss: 1504275.750000, 		 Training Loss: 1523124.700893Epoch 109 		 Validation Loss: 1790548.916667, 		 Training Loss: 1523813.638393Epoch 110 		 Validation Loss: 1408320.854167, 		 Training Loss: 1419917.937500Epoch 111 		 Validation Loss: 2684954.791667, 		 Training Loss: 1484524.455357Validation Loss Decreased(890128.125000--->878283.854167) Saving model ...
Epoch 112 		 Validation Loss: 878283.854167, 		 Training Loss: 1455696.156250Epoch 113 		 Validation Loss: 1334540.062500, 		 Training Loss: 845480.754464Epoch 114 		 Validation Loss: 1226766.937500, 		 Training Loss: 1274463.267857Validation Loss Decreased(878283.854167--->797896.187500) Saving model ...
Epoch 115 		 Validation Loss: 797896.187500, 		 Training Loss: 867927.263393Epoch 116 		 Validation Loss: 1315042.291667, 		 Training Loss: 823772.441964Validation Loss Decreased(797896.187500--->745209.770833) Saving model ...
Epoch 117 		 Validation Loss: 745209.770833, 		 Training Loss: 886093.638393Epoch 118 		 Validation Loss: 3472744.000000, 		 Training Loss: 1679557.558036Epoch 119 		 Validation Loss: 2795744.583333, 		 Training Loss: 2606055.843750Epoch 120 		 Validation Loss: 865631.416667, 		 Training Loss: 1458543.709821Epoch 121 		 Validation Loss: 1760575.791667, 		 Training Loss: 936113.727679Epoch 122 		 Validation Loss: 1106861.604167, 		 Training Loss: 1410377.031250Validation Loss Decreased(745209.770833--->692168.489583) Saving model ...
Epoch 123 		 Validation Loss: 692168.489583, 		 Training Loss: 911429.571429Epoch 124 		 Validation Loss: 705305.750000, 		 Training Loss: 767191.678571Epoch 125 		 Validation Loss: 2713094.958333, 		 Training Loss: 1559846.375000Epoch 126 		 Validation Loss: 747613.333333, 		 Training Loss: 1652673.910714Epoch 127 		 Validation Loss: 1046305.479167, 		 Training Loss: 1107267.674107Epoch 128 		 Validation Loss: 1332681.000000, 		 Training Loss: 722527.926339Epoch 129 		 Validation Loss: 1650063.625000, 		 Training Loss: 1173936.915179Epoch 130 		 Validation Loss: 1079210.666667, 		 Training Loss: 1278430.939732Epoch 131 		 Validation Loss: 2342993.958333, 		 Training Loss: 1011162.674107Epoch 132 		 Validation Loss: 1373225.687500, 		 Training Loss: 1280892.453125Epoch 133 		 Validation Loss: 1544425.875000, 		 Training Loss: 1148508.071429Epoch 134 		 Validation Loss: 919957.062500, 		 Training Loss: 1235700.674107Epoch 135 		 Validation Loss: 2057491.125000, 		 Training Loss: 1845665.165179Epoch 136 		 Validation Loss: 1988846.958333, 		 Training Loss: 1779032.870536Epoch 137 		 Validation Loss: 806105.770833, 		 Training Loss: 1411672.049107Validation Loss Decreased(692168.489583--->642961.239583) Saving model ...
Epoch 138 		 Validation Loss: 642961.239583, 		 Training Loss: 717165.662946Epoch 139 		 Validation Loss: 777594.875000, 		 Training Loss: 714453.131696Epoch 140 		 Validation Loss: 1792733.625000, 		 Training Loss: 1003033.982143Epoch 141 		 Validation Loss: 1039581.937500, 		 Training Loss: 1692994.441964Epoch 142 		 Validation Loss: 2509353.791667, 		 Training Loss: 1417643.332589Epoch 143 		 Validation Loss: 2149296.458333, 		 Training Loss: 1525322.888393Epoch 144 		 Validation Loss: 705120.885417, 		 Training Loss: 1118198.316964Epoch 145 		 Validation Loss: 1550359.416667, 		 Training Loss: 787994.180804Epoch 146 		 Validation Loss: 717383.562500, 		 Training Loss: 970942.415179Epoch 147 		 Validation Loss: 975275.479167, 		 Training Loss: 876186.993304Epoch 148 		 Validation Loss: 2471044.500000, 		 Training Loss: 864853.468750Validation Loss Decreased(642961.239583--->621288.083333) Saving model ...
Epoch 149 		 Validation Loss: 621288.083333, 		 Training Loss: 1819048.540179Epoch 150 		 Validation Loss: 652159.625000, 		 Training Loss: 903870.977679Epoch 151 		 Validation Loss: 668953.125000, 		 Training Loss: 880262.167411Epoch 152 		 Validation Loss: 1213186.541667, 		 Training Loss: 965902.609375Epoch 153 		 Validation Loss: 869631.458333, 		 Training Loss: 987173.459821Epoch 154 		 Validation Loss: 2320707.083333, 		 Training Loss: 897888.209821Epoch 155 		 Validation Loss: 2789777.083333, 		 Training Loss: 1702167.075893Epoch 156 		 Validation Loss: 1575779.166667, 		 Training Loss: 1273245.276786Validation Loss Decreased(621288.083333--->583083.416667) Saving model ...
Epoch 157 		 Validation Loss: 583083.416667, 		 Training Loss: 667851.843750Epoch 158 		 Validation Loss: 833161.520833, 		 Training Loss: 471481.118304Validation Loss Decreased(583083.416667--->488317.770833) Saving model ...
Epoch 159 		 Validation Loss: 488317.770833, 		 Training Loss: 530303.066964Epoch 160 		 Validation Loss: 580609.895833, 		 Training Loss: 511361.627232Epoch 161 		 Validation Loss: 1103074.125000, 		 Training Loss: 879995.763393Epoch 162 		 Validation Loss: 1771123.833333, 		 Training Loss: 1014427.861607Epoch 163 		 Validation Loss: 894334.104167, 		 Training Loss: 1038741.433036Epoch 164 		 Validation Loss: 789590.062500, 		 Training Loss: 879409.598214Validation Loss Decreased(488317.770833--->442771.052083) Saving model ...
Epoch 165 		 Validation Loss: 442771.052083, 		 Training Loss: 677359.145089Epoch 166 		 Validation Loss: 555844.020833, 		 Training Loss: 457528.984375Epoch 167 		 Validation Loss: 461380.260417, 		 Training Loss: 472888.647321Epoch 168 		 Validation Loss: 653591.031250, 		 Training Loss: 482937.687500Epoch 169 		 Validation Loss: 3014281.083333, 		 Training Loss: 1015049.044643Epoch 170 		 Validation Loss: 2001740.333333, 		 Training Loss: 1641624.272321Epoch 171 		 Validation Loss: 2049082.916667, 		 Training Loss: 1163578.877232Epoch 172 		 Validation Loss: 1819535.958333, 		 Training Loss: 1266554.345982Epoch 173 		 Validation Loss: 1721971.083333, 		 Training Loss: 1330881.243304Epoch 174 		 Validation Loss: 1054966.833333, 		 Training Loss: 1248992.142857Epoch 175 		 Validation Loss: 457674.958333, 		 Training Loss: 899019.819196Epoch 176 		 Validation Loss: 1598110.708333, 		 Training Loss: 583314.636161Epoch 177 		 Validation Loss: 949204.458333, 		 Training Loss: 897169.345982Epoch 178 		 Validation Loss: 801705.395833, 		 Training Loss: 756083.691964Epoch 179 		 Validation Loss: 883361.770833, 		 Training Loss: 679261.424107Epoch 180 		 Validation Loss: 1294411.729167, 		 Training Loss: 1159922.841518Epoch 181 		 Validation Loss: 1535503.625000, 		 Training Loss: 1249401.589286Epoch 182 		 Validation Loss: 1263914.541667, 		 Training Loss: 900138.866071Epoch 183 		 Validation Loss: 458048.687500, 		 Training Loss: 713327.325893Epoch 184 		 Validation Loss: 890388.145833, 		 Training Loss: 647906.542411Epoch 185 		 Validation Loss: 891752.895833, 		 Training Loss: 604815.468750Epoch 186 		 Validation Loss: 1284186.520833, 		 Training Loss: 569123.540179Validation Loss Decreased(442771.052083--->402568.229167) Saving model ...
Epoch 187 		 Validation Loss: 402568.229167, 		 Training Loss: 625066.723214Epoch 188 		 Validation Loss: 450845.187500, 		 Training Loss: 360470.429688Epoch 189 		 Validation Loss: 462702.697917, 		 Training Loss: 354490.101562Epoch 190 		 Validation Loss: 1610295.916667, 		 Training Loss: 906138.705357Validation Loss Decreased(402568.229167--->336574.911458) Saving model ...
Epoch 191 		 Validation Loss: 336574.911458, 		 Training Loss: 779939.397321Epoch 192 		 Validation Loss: 600271.656250, 		 Training Loss: 578644.937500Epoch 193 		 Validation Loss: 517411.187500, 		 Training Loss: 644937.959821Epoch 194 		 Validation Loss: 596268.020833, 		 Training Loss: 784470.000000Epoch 195 		 Validation Loss: 677312.437500, 		 Training Loss: 861006.272321Epoch 196 		 Validation Loss: 1402624.916667, 		 Training Loss: 554094.006696Epoch 197 		 Validation Loss: 660859.718750, 		 Training Loss: 906638.792411Epoch 198 		 Validation Loss: 1490008.125000, 		 Training Loss: 943140.723214Epoch 199 		 Validation Loss: 789250.291667, 		 Training Loss: 796757.408482Validation Loss Decreased(336574.911458--->334817.104167) Saving model ...
Epoch 200 		 Validation Loss: 334817.104167, 		 Training Loss: 482350.488839Validation Loss Decreased(334817.104167--->324110.473958) Saving model ...
Epoch 201 		 Validation Loss: 324110.473958, 		 Training Loss: 264055.540179Validation Loss Decreased(324110.473958--->315539.515625) Saving model ...
Epoch 202 		 Validation Loss: 315539.515625, 		 Training Loss: 252832.116071Validation Loss Decreased(315539.515625--->310476.041667) Saving model ...
Epoch 203 		 Validation Loss: 310476.041667, 		 Training Loss: 253447.853795Validation Loss Decreased(310476.041667--->307419.171875) Saving model ...
Epoch 204 		 Validation Loss: 307419.171875, 		 Training Loss: 247298.429688Validation Loss Decreased(307419.171875--->302433.369792) Saving model ...
Epoch 205 		 Validation Loss: 302433.369792, 		 Training Loss: 247584.231027Validation Loss Decreased(302433.369792--->299006.020833) Saving model ...
Epoch 206 		 Validation Loss: 299006.020833, 		 Training Loss: 246120.743304Validation Loss Decreased(299006.020833--->295640.869792) Saving model ...
Epoch 207 		 Validation Loss: 295640.869792, 		 Training Loss: 240868.251116Validation Loss Decreased(295640.869792--->292607.114583) Saving model ...
Epoch 208 		 Validation Loss: 292607.114583, 		 Training Loss: 241776.131696Validation Loss Decreased(292607.114583--->291551.484375) Saving model ...
Epoch 209 		 Validation Loss: 291551.484375, 		 Training Loss: 235057.014509Validation Loss Decreased(291551.484375--->287121.442708) Saving model ...
Epoch 210 		 Validation Loss: 287121.442708, 		 Training Loss: 236992.647321Validation Loss Decreased(287121.442708--->285386.994792) Saving model ...
Epoch 211 		 Validation Loss: 285386.994792, 		 Training Loss: 234995.570312Validation Loss Decreased(285386.994792--->281850.458333) Saving model ...
Epoch 212 		 Validation Loss: 281850.458333, 		 Training Loss: 232482.027902Validation Loss Decreased(281850.458333--->279657.692708) Saving model ...
Epoch 213 		 Validation Loss: 279657.692708, 		 Training Loss: 231750.224330Validation Loss Decreased(279657.692708--->277599.427083) Saving model ...
Epoch 214 		 Validation Loss: 277599.427083, 		 Training Loss: 226170.751116Validation Loss Decreased(277599.427083--->275078.244792) Saving model ...
Epoch 215 		 Validation Loss: 275078.244792, 		 Training Loss: 223999.967634Validation Loss Decreased(275078.244792--->274490.546875) Saving model ...
Epoch 216 		 Validation Loss: 274490.546875, 		 Training Loss: 227585.081473Validation Loss Decreased(274490.546875--->271231.854167) Saving model ...
Epoch 217 		 Validation Loss: 271231.854167, 		 Training Loss: 228478.635045Validation Loss Decreased(271231.854167--->268989.994792) Saving model ...
Epoch 218 		 Validation Loss: 268989.994792, 		 Training Loss: 225733.453125Validation Loss Decreased(268989.994792--->266739.625000) Saving model ...
Epoch 219 		 Validation Loss: 266739.625000, 		 Training Loss: 223208.722098Validation Loss Decreased(266739.625000--->265685.406250) Saving model ...
Epoch 220 		 Validation Loss: 265685.406250, 		 Training Loss: 219372.825893Validation Loss Decreased(265685.406250--->263961.177083) Saving model ...
Epoch 221 		 Validation Loss: 263961.177083, 		 Training Loss: 221669.027902Validation Loss Decreased(263961.177083--->261852.864583) Saving model ...
Epoch 222 		 Validation Loss: 261852.864583, 		 Training Loss: 215968.750000Validation Loss Decreased(261852.864583--->260107.494792) Saving model ...
Epoch 223 		 Validation Loss: 260107.494792, 		 Training Loss: 216998.003348Validation Loss Decreased(260107.494792--->259353.067708) Saving model ...
Epoch 224 		 Validation Loss: 259353.067708, 		 Training Loss: 210569.004464Validation Loss Decreased(259353.067708--->257053.083333) Saving model ...
Epoch 225 		 Validation Loss: 257053.083333, 		 Training Loss: 212855.809152Validation Loss Decreased(257053.083333--->255209.458333) Saving model ...
Epoch 226 		 Validation Loss: 255209.458333, 		 Training Loss: 215854.101562Validation Loss Decreased(255209.458333--->253882.817708) Saving model ...
Epoch 227 		 Validation Loss: 253882.817708, 		 Training Loss: 212681.655134Validation Loss Decreased(253882.817708--->253407.109375) Saving model ...
Epoch 228 		 Validation Loss: 253407.109375, 		 Training Loss: 211107.396205Validation Loss Decreased(253407.109375--->250871.072917) Saving model ...
Epoch 229 		 Validation Loss: 250871.072917, 		 Training Loss: 213393.260045Validation Loss Decreased(250871.072917--->250356.281250) Saving model ...
Epoch 230 		 Validation Loss: 250356.281250, 		 Training Loss: 206883.166295Validation Loss Decreased(250356.281250--->247736.583333) Saving model ...
Epoch 231 		 Validation Loss: 247736.583333, 		 Training Loss: 208098.739955Validation Loss Decreased(247736.583333--->247261.130208) Saving model ...
Epoch 232 		 Validation Loss: 247261.130208, 		 Training Loss: 208488.156250Validation Loss Decreased(247261.130208--->246490.864583) Saving model ...
Epoch 233 		 Validation Loss: 246490.864583, 		 Training Loss: 204866.390625Validation Loss Decreased(246490.864583--->243818.000000) Saving model ...
Epoch 234 		 Validation Loss: 243818.000000, 		 Training Loss: 203602.658482Validation Loss Decreased(243818.000000--->242434.166667) Saving model ...
Epoch 235 		 Validation Loss: 242434.166667, 		 Training Loss: 209417.811384Validation Loss Decreased(242434.166667--->240685.807292) Saving model ...
Epoch 236 		 Validation Loss: 240685.807292, 		 Training Loss: 204946.902902Validation Loss Decreased(240685.807292--->239552.109375) Saving model ...
Epoch 237 		 Validation Loss: 239552.109375, 		 Training Loss: 199925.517857Validation Loss Decreased(239552.109375--->239238.380208) Saving model ...
Epoch 238 		 Validation Loss: 239238.380208, 		 Training Loss: 201892.478795Validation Loss Decreased(239238.380208--->239056.088542) Saving model ...
Epoch 239 		 Validation Loss: 239056.088542, 		 Training Loss: 201937.791295Validation Loss Decreased(239056.088542--->238952.171875) Saving model ...
Epoch 240 		 Validation Loss: 238952.171875, 		 Training Loss: 200862.573661Validation Loss Decreased(238952.171875--->238882.265625) Saving model ...
Epoch 241 		 Validation Loss: 238882.265625, 		 Training Loss: 200260.463170Validation Loss Decreased(238882.265625--->238626.625000) Saving model ...
Epoch 242 		 Validation Loss: 238626.625000, 		 Training Loss: 202838.904018Validation Loss Decreased(238626.625000--->238478.744792) Saving model ...
Epoch 243 		 Validation Loss: 238478.744792, 		 Training Loss: 198902.597098Validation Loss Decreased(238478.744792--->238396.531250) Saving model ...
Epoch 244 		 Validation Loss: 238396.531250, 		 Training Loss: 200632.984375Epoch 245 		 Validation Loss: 238485.395833, 		 Training Loss: 198437.263393Epoch 246 		 Validation Loss: 238396.546875, 		 Training Loss: 200055.731027Validation Loss Decreased(238396.531250--->237992.348958) Saving model ...
Epoch 247 		 Validation Loss: 237992.348958, 		 Training Loss: 197219.026786Validation Loss Decreased(237992.348958--->237928.239583) Saving model ...
Epoch 248 		 Validation Loss: 237928.239583, 		 Training Loss: 200680.684152Validation Loss Decreased(237928.239583--->237688.005208) Saving model ...
Epoch 249 		 Validation Loss: 237688.005208, 		 Training Loss: 200310.185268Epoch 250 		 Validation Loss: 237733.239583, 		 Training Loss: 197776.543527Training Completed!
Training with lr=0.1, batch_size=128, n_epochs=50
Initializing Training Process..

Torch version: 1.11.0 ------ Selected Device: cuda:0
Sample Rate: 16000 Hz ------  Crop Lenght:3200 samples

Found 4 files in ../plate-spring/spring
Using dry_train.h5 and wet_train.h5 for train split.
Parameters: 395.339 k
Receptive field: 3495251 samples or 218453.2 ms

Training Loop

Validation Loss Decreased(inf--->2021992064.000000) Saving model ...
Epoch 1 		 Validation Loss: 2021992064.000000, 		 Training Loss: 10691775969.023550Epoch 2 		 Validation Loss: 117257633792.000000, 		 Training Loss: 3879916233.142857Epoch 3 		 Validation Loss: 15022686208.000000, 		 Training Loss: 21168611364.571430Epoch 4 		 Validation Loss: 1738938515456.000000, 		 Training Loss: 136772519936.000000Epoch 5 		 Validation Loss: 686639153152.000000, 		 Training Loss: 525928886857.142883Epoch 6 		 Validation Loss: 690369134592.000000, 		 Training Loss: 881455731273.142822Epoch 7 		 Validation Loss: 49321435136.000000, 		 Training Loss: 136316739876.571426Epoch 8 		 Validation Loss: 13934794752.000000, 		 Training Loss: 28190917193.142857Epoch 9 		 Validation Loss: 2808202919936.000000, 		 Training Loss: 168003539236.571442Epoch 10 		 Validation Loss: 52664152064.000000, 		 Training Loss: 972313530953.142822Epoch 11 		 Validation Loss: 188280324096.000000, 		 Training Loss: 243122247972.571442Epoch 12 		 Validation Loss: 698692861952.000000, 		 Training Loss: 247313788342.857147Epoch 13 		 Validation Loss: 79287877632.000000, 		 Training Loss: 376943099026.285706Epoch 14 		 Validation Loss: 87417356288.000000, 		 Training Loss: 128010082596.571426Epoch 15 		 Validation Loss: 17167295488.000000, 		 Training Loss: 29642476982.857143Epoch 16 		 Validation Loss: 8656317440.000000, 		 Training Loss: 14193570889.142857Epoch 17 		 Validation Loss: 4485681664.000000, 		 Training Loss: 6165095350.857142Epoch 18 		 Validation Loss: 2169790208.000000, 		 Training Loss: 3158014354.285714Validation Loss Decreased(2021992064.000000--->954403136.000000) Saving model ...
Epoch 19 		 Validation Loss: 954403136.000000, 		 Training Loss: 1472534592.000000Validation Loss Decreased(954403136.000000--->599527104.000000) Saving model ...
Epoch 20 		 Validation Loss: 599527104.000000, 		 Training Loss: 731256475.428571Validation Loss Decreased(599527104.000000--->408462144.000000) Saving model ...
Epoch 21 		 Validation Loss: 408462144.000000, 		 Training Loss: 474814057.142857Validation Loss Decreased(408462144.000000--->341795776.000000) Saving model ...
Epoch 22 		 Validation Loss: 341795776.000000, 		 Training Loss: 333258866.285714Validation Loss Decreased(341795776.000000--->270412512.000000) Saving model ...
Epoch 23 		 Validation Loss: 270412512.000000, 		 Training Loss: 258286777.142857Validation Loss Decreased(270412512.000000--->244860896.000000) Saving model ...
Epoch 24 		 Validation Loss: 244860896.000000, 		 Training Loss: 214883945.142857Validation Loss Decreased(244860896.000000--->178657712.000000) Saving model ...
Epoch 25 		 Validation Loss: 178657712.000000, 		 Training Loss: 213117753.142857Epoch 26 		 Validation Loss: 324620736.000000, 		 Training Loss: 170683744.000000Validation Loss Decreased(178657712.000000--->136179280.000000) Saving model ...
Epoch 27 		 Validation Loss: 136179280.000000, 		 Training Loss: 225955768.000000Validation Loss Decreased(136179280.000000--->133139440.000000) Saving model ...
Epoch 28 		 Validation Loss: 133139440.000000, 		 Training Loss: 174432932.571429Validation Loss Decreased(133139440.000000--->118863560.000000) Saving model ...
Epoch 29 		 Validation Loss: 118863560.000000, 		 Training Loss: 163929795.428571Epoch 30 		 Validation Loss: 268347824.000000, 		 Training Loss: 208817629.714286Epoch 31 		 Validation Loss: 134819824.000000, 		 Training Loss: 274985021.714286Epoch 32 		 Validation Loss: 130713832.000000, 		 Training Loss: 137139948.571429Epoch 33 		 Validation Loss: 140329648.000000, 		 Training Loss: 110492929.142857Epoch 34 		 Validation Loss: 180045728.000000, 		 Training Loss: 119488473.142857Validation Loss Decreased(118863560.000000--->106556600.000000) Saving model ...
Epoch 35 		 Validation Loss: 106556600.000000, 		 Training Loss: 136418705.142857Epoch 36 		 Validation Loss: 113204112.000000, 		 Training Loss: 103427460.571429Validation Loss Decreased(106556600.000000--->87248952.000000) Saving model ...
Epoch 37 		 Validation Loss: 87248952.000000, 		 Training Loss: 108535125.714286Epoch 38 		 Validation Loss: 111331504.000000, 		 Training Loss: 94312826.285714Validation Loss Decreased(87248952.000000--->73409600.000000) Saving model ...
Epoch 39 		 Validation Loss: 73409600.000000, 		 Training Loss: 95904066.285714Epoch 40 		 Validation Loss: 307725632.000000, 		 Training Loss: 106331533.714286Epoch 41 		 Validation Loss: 192714944.000000, 		 Training Loss: 185713245.714286Epoch 42 		 Validation Loss: 132774096.000000, 		 Training Loss: 127333372.000000Validation Loss Decreased(73409600.000000--->70675920.000000) Saving model ...
Epoch 43 		 Validation Loss: 70675920.000000, 		 Training Loss: 89612786.285714Epoch 44 		 Validation Loss: 81603152.000000, 		 Training Loss: 72359541.714286Epoch 45 		 Validation Loss: 73856400.000000, 		 Training Loss: 67272580.571429Validation Loss Decreased(70675920.000000--->67740168.000000) Saving model ...
Epoch 46 		 Validation Loss: 67740168.000000, 		 Training Loss: 63822522.857143Validation Loss Decreased(67740168.000000--->65654120.000000) Saving model ...
Epoch 47 		 Validation Loss: 65654120.000000, 		 Training Loss: 61556673.714286Validation Loss Decreased(65654120.000000--->65535348.000000) Saving model ...
Epoch 48 		 Validation Loss: 65535348.000000, 		 Training Loss: 59048013.142857Validation Loss Decreased(65535348.000000--->65465992.000000) Saving model ...
Epoch 49 		 Validation Loss: 65465992.000000, 		 Training Loss: 59217552.571429Validation Loss Decreased(65465992.000000--->65255996.000000) Saving model ...
Epoch 50 		 Validation Loss: 65255996.000000, 		 Training Loss: 59131274.857143CUDA out of memory. Tried to allocate 1000.00 MiB (GPU 0; 14.76 GiB total capacity; 13.71 GiB already allocated; 109.75 MiB free; 13.75 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Error occurs, No graph saved
