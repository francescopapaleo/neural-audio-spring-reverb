{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "O3lGduSHXHE1"
      },
      "source": [
        "# LSTM\n",
        "\n",
        "Source code from:\n",
        "https://github.com/GuitarML/GuitarLSTM/blob/ee0983bb02af1e2db476466614d6421473beb01d/guitar_lstm_colab.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-IoypK1v1AO",
        "outputId": "651e6ebb-1997-4b00-9b58-28549ee7227b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "System Information:\n",
            "Node: node019\n",
            "Machine: x86_64\n",
            "Processor: x86_64\n",
            "\n",
            "Python Version:\n",
            "3.9.16 (main, Mar  8 2023, 14:00:05) \n",
            "[GCC 11.2.0]\n"
          ]
        }
      ],
      "source": [
        "# Check system information and python version\n",
        "import sys\n",
        "import platform\n",
        "import pkg_resources\n",
        "\n",
        "# System information\n",
        "print(f\"System Information:\")\n",
        "print(f\"Node: {platform.node()}\")\n",
        "print(f\"Machine: {platform.machine()}\")\n",
        "print(f\"Processor: {platform.processor()}\")\n",
        "\n",
        "# Python version\n",
        "print(\"\\nPython Version:\")\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RF2uyPfxgi8H"
      },
      "outputs": [],
      "source": [
        "# Import modules\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import os\n",
        "from scipy.io import wavfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U22mDBe4jaf2",
        "outputId": "03d77747-827a-45f8-8a1d-a57b45eb36e1"
      },
      "outputs": [],
      "source": [
        "# WindowArray Dataset\n",
        "class WindowArrayDataset(Dataset):\n",
        "    def __init__(self, x, y, window_len):\n",
        "        self.x = x\n",
        "        self.y = y[window_len-1:]\n",
        "        self.window_len = window_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x) - self.window_len + 1\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x_out = self.x[index: index+self.window_len]\n",
        "        y_out = self.y[index]\n",
        "        return x_out, y_out\n",
        "\n",
        "\n",
        "# Model Definition\n",
        "class GuitarAmpEmulator(nn.Module):\n",
        "    def __init__(self, conv1d_filters, conv1d_strides, hidden_units):\n",
        "        super(GuitarAmpEmulator, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(1, conv1d_filters, 12, stride=conv1d_strides, padding=6)\n",
        "        self.conv2 = nn.Conv1d(conv1d_filters, conv1d_filters, 12, stride=conv1d_strides, padding=6)\n",
        "        self.lstm = nn.LSTM(conv1d_filters, hidden_units, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_units, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x, _ = self.lstm(x)\n",
        "        x = self.fc(x[:, -1, :])\n",
        "        return x.squeeze(1)\n",
        "\n",
        "\n",
        "# Error to signal function\n",
        "def error_to_signal(y_true, y_pred):\n",
        "    y_true, y_pred = pre_emphasis_filter(y_true), pre_emphasis_filter(y_pred)\n",
        "    return torch.sum(torch.pow(y_true - y_pred, 2), dim=0) / (torch.sum(torch.pow(y_true, 2), dim=0) + 1e-10)\n",
        "\n",
        "# Pre-emphasis filter function\n",
        "def pre_emphasis_filter(x, coeff=0.95):\n",
        "    return torch.cat([x, x - coeff * x], 1)\n",
        "\n",
        "# Save .wav file function\n",
        "def save_wav(name, data):\n",
        "    wavfile.write(name, 44100, data.flatten().astype(np.float32))\n",
        "\n",
        "# Normalize function\n",
        "def normalize(data):\n",
        "    data_max = max(data)\n",
        "    data_min = min(data)\n",
        "    data_norm = max(data_max, abs(data_min))\n",
        "    return data / data_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set training_mode and hyperparameters\n",
        "train_mode = 0\n",
        "\n",
        "if train_mode == 0:         # Speed Training\n",
        "    learning_rate = 0.01 \n",
        "    conv1d_strides = 12    \n",
        "    conv1d_filters = 16\n",
        "    hidden_units = 36\n",
        "elif train_mode == 1:       # Accuracy Training (~10x longer than Speed Training)\n",
        "    learning_rate = 0.01 \n",
        "    conv1d_strides = 4\n",
        "    conv1d_filters = 36\n",
        "    hidden_units= 64\n",
        "else:                       # Extended Training (~60x longer than Accuracy Training)\n",
        "    learning_rate = 0.0005 \n",
        "    conv1d_strides = 3\n",
        "    conv1d_filters = 36\n",
        "    hidden_units= 96\n",
        "\n",
        "# Instantiate model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GuitarAmpEmulator(conv1d_filters, conv1d_strides, hidden_units).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Load and preprocess data\n",
        "in_rate, in_data = wavfile.read(in_file)\n",
        "out_rate, out_data = wavfile.read(out_file)\n",
        "\n",
        "X_all = in_data.astype(np.float32).flatten()\n",
        "X_all = normalize(X_all).reshape(len(X_all),1)\n",
        "y_all = out_data.astype(np.float32).flatten()\n",
        "y_all = normalize(y_all).reshape(len(y_all),1)\n",
        "\n",
        "dataset = WindowArrayDataset(X_all, y_all, input_size)\n",
        "train_examples = int(len(X_all) * 0.8)\n",
        "train_set, val_set = random_split(dataset, [train_examples, len(dataset) - train_examples])\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Train Model\n",
        "epochs = 50\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for x_batch, y_batch in train_loader:\n",
        "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(x_batch)\n",
        "        loss = criterion(y_pred, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item() * x_batch.size(0)\n",
        "\n",
        "    train_loss /= len(train_set)\n",
        "    print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss}')\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for x_batch, y_batch in val_loader:\n",
        "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "            y_pred = model(x_batch)\n",
        "            loss = criterion(y_pred, y_batch)\n",
        "            val_loss += loss.item() * x_batch.size(0)\n",
        "\n",
        "    val_loss /= len(val_set)\n",
        "    print(f'Epoch {epoch+1}/{epochs}, Validation Loss: {val_loss}')\n",
        "\n",
        "# Save Model\n",
        "torch.save(model.state_dict(), f'/content/models/{name}/{name}.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GuitarAmpEmulator(\n",
            "  (conv1): Conv1d(1, 16, kernel_size=(12,), stride=(12,), padding=(6,))\n",
            "  (conv2): Conv1d(16, 16, kernel_size=(12,), stride=(12,), padding=(6,))\n",
            "  (lstm): LSTM(16, 36, batch_first=True)\n",
            "  (fc): Linear(in_features=36, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# show model structure\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
